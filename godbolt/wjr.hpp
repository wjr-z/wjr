#ifndef WJR_MATH_BROADCAST_HPP__
#define WJR_MATH_BROADCAST_HPP__

#include <cstdint>

#ifndef WJR_PREPROCESSOR_HPP__
#define WJR_PREPROCESSOR_HPP__

#ifndef WJR_PREPROCESSOR_PREVIEW_HPP__
#define WJR_PREPROCESSOR_PREVIEW_HPP__

// testing ...

#ifndef WJR_PREPROCESSOR_ARITHMATIC_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_HPP__

#ifndef WJR_PREPROCESSOR_ARITHMATIC_CMP_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_CMP_HPP__

#ifndef WJR_PREPROCESSOR_ARITHMATIC_BASIC_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_BASIC_HPP__

#define WJR_PP_ARITHMATIC_FROM_NUMBER(x) WJR_PP_ARITHMATIC_FROM_NUMBER_I(x)
#define WJR_PP_ARITHMATIC_FROM_NUMBER_I(x) __wjr_pp_arithmatic_from_number_##x

#define WJR_PP_ARITHMATIC_TO_NUMBER(x) WJR_PP_ARITHMATIC_TO_NUMBER_I(x)
#define WJR_PP_ARITHMATIC_TO_NUMBER_I(x) __wjr_pp_arithmatic_to_number_##x

#define __wjr_pp_arithmatic_from_number_0
#define __wjr_pp_arithmatic_from_number_1 x
#define __wjr_pp_arithmatic_from_number_2 xx
#define __wjr_pp_arithmatic_from_number_3 xxx
#define __wjr_pp_arithmatic_from_number_4 xxxx
#define __wjr_pp_arithmatic_from_number_5 xxxxx
#define __wjr_pp_arithmatic_from_number_6 xxxxxx
#define __wjr_pp_arithmatic_from_number_7 xxxxxxx
#define __wjr_pp_arithmatic_from_number_8 xxxxxxxx
#define __wjr_pp_arithmatic_from_number_9 xxxxxxxxx
#define __wjr_pp_arithmatic_from_number_10 xxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_11 xxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_12 xxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_13 xxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_14 xxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_15 xxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_16 xxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_17 xxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_18 xxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_19 xxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_20 xxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_21 xxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_22 xxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_23 xxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_24 xxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_25 xxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_26 xxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_27 xxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_28 xxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_29 xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_30 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_31 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_32 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_33 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_34 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_35 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_36 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_37 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_38 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_39 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_40 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_41 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_42 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_43 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_44 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_45 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_46 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_47 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_48                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_49                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_50                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_51                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_52                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_53                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_54                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_55                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_56                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_57                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_58                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_59                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_60                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_61                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_62                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#define __wjr_pp_arithmatic_from_number_63                                               \
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

#define __wjr_pp_arithmatic_to_number_ 0
#define __wjr_pp_arithmatic_to_number_x 1
#define __wjr_pp_arithmatic_to_number_xx 2
#define __wjr_pp_arithmatic_to_number_xxx 3
#define __wjr_pp_arithmatic_to_number_xxxx 4
#define __wjr_pp_arithmatic_to_number_xxxxx 5
#define __wjr_pp_arithmatic_to_number_xxxxxx 6
#define __wjr_pp_arithmatic_to_number_xxxxxxx 7
#define __wjr_pp_arithmatic_to_number_xxxxxxxx 8
#define __wjr_pp_arithmatic_to_number_xxxxxxxxx 9
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxx 10
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxx 11
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxx 12
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxx 13
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxx 14
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxx 15
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxx 16
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxx 17
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxx 18
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxx 19
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxx 20
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxx 21
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxx 22
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxx 23
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxx 24
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxx 25
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxx 26
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxx 27
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxx 28
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx 29
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 30
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 31
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 32
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 33
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 34
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 35
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 36
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 37
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 38
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 39
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 40
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 41
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 42
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 43
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 44
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 45
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 46
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 47
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 48
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 49
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    50
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    51
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    52
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    53
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    54
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    55
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    56
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    57
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    58
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    59
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    60
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    61
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    62
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    63
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    2
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    3
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    4
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    5
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    6
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    7
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    8
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    9
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    10
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    11
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    12
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    13
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    14
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    15
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    16
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    17
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    18
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    19
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    20
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    21
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    22
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    23
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    24
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    25
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    26
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    27
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    28
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    29
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    30
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    31
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    32
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    33
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    34
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    35
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    36
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    37
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    38
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    39
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    40
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    41
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    42
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    43
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    44
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    45
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    46
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    47
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    48
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    49
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    50
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    51
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    52
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    53
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    54
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    55
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    56
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    57
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    58
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    59
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    60
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    61
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    62
#define __wjr_pp_arithmatic_to_number_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    63

#endif // ! WJR_PREPROCESSOR_ARITHMATIC_BASIC_HPP__
#ifndef WJR_PREPROCESSOR_ARITHMATIC_NEG_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_NEG_HPP__

#define WJR_PP_NEG(x) WJR_PP_NEG_I(x)
#define WJR_PP_NEG_I(x) WJR_PP_NEG_##x

#define WJR_PP_NEG_0 0
#define WJR_PP_NEG_1 63
#define WJR_PP_NEG_2 62
#define WJR_PP_NEG_3 61
#define WJR_PP_NEG_4 60
#define WJR_PP_NEG_5 59
#define WJR_PP_NEG_6 58
#define WJR_PP_NEG_7 57
#define WJR_PP_NEG_8 56
#define WJR_PP_NEG_9 55
#define WJR_PP_NEG_10 54
#define WJR_PP_NEG_11 53
#define WJR_PP_NEG_12 52
#define WJR_PP_NEG_13 51
#define WJR_PP_NEG_14 50
#define WJR_PP_NEG_15 49
#define WJR_PP_NEG_16 48
#define WJR_PP_NEG_17 47
#define WJR_PP_NEG_18 46
#define WJR_PP_NEG_19 45
#define WJR_PP_NEG_20 44
#define WJR_PP_NEG_21 43
#define WJR_PP_NEG_22 42
#define WJR_PP_NEG_23 41
#define WJR_PP_NEG_24 40
#define WJR_PP_NEG_25 39
#define WJR_PP_NEG_26 38
#define WJR_PP_NEG_27 37
#define WJR_PP_NEG_28 36
#define WJR_PP_NEG_29 35
#define WJR_PP_NEG_30 34
#define WJR_PP_NEG_31 33
#define WJR_PP_NEG_32 32
#define WJR_PP_NEG_33 31
#define WJR_PP_NEG_34 30
#define WJR_PP_NEG_35 29
#define WJR_PP_NEG_36 28
#define WJR_PP_NEG_37 27
#define WJR_PP_NEG_38 26
#define WJR_PP_NEG_39 25
#define WJR_PP_NEG_40 24
#define WJR_PP_NEG_41 23
#define WJR_PP_NEG_42 22
#define WJR_PP_NEG_43 21
#define WJR_PP_NEG_44 20
#define WJR_PP_NEG_45 19
#define WJR_PP_NEG_46 18
#define WJR_PP_NEG_47 17
#define WJR_PP_NEG_48 16
#define WJR_PP_NEG_49 15
#define WJR_PP_NEG_50 14
#define WJR_PP_NEG_51 13
#define WJR_PP_NEG_52 12
#define WJR_PP_NEG_53 11
#define WJR_PP_NEG_54 10
#define WJR_PP_NEG_55 9
#define WJR_PP_NEG_56 8
#define WJR_PP_NEG_57 7
#define WJR_PP_NEG_58 6
#define WJR_PP_NEG_59 5
#define WJR_PP_NEG_60 4
#define WJR_PP_NEG_61 3
#define WJR_PP_NEG_62 2
#define WJR_PP_NEG_63 1

#endif // ! WJR_PREPROCESSOR_ARITHMATIC_NEG_HPP__
#ifndef WJR_PREPROCESSOR_ARITHMATIC_SUB_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_SUB_HPP__

#ifndef WJR_PREPROCESSOR_ARITHMATIC_ADD_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_ADD_HPP__

// Already included
#ifndef WJR_PREPROCESSOR_DETAIL_BASIC_HPP__
#define WJR_PREPROCESSOR_DETAIL_BASIC_HPP__

#define WJR_PP_EMPTY(...)

#define WJR_PP_CONCAT(x, y) WJR_PP_CONCAT_I(x, y)
#define WJR_PP_CONCAT_I(x, y) x##y

#define WJR_PP_EXPAND(...) WJR_PP_EXPAND_I(__VA_ARGS__)
#define WJR_PP_EXPAND_I(...) __VA_ARGS__

#define WJR_PP_STR(x) WJR_PP_STR_I(x)
#define WJR_PP_STR_I(x) #x

#define WJR_PP_STRS(...) WJR_PP_STRS_I(__VA_ARGS__)
#define WJR_PP_STRS_I(...) #__VA_ARGS__

#define WJR_PP_ESC(x) WJR_PP_ESC_(WJR_PP_ESC_I, x)
#define WJR_PP_ESC_(M, x) M x
#define WJR_PP_ESC_I(...) __VA_ARGS__

// don't support 0 agument
#define WJR_PP_ARGS_LEN(...) WJR_PP_ARGS_LEN_I(__VA_ARGS__)

#define WJR_PP_ARGS_LEN_I(...)                                                           \
    WJR_PP_EXPAND(WJR_PP_ARGS_LEN_(0, ##__VA_ARGS__, WJR_PP_ARGS_LEN_RSEQ_N()))

#define WJR_PP_ARGS_LEN_RSEQ_N()                                                         \
    64, 63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44,  \
        43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24,  \
        23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2,  \
        1, 0
#define WJR_PP_ARGS_LEN_(...) WJR_PP_EXPAND(WJR_PP_ARGS_LEN_N(__VA_ARGS__))
#define WJR_PP_ARGS_LEN_N(                                                               \
    _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18,     \
    _19, _20, _21, _22, _23, _24, _25, _26, _27, _28, _29, _30, _31, _32, _33, _34, _35, \
    _36, _37, _38, _39, _40, _41, _42, _43, _44, _45, _46, _47, _48, _49, _50, _51, _52, \
    _53, _54, _55, _56, _57, _58, _59, _60, _61, _62, _63, _64, _65, N, ...)             \
    N

#define WJR_PP_IS_NULLPTR(VAL)                                                           \
    WJR_PP_IS_NULLPTR_I(WJR_PP_CONCAT(WJR_PP_IS_NULLPTR_, VAL), 0)
#define WJR_PP_IS_NULLPTR_I(...) WJR_PP_IS_NULLPTR_II(__VA_ARGS__)
#define WJR_PP_IS_NULLPTR_II(HOLDER, VAL, ...) VAL
#define WJR_PP_IS_NULLPTR_WJR_PP_NULLPTR _, 1

#define WJR_PP_MAP_DEF(VAL) _, VAL

// if MAP ## KEY is defined as WJR_PP_MAP_DEF, then return VAL
// else return WJR_PP_NULLPTR
#define WJR_PP_MAP_FIND(MAP, KEY) WJR_PP_MAP_FIND_I(MAP, KEY)
#define WJR_PP_MAP_FIND_I(MAP, KEY)                                                      \
    WJR_PP_MAP_FIND_II(WJR_PP_CONCAT(MAP, KEY), WJR_PP_NULLPTR)
#define WJR_PP_MAP_FIND_II(...) WJR_PP_MAP_FIND_III(__VA_ARGS__)
#define WJR_PP_MAP_FIND_III(HOLDER, VAL, ...) VAL

#endif // ! WJR_PREPROCESSOR_DETAIL_BASIC_HPP__

#define WJR_PP_ADD(x, y) WJR_PP_ADD_I(x, y)
#define WJR_PP_ADD_I(x, y)                                                               \
    WJR_PP_ARITHMATIC_TO_NUMBER(WJR_PP_CONCAT(WJR_PP_ARITHMATIC_FROM_NUMBER(x),          \
                                              WJR_PP_ARITHMATIC_FROM_NUMBER(y)))

#endif // ! WJR_PREPROCESSOR_ARITHMATIC_ADD_HPP__
#ifndef WJR_PREPROCESSOR_ARITHMATIC_INC_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_INC_HPP__

#define WJR_PP_INC(x) WJR_PP_INC_I(x)
#define WJR_PP_INC_I(x) WJR_PP_INC_##x

#define WJR_PP_INC_0 1
#define WJR_PP_INC_1 2
#define WJR_PP_INC_2 3
#define WJR_PP_INC_3 4
#define WJR_PP_INC_4 5
#define WJR_PP_INC_5 6
#define WJR_PP_INC_6 7
#define WJR_PP_INC_7 8
#define WJR_PP_INC_8 9
#define WJR_PP_INC_9 10
#define WJR_PP_INC_10 11
#define WJR_PP_INC_11 12
#define WJR_PP_INC_12 13
#define WJR_PP_INC_13 14
#define WJR_PP_INC_14 15
#define WJR_PP_INC_15 16
#define WJR_PP_INC_16 17
#define WJR_PP_INC_17 18
#define WJR_PP_INC_18 19
#define WJR_PP_INC_19 20
#define WJR_PP_INC_20 21
#define WJR_PP_INC_21 22
#define WJR_PP_INC_22 23
#define WJR_PP_INC_23 24
#define WJR_PP_INC_24 25
#define WJR_PP_INC_25 26
#define WJR_PP_INC_26 27
#define WJR_PP_INC_27 28
#define WJR_PP_INC_28 29
#define WJR_PP_INC_29 30
#define WJR_PP_INC_30 31
#define WJR_PP_INC_31 32
#define WJR_PP_INC_32 33
#define WJR_PP_INC_33 34
#define WJR_PP_INC_34 35
#define WJR_PP_INC_35 36
#define WJR_PP_INC_36 37
#define WJR_PP_INC_37 38
#define WJR_PP_INC_38 39
#define WJR_PP_INC_39 40
#define WJR_PP_INC_40 41
#define WJR_PP_INC_41 42
#define WJR_PP_INC_42 43
#define WJR_PP_INC_43 44
#define WJR_PP_INC_44 45
#define WJR_PP_INC_45 46
#define WJR_PP_INC_46 47
#define WJR_PP_INC_47 48
#define WJR_PP_INC_48 49
#define WJR_PP_INC_49 50
#define WJR_PP_INC_50 51
#define WJR_PP_INC_51 52
#define WJR_PP_INC_52 53
#define WJR_PP_INC_53 54
#define WJR_PP_INC_54 55
#define WJR_PP_INC_55 56
#define WJR_PP_INC_56 57
#define WJR_PP_INC_57 58
#define WJR_PP_INC_58 59
#define WJR_PP_INC_59 60
#define WJR_PP_INC_60 61
#define WJR_PP_INC_61 62
#define WJR_PP_INC_62 63
#define WJR_PP_INC_63 0

#endif // ! WJR_PREPROCESSOR_ARITHMATIC_INC_HPP__
// Already included

#define WJR_PP_SUB(x, y) WJR_PP_ADD(x, WJR_PP_NEG(y))

#endif // ! WJR_PREPROCESSOR_ARITHMATIC_SUB_HPP__
// Already included
#ifndef WJR_PREPROCESSOR_LOGICAL_BASIC_HPP__
#define WJR_PREPROCESSOR_LOGICAL_BASIC_HPP__

#define WJR_PP_BOOL_IF(cond, t, f) WJR_PP_BOOL_IF_I(cond, t, f)
#define WJR_PP_BOOL_IF_I(cond, t, f) WJR_PP_BOOL_IF_I##cond(t, f)
#define WJR_PP_BOOL_IF_I0(t, f) f
#define WJR_PP_BOOL_IF_I1(t, f) t

#define WJR_PP_BOOL_NOT(x) WJR_PP_BOOL_IF(x, 0, 1)

#define WJR_PP_BOOL_AND(x, y) WJR_PP_BOOL_IF(x, WJR_PP_BOOL_IF(y, 1, 0), 0)
#define WJR_PP_BOOL_OR(x, y) WJR_PP_BOOL_IF(x, 1, WJR_PP_BOOL_IF(y, 1, 0))
#define WJR_PP_BOOL_XOR(x, y) WJR_PP_BOOL_IF(x, WJR_PP_BOOL_NOT(y), y)

#endif // ! WJR_PREPROCESSOR_LOGICAL_BASIC_HPP__
#ifndef WJR_PREPROCESSOR_LOGICAL_BOOL_HPP__
#define WJR_PREPROCESSOR_LOGICAL_BOOL_HPP__

#define WJR_PP_BOOL(x) WJR_PP_BOOL_I(x)

#define WJR_PP_BOOL_I(x) WJR_PP_BOOL_##x

#define WJR_PP_BOOL_0 0
#define WJR_PP_BOOL_1 1
#define WJR_PP_BOOL_2 1
#define WJR_PP_BOOL_3 1
#define WJR_PP_BOOL_4 1
#define WJR_PP_BOOL_5 1
#define WJR_PP_BOOL_6 1
#define WJR_PP_BOOL_7 1
#define WJR_PP_BOOL_8 1
#define WJR_PP_BOOL_9 1
#define WJR_PP_BOOL_10 1
#define WJR_PP_BOOL_11 1
#define WJR_PP_BOOL_12 1
#define WJR_PP_BOOL_13 1
#define WJR_PP_BOOL_14 1
#define WJR_PP_BOOL_15 1
#define WJR_PP_BOOL_16 1
#define WJR_PP_BOOL_17 1
#define WJR_PP_BOOL_18 1
#define WJR_PP_BOOL_19 1
#define WJR_PP_BOOL_20 1
#define WJR_PP_BOOL_21 1
#define WJR_PP_BOOL_22 1
#define WJR_PP_BOOL_23 1
#define WJR_PP_BOOL_24 1
#define WJR_PP_BOOL_25 1
#define WJR_PP_BOOL_26 1
#define WJR_PP_BOOL_27 1
#define WJR_PP_BOOL_28 1
#define WJR_PP_BOOL_29 1
#define WJR_PP_BOOL_30 1
#define WJR_PP_BOOL_31 1
#define WJR_PP_BOOL_32 1
#define WJR_PP_BOOL_33 1
#define WJR_PP_BOOL_34 1
#define WJR_PP_BOOL_35 1
#define WJR_PP_BOOL_36 1
#define WJR_PP_BOOL_37 1
#define WJR_PP_BOOL_38 1
#define WJR_PP_BOOL_39 1
#define WJR_PP_BOOL_40 1
#define WJR_PP_BOOL_41 1
#define WJR_PP_BOOL_42 1
#define WJR_PP_BOOL_43 1
#define WJR_PP_BOOL_44 1
#define WJR_PP_BOOL_45 1
#define WJR_PP_BOOL_46 1
#define WJR_PP_BOOL_47 1
#define WJR_PP_BOOL_48 1
#define WJR_PP_BOOL_49 1
#define WJR_PP_BOOL_50 1
#define WJR_PP_BOOL_51 1
#define WJR_PP_BOOL_52 1
#define WJR_PP_BOOL_53 1
#define WJR_PP_BOOL_54 1
#define WJR_PP_BOOL_55 1
#define WJR_PP_BOOL_56 1
#define WJR_PP_BOOL_57 1
#define WJR_PP_BOOL_58 1
#define WJR_PP_BOOL_59 1
#define WJR_PP_BOOL_60 1
#define WJR_PP_BOOL_61 1
#define WJR_PP_BOOL_62 1
#define WJR_PP_BOOL_63 1

#endif // WJR_PREPROCESSOR_LOGICAL_BOOL_HPP__

#define WJR_PP_GE(x, y) WJR_PP_BOOL_IF(WJR_PP_BOOL(y), WJR_PP_SUB_OVERFLOW(x, y), 1)
#define WJR_PP_LE(x, y) WJR_PP_GE(y, x)
#define WJR_PP_LT(x, y) WJR_PP_BOOL_NOT(WJR_PP_GE(x, y))
#define WJR_PP_GT(x, y) WJR_PP_LT(y, x)
#define WJR_PP_NE(x, y) WJR_PP_BOOL(WJR_PP_SUB(x, y))
#define WJR_PP_EQ(x, y) WJR_PP_BOOL_NOT(WJR_PP_NE(x, y))

#define WJR_PP_ADD_OVERFLOW(x, y)                                                        \
    WJR_PP_ADD_OVERFLOW_I(WJR_PP_CONCAT(WJR_PP_ARITHMATIC_FROM_NUMBER(x),                \
                                        WJR_PP_ARITHMATIC_FROM_NUMBER(y)))
#define WJR_PP_ADD_OVERFLOW_I(x) WJR_PP_ADD_OVERFLOW_II(x)
#define WJR_PP_ADD_OVERFLOW_II(x) __wjr_arithmatic_overflow_##x

#define WJR_PP_SUB_OVERFLOW(x, y)                                                        \
    WJR_PP_SUB_OVERFLOW_I(WJR_PP_CONCAT(WJR_PP_ARITHMATIC_FROM_NUMBER(x),                \
                                        WJR_PP_ARITHMATIC_FROM_NUMBER(WJR_PP_NEG(y))))
#define WJR_PP_SUB_OVERFLOW_I(x) WJR_PP_SUB_OVERFLOW_II(x)
#define WJR_PP_SUB_OVERFLOW_II(x) __wjr_arithmatic_overflow_##x

#define __wjr_arithmatic_overflow_ 0
#define __wjr_arithmatic_overflow_x 0
#define __wjr_arithmatic_overflow_xx 0
#define __wjr_arithmatic_overflow_xxx 0
#define __wjr_arithmatic_overflow_xxxx 0
#define __wjr_arithmatic_overflow_xxxxx 0
#define __wjr_arithmatic_overflow_xxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    0
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1
#define __wjr_arithmatic_overflow_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \
    1

#endif // ! WJR_PREPROCESSOR_ARITHMATIC_CMP_HPP__
#ifndef WJR_PREPROCESSOR_ARITHMATIC_DEC_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_DEC_HPP__

#define WJR_PP_DEC(x) WJR_PP_DEC_I(x)

#define WJR_PP_DEC_I(x) WJR_PP_DEC_##x

#define WJR_PP_DEC_0 63
#define WJR_PP_DEC_1 0
#define WJR_PP_DEC_2 1
#define WJR_PP_DEC_3 2
#define WJR_PP_DEC_4 3
#define WJR_PP_DEC_5 4
#define WJR_PP_DEC_6 5
#define WJR_PP_DEC_7 6
#define WJR_PP_DEC_8 7
#define WJR_PP_DEC_9 8
#define WJR_PP_DEC_10 9
#define WJR_PP_DEC_11 10
#define WJR_PP_DEC_12 11
#define WJR_PP_DEC_13 12
#define WJR_PP_DEC_14 13
#define WJR_PP_DEC_15 14
#define WJR_PP_DEC_16 15
#define WJR_PP_DEC_17 16
#define WJR_PP_DEC_18 17
#define WJR_PP_DEC_19 18
#define WJR_PP_DEC_20 19
#define WJR_PP_DEC_21 20
#define WJR_PP_DEC_22 21
#define WJR_PP_DEC_23 22
#define WJR_PP_DEC_24 23
#define WJR_PP_DEC_25 24
#define WJR_PP_DEC_26 25
#define WJR_PP_DEC_27 26
#define WJR_PP_DEC_28 27
#define WJR_PP_DEC_29 28
#define WJR_PP_DEC_30 29
#define WJR_PP_DEC_31 30
#define WJR_PP_DEC_32 31
#define WJR_PP_DEC_33 32
#define WJR_PP_DEC_34 33
#define WJR_PP_DEC_35 34
#define WJR_PP_DEC_36 35
#define WJR_PP_DEC_37 36
#define WJR_PP_DEC_38 37
#define WJR_PP_DEC_39 38
#define WJR_PP_DEC_40 39
#define WJR_PP_DEC_41 40
#define WJR_PP_DEC_42 41
#define WJR_PP_DEC_43 42
#define WJR_PP_DEC_44 43
#define WJR_PP_DEC_45 44
#define WJR_PP_DEC_46 45
#define WJR_PP_DEC_47 46
#define WJR_PP_DEC_48 47
#define WJR_PP_DEC_49 48
#define WJR_PP_DEC_50 49
#define WJR_PP_DEC_51 50
#define WJR_PP_DEC_52 51
#define WJR_PP_DEC_53 52
#define WJR_PP_DEC_54 53
#define WJR_PP_DEC_55 54
#define WJR_PP_DEC_56 55
#define WJR_PP_DEC_57 56
#define WJR_PP_DEC_58 57
#define WJR_PP_DEC_59 58
#define WJR_PP_DEC_60 59
#define WJR_PP_DEC_61 60
#define WJR_PP_DEC_62 61
#define WJR_PP_DEC_63 62

#endif // WJR_PREPROCESSOR_ARITHMATIC_DEC_HPP__
// Already included
#ifndef WJR_PREPROCESSOR_ARITHMATIC_NOT_HPP__
#define WJR_PREPROCESSOR_ARITHMATIC_NOT_HPP__

#define WJR_PP_NOT(x) WJR_PP_NOT_I(x)
#define WJR_PP_NOT_I(x) WJR_PP_NOT_##x

#define WJR_PP_NOT_0 63
#define WJR_PP_NOT_1 62
#define WJR_PP_NOT_2 61
#define WJR_PP_NOT_3 60
#define WJR_PP_NOT_4 59
#define WJR_PP_NOT_5 58
#define WJR_PP_NOT_6 57
#define WJR_PP_NOT_7 56
#define WJR_PP_NOT_8 55
#define WJR_PP_NOT_9 54
#define WJR_PP_NOT_10 53
#define WJR_PP_NOT_11 52
#define WJR_PP_NOT_12 51
#define WJR_PP_NOT_13 50
#define WJR_PP_NOT_14 49
#define WJR_PP_NOT_15 48
#define WJR_PP_NOT_16 47
#define WJR_PP_NOT_17 46
#define WJR_PP_NOT_18 45
#define WJR_PP_NOT_19 44
#define WJR_PP_NOT_20 43
#define WJR_PP_NOT_21 42
#define WJR_PP_NOT_22 41
#define WJR_PP_NOT_23 40
#define WJR_PP_NOT_24 39
#define WJR_PP_NOT_25 38
#define WJR_PP_NOT_26 37
#define WJR_PP_NOT_27 36
#define WJR_PP_NOT_28 35
#define WJR_PP_NOT_29 34
#define WJR_PP_NOT_30 33
#define WJR_PP_NOT_31 32
#define WJR_PP_NOT_32 31
#define WJR_PP_NOT_33 30
#define WJR_PP_NOT_34 29
#define WJR_PP_NOT_35 28
#define WJR_PP_NOT_36 27
#define WJR_PP_NOT_37 26
#define WJR_PP_NOT_38 25
#define WJR_PP_NOT_39 24
#define WJR_PP_NOT_40 23
#define WJR_PP_NOT_41 22
#define WJR_PP_NOT_42 21
#define WJR_PP_NOT_43 20
#define WJR_PP_NOT_44 19
#define WJR_PP_NOT_45 18
#define WJR_PP_NOT_46 17
#define WJR_PP_NOT_47 16
#define WJR_PP_NOT_48 15
#define WJR_PP_NOT_49 14
#define WJR_PP_NOT_50 13
#define WJR_PP_NOT_51 12
#define WJR_PP_NOT_52 11
#define WJR_PP_NOT_53 10
#define WJR_PP_NOT_54 9
#define WJR_PP_NOT_55 8
#define WJR_PP_NOT_56 7
#define WJR_PP_NOT_57 6
#define WJR_PP_NOT_58 5
#define WJR_PP_NOT_59 4
#define WJR_PP_NOT_60 3
#define WJR_PP_NOT_61 2
#define WJR_PP_NOT_62 1
#define WJR_PP_NOT_63 0

#endif // ! WJR_PREPROCESSOR_ARITHMATIC_NOT_HPP__
// Already included

#endif // ! WJR_PREPROCESSOR_ARITHMATIC_HPP__
#ifndef WJR_PREPROCESSOR_COMPILER_HPP__
#define WJR_PREPROCESSOR_COMPILER_HPP__

#ifndef WJR_PREPROCESSOR_COMPILER_ATTRIBUTE_HPP__
#define WJR_PREPROCESSOR_COMPILER_ATTRIBUTE_HPP__

#ifndef WJR_PREPROCESSOR_COMPILER_HAS_HPP__
#define WJR_PREPROCESSOR_COMPILER_HAS_HPP__

#ifndef WJR_PREPROCESSOR_COMPILER_ARCH_HPP__
#define WJR_PREPROCESSOR_COMPILER_ARCH_HPP__

#if defined(__pnacl__) || defined(__CLR_VER)
#define WJR_VM
#endif

#if (defined(_M_IX86) || defined(__i386__)) && !defined(WJR_VM)
#define WJR_X86_32
#endif

#if (defined(_M_X64) || defined(__x86_64__)) && !defined(WJR_VM)
#define WJR_X86_64
#endif

#if defined(WJR_X86_32) || defined(WJR_X86_64)
#define WJR_X86
#endif

#if (defined(__arm__) || defined(_M_ARM))
#define WJR_ARM
#endif

#if defined(__aarch64__)
#define WJR_AARCH64
#endif

#if defined(__powerpc64__)
#define WJR_PPC64
#endif

#if defined(WJR_X86_64)
#if defined(__i386__) || defined(_M_IX86) || defined(_X86_)
#define CPU_INTEL
#elif defined(_M_AMD64)
#define CPU_AMD
#endif
#else
#define CPU_UNKNOWN
#endif

#endif // !WJR_PREPROCESSOR_COMPILER_ARCH_HPP__
#ifndef WJR_PREPROCESSOR_COMPILER_COMPILER_HPP__
#define WJR_PREPROCESSOR_COMPILER_COMPILER_HPP__

#if defined(__clang__)
#define WJR_COMPILER_CLANG
#elif defined(__GNUC__)
#define WJR_COMPILER_GCC
#elif defined(_MSC_VER)
#define WJR_COMPILER_MSVC
#endif

#if defined(_MSC_VER)
#define WJR_MSVC
#endif // _MSC_VER

#if defined(__GNUC__)
#define WJR_HAS_GCC(major, minor, patchlevel)                                            \
    ((__GNUC__ > (major)) || (__GNUC__ == (major) && __GNUC_MINOR__ > (minor)) ||        \
     (__GNUC__ == (major) && __GNUC_MINOR__ == (minor) &&                                \
      __GNUC_PATCHLEVEL__ >= (patchlevel)))
#else
#define WJR_HAS_GCC(major, minor, patchlevel) 0
#endif // __GNUC__

#if defined(__clang__)
#define WJR_HAS_CLANG(major, minor, patchlevel)                                          \
    ((__clang_major__ > (major)) ||                                                      \
     (__clang_major__ == (major) && __clang_minor__ > (minor)) ||                        \
     (__clang_major__ == (major) && __clang_minor__ == (minor) &&                        \
      __clang_patchlevel__ >= (patchlevel)))
#else
#define WJR_HAS_CLANG(major, minor, patchlevel) 0
#endif

#if defined(_MSC_VER)
#define WJR_HAS_MSVC(minor, level) (_MSC_VER >= (minor)*100 + (level))
#else
#define WJR_HAS_MSVC(minor, level) 0
#endif

#if (defined(WJR_COMPILER_GCC) && !WJR_HAS_GCC(7, 1, 0)) ||                              \
    (defined(WJR_COMPILER_CLANG) && !WJR_HAS_CLANG(5, 0, 0))
#error "GCC 7.1.0 or Clang 5.0.0 or later is required"
#endif

#if defined(WJR_COMPILER_CLANG) || defined(WJR_COMPILER_GCC)
#define WJR_CXX_STANDARD __cplusplus
#elif defined(WJR_COMPILER_MSVC)
#define WJR_CXX_STANDARD _MSVC_LANG
#endif

#if WJR_CXX_STANDARD >= 199711L
#define WJR_CXX_03
#endif
#if WJR_CXX_STANDARD >= 201103L
#define WJR_CXX_11
#endif
#if WJR_CXX_STANDARD >= 201402L
#define WJR_CXX_14
#endif
#if WJR_CXX_STANDARD >= 201703L
#define WJR_CXX_17
#endif
#if WJR_CXX_STANDARD >= 202002L
#define WJR_CXX_20
#endif

#ifndef WJR_CXX_17
#error "required C++17 or later"
#endif // c++17

#if defined(__cpp_char8_t)
#define WJR_CHAR8_T
#endif // __cpp_char8_t

#if defined(__LINE__)
#define WJR_LINE __LINE__
#elif defined(__COUNTER__)
#define WJR_LINE __COUNTER__
#else
#define WJR_LINE -1
#endif

#ifdef __FILE__
#define WJR_FILE __FILE__
#else
#define WJR_FILE ""
#endif

// reference: boost BOOST_CURRENT_FUNCTION
#if defined(WJR_DISABLE_CURRENT_FUNCTION)
#define WJR_CURRENT_FUNCTION "(unknown)"
#elif defined(__GNUC__) || (defined(__MWERKS__) && (__MWERKS__ >= 0x3000)) ||            \
    (defined(__ICC) && (__ICC >= 600)) || defined(__ghs__)
#define WJR_CURRENT_FUNCTION __PRETTY_FUNCTION__
#elif defined(__DMC__) && (__DMC__ >= 0x810)
#define WJR_CURRENT_FUNCTION __PRETTY_FUNCTION__
#elif defined(__FUNCSIG__)
#define WJR_CURRENT_FUNCTION __FUNCSIG__
#elif (defined(__INTEL_COMPILER) && (__INTEL_COMPILER >= 600)) ||                        \
    (defined(__IBMCPP__) && (__IBMCPP__ >= 500))
#define WJR_CURRENT_FUNCTION __FUNCTION__
#elif defined(__BORLANDC__) && (__BORLANDC__ >= 0x550)
#define WJR_CURRENT_FUNCTION __FUNC__
#elif defined(__STDC_VERSION__) && (__STDC_VERSION__ >= 199901)
#define WJR_CURRENT_FUNCTION __func__
#elif defined(__cplusplus) && (__cplusplus >= 201103)
#define WJR_CURRENT_FUNCTION __func__
#else
#define WJR_CURRENT_FUNCTION "(unknown)"
#endif

#endif // !WJR_PREPROCESSOR_COMPILER_COMPILER_HPP__
// Already included
// Already included

/**
 * @details
 * 0 : non-defined  \n
 * 1 : builtin  \n
 * 2 : intrinsic    \n
 * 3 : assembly \n
 * 4~15 : reserved  \n
 * 16~63 : user-defined
 *
 */
#define WJR_HAS_DEF_VAR(var) WJR_PP_MAP_DEF(var)
#define WJR_HAS_DEF WJR_HAS_DEF_VAR(1)

#define WJR_HAS_FIND(MAP, KEY)                                                           \
    WJR_HAS_FIND_I(WJR_PP_MAP_FIND(MAP, WJR_PP_CONCAT(NO_, KEY)),                        \
                   WJR_PP_MAP_FIND(MAP, KEY))
#define WJR_HAS_FIND_I(NO_VAL, VAL)                                                      \
    WJR_PP_BOOL_IF(WJR_PP_IS_NULLPTR(NO_VAL), WJR_HAS_FIND_II(VAL), 0)
#define WJR_HAS_FIND_II(VAL) WJR_PP_BOOL_IF(WJR_PP_IS_NULLPTR(VAL), 0, VAL)

// Currently only has_builtin, has_attribute, has_feature are supported.
#define WJR_HAS_BUILTIN_FIND(KEY) WJR_HAS_FIND(WJR_HAS_BUILTIN_, KEY)
#define WJR_HAS_ATTRIBUTE_FIND(KEY) WJR_HAS_FIND(WJR_HAS_ATTRIBUTE_, KEY)
#define WJR_HAS_FEATURE_FIND(KEY) WJR_HAS_FIND(WJR_HAS_FEATURE_, KEY)
#define WJR_HAS_SIMD_FIND(KEY) WJR_HAS_FIND(WJR_HAS_SIMD_, KEY)
#define WJR_HAS_DEBUG_FIND(KEY) WJR_HAS_FIND(WJR_HAS_DEBUG_, KEY)

#if (defined(WJR_COMPILER_GCC) && WJR_HAS_GCC(10, 1, 0)) ||                              \
    (defined(WJR_COMPILER_CLANG) && WJR_HAS_CLANG(10, 0, 0)) ||                          \
    (!defined(WJR_COMPILER_GCC) && !defined(WJR_COMPILER_CLANG) &&                       \
     defined(__has_builtin))
#define WJR_HAS_BUILTIN(x) WJR_HAS_BUILTIN_I(x, WJR_HAS_BUILTIN_FIND(x))
#define WJR_HAS_BUILTIN_I(x, VAR) WJR_PP_BOOL_IF(WJR_PP_BOOL(VAR), VAR, __has_builtin(x))
#else
#define WJR_HAS_BUILTIN(x) WJR_HAS_BUILTIN_FIND(x)
#endif

#if defined(__has_include)
#define WJR_HAS_INCLUDE(x) __has_include(x)
#else
#define WJR_HAS_INCLUDE(x) 0
#endif // __has_include

#if defined(__has_attribute)
#define WJR_HAS_ATTRIBUTE(x) WJR_HAS_ATTRIBUTE_I(x, WJR_HAS_ATTRIBUTE_FIND(x))
#define WJR_HAS_ATTRIBUTE_I(x, VAR)                                                      \
    WJR_PP_BOOL_IF(WJR_PP_BOOL(VAR), VAR, __has_attribute(x))
#else
#define WJR_HAS_ATTRIBUTE(x) WJR_HAS_ATTRIBUTE_FIND(x)
#endif

#if defined(__has_cpp_attribute)
#define WJR_HAS_CPP_ATTRIBUTE(x) __has_cpp_attribute(x)
#else
#define WJR_HAS_CPP_ATTRIBUTE(x) 0
#endif

#define WJR_HAS_FEATURE(x) WJR_HAS_FEATURE_FIND(x)
#define WJR_HAS_SIMD(x) WJR_HAS_SIMD_FIND(x)
#define WJR_HAS_DEBUG(x) WJR_HAS_DEBUG_FIND(x)

// WJR_HAS_BUILTIN

#if WJR_HAS_GCC(7, 1, 0) || WJR_HAS_CLANG(5, 0, 0)
#define WJR_HAS_BUILTIN___builtin_unreachable WJR_HAS_DEF
#define WJR_HAS_BUILTIN___builtin_expect WJR_HAS_DEF
#define WJR_HAS_BUILTIN___builtin_constant_p WJR_HAS_DEF
#define WJR_HAS_BUILTIN___builtin_clz WJR_HAS_DEF
#define WJR_HAS_BUILTIN___builtin_ctz WJR_HAS_DEF
#define WJR_HAS_BUILTIN___builtin_popcount WJR_HAS_DEF
#endif

#if WJR_HAS_GCC(9, 1, 0) || WJR_HAS_CLANG(9, 0, 0)
#define WJR_HAS_BUILTIN___builtin_is_constant_evaluated WJR_HAS_DEF
#endif

#if WJR_HAS_CLANG(5, 0, 0)
#define WJR_HAS_BUILTIN___builtin_addc WJR_HAS_DEF
#define WJR_HAS_BUILTIN___builtin_subc WJR_HAS_DEF
#endif

#if WJR_HAS_GCC(9, 1, 0) || WJR_HAS_CLANG(11, 0, 0)
#define WJR_HAS_BUILTIN___builtin_expect_with_probability WJR_HAS_DEF
#endif

// WJR_HAS_FEATURE

#if WJR_HAS_GCC(7, 1, 0) || WJR_HAS_CLANG(5, 0, 0)
#define WJR_HAS_FEATURE_PRAGMA_UNROLL WJR_HAS_DEF
#endif

#if defined(WJR_COMPILER_GCC) || defined(WJR_COMPILER_CLANG) || defined(WJR_COMPILER_MSVC)
#define WJR_HAS_FEATURE_INLINE_ASM WJR_HAS_DEF
#ifndef WJR_COMPILER_MSVC
#define WJR_HAS_FEATURE_GCC_STYLE_INLINE_ASM WJR_HAS_DEF
#endif
#endif

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)

#if WJR_HAS_GCC(7, 1, 0) || WJR_HAS_CLANG(9, 0, 0)
#define WJR_HAS_FEATURE_INLINE_ASM_GOTO WJR_HAS_DEF
#endif

#if WJR_HAS_GCC(11, 1, 0) || WJR_HAS_CLANG(11, 0, 0)
#define WJR_HAS_FEATURE_INLINE_ASM_GOTO_OUTPUT WJR_HAS_DEF
#endif

#if defined(WJR_COMPILER_GCC) || WJR_HAS_CLANG(9, 0, 0)
#define WJR_HAS_FEATURE_INLINE_ASM_CCCOND WJR_HAS_DEF
#endif

#endif

#if defined(__SIZEOF_INT128__)
#define WJR_HAS_FEATURE_INT128 WJR_HAS_DEF
#if !(defined(__clang__) && defined(LIBDIVIDE_VC))
#define WJR_HAS_FEATURE_INT128_DIV WJR_HAS_DEF
#endif
#endif

// There are some issues with the optimization of int128 in both lower and higher versions
// (13.1/13.2) of GCC.
#if WJR_HAS_FEATURE(INT128) &&                                                           \
    (defined(WJR_COMPILER_CLANG) ||                                                      \
     (defined(WJR_COMPILER_GCC) && WJR_HAS_GCC(8, 1, 0) && !WJR_HAS_GCC(13, 1, 0)))
#define WJR_HAS_FEATURE_FAST_INT128_COMPARE WJR_HAS_DEF
#endif

// performance bug
#if WJR_HAS_FEATURE(INT128) && defined(WJR_COMPILER_CLANG)
// #define WJR_HAS_FEATURE_FAST_INT128_ADDSUB WJR_HAS_DEF
#endif

#if WJR_HAS_GCC(11, 1, 0) || WJR_HAS_CLANG(5, 0, 0)
#define WJR_HAS_FEATURE_FORCEINLINE_LAMBDA WJR_HAS_DEF
#endif

#if WJR_HAS_GCC(8, 1, 0) || WJR_HAS_CLANG(7, 0, 0)
#define WJR_HAS_FEATURE_GOTO_POINTER WJR_HAS_DEF
#endif

#if defined(__AVX512VL__)
#define WJR_HAS_SIMD_AVX512VL WJR_HAS_DEF
#endif

#if defined(__AVX512BW__)
#define WJR_HAS_SIMD_AVX512BW WJR_HAS_DEF
#endif

#if defined(__AVX512DQ__)
#define WJR_HAS_SIMD_AVX512DQ WJR_HAS_DEF
#endif

#if defined(__AVX512F__) ||                                                              \
    (WJR_HAS_SIMD(AVX512VL) && WJR_HAS_SIMD(AVX512BW) && WJR_HAS_SIMD(AVX512DQ))
#define WJR_HAS_SIMD_AVX512F WJR_HAS_DEF
#endif

#if defined(__AVX512__) ||                                                               \
    (WJR_HAS_SIMD(AVX512F) && WJR_HAS_SIMD(AVX512BW) && WJR_HAS_SIMD(AVX512DQ))
#define WJR_HAS_SIMD_AVX512 WJR_HAS_DEF
#endif

#if defined(__AVX2__) || (WJR_HAS_SIMD(AVX512) || WJR_HAS_SIMD(AVX512F))
#define WJR_HAS_SIMD_AVX2 WJR_HAS_DEF
#endif

#if defined(__AVX__) || WJR_HAS_SIMD(AVX2)
#define WJR_HAS_SIMD_AVX WJR_HAS_DEF
#endif

#if defined(__SSE4_2__) || WJR_HAS_SIMD(AVX)
#define WJR_HAS_SIMD_SSE4_2 WJR_HAS_DEF
#endif

#if defined(__SSE4_1__) || WJR_HAS_SIMD(SSE4_2)
#define WJR_HAS_SIMD_SSE4_1 WJR_HAS_DEF
#endif

#if defined(__SSSE3__) || WJR_HAS_SIMD(SSE4_1)
#define WJR_HAS_SIMD_SSSE3 WJR_HAS_DEF
#endif

#if defined(__SSE3__) || WJR_HAS_SIMD(SSSE3)
#define WJR_HAS_SIMD_SSE3 WJR_HAS_DEF
#endif

#if defined(__SSE2__) || WJR_HAS_SIMD(SSE3) || _M_IX86_FP >= 2 ||                        \
    (defined(_MSC_VER) && (defined(_M_AMD64) || defined(_M_X64)))
#define WJR_HAS_SIMD_SSE2 WJR_HAS_DEF
#endif

#if defined(__SSE__) || WJR_HAS_SIMD(SSE2) || _M_IX86_FP >= 1
#define WJR_HAS_SIMD_SSE WJR_HAS_DEF
#endif

#if defined(__MMX__) || WJR_HAS_SIMD(SSE)
#define WJR_HAS_SIMD_MMX WJR_HAS_DEF
#endif

#if defined(__XOP__)
#define WJR_HAS_SIMD_XOP WJR_HAS_DEF
#endif

#if defined(__POPCNT__)
#define WJR_HAS_SIMD_POPCNT WJR_HAS_DEF
#endif

#if defined(__PCLMUL__)
#define WJR_HAS_SIMD_PCLMUL WJR_HAS_DEF
#endif

#endif // WJR_PREPROCESSOR_COMPILER_HAS_HPP__

#if defined(WJR_CXX_20)
#include <version>
#endif

#if WJR_HAS_CPP_ATTRIBUTE(fallthrough)
#define WJR_FALLTHROUGH [[fallthrough]]
#elif WJR_HAS_ATTRIBUTE(fallthrough)
#define WJR_FALLTHROUGH __attribute__((fallthrough))
#elif defined(_MSC_VER) && defined(__fallthrough)
#define WJR_FALLTHROUGH __fallthrough
#else
#define WJR_FALLTHROUGH
#endif

#if WJR_HAS_CPP_ATTRIBUTE(noreturn)
#define WJR_NORETURN [[noreturn]]
#elif WJR_HAS_ATTRIBUTE(noreturn)
#define WJR_NORETURN __attribute__((noreturn))
#elif defined(_MSC_VER)
#define WJR_NORETURN __declspec(noreturn)
#else
#define WJR_NORETURN
#endif

#if WJR_HAS_CPP_ATTRIBUTE(nodiscard)
#define WJR_NODISCARD [[nodiscard]]
#elif WJR_HAS_ATTRIBUTE(nodiscard)
#define WJR_NODISCARD __attribute__((nodiscard))
#elif defined(_MSC_VER)
#define WJR_NODISCARD _Check_return_
#else
#define WJR_NODISCARD
#endif

#if WJR_HAS_CPP_ATTRIBUTE(deprecated)
#define WJR_DEPRECATED [[deprecated]]
#elif WJR_HAS_ATTRIBUTE(deprecated)
#define WJR_DEPRECATED __attribute__((deprecated))
#elif defined(_MSC_VER)
#define WJR_DEPRECATED __declspec(deprecated)
#else
#define WJR_DEPRECATED
#endif

#if WJR_HAS_CPP_ATTRIBUTE(maybe_unused)
#define WJR_MAYBE_UNUSED [[maybe_unused]]
#elif WJR_HAS_ATTRIBUTE(maybe_unused)
#define WJR_MAYBE_UNUSED __attribute__((maybe_unused))
#elif defined(_MSC_VER)
#define WJR_MAYBE_UNUSED
#else
#define WJR_MAYBE_UNUSED
#endif

#if WJR_HAS_ATTRIBUTE(always_inline)
#define WJR_FORCEINLINE __attribute__((always_inline))
#elif defined(_MSC_VER)
#define WJR_FORCEINLINE __forceinline
#else
#define WJR_FORCEINLINE
#endif

#if WJR_HAS_FEATURE(FORCEINLINE_LAMBDA)
#define WJR_FORCEINLINE_LAMBDA WJR_FORCEINLINE
#else
#define WJR_FORCEINLINE_LAMBDA
#endif

// NOINLINE for MSVC/GCC/CLANG ...
#if WJR_HAS_ATTRIBUTE(noinline)
#define WJR_NOINLINE __attribute__((noinline))
#elif defined(_MSC_VER)
#define WJR_NOINLINE __declspec(noinline)
#else
#define WJR_NOINLINE
#endif

#if WJR_HAS_ATTRIBUTE(hot)
#define WJR_HOT __attribute__((hot))
#elif defined(_MSC_VER)
#define WJR_HOT
#else
#define WJR_HOT
#endif

#if WJR_HAS_ATTRIBUTE(cold)
#define WJR_COLD __attribute__((cold))
#elif defined(_MSC_VER)
#define WJR_COLD
#else
#define WJR_COLD
#endif

#if WJR_HAS_ATTRIBUTE(aligned)
#define WJR_ALIGNED(size) __attribute__((aligned(size)))
#elif defined(_MSC_VER)
#define WJR_ALIGNED(size)
#else
#define WJR_ALIGNED(size)
#endif

#if defined(__cpp_lib_unreachable)
#define WJR_UNREACHABLE() std::unreachable()
#elif WJR_HAS_BUILTIN(__builtin_unreachable)
#define WJR_UNREACHABLE() __builtin_unreachable()
#elif defined(WJR_COMPILER_MSVC)
#define WJR_UNREACHABLE() __assume(0)
#else
#define WJR_UNREACHABLE()
#endif

#if defined(WJR_COMPILER_CLANG) || defined(WJR_COMPILER_GCC)
#define WJR_RESTRICT __restrict
#else
#define WJR_RESTRICT
#endif

#if defined(WJR_COMPILER_MSVC)
#define WJR_MS_ABI
#define WJR_HAS_FEATURE_MS_ABI WJR_HAS_DEF
#elif WJR_HAS_ATTRIBUTE(__ms_abi__)
#define WJR_MS_ABI __attribute__((__ms_abi__))
#define WJR_HAS_FEATURE_MS_ABI WJR_HAS_DEF
#elif defined(WJR_ENABLE_ASSEMBLY)
#undef WJR_ENABLE_ASSEMBLY
#endif

#define WJR_ASSUME_MAY_NOT_PURE(expr)                                                    \
    do {                                                                                 \
        if (!(expr)) {                                                                   \
            WJR_UNREACHABLE();                                                           \
        }                                                                                \
    } while (0)

#if WJR_HAS_BUILTIN(__builtin_assume)
#define WJR_ASSUME(expr) __builtin_assume(expr)
#elif defined(WJR_COMPILER_MSVC)
#define WJR_ASSUME(expr) __assume(expr)
#elif WJR_HAS_CPP_ATTRIBUTE(assume)
#define WJR_ASSUME(expr) [[assume(expr)]]
#else
#define WJR_ASSUME(expr) WJR_ASSUME_MAY_NOT_PURE(expr)
#endif

#define WJR_BOOL_EXPR(expr) (!!(expr))

#if WJR_HAS_BUILTIN(__builtin_expect)
#define WJR_EXPECT(expr, expect) __builtin_expect((expr), (expect))
#else
#define WJR_EXPECT(expr, expect) (expr)
#endif

#define WJR_LIKELY(expr) WJR_EXPECT(WJR_BOOL_EXPR(expr), true)
#define WJR_UNLIKELY(expr) WJR_EXPECT(WJR_BOOL_EXPR(expr), false)

#define WJR_HAS_FEATURE_IS_CONSTANT_EVALUATED WJR_HAS_DEF

#if WJR_HAS_BUILTIN(__builtin_expect_with_probability)
#define WJR_EXPECT_WITH_PROBABILITY(exp, c, probability)                                 \
    __builtin_expect_with_probability(exp, c, probability)
#else
#define WJR_EXPECT_WITH_PROBABILITY(exp, c, probability) (expr)
#endif

#if WJR_HAS_BUILTIN(__builtin_expect_with_probability)
#define WJR_VERY_LIKELY(exp, probability)                                                \
    WJR_EXPECT_WITH_PROBABILITY(exp, true, probability)
#define WJR_VERY_UNLIKELY(exp, probability)                                              \
    WJR_EXPECT_WITH_PROBABILITY(exp, false, probability)
#else
#define WJR_VERY_LIKELY(exp, probability) WJR_LIKELY((exp))
#define WJR_VERY_UNLIKELY(exp, probability) WJR_UNLIKELY((exp))
#endif

#if defined(__cpp_lib_is_constant_evaluated)
#define WJR_IS_CONSTANT_EVALUATED() std::is_constant_evaluated()
#elif WJR_HAS_BUILTIN(__builtin_is_constant_evaluated)
#define WJR_IS_CONSTANT_EVALUATED() __builtin_is_constant_evaluated()
#else
#define WJR_IS_CONSTANT_EVALUATED() false
#undef WJR_HAS_FEATURE_IS_CONSTANT_EVALUATED
#endif

#if WJR_HAS_BUILTIN(__builtin_constant_p)
#define WJR_BUILTIN_CONSTANT_P(expr) __builtin_constant_p(expr)
#else
#define WJR_BUILTIN_CONSTANT_P(expr) false
#endif

#if WJR_HAS_BUILTIN(__builtin_constant_p)
#define WJR_BUILTIN_CONSTANT_P_TRUE(expr) (WJR_BUILTIN_CONSTANT_P(expr) && (expr))
#else
#define WJR_BUILTIN_CONSTANT_P_TRUE(expr) false
#endif

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_COMPILER_BARRIER() asm volatile("" ::: "memory")
#define WJR_COMPILER_EMPTY_ASM() asm("")
#else
#define WJR_COMPILER_BARRIER()
#define WJR_COMPILER_EMPTY_ASM()
#endif

#define WJR_CONSTEXPR_COMPILER_BARRIER()                                                 \
    do {                                                                                 \
        if (!(WJR_IS_CONSTANT_EVALUATED())) {                                            \
            WJR_COMPILER_BARRIER();                                                      \
        }                                                                                \
    } while (0)

#if defined(WJR_FORCEINLINE)
#define WJR_INTRINSIC_INLINE inline WJR_FORCEINLINE
#else
#define WJR_INTRINSIC_INLINE inline
#endif

// pure attribute
#if WJR_HAS_ATTRIBUTE(pure)
#define WJR_PURE __attribute__((pure))
#else
#define WJR_PURE
#endif

// const attribute
#if WJR_HAS_ATTRIBUTE(const)
#define WJR_CONST __attribute__((const))
#else
#define WJR_CONST
#endif

#if WJR_HAS_ATTRIBUTE(malloc)
#define WJR_MALLOC __attribute__((malloc))
#else
#define WJR_MALLOC
#endif

#if WJR_HAS_ATTRIBUTE(nonnull)
#define WJR_NONNULL(...) __attribute__((__VA_ARGS__))
#else
#define WJR_NONNULL(...)
#endif

#define WJR_INLINE inline
#define WJR_CONSTEXPR constexpr

#if defined(WJR_CXX_20)
#define WJR_CONSTEXPR20 constexpr
#else
#define WJR_CONSTEXPR20
#endif

#define WJR_INTRINSIC_CONSTEXPR WJR_INTRINSIC_INLINE constexpr
#define WJR_INTRINSIC_CONSTEXPR20 WJR_INTRINSIC_INLINE WJR_CONSTEXPR20

#define WJR_INLINE_CONSTEXPR inline constexpr
#define WJR_INLINE_CONSTEXPR20 inline WJR_CONSTEXPR20

#define WJR_ATTRIBUTE(attribute) WJR_ATTRIBUTE_I(attribute)
#define WJR_ATTRIBUTE_I(attribute) WJR_##attribute

#if defined(_MSC_VER)
#define WJR_EMPTY_BASES __declspec(empty_bases)
#else
#define WJR_EMPTY_BASES
#endif

#endif // WJR_PREPROCESSOR_COMPILER_ATTRIBUTE_HPP__

#endif // ! WJR_PREPROCESSOR_COMPILER_HPP__
#ifndef WJR_PREPROCESSOR_DETAIL_HPP__
#define WJR_PREPROCESSOR_DETAIL_HPP__

// Already included
#ifndef WJR_PREPROCESSOR_DETAIL_IOTA_HPP__
#define WJR_PREPROCESSOR_DETAIL_IOTA_HPP__

#define WJR_PP_IOTA(n) WJR_PP_IOTA_I(n)
#define WJR_PP_IOTA_I(n) WJR_PP_IOTA_##n

#define WJR_PP_IOTA_0
#define WJR_PP_IOTA_1 0
#define WJR_PP_IOTA_2 WJR_PP_IOTA_1, 1
#define WJR_PP_IOTA_3 WJR_PP_IOTA_2, 2
#define WJR_PP_IOTA_4 WJR_PP_IOTA_3, 3
#define WJR_PP_IOTA_5 WJR_PP_IOTA_4, 4
#define WJR_PP_IOTA_6 WJR_PP_IOTA_5, 5
#define WJR_PP_IOTA_7 WJR_PP_IOTA_6, 6
#define WJR_PP_IOTA_8 WJR_PP_IOTA_7, 7
#define WJR_PP_IOTA_9 WJR_PP_IOTA_8, 8
#define WJR_PP_IOTA_10 WJR_PP_IOTA_9, 9
#define WJR_PP_IOTA_11 WJR_PP_IOTA_10, 10
#define WJR_PP_IOTA_12 WJR_PP_IOTA_11, 11
#define WJR_PP_IOTA_13 WJR_PP_IOTA_12, 12
#define WJR_PP_IOTA_14 WJR_PP_IOTA_13, 13
#define WJR_PP_IOTA_15 WJR_PP_IOTA_14, 14
#define WJR_PP_IOTA_16 WJR_PP_IOTA_15, 15
#define WJR_PP_IOTA_17 WJR_PP_IOTA_16, 16
#define WJR_PP_IOTA_18 WJR_PP_IOTA_17, 17
#define WJR_PP_IOTA_19 WJR_PP_IOTA_18, 18
#define WJR_PP_IOTA_20 WJR_PP_IOTA_19, 19
#define WJR_PP_IOTA_21 WJR_PP_IOTA_20, 20
#define WJR_PP_IOTA_22 WJR_PP_IOTA_21, 21
#define WJR_PP_IOTA_23 WJR_PP_IOTA_22, 22
#define WJR_PP_IOTA_24 WJR_PP_IOTA_23, 23
#define WJR_PP_IOTA_25 WJR_PP_IOTA_24, 24
#define WJR_PP_IOTA_26 WJR_PP_IOTA_25, 25
#define WJR_PP_IOTA_27 WJR_PP_IOTA_26, 26
#define WJR_PP_IOTA_28 WJR_PP_IOTA_27, 27
#define WJR_PP_IOTA_29 WJR_PP_IOTA_28, 28
#define WJR_PP_IOTA_30 WJR_PP_IOTA_29, 29
#define WJR_PP_IOTA_31 WJR_PP_IOTA_30, 30
#define WJR_PP_IOTA_32 WJR_PP_IOTA_31, 31
#define WJR_PP_IOTA_33 WJR_PP_IOTA_32, 32
#define WJR_PP_IOTA_34 WJR_PP_IOTA_33, 33
#define WJR_PP_IOTA_35 WJR_PP_IOTA_34, 34
#define WJR_PP_IOTA_36 WJR_PP_IOTA_35, 35
#define WJR_PP_IOTA_37 WJR_PP_IOTA_36, 36
#define WJR_PP_IOTA_38 WJR_PP_IOTA_37, 37
#define WJR_PP_IOTA_39 WJR_PP_IOTA_38, 38
#define WJR_PP_IOTA_40 WJR_PP_IOTA_39, 39
#define WJR_PP_IOTA_41 WJR_PP_IOTA_40, 40
#define WJR_PP_IOTA_42 WJR_PP_IOTA_41, 41
#define WJR_PP_IOTA_43 WJR_PP_IOTA_42, 42
#define WJR_PP_IOTA_44 WJR_PP_IOTA_43, 43
#define WJR_PP_IOTA_45 WJR_PP_IOTA_44, 44
#define WJR_PP_IOTA_46 WJR_PP_IOTA_45, 45
#define WJR_PP_IOTA_47 WJR_PP_IOTA_46, 46
#define WJR_PP_IOTA_48 WJR_PP_IOTA_47, 47
#define WJR_PP_IOTA_49 WJR_PP_IOTA_48, 48
#define WJR_PP_IOTA_50 WJR_PP_IOTA_49, 49
#define WJR_PP_IOTA_51 WJR_PP_IOTA_50, 50
#define WJR_PP_IOTA_52 WJR_PP_IOTA_51, 51
#define WJR_PP_IOTA_53 WJR_PP_IOTA_52, 52
#define WJR_PP_IOTA_54 WJR_PP_IOTA_53, 53
#define WJR_PP_IOTA_55 WJR_PP_IOTA_54, 54
#define WJR_PP_IOTA_56 WJR_PP_IOTA_55, 55
#define WJR_PP_IOTA_57 WJR_PP_IOTA_56, 56
#define WJR_PP_IOTA_58 WJR_PP_IOTA_57, 57
#define WJR_PP_IOTA_59 WJR_PP_IOTA_58, 58
#define WJR_PP_IOTA_60 WJR_PP_IOTA_59, 59
#define WJR_PP_IOTA_61 WJR_PP_IOTA_60, 60
#define WJR_PP_IOTA_62 WJR_PP_IOTA_61, 61
#define WJR_PP_IOTA_63 WJR_PP_IOTA_62, 62
#define WJR_PP_IOTA_64 WJR_PP_IOTA_63, 63

#endif // ! WJR_PREPROCESSOR_DETAIL_IOTA_HPP__
#ifndef WJR_PREPROCESSOR_DETAIL_REPEAT_HPP__
#define WJR_PREPROCESSOR_DETAIL_REPEAT_HPP__

#define WJR_PP_REPEAT(x, n) WJR_PP_REPEAT_I(x, n)
#define WJR_PP_REPEAT_I(x, n) WJR_PP_REPEAT_##n(x)

#define WJR_PP_REPEAT_0(x)
#define WJR_PP_REPEAT_1(x) x
#define WJR_PP_REPEAT_2(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_1(x)
#define WJR_PP_REPEAT_3(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x)
#define WJR_PP_REPEAT_4(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_2(x)
#define WJR_PP_REPEAT_5(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_4(x)
#define WJR_PP_REPEAT_6(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x)
#define WJR_PP_REPEAT_7(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x)
#define WJR_PP_REPEAT_8(x) WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_4(x)
#define WJR_PP_REPEAT_9(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_8(x)
#define WJR_PP_REPEAT_10(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_8(x)
#define WJR_PP_REPEAT_11(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_8(x)
#define WJR_PP_REPEAT_12(x) WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x)
#define WJR_PP_REPEAT_13(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x)
#define WJR_PP_REPEAT_14(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x)
#define WJR_PP_REPEAT_15(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x)
#define WJR_PP_REPEAT_16(x) WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_8(x)
#define WJR_PP_REPEAT_17(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_18(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_19(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_20(x) WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_21(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_22(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_23(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_24(x) WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_25(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_26(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_27(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_28(x) WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_29(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_30(x)                                                              \
    WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_31(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x),      \
        WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_32(x) WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_16(x)
#define WJR_PP_REPEAT_33(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_34(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_35(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_36(x) WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_37(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_38(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_39(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_40(x) WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_41(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_42(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_43(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_44(x) WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_45(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_46(x)                                                              \
    WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_47(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x),      \
        WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_48(x) WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_49(x) WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_50(x) WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_51(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_52(x) WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_53(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_54(x)                                                              \
    WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_55(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_16(x),     \
        WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_56(x) WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_57(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_58(x)                                                              \
    WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_59(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x),     \
        WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_60(x)                                                              \
    WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_61(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x),     \
        WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_62(x)                                                              \
    WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x), WJR_PP_REPEAT_16(x),     \
        WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_63(x)                                                              \
    WJR_PP_REPEAT_1(x), WJR_PP_REPEAT_2(x), WJR_PP_REPEAT_4(x), WJR_PP_REPEAT_8(x),      \
        WJR_PP_REPEAT_16(x), WJR_PP_REPEAT_32(x)
#define WJR_PP_REPEAT_64(x) WJR_PP_REPEAT_32(x), WJR_PP_REPEAT_32(x)

#endif // ! WJR_PREPROCESSOR_DETAIL_REPEAT_HPP__

#endif // ! WJR_PREPROCESSOR_DETAIL_HPP__
#ifndef WJR_PREPROCESSOR_LOGICAL_HPP__
#define WJR_PREPROCESSOR_LOGICAL_HPP__

// Already included
// Already included

#endif // ! WJR_PREPROCESSOR_LOGICAL_HPP__

// Due to the fact that call is not a simple expansion, but takes the previous output as
// the next input, the difficulty of implementing recursion is also high.
#ifndef WJR_PREPROCESSOR_QUEUE_ALGORITHM_HPP__
#define WJR_PREPROCESSOR_QUEUE_ALGORITHM_HPP__

// Already included
// Already included
#ifndef WJR_PREPROCESSOR_QUEUE_CALL_HPP__
#define WJR_PREPROCESSOR_QUEUE_CALL_HPP__

// Already included
// Already included
// Already included
#ifndef WJR_PREPROCCESSOR_QUEUE_BASIC_HPP__
#define WJR_PREPROCCESSOR_QUEUE_BASIC_HPP__

// Already included

#define WJR_PP_QUEUE_EXPAND(queue) WJR_PP_QUEUE_EXPAND_I queue
#define WJR_PP_QUEUE_EXPAND_I(...) __VA_ARGS__

#define WJR_PP_QUEUE_FRONT(queue) WJR_PP_QUEUE_FRONT_I queue
#define WJR_PP_QUEUE_FRONT_I(x, ...) x

#define WJR_PP_QUEUE_POP_FRONT(queue) WJR_PP_QUEUE_POP_FRONT_I queue
#define WJR_PP_QUEUE_POP_FRONT_I(x, ...) (__VA_ARGS__)

#define WJR_PP_QUEUE_PUSH_FRONT(queue, x) WJR_PP_QUEUE_PUSH_FRONT_I(queue, x)
#define WJR_PP_QUEUE_PUSH_FRONT_I(queue, x) (x, WJR_PP_QUEUE_EXPAND(queue))

#define WJR_PP_QUEUE_PUSH_BACK(queue, x) WJR_PP_QUEUE_PUSH_BACK_I(queue, x)
#define WJR_PP_QUEUE_PUSH_BACK_I(queue, x) (WJR_PP_QUEUE_EXPAND(queue), x)

#define WJR_PP_QUEUE_SIZE(queue) WJR_PP_QUEUE_SIZE_I(queue)
#define WJR_PP_QUEUE_SIZE_I(queue) WJR_PP_ARGS_LEN queue

#endif // ! WJR_PREPROCCESSOR_QUEUE_BASIC_HPP__

#define WJR_PP_QUEUE_CALL(args, ops)                                                     \
    WJR_PP_QUEUE_CALL_N_I(args, ops, WJR_PP_QUEUE_SIZE(args))
#define WJR_PP_QUEUE_CALL_N(args, ops, N) WJR_PP_QUEUE_CALL_N_I(args, ops, WJR_PP_INC(N))

#define WJR_PP_QUEUE_CALL_N_I(args, ops, N) WJR_PP_QUEUE_CALL_N_II(args, ops, N)
#define WJR_PP_QUEUE_CALL_N_II(args, ops, N) WJR_PP_QUEUE_CALL_##N(args, ops)

#define WJR_PP_QUEUE_CALL_GEN(args, ops)                                                 \
    WJR_PP_QUEUE_CALL_GEN_I(WJR_PP_QUEUE_FRONT(ops), WJR_PP_QUEUE_FRONT(args),           \
                            WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_POP_FRONT(args)))
#define WJR_PP_QUEUE_CALL_GEN_I(op, arg1, arg2) op(arg1, arg2)

#define WJR_PP_QUEUE_CALL_NEW_ARGS_EQ(args, ops) (WJR_PP_QUEUE_CALL_GEN(args, ops))

#define WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)                                         \
    WJR_PP_QUEUE_CALL_NEW_ARGS_NE_I(                                                     \
        WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_POP_FRONT(args)),                            \
        WJR_PP_QUEUE_CALL_GEN(args, ops))
#define WJR_PP_QUEUE_CALL_NEW_ARGS_NE_I(arg1, arg2) WJR_PP_QUEUE_PUSH_FRONT(arg1, arg2)

#define WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops)                                            \
    WJR_PP_QUEUE_CALL_NEW_ARGS_I(args, ops, WJR_PP_QUEUE_SIZE(args))
#define WJR_PP_QUEUE_CALL_NEW_ARGS_I(args, ops, N)                                       \
    WJR_PP_QUEUE_CALL_NEW_ARGS_II(args, ops, N)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_II(args, ops, N)                                      \
    WJR_PP_QUEUE_CALL_NEW_ARGS_##N(args, ops)

#define WJR_PP_QUEUE_CALL_1(args, ops) args

#define WJR_PP_QUEUE_CALL_2(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops)

#define WJR_PP_QUEUE_CALL_3(args, ops)                                                   \
    WJR_PP_QUEUE_CALL_2(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                           \
                        WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_4(args, ops)                                                   \
    WJR_PP_QUEUE_CALL_3(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                           \
                        WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_5(args, ops)                                                   \
    WJR_PP_QUEUE_CALL_4(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                           \
                        WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_6(args, ops)                                                   \
    WJR_PP_QUEUE_CALL_5(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                           \
                        WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_7(args, ops)                                                   \
    WJR_PP_QUEUE_CALL_6(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                           \
                        WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_8(args, ops)                                                   \
    WJR_PP_QUEUE_CALL_7(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                           \
                        WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_9(args, ops)                                                   \
    WJR_PP_QUEUE_CALL_8(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                           \
                        WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_10(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_9(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                           \
                        WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_11(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_10(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_12(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_11(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_13(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_12(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_14(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_13(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_15(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_14(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_16(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_15(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_17(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_16(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_18(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_17(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_19(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_18(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_20(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_19(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_21(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_20(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_22(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_21(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_23(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_22(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_24(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_23(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_25(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_24(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_26(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_25(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_27(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_26(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_28(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_27(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_29(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_28(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_30(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_29(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_31(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_30(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_32(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_31(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_33(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_32(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_34(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_33(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_35(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_34(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_36(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_35(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_37(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_36(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_38(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_37(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_39(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_38(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_40(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_39(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_41(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_40(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_42(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_41(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_43(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_42(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_44(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_43(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_45(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_44(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_46(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_45(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_47(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_46(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_48(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_47(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_49(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_48(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_50(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_49(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_51(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_50(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_52(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_51(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_53(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_52(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_54(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_53(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_55(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_54(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_56(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_55(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_57(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_56(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_58(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_57(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_59(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_58(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_60(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_59(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_61(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_60(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_62(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_61(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_63(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_62(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))
#define WJR_PP_QUEUE_CALL_64(args, ops)                                                  \
    WJR_PP_QUEUE_CALL_63(WJR_PP_QUEUE_CALL_NEW_ARGS(args, ops),                          \
                         WJR_PP_QUEUE_POP_FRONT(ops))

#define WJR_PP_QUEUE_CALL_NEW_ARGS_2(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_EQ(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_3(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_4(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_5(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_6(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_7(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_8(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_9(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_10(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_11(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_12(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_13(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_14(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_15(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_16(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_17(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_18(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_19(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_20(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_21(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_22(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_23(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_24(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_25(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_26(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_27(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_28(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_29(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_30(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_31(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_32(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_33(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_34(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_35(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_36(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_37(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_38(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_39(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_40(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_41(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_42(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_43(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_44(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_45(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_46(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_47(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_48(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_49(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_50(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_51(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_52(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_53(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_54(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_55(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_56(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_57(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_58(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_59(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_60(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_61(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_62(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_63(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)
#define WJR_PP_QUEUE_CALL_NEW_ARGS_64(args, ops) WJR_PP_QUEUE_CALL_NEW_ARGS_NE(args, ops)

#endif // ! WJR_PREPROCESSOR_QUEUE_CALL_HPP__

#define WJR_PP_QUEUE_INIT_N(x, N) WJR_PP_QUEUE_INIT_N_I(x, N)
#define WJR_PP_QUEUE_INIT_N_I(x, N) (WJR_PP_REPEAT(x, N))

#define WJR_PP_QUEUE_CALL_N_SAME(args, op, N)                                            \
    WJR_PP_QUEUE_CALL_N(args, WJR_PP_QUEUE_INIT_N(op, N), N)

#define WJR_PP_QUEUE_CALL_SAME(args, op)                                                 \
    WJR_PP_QUEUE_CALL_N_SAME(args, op, WJR_PP_QUEUE_SIZE(args))

// (1,2,3), (f, g, h) -> (f(1), g(2), h(3))
#define WJR_PP_QUEUE_TRANSFORMS(queue, ops)                                              \
    WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_CALL_N_SAME(                  \
        WJR_PP_QUEUE_PUSH_FRONT(queue, WJR_PP_QUEUE_PUSH_BACK(ops, 0)),                  \
        WJR_PP_QUEUE_TRANSFORMS_CALLER, WJR_PP_QUEUE_SIZE(queue))))

#define WJR_PP_QUEUE_TRANSFORMS_CALLER(x, y)                                             \
    WJR_PP_QUEUE_PUSH_BACK(WJR_PP_QUEUE_POP_FRONT(x), WJR_PP_QUEUE_FRONT(x)(y))

// (1,2,3), f -> (f(1), f(2), f(3))
#define WJR_PP_QUEUE_TRANSFORM(queue, op)                                                \
    WJR_PP_QUEUE_TRANSFORMS(queue, WJR_PP_QUEUE_INIT_N(op, WJR_PP_QUEUE_SIZE(queue)))

// 0, (1, 2, 3), (f, g, h) -> h(g(f(0, 1), 2), 3)
#define WJR_PP_QUEUE_ACCUMULATES(init, queue, ops)                                       \
    WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_CALL_N_SAME(                      \
        WJR_PP_QUEUE_PUSH_FRONT(                                                         \
            queue, WJR_PP_QUEUE_PUSH_BACK(WJR_PP_QUEUE_PUSH_FRONT(ops, init), 0)),       \
        WJR_PP_QUEUE_ACCUMULATES_CALLER, WJR_PP_QUEUE_SIZE(queue))))

#define WJR_PP_QUEUE_ACCUMULATES_CALLER(x, y)                                            \
    WJR_PP_QUEUE_PUSH_FRONT(                                                             \
        WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_POP_FRONT(x)),                               \
        WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_POP_FRONT(x))(WJR_PP_QUEUE_FRONT(x), y))

// 0, (1, 2, 3), f
#define WJR_PP_QUEUE_ACCUMULATE(init, queue, op)                                         \
    WJR_PP_QUEUE_ACCUMULATES(init, queue,                                                \
                             WJR_PP_QUEUE_INIT_N(op, WJR_PP_QUEUE_SIZE(queue)))

// (1, 2, 3) -> 3
#define WJR_PP_QUEUE_BACK(queue)                                                         \
    WJR_PP_QUEUE_ACCUMULATE(0, queue, WJR_PP_QUEUE_BACK_CALLER)

#define WJR_PP_QUEUE_BACK_CALLER(x, y) y

// (1, 2, 3, 4, 5), 2 -> (3, 4, 5)
#define WJR_PP_QUEUE_POP_FRONT_N(queue, N)                                               \
    WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_CALL_N(                       \
        WJR_PP_QUEUE_PUSH_FRONT(WJR_PP_QUEUE_PUSH_FRONT(queue, holder), (0)),            \
        (WJR_PP_REPEAT(WJR_PP_QUEUE_POP_FRONT_N_HEADER_CALLER, WJR_PP_INC(N)),           \
         WJR_PP_REPEAT(WJR_PP_QUEUE_POP_FRONT_N_TAILER_CALLER,                           \
                       WJR_PP_QUEUE_SIZE(queue))),                                       \
        WJR_PP_INC(WJR_PP_QUEUE_SIZE(queue)))))

#define WJR_PP_QUEUE_POP_FRONT_N_HEADER_CALLER(x, y) x
#define WJR_PP_QUEUE_POP_FRONT_N_TAILER_CALLER(x, y) WJR_PP_QUEUE_PUSH_BACK(x, y)

// (1, 2, 3, 4, 5), 2 -> (1, 2, 3)
#define WJR_PP_QUEUE_POP_BACK_N(queue, N)                                                \
    WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_FRONT(                                           \
        WJR_PP_QUEUE_CALL(WJR_PP_QUEUE_PUSH_FRONT(queue, (0)),                           \
                          WJR_PP_QUEUE_POP_FRONT_N(                                      \
                              (WJR_PP_REPEAT(WJR_PP_QUEUE_POP_BACK_N_HEADER_CALLER,      \
                                             WJR_PP_QUEUE_SIZE(queue)),                  \
                               WJR_PP_REPEAT(WJR_PP_QUEUE_POP_BACK_N_TAILER_CALLER, N)), \
                              N))))

#define WJR_PP_QUEUE_POP_BACK_N_HEADER_CALLER(x, y) WJR_PP_QUEUE_PUSH_BACK(x, y)
#define WJR_PP_QUEUE_POP_BACK_N_TAILER_CALLER(x, y) x

#define WJR_PP_QUEUE_POP_BACK(queue) WJR_PP_QUEUE_POP_BACK_N(queue, 1)

#define WJR_PP_QUEUE_AT(queue, N) WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_POP_FRONT_N(queue, N))

#define WJR_PP_QUEUE_REVERSE(queue)                                                      \
    WJR_PP_QUEUE_POP_BACK(WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_CALL_N_SAME(                   \
        WJR_PP_QUEUE_PUSH_FRONT(queue, (0)), WJR_PP_QUEUE_REVERSE_CALLER,                \
        WJR_PP_QUEUE_SIZE(queue))))

#define WJR_PP_QUEUE_REVERSE_CALLER(x, y) WJR_PP_QUEUE_PUSH_FRONT(x, y)

// (a, b, c) -> a b c
#define WJR_PP_QUEUE_PUT(queue) WJR_PP_QUEUE_ACCUMULATE(, queue, WJR_PP_QUEUE_PUT_CALLER)

#define WJR_PP_QUEUE_PUT_CALLER(x, y) x y

// ((A), (B), (C)) -> (A, B, C)
#define WJR_PP_QUEUE_UNWRAP(queue)                                                       \
    WJR_PP_QUEUE_TRANSFORM(queue, WJR_PP_QUEUE_UNWRAP_CALLER)

#define WJR_PP_QUEUE_UNWRAP_CALLER(x) WJR_PP_QUEUE_UNWRAP_CALLER_I x
#define WJR_PP_QUEUE_UNWRAP_CALLER_I(x) x

// ((A), (B), (C)) -> A B C
#define WJR_PP_QUEUE_UNWRAP_PUT(queue)                                                   \
    WJR_PP_QUEUE_EXPAND(WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_CALL_N_SAME(                     \
        WJR_PP_QUEUE_PUSH_FRONT(queue, ()), WJR_PP_QUEUE_UNWRAP_PUT_CALLER,              \
        WJR_PP_QUEUE_SIZE(queue))))

#define WJR_PP_QUEUE_UNWRAP_PUT_CALLER(x, y)                                             \
    (WJR_PP_QUEUE_EXPAND(x) WJR_PP_QUEUE_EXPAND(y))

// (A, B, C) (x, y, z) -> ((A, x), (B, y), (C, z))
#define WJR_PP_QUEUE_ZIP_2(queue1, queue2)                                               \
    WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_CALL_N_SAME(                  \
        ((queue1), queue2), WJR_PP_QUEUE_ZIP_2_CALLER, WJR_PP_QUEUE_SIZE(queue1))))

#define WJR_PP_QUEUE_ZIP_2_CALLER(x, y)                                                  \
    WJR_PP_QUEUE_PUSH_FRONT(                                                             \
        WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_PUSH_BACK(                                   \
            x, (WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_FRONT(x)), WJR_PP_QUEUE_FRONT(y)))),     \
        WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_FRONT(x))),                                  \
        WJR_PP_QUEUE_POP_FRONT(y)

// ((A), (B), (C)) (x, y, z) -> ((A, x), (B, y), (C, z))
#define WJR_PP_QUEUE_ZIP_MORE(queue1, queue2)                                            \
    WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_CALL_N_SAME(                  \
        ((queue1), queue2), WJR_PP_QUEUE_ZIP_MORE_CALLER, WJR_PP_QUEUE_SIZE(queue1))))

#define WJR_PP_QUEUE_ZIP_MORE_CALLER(x, y)                                               \
    WJR_PP_QUEUE_PUSH_FRONT(                                                             \
        WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_PUSH_BACK(                                   \
            x, (WJR_PP_QUEUE_EXPAND(WJR_PP_QUEUE_FRONT(WJR_PP_QUEUE_FRONT(x))),          \
                WJR_PP_QUEUE_FRONT(y)))),                                                \
        WJR_PP_QUEUE_POP_FRONT(WJR_PP_QUEUE_FRONT(x))),                                  \
        WJR_PP_QUEUE_POP_FRONT(y)

#endif // WJR_PREPROCESSOR_QUEUE_ALGORITHM_HPP__

#define WJR_PP_BOOL_IF_NE(expr, t, f) WJR_PP_BOOL_IF(WJR_PP_BOOL(expr), t, f)

// (a, b, c) -> f(a) f(b) f(c)
#define WJR_PP_TRANSFORM_PUT(queue, op)                                                  \
    WJR_PP_QUEUE_PUT(WJR_PP_QUEUE_TRANSFORM(queue, op))

// (a, b, c) -> (f(a), f(b), f(c)) (note : f(x) = (g(x))) -> g(a) g(b) g(c)
#define WJR_PP_TRANSFORM_UNWRAP_PUT(queue, op)                                           \
    WJR_PP_QUEUE_UNWRAP_PUT(WJR_PP_QUEUE_TRANSFORM(queue, op))

#define WJR_ATTRIBUTES(...) WJR_PP_TRANSFORM_PUT((__VA_ARGS__), WJR_ATTRIBUTES_CALLER)
#define WJR_ATTRIBUTES_CALLER(x) WJR_ATTRIBUTE(x)

#define WJR_PRAGMA_I(expr) _Pragma(#expr)
#if defined(WJR_COMPILER_GCC) || defined(WJR_COMPILER_CLANG) || defined(WJR_COMPILER_MSVC)
#define WJR_PRAGMA(expr) WJR_PRAGMA_I(expr)
#else
#define WJR_PRAGMA(expr)
#endif

#if WJR_HAS_FEATURE(PRAGMA_UNROLL)
#if defined(WJR_COMPILER_GCC)
#define WJR_UNROLL(loop) WJR_PRAGMA(GCC unroll(loop))
#else
#define WJR_UNROLL(loop) WJR_PRAGMA(unroll(loop))
#endif
#else
#define WJR_UNROLL(loop)
#endif

#define WJR_IS_OVERLAP_P(p, pn, q, qn) ((p) + (pn) > (q) && (q) + (qn) > (p))
#define WJR_IS_SEPARATE_P(p, pn, q, qn) (!WJR_IS_OVERLAP_P(p, pn, q, qn))
#define WJR_IS_SAME_OR_SEPARATE_P(p, pn, q, qn)                                          \
    (((p) == (q)) || WJR_IS_SEPARATE_P(p, pn, q, qn))
#define WJR_IS_SAME_OR_INCR_P(p, pn, q, qn)                                              \
    (((p) <= (q)) || WJR_IS_SEPARATE_P(p, pn, q, qn))
#define WJR_IS_SAME_OR_DECR_P(p, pn, q, qn)                                              \
    (((p) >= (q)) || WJR_IS_SEPARATE_P(p, pn, q, qn))

#define WJR_ASM_PIC_JMPL(LABEL, TABLE) ".long " #LABEL "-" #TABLE
#define WJR_ASM_NOPIC_JMPL(LABEL) ".quad " #LABEL

#if WJR_HAS_FEATURE(INLINE_ASM_CCCOND)
#define WJR_ASM_CCSET(c) "/* set condition codes */\n\t"
#define WJR_ASM_CCOUT(c) "=@cc" #c
#else
#define WJR_ASM_CCSET(c) "set" #c " %[_cc_" #c "]\n\t"
#define WJR_ASM_CCOUT(c) [_cc_##c] "=r"
#endif

#if defined(WJR_DISABLE_EXCEPTIONS)
#define WJR_EXCEPTIONS_IF(ENABLE, DISABLE) DISABLE
#else
#define WJR_EXCEPTIONS_IF(ENABLE, DISABLE) ENABLE
#endif

#define WJR_ENABLE_EXCEPTIONS_TRY_I try
#define WJR_ENABLE_EXCEPTIONS_CATCH_I(...) catch (__VA_ARGS__)
#define WJR_ENABLE_EXCEPTIONS_THROW_I(X) throw X
#define WJR_ENABLE_EXCEPTIONS_XTHROW_I throw

#define WJR_DISABLE_EXCEPTIONS_TRY_I if constexpr (true)
#define WJR_DISABLE_EXCEPTIONS_CATCH_I(...) if constexpr (false)
#define WJR_DISABLE_EXCEPTIONS_THROW_I(X)
#define WJR_DISABLE_EXCEPTIONS_XTHROW_I

#define WJR_TRY                                                                          \
    WJR_EXCEPTIONS_IF(WJR_ENABLE_EXCEPTIONS_TRY_I, WJR_DISABLE_EXCEPTIONS_TRY_I)
#define WJR_CATCH(...)                                                                   \
    WJR_EXCEPTIONS_IF(WJR_ENABLE_EXCEPTIONS_CATCH_I(__VA_ARGS__),                        \
                      WJR_DISABLE_EXCEPTIONS_CATCH_I(__VA_ARGS__))
#define WJR_THROW(X)                                                                     \
    WJR_EXCEPTIONS_IF(WJR_ENABLE_EXCEPTIONS_THROW_I(X), WJR_DISABLE_EXCEPTIONS_THROW_I(X))
#define WJR_XTHROW                                                                       \
    WJR_EXCEPTIONS_IF(WJR_ENABLE_EXCEPTIONS_XTHROW_I, WJR_DISABLE_EXCEPTIONS_XTHROW_I)

#define WJR_REQUIRES(...) std::enable_if_t<(__VA_ARGS__), int> = 0
#define WJR_REQUIRES_I(...) std::enable_if_t<(__VA_ARGS__), int>

#define WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(CLASS)                                        \
    CLASS() = default;                                                                   \
    CLASS(const CLASS &) = default;                                                      \
    CLASS(CLASS &&) = default;                                                           \
    CLASS &operator=(const CLASS &) = default;                                           \
    CLASS &operator=(CLASS &&) = default;                                                \
    ~CLASS() = default

#endif // ! WJR_PREPROCESSOR_PREVIEW_HPP__

#endif // WJR_PREPROCESSOR_HPP__

namespace wjr {

template <typename From, typename To>
struct broadcast_fn {};

/**
 * @brief Broadcast a value to a wider type.
 *
 * @note From must be a smaller type than To.
 */
template <typename From, typename To>
inline constexpr broadcast_fn<From, To> broadcast{};

template <>
struct broadcast_fn<uint8_t, uint8_t> {
    WJR_CONST constexpr uint8_t operator()(uint8_t x) const noexcept { return x; }
};

template <>
struct broadcast_fn<uint16_t, uint16_t> {
    WJR_CONST constexpr uint16_t operator()(uint16_t x) const noexcept { return x; }
};

template <>
struct broadcast_fn<uint32_t, uint32_t> {
    WJR_CONST constexpr uint32_t operator()(uint32_t x) const noexcept { return x; }
};

template <>
struct broadcast_fn<uint64_t, uint64_t> {
    WJR_CONST constexpr uint64_t operator()(uint64_t x) const noexcept { return x; }
};

template <>
struct broadcast_fn<uint8_t, uint16_t> {
    WJR_CONST constexpr uint16_t operator()(uint8_t x) const noexcept {
        return static_cast<uint16_t>(static_cast<uint32_t>(x) |
                                     (static_cast<uint16_t>(x) << 8));
    }
};

template <>
struct broadcast_fn<uint16_t, uint32_t> {
    WJR_CONST constexpr uint32_t operator()(uint16_t x) const noexcept {
        return x | (static_cast<uint32_t>(x) << 16);
    }
};

template <>
struct broadcast_fn<uint32_t, uint64_t> {
    WJR_CONST constexpr uint64_t operator()(uint32_t x) const noexcept {
        return static_cast<uint64_t>(x) | (static_cast<uint64_t>(x) << 32);
    }
};

template <>
struct broadcast_fn<uint8_t, uint32_t> {
    WJR_CONST constexpr uint32_t operator()(uint8_t x) const noexcept {
        return x * static_cast<uint32_t>(0x01010101u);
    }
};

template <>
struct broadcast_fn<uint16_t, uint64_t> {
    WJR_CONST constexpr uint64_t operator()(uint16_t x) const noexcept {
        return x * static_cast<uint64_t>(0x0001000100010001ull);
    }
};

template <>
struct broadcast_fn<uint8_t, uint64_t> {
    WJR_CONST constexpr uint64_t operator()(uint8_t x) const noexcept {
        return x * static_cast<uint64_t>(0x0101010101010101ull);
    }
};

} // namespace wjr

#endif // WJR_MATH_BROADCAST_HPP__
#ifndef WJR_MEMORY_DETAIL_HPP__
#define WJR_MEMORY_DETAIL_HPP__

#include <cstring>

#ifndef WJR_ITERATOR_DETAIL_HPP__
#define WJR_ITERATOR_DETAIL_HPP__

#ifndef WJR_TYPE_TRAITS_HPP__
#define WJR_TYPE_TRAITS_HPP__

#include <cstddef>
#include <cstdint>
#include <functional>
#include <limits>
#include <type_traits>
#include <utility>

// Already included

namespace wjr {

enum class branch {
    free,
    full,
};

struct in_place_empty_t {};

inline constexpr in_place_empty_t in_place_empty = {};

/**
 * @brief Tag of default constructor.
 *
 * @details Use dctor to indicate default constructor. \n
 * Used to avoid value initialization.  \n
 * For example : \n
 * @code
 * wjr::vector<int> vec(10, dctor); // default construct with 10 elements.
 * wjr::vector<int> vec2(10); // value construct with 10 elements.
 * wjr::vector<int> vec3(10, 0); // value construct with 10 elements.
 * wjr::vector<int> vec4(10, vctor); // value construct with 10 elements.
 * @endcode
 * elements of vec are not initialized. \n
 * elements of vec2, vec3, vec4 are initialized with 0.
 */
struct dctor_t {};

/**
 * @see dctor_t
 */
inline constexpr dctor_t dctor = {};

/**
 * @brief Tag of value constructor.
 *
 */
struct vctor_t {};

inline constexpr vctor_t vctor = {};

struct in_place_reallocate_t {};

inline constexpr in_place_reallocate_t in_place_reallocate = {};

struct in_place_reserve_t {};

inline constexpr in_place_reserve_t in_place_reserve = {};

struct in_place_move_t {};

inline constexpr in_place_move_t in_place_move = {};

struct in_place_max_t {
    template <typename T>
    WJR_CONST constexpr operator T() const noexcept {
        return std::numeric_limits<T>::max();
    }
};

inline constexpr in_place_max_t in_place_max = {};

struct in_place_min_t {
    template <typename T>
    WJR_CONST constexpr operator T() const noexcept {
        return std::numeric_limits<T>::min();
    }
};

inline constexpr in_place_min_t in_place_min = {};

struct self_init_t {};

inline constexpr self_init_t self_init = {};

inline constexpr std::size_t dynamic_extent = in_place_max;

template <typename... Args>
struct multi_conditional;

template <typename... Args>
using multi_conditional_t = typename multi_conditional<Args...>::type;

template <bool f, typename T, typename... Args>
struct multi_conditional_impl {
    using type = T;
};

template <typename T, typename... Args>
struct multi_conditional_impl<false, T, Args...> {
    using type = multi_conditional_t<Args...>;
};

template <typename F, typename T, typename U>
struct multi_conditional<F, T, U> {
    using type = std::conditional_t<F::value, T, U>;
};

template <typename F, typename T, typename U, typename V, typename... Args>
struct multi_conditional<F, T, U, V, Args...> {
    using type = typename multi_conditional_impl<F::value, T, U, V, Args...>::type;
};

template <typename T, typename... Args>
struct is_any_of : std::disjunction<std::is_same<T, Args>...> {};

template <typename T, typename... Args>
inline constexpr bool is_any_of_v = is_any_of<T, Args...>::value;

template <typename T>
struct remove_cvref {
    using type = std::remove_cv_t<std::remove_reference_t<T>>;
};

template <typename T>
using remove_cvref_t = typename remove_cvref<T>::type;

/// @private
template <size_t n>
struct __uint_selector {};

/// @private
template <>
struct __uint_selector<8> {
    using type = std::uint8_t;
};

/// @private
template <>
struct __uint_selector<16> {
    using type = std::uint16_t;
};

/// @private
template <>
struct __uint_selector<32> {
    using type = std::uint32_t;
};

/// @private
template <>
struct __uint_selector<64> {
    using type = std::uint64_t;
};

/// @private
template <size_t n>
struct __int_selector {
    using type = std::make_signed_t<typename __uint_selector<n>::type>;
};

#if WJR_HAS_FEATURE(INT128)
/// @private
template <>
struct __uint_selector<128> {
    using type = __uint128_t;
};

/// @private
template <>
struct __int_selector<128> {
    using type = __int128_t;
};
#endif

template <size_t n>
using uint_t = typename __uint_selector<n>::type;

template <size_t n>
using int_t = typename __int_selector<n>::type;

template <size_t n, bool __s>
using usint_t = std::conditional_t<__s, int_t<n>, uint_t<n>>;

using ssize_t = std::make_signed_t<size_t>;

template <typename T>
struct is_nonbool_integral
    : std::conjunction<std::is_integral<T>, std::negation<std::is_same<T, bool>>> {};

template <typename T>
inline constexpr bool is_nonbool_integral_v = is_nonbool_integral<T>::value;

template <typename T>
struct is_unsigned_integral : std::conjunction<std::is_integral<T>, std::is_unsigned<T>> {
};

template <typename T>
inline constexpr bool is_unsigned_integral_v = is_unsigned_integral<T>::value;

template <typename T>
struct is_signed_integral : std::conjunction<std::is_integral<T>, std::is_signed<T>> {};

template <typename T>
inline constexpr bool is_signed_integral_v = is_signed_integral<T>::value;

template <typename T>
struct is_nonbool_unsigned_integral
    : std::conjunction<is_unsigned_integral<T>, std::negation<std::is_same<T, bool>>> {};

template <typename T>
inline constexpr bool is_nonbool_unsigned_integral_v =
    is_nonbool_unsigned_integral<T>::value;

template <typename T>
struct is_nonbool_signed_integral
    : std::conjunction<is_signed_integral<T>, std::negation<std::is_same<T, bool>>> {};

template <typename T>
inline constexpr bool is_nonbool_signed_integral_v = is_nonbool_signed_integral<T>::value;

// type identity
template <typename T>
struct type_identity {
    using type = T;
};

template <typename T>
using type_identity_t = typename type_identity<T>::type;

template <typename T>
struct add_restrict {
    using type = T;
};

template <typename T>
struct add_restrict<T *> {
    using type = T *WJR_RESTRICT;
};

template <typename T>
using add_restrict_t = typename add_restrict<T>::type;

/**
 * @brief Return if is constant evaluated.
 *
 * @details Use macro WJR_IS_CONSTANT_EVALUATED(). \n
 * Use std::is_constant_evaluated() if C++ 20 is supported. \n
 * Otherwise, use __builtin_constant_evaluated() if
 * WJR_HAS_BUILTIN(__builtin_is_constant_evaluated). Otherwise, return false.
 *
 */
WJR_INTRINSIC_CONSTEXPR bool is_constant_evaluated() noexcept {
    return WJR_IS_CONSTANT_EVALUATED();
}

template <typename T, typename U, typename = void>
struct __is_swappable_with : std::false_type {};

template <typename T, typename U>
struct __is_swappable_with<
    T, U, std::void_t<decltype(std::swap(std::declval<T &>(), std::declval<U &>()))>>
    : std::true_type {};

template <typename T, typename U>
struct is_swappable_with
    : std::conjunction<__is_swappable_with<T, U>, __is_swappable_with<U, T>> {};

template <typename T, typename U>
inline constexpr bool is_swappable_with_v = is_swappable_with<T, U>::value;

template <typename T>
struct is_swappable
    : is_swappable_with<std::add_lvalue_reference_t<T>, std::add_lvalue_reference_t<T>> {
};

template <typename T>
inline constexpr bool is_swappable_v = is_swappable<T>::value;

template <typename T, typename U>
struct __is_nothrow_swappable_with
    : std::bool_constant<noexcept(std::swap(std::declval<T &>(), std::declval<U &>())) &&
                         noexcept(std::swap(std::declval<U &>(), std::declval<T &>()))> {
};

template <typename T, typename U>
struct is_nothrow_swappable_with
    : std::conjunction<is_swappable_with<T, U>, __is_nothrow_swappable_with<T, U>> {};

template <typename T, typename U>
inline constexpr bool is_nothrow_swappable_with_v =
    is_nothrow_swappable_with<T, U>::value;

template <typename T>
struct is_nothrow_swappable : is_nothrow_swappable_with<std::add_lvalue_reference_t<T>,
                                                        std::add_lvalue_reference_t<T>> {
};

template <typename T>
inline constexpr bool is_nothrow_swappable_v = is_nothrow_swappable<T>::value;

/// @private
template <typename T>
struct __unref_wrapper_helper {
    using type = T;
};

/// @private
template <typename T>
struct __unref_wrapper_helper<std::reference_wrapper<T>> {
    using type = T &;
};

template <typename T>
struct unref_wrapper {
    using type = typename __unref_wrapper_helper<std::decay_t<T>>::type;
};

template <typename T>
using unref_wrapper_t = typename unref_wrapper<T>::type;

template <typename T, typename = void>
struct __is_default_convertible : std::false_type {};

template <typename T>
void __test_default_convertible(const T &);

template <typename T>
struct __is_default_convertible<T,
                                std::void_t<decltype(__test_default_convertible<T>({}))>>
    : std::true_type {};

template <typename T>
using is_default_convertible = __is_default_convertible<T>;

template <typename T>
inline constexpr bool is_default_convertible_v = is_default_convertible<T>::value;

template <typename T>
struct get_place_index {};

template <size_t idx>
struct get_place_index<std::in_place_index_t<idx>> {
    static constexpr size_t value = idx;
};

template <typename T>
inline constexpr size_t get_place_index_v = get_place_index<T>::value;

// C++ 17 concept adapt

template <typename Derived, typename Base>
struct is_derived_from
    : std::conjunction<
          std::is_base_of<Base, Derived>,
          std::is_convertible<const volatile Derived *, const volatile Base *>> {};

template <typename Derived, typename Base>
inline constexpr bool is_derived_from_v = is_derived_from<Derived, Base>::Value;

/// @private
template <typename From, typename To, typename = void>
struct __is_convertible_to_helper : std::false_type {};

/// @private
template <typename From, typename To>
struct __is_convertible_to_helper<
    From, To, std::void_t<decltype(static_cast<To>(std::declval<From>()))>>
    : std::true_type {};

template <typename From, typename To>
struct is_convertible_to : std::conjunction<std::is_convertible<From, To>,
                                            __is_convertible_to_helper<From, To, void>> {
};

template <typename From, typename To>
inline constexpr bool is_convertible_to_v = is_convertible_to<From, To>::value;

template <typename Value, WJR_REQUIRES(is_nonbool_integral_v<Value>)>
WJR_CONST constexpr std::make_signed_t<Value> to_signed(Value value) noexcept {
    return static_cast<std::make_signed_t<Value>>(value);
}

template <typename Value, WJR_REQUIRES(is_nonbool_integral_v<Value>)>
WJR_CONST constexpr std::make_unsigned_t<Value> to_unsigned(Value value) noexcept {
    return static_cast<std::make_unsigned_t<Value>>(value);
}

template <typename T, typename U>
WJR_CONST constexpr bool cmp_equal(T t, U u) noexcept {
    if constexpr (std::is_signed_v<T> == std::is_signed_v<U>) {
        return t == u;
    } else if constexpr (std::is_signed_v<T>) {
        return t >= 0 && to_unsigned(t) == u;
    } else {
        return u >= 0 && to_unsigned(u) == t;
    }
}

template <typename T, typename U>
WJR_CONST constexpr bool cmp_not_equal(T t, U u) noexcept {
    return !cmp_equal(t, u);
}

template <typename T, typename U>
WJR_CONST constexpr bool cmp_less(T t, U u) noexcept {
    if constexpr (std::is_signed_v<T> == std::is_signed_v<U>) {
        return t < u;
    } else if constexpr (std::is_signed_v<T>) {
        return t < 0 || to_unsigned(t) < u;
    } else {
        return u >= 0 && t < to_unsigned(u);
    }
}

template <typename T, typename U>
WJR_CONST constexpr bool cmp_greater(T t, U u) noexcept {
    return cmp_less(u, t);
}

template <typename T, typename U>
WJR_CONST constexpr bool cmp_less_equal(T t, U u) noexcept {
    return !cmp_less(u, t);
}

template <typename T, typename U>
WJR_CONST constexpr bool cmp_greater_equal(T t, U u) noexcept {
    return !cmp_less(t, u);
}

template <typename T, typename U>
WJR_CONST constexpr bool in_range(U value) noexcept {
    if constexpr (std::is_same_v<T, U>) {
        return true;
    } else {
        if constexpr (std::is_signed_v<T> == std::is_signed_v<U>) {
            if constexpr (std::is_signed_v<T>) {
                return value >= std::numeric_limits<T>::min() &&
                       value <= std::numeric_limits<T>::max();
            } else {
                return value <= std::numeric_limits<T>::max();
            }
        } else if constexpr (std::is_signed_v<T>) {
            return value <= to_unsigned(std::numeric_limits<T>::max());
        } else {
            return value >= 0 && to_unsigned(value) <= std::numeric_limits<T>::max();
        }
    }
}

template <typename From, typename To, typename Enable = void>
struct __is_value_preserving_impl : std::false_type {};

template <typename From, typename To>
struct __is_value_preserving_impl<From, To, std::enable_if_t<std::is_integral_v<From>>>
    : std::bool_constant<in_range<To>(std::numeric_limits<From>::min()) &&
                         in_range<To>(std::numeric_limits<From>::max())> {};

template <typename From, typename To>
struct is_value_preserving : __is_value_preserving_impl<From, To> {};

template <typename From>
struct is_value_preserving<From, From> : std::true_type {};

template <typename From, typename To>
inline constexpr bool is_value_preserving_v = is_value_preserving<From, To>::value;

template <typename From, typename To>
struct is_value_preserving_or_int
    : std::disjunction<
          std::is_same<From, int>, is_value_preserving<From, To>,
          std::conjunction<std::is_unsigned<To>, std::is_same<From, unsigned int>>> {};

template <typename From, typename To>
inline constexpr bool is_value_preserving_or_int_v =
    is_value_preserving_or_int<From, To>::value;

template <typename T, typename U,
          WJR_REQUIRES(std::is_integral_v<T> &&std::is_integral_v<U>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR T fast_cast(U value) noexcept {
    WJR_ASSUME(in_range<T>(value));
    return static_cast<T>(value);
}

#define __WJR_REGISTER_TYPENAMES(...)                                                    \
    WJR_PP_QUEUE_EXPAND(                                                                 \
        WJR_PP_QUEUE_TRANSFORM((__VA_ARGS__), __WJR_REGISTER_TYPENAMES_CALLER))
#define __WJR_REGISTER_TYPENAMES_CALLER(x) typename x

#define WJR_REGISTER_HAS_TYPE_0(NAME, HAS_EXPR)                                          \
    template <typename Enable, typename... Args>                                         \
    struct __has_##NAME : std::false_type {};                                            \
    template <typename... Args>                                                          \
    struct __has_##NAME<std::void_t<decltype(HAS_EXPR)>, Args...> : std::true_type {};   \
    template <typename... Args>                                                          \
    struct has_##NAME : __has_##NAME<void, Args...> {};                                  \
    template <typename... Args>                                                          \
    constexpr bool has_##NAME##_v = has_##NAME<Args...>::value

#define WJR_REGISTER_HAS_TYPE_MORE(NAME, HAS_EXPR, ...)                                  \
    template <typename Enable, __WJR_REGISTER_TYPENAMES(__VA_ARGS__), typename... Args>  \
    struct __has_##NAME : std::false_type {};                                            \
    template <__WJR_REGISTER_TYPENAMES(__VA_ARGS__), typename... Args>                   \
    struct __has_##NAME<std::void_t<decltype(HAS_EXPR)>, __VA_ARGS__, Args...>           \
        : std::true_type {};                                                             \
    template <__WJR_REGISTER_TYPENAMES(__VA_ARGS__), typename... Args>                   \
    struct has_##NAME : __has_##NAME<void, __VA_ARGS__, Args...> {};                     \
    template <__WJR_REGISTER_TYPENAMES(__VA_ARGS__), typename... Args>                   \
    constexpr bool has_##NAME##_v = has_##NAME<__VA_ARGS__, Args...>::value

#define WJR_REGISTER_HAS_TYPE(NAME, ...)                                                 \
    WJR_REGISTER_HAS_TYPE_N(WJR_PP_ARGS_LEN(__VA_ARGS__), NAME, __VA_ARGS__)
#define WJR_REGISTER_HAS_TYPE_N(N, ...)                                                  \
    WJR_PP_BOOL_IF(WJR_PP_EQ(N, 1), WJR_REGISTER_HAS_TYPE_0, WJR_REGISTER_HAS_TYPE_MORE) \
    (__VA_ARGS__)

// used for SFINAE
constexpr static void allow_true_type(std::true_type) noexcept {}
constexpr static void allow_false_type(std::false_type) noexcept {}

WJR_REGISTER_HAS_TYPE(compare, std::declval<Comp>()(std::declval<T>(), std::declval<U>()),
                      Comp, T, U);
WJR_REGISTER_HAS_TYPE(
    noexcept_compare,
    allow_true_type(std::declval<std::bool_constant<noexcept(
                        std::declval<Comp>()(std::declval<T>(), std::declval<U>()))>>()),
    Comp, T, U);

#define WJR_REGISTER_HAS_COMPARE(NAME, STD)                                              \
    template <typename T, typename U>                                                    \
    struct has_##NAME : has_compare<STD, T, U> {};                                       \
    template <typename T, typename U>                                                    \
    inline constexpr bool has_##NAME##_v = has_##NAME<T, U>::value;                      \
    template <typename T, typename U>                                                    \
    struct has_noexcept_##NAME : has_noexcept_compare<STD, T, U> {};                     \
    template <typename T, typename U>                                                    \
    inline constexpr bool has_noexcept_##NAME##_v = has_noexcept_##NAME<T, U>::value;

WJR_REGISTER_HAS_COMPARE(equal_to, std::equal_to<>);
WJR_REGISTER_HAS_COMPARE(not_equal_to, std::not_equal_to<>);
WJR_REGISTER_HAS_COMPARE(less, std::less<>);
WJR_REGISTER_HAS_COMPARE(less_equal, std::less_equal<>);
WJR_REGISTER_HAS_COMPARE(greater, std::greater<>);
WJR_REGISTER_HAS_COMPARE(greater_equal, std::greater_equal<>);

#undef WJR_REGISTER_HAS_COMPARE

WJR_REGISTER_HAS_TYPE(invocable,
                      std::invoke(std::declval<Func>(), std::declval<Args>()...), Func);

template <typename T>
struct is_bounded_array : std::false_type {};

template <typename T, std::size_t N>
struct is_bounded_array<T[N]> : std::true_type {};

template <typename T>
inline constexpr bool is_bounded_array_v = is_bounded_array<T>::value;

template <typename T>
struct is_unbounded_array : std::false_type {};

template <typename T>
struct is_unbounded_array<T[]> : std::true_type {};

template <typename T>
inline constexpr bool is_unbounded_array_v = is_unbounded_array<T>::value;

template <typename Unqualified, bool IsConst, bool IsVol>
struct __cv_selector;

template <typename Unqualified>
struct __cv_selector<Unqualified, false, false> {
    using __type = Unqualified;
};

template <typename Unqualified>
struct __cv_selector<Unqualified, false, true> {
    using __type = volatile Unqualified;
};

template <typename Unqualified>
struct __cv_selector<Unqualified, true, false> {
    using __type = const Unqualified;
};

template <typename Unqualified>
struct __cv_selector<Unqualified, true, true> {
    using __type = const volatile Unqualified;
};

template <typename _Qualified, typename Unqualified,
          bool IsConst = std::is_const<_Qualified>::value,
          bool IsVol = std::is_volatile<_Qualified>::value>
class __match_cv_qualifiers {
    using __match = __cv_selector<Unqualified, IsConst, IsVol>;

public:
    using __type = typename __match::__type;
};

template <typename From, typename To>
using __copy_cv = typename __match_cv_qualifiers<From, To>::__type;

template <typename Xp, typename Yp>
using __cond_res =
    decltype(false ? std::declval<Xp (&)()>()() : std::declval<Yp (&)()>()());

template <typename _Ap, typename _Bp, typename = void>
struct __common_ref_impl {};

// [meta.trans.other], COMMON-REF(A, B)
template <typename _Ap, typename _Bp>
using __common_ref = typename __common_ref_impl<_Ap, _Bp>::type;

// COND-RES(COPYCV(X, Y) &, COPYCV(Y, X) &)
template <typename _Xp, typename _Yp>
using __condres_cvref = __cond_res<__copy_cv<_Xp, _Yp> &, __copy_cv<_Yp, _Xp> &>;

// If A and B are both lvalue reference types, ...
template <typename _Xp, typename _Yp>
struct __common_ref_impl<_Xp &, _Yp &, std::void_t<__condres_cvref<_Xp, _Yp>>>
    : std::enable_if<std::is_reference_v<__condres_cvref<_Xp, _Yp>>,
                     __condres_cvref<_Xp, _Yp>> {};

// let C be remove_reference_t<COMMON-REF(X&, Y&)>&&
template <typename _Xp, typename _Yp>
using __common_ref_C = std::remove_reference_t<__common_ref<_Xp &, _Yp &>> &&;

// If A and B are both rvalue reference types, ...
template <typename _Xp, typename _Yp>
struct __common_ref_impl<_Xp &&, _Yp &&,
                         std::enable_if_t<std::conjunction_v<
                             std::is_convertible<_Xp &&, __common_ref_C<_Xp, _Yp>>,
                             std::is_convertible<_Yp &&, __common_ref_C<_Xp, _Yp>>>>> {
    using type = __common_ref_C<_Xp, _Yp>;
};

// let D be COMMON-REF(const X&, Y&)
template <typename _Xp, typename _Yp>
using __common_ref_D = __common_ref<const _Xp &, _Yp &>;

// If A is an rvalue reference and B is an lvalue reference, ...
template <typename _Xp, typename _Yp>
struct __common_ref_impl<
    _Xp &&, _Yp &,
    std::enable_if_t<std::is_convertible_v<_Xp &&, __common_ref_D<_Xp, _Yp>>>> {
    using type = __common_ref_D<_Xp, _Yp>;
};

// If A is an lvalue reference and B is an rvalue reference, ...
template <typename _Xp, typename _Yp>
struct __common_ref_impl<_Xp &, _Yp &&> : __common_ref_impl<_Yp &&, _Xp &> {};

template <typename Tp, typename Up, template <typename> typename TQual,
          template <typename> typename UQual, typename Enable = void>
struct __basic_common_reference_impl {};

template <typename Tp, typename Up, template <typename> typename TQual,
          template <typename> typename UQual>
struct basic_common_reference : __basic_common_reference_impl<Tp, Up, TQual, UQual> {};

/// @cond undocumented
template <typename Tp>
struct __xref {
    template <typename Up>
    using __type = __copy_cv<Tp, Up>;
};

template <typename Tp>
struct __xref<Tp &> {
    template <typename Up>
    using __type = __copy_cv<Tp, Up> &;
};

template <typename Tp>
struct __xref<Tp &&> {
    template <typename Up>
    using __type = __copy_cv<Tp, Up> &&;
};

template <typename Tp1, typename Tp2>
using __basic_common_ref =
    typename basic_common_reference<remove_cvref_t<Tp1>, remove_cvref_t<Tp2>,
                                    __xref<Tp1>::template __type,
                                    __xref<Tp2>::template __type>::type;

template <typename... Tp>
struct common_reference;

template <typename... Tp>
using common_reference_t = typename common_reference<Tp...>::type;

// If sizeof...(T) is zero, there shall be no member type.
template <>
struct common_reference<> {};

// If sizeof...(T) is one ...
template <typename Tp0>
struct common_reference<Tp0> {
    using type = Tp0;
};

template <typename Tp1, typename Tp2, int _Bullet = 1, typename = void>
struct __common_reference_impl : __common_reference_impl<Tp1, Tp2, _Bullet + 1> {};

// If sizeof...(T) is two ...
template <typename Tp1, typename Tp2>
struct common_reference<Tp1, Tp2> : __common_reference_impl<Tp1, Tp2> {};

// If T1 and T2 are reference types and COMMON-REF(T1, T2) is well-formed, ...
template <typename Tp1, typename Tp2>
struct __common_reference_impl<Tp1 &, Tp2 &, 1, std::void_t<__common_ref<Tp1 &, Tp2 &>>> {
    using type = __common_ref<Tp1 &, Tp2 &>;
};

template <typename Tp1, typename Tp2>
struct __common_reference_impl<Tp1 &&, Tp2 &&, 1,
                               std::void_t<__common_ref<Tp1 &&, Tp2 &&>>> {
    using type = __common_ref<Tp1 &&, Tp2 &&>;
};

template <typename Tp1, typename Tp2>
struct __common_reference_impl<Tp1 &, Tp2 &&, 1,
                               std::void_t<__common_ref<Tp1 &, Tp2 &&>>> {
    using type = __common_ref<Tp1 &, Tp2 &&>;
};

template <typename Tp1, typename Tp2>
struct __common_reference_impl<Tp1 &&, Tp2 &, 1,
                               std::void_t<__common_ref<Tp1 &&, Tp2 &>>> {
    using type = __common_ref<Tp1 &&, Tp2 &>;
};

// Otherwise, if basic_common_reference<...>::type is well-formed, ...
template <typename Tp1, typename Tp2>
struct __common_reference_impl<Tp1, Tp2, 2, std::void_t<__basic_common_ref<Tp1, Tp2>>> {
    using type = __basic_common_ref<Tp1, Tp2>;
};

// Otherwise, if COND-RES(T1, T2) is well-formed, ...
template <typename Tp1, typename Tp2>
struct __common_reference_impl<Tp1, Tp2, 3, std::void_t<__cond_res<Tp1, Tp2>>> {
    using type = __cond_res<Tp1, Tp2>;
};

// Otherwise, if common_type_t<T1, T2> is well-formed, ...
template <typename Tp1, typename Tp2>
struct __common_reference_impl<Tp1, Tp2, 4, std::void_t<std::common_type_t<Tp1, Tp2>>> {
    using type = std::common_type_t<Tp1, Tp2>;
};

// Otherwise, there shall be no member type.
template <typename Tp1, typename Tp2>
struct __common_reference_impl<Tp1, Tp2, 5, void> {};

// Otherwise, if sizeof...(T) is greater than two, ...
template <typename Tp1, typename Tp2, typename... Rest>
struct common_reference<Tp1, Tp2, Rest...>
    : common_reference<common_reference_t<Tp1, Tp2>, Rest...> {};

template <typename Enum>
WJR_CONST constexpr std::underlying_type_t<Enum> to_underlying(Enum e) noexcept {
    return static_cast<std::underlying_type_t<Enum>>(e);
}

#define __WJR_INDEXS_RANGE_I(START, END)                                                 \
    WJR_PP_QUEUE_POP_FRONT_N((WJR_PP_IOTA(END)), START)

#define WJR__INDEXS_RANGE(START, END)                                                    \
    WJR_PP_QUEUE_EXPAND(__WJR_INDEXS_RANGE_I(START, END))

#define __WJR_CASES_RANGE_CALLBACK(x) case (x):

#define WJR_CASES_RANGE(START, END)                                                      \
    WJR_PP_QUEUE_PUT(WJR_PP_QUEUE_TRANSFORM(__WJR_INDEXS_RANGE_I(START, END),            \
                                            __WJR_CASES_RANGE_CALLBACK))

} // namespace wjr

#endif // ! WJR_TYPE_TRAITS_HPP__

namespace wjr {

template <typename Iter>
using iterator_difference_t = typename std::iterator_traits<Iter>::difference_type;

template <typename Iter>
using iterator_value_t = typename std::iterator_traits<Iter>::value_type;

template <typename Iter>
using iterator_reference_t = typename std::iterator_traits<Iter>::reference;

template <typename Iter>
using iterator_pointer_t = typename std::iterator_traits<Iter>::pointer;

template <typename Iter>
using iterator_category_t = typename std::iterator_traits<Iter>::iterator_category;

template <typename T>
using iterator_common_reference_t =
    common_reference_t<iterator_reference_t<T>, iterator_value_t<T> &>;

template <typename In, typename = void>
struct __is_indirectly_readable_impl : std::false_type {};

// template <typename In>
// struct __is_indirectly_readable_impl<In, std::void_t<
// >> : std::true_type {};

template <typename Iter, typename = void>
struct __is_iterator_impl : std::false_type {};

template <typename Iter>
struct __is_iterator_impl<
    Iter, std::void_t<typename std::iterator_traits<Iter>::iterator_category>>
    : std::true_type {};

template <typename Iter>
struct is_iterator : __is_iterator_impl<Iter> {};

template <typename Iter>
inline constexpr bool is_iterator_v = is_iterator<Iter>::value;

/// @private
template <typename Iter, typename Category, typename = void>
struct __is_category_iterator_impl : std::false_type {};

/// @private
template <typename Iter, typename Category>
struct __is_category_iterator_impl<
    Iter, Category, std::void_t<typename std::iterator_traits<Iter>::iterator_category>>
    : std::is_base_of<Category, iterator_category_t<Iter>> {};

template <typename Iter>
struct is_input_iterator : __is_category_iterator_impl<Iter, std::input_iterator_tag> {};

template <typename Iter>
inline constexpr bool is_input_iterator_v = is_input_iterator<Iter>::value;

template <typename Iter>
struct is_output_iterator : __is_category_iterator_impl<Iter, std::output_iterator_tag> {
};

template <typename Iter>
inline constexpr bool is_output_iterator_v = is_output_iterator<Iter>::value;

template <typename Iter>
struct is_forward_iterator
    : __is_category_iterator_impl<Iter, std::forward_iterator_tag> {};

template <typename Iter>
inline constexpr bool is_forward_iterator_v = is_forward_iterator<Iter>::value;

template <typename Iter>
struct is_bidirectional_iterator
    : __is_category_iterator_impl<Iter, std::bidirectional_iterator_tag> {};

template <typename Iter>
inline constexpr bool is_bidirectional_iterator_v =
    is_bidirectional_iterator<Iter>::value;

template <typename Iter>
struct is_random_access_iterator
    : __is_category_iterator_impl<Iter, std::random_access_iterator_tag> {};

template <typename Iter>
inline constexpr bool is_random_access_iterator_v =
    is_random_access_iterator<Iter>::value;

/// @private
template <typename Iter>
struct __is_contiguous_iterator_impl
    : std::disjunction<std::is_pointer<Iter>, std::is_array<Iter>> {};

/// @private
template <typename Iter>
struct __is_contiguous_iterator_impl<std::move_iterator<Iter>>
    : std::conjunction<__is_contiguous_iterator_impl<Iter>,
                       std::is_trivial<iterator_value_t<Iter>>> {};

#if defined(WJR_CXX_20)
template <typename Iter>
struct is_contiguous_iterator
    : std::bool_constant<std::contiguous_iterator<Iter> ||
                         __is_contiguous_iterator_impl<Iter>::value> {};
#else
template <typename Iter>
struct is_contiguous_iterator : __is_contiguous_iterator_impl<Iter> {};
#endif

template <typename Iter>
inline constexpr bool is_contiguous_iterator_v = is_contiguous_iterator<Iter>::value;

template <typename Iter, WJR_REQUIRES(is_contiguous_iterator_v<Iter>)>
using iterator_contiguous_value_t = std::remove_reference_t<iterator_reference_t<Iter>>;

template <typename Iter, WJR_REQUIRES(is_contiguous_iterator_v<Iter>)>
using iterator_contiguous_pointer_t =
    std::add_pointer_t<iterator_contiguous_value_t<Iter>>;

#if WJR_DEBUG_LEVEL > 1
#define WJR_HAS_DEBUG_CONTIGUOUS_ITERATOR_CHECK WJR_HAS_DEF
#endif

} // namespace wjr

#endif // WJR_ITERATOR_DETAIL_HPP__

namespace wjr {

WJR_REGISTER_HAS_TYPE(pointer_traits_to_address,
                      std::pointer_traits<Ptr>::to_address(std::declval<const Ptr &>()),
                      Ptr);

WJR_REGISTER_HAS_TYPE(pointer_access, std::declval<const Ptr &>().operator->(), Ptr);

template <typename T>
constexpr T *to_address(T *p) noexcept {
    static_assert(!std::is_function_v<T>, "T cannot be a function.");
    return p;
}

/**
 * @details If std::pointer_traits<remove_cvref_t<Ptr>>::to_address(p) is valid, return
 * std::pointer_traits<remove_cvref_t<Ptr>>::to_address(p), otherwise return
 * to_address(p.operator->()).
 */
template <typename Ptr>
constexpr auto to_address(const Ptr &p) noexcept {
    if constexpr (has_pointer_traits_to_address_v<remove_cvref_t<Ptr>>) {
        return std::pointer_traits<remove_cvref_t<Ptr>>::to_address(p);
    } else {
        return wjr::to_address(p.operator->());
    }
}

/**
 * @return to_address(p.base()).
 *
 */
template <typename Iter>
constexpr auto to_address(const std::move_iterator<Iter> &p) noexcept {
    return wjr::to_address(p.base());
}

/**
 * @brief Return to_address(p) if p is a contiguous iterator and contiguouse iterato check
 * is disabled, otherwise return p.
 *
 */
template <typename T>
constexpr decltype(auto) to_contiguous_address(T &&t) noexcept {
#if !WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
    if constexpr (is_contiguous_iterator_v<remove_cvref_t<T>>) {
        return wjr::to_address(std::forward<T>(t));
    } else {
#endif
        return std::forward<T>(t);
#if !WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
    }
#endif
}

/// @private
class __is_little_endian_helper {
    constexpr static std::uint32_t u4 = 1;
    constexpr static std::uint8_t u1 = static_cast<const std::uint8_t &>(u4);

public:
    constexpr static bool value = u1 != 0;
};

// constexpr endian
enum class endian {
    little = 0,
    big = 1,
    native = __is_little_endian_helper::value ? little : big,
};

inline constexpr bool is_little_endian = endian::native == endian::little;
inline constexpr bool is_big_endian = !is_little_endian;

static_assert(is_little_endian, "Big endian has not been tested.");

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR T fallback_byteswap(T x) noexcept {
    constexpr auto digits = std::numeric_limits<T>::digits;
    const auto val = static_cast<uint_t<digits>>(x);
    if constexpr (digits == 8) {
        return val;
    } else if constexpr (digits == 16) {
        return (val >> 8) | (val << 8);
    } else if constexpr (digits == 32) {
        return ((val >> 24) & 0xff) | ((val >> 8) & 0xff00) | ((val << 8) & 0xff0000) |
               ((val << 24));
    } else if constexpr (digits == 64) {
        return ((val >> 56) & 0xff) | ((val >> 40) & 0xff00) | ((val >> 24) & 0xff0000) |
               ((val >> 8) & 0xff000000) | ((val << 8) & 0xff00000000) |
               ((val << 24) & 0xff0000000000) | ((val << 40) & 0xff000000000000) |
               ((val << 56));
    } else {
        static_assert(digits <= 64, "Unsupported bit width");
    }
}

#if WJR_HAS_BUILTIN(__builtin_bswap16)
#define WJR_HAS_BUILTIN_BYTESWAP WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(BYTESWAP)

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 T builtin_byteswap(T x) noexcept {
    constexpr auto digits = std::numeric_limits<T>::digits;
    auto val = static_cast<uint_t<digits>>(x);
    if constexpr (digits == 8) {
        return val;
    } else if constexpr (digits == 16) {
        return __builtin_bswap16(val);
    } else if constexpr (digits == 32) {
        return __builtin_bswap32(val);
    } else if constexpr (digits == 64) {
        return __builtin_bswap64(val);
    } else {
        static_assert(digits <= 64, "Unsupported bit width");
    }
}

#endif

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 T byteswap(T x, endian to = endian::little) noexcept {
    if (to == endian::native) {
        return x;
    }

#if WJR_HAS_BUILTIN(BYTESWAP)
    if (is_constant_evaluated() || WJR_BUILTIN_CONSTANT_P(x)) {
        return fallback_byteswap(x);
    }

    return builtin_byteswap(x);
#else
    return fallback_byteswap(x);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_INLINE T read_memory(const void *ptr,
                                            endian to = endian::little) noexcept {
    T x;
    std::memcpy(&x, ptr, sizeof(T));

    if (to != endian::native) {
        x = byteswap(x);
    }

    return x;
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_INLINE void write_memory(void *ptr, T x,
                                       endian to = endian::little) noexcept {
    if (to != endian::native) {
        x = byteswap(x);
    }

    std::memcpy(ptr, &x, sizeof(T));
}

template <class Pointer, class SizeType = std::size_t>
struct allocation_result {
    Pointer ptr;
    SizeType count;
};

WJR_REGISTER_HAS_TYPE(
    allocate_at_least,
    std::declval<Allocator>().allocate_at_least(std::declval<SizeType>()), Allocator,
    SizeType);

template <typename Allocator, typename SizeType,
          typename Pointer = typename std::allocator_traits<Allocator>::pointer>
WJR_NODISCARD auto allocate_at_least(Allocator &alloc, SizeType count) {
    if constexpr (has_allocate_at_least_v<Allocator, SizeType>) {
        return alloc.allocate_at_least(count);
    } else {
        const auto ptr = std::allocator_traits<Allocator>::allocate(alloc, count);
        return allocation_result<decltype(ptr), SizeType>{ptr, count};
    }
}

} // namespace wjr

#endif // WJR_MEMORY_DETAIL_HPP__
// Already included

#ifndef WJR_MATH_PREFIX_XOR_HPP__
#define WJR_MATH_PREFIX_XOR_HPP__

// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_PREFIX_XOR_HPP__
#define WJR_X86_MATH_PREFIX_XOR_HPP__

// Already included
#ifndef WJR_X86_SIMD_SIMD_HPP__
#define WJR_X86_SIMD_SIMD_HPP__

#ifndef WJR_X86_SIMD_AVX_HPP__
#define WJR_X86_SIMD_AVX_HPP__

#ifndef WJR_X86_SIMD_SSE_HPP__
#define WJR_X86_SIMD_SSE_HPP__

#ifndef WJR_X86_SIMD_SIMD_CAST_HPP__
#define WJR_X86_SIMD_SIMD_CAST_HPP__

#include <cstdint>

#ifndef WJR_SIMD_DETAIL_HPP__
#define WJR_SIMD_DETAIL_HPP__

#ifndef WJR_SIMD_SIMD_CAST_HPP__
#define WJR_SIMD_SIMD_CAST_HPP__

namespace wjr {

template <typename From, typename To>
struct simd_cast_fn;

template <typename From, typename To>
inline constexpr simd_cast_fn<From, To> simd_cast;

} // namespace wjr

#endif // WJR_SIMD_SIMD_CAST_HPP__
#ifndef WJR_SIMD_SIMD_MASK_HPP__
#define WJR_SIMD_SIMD_MASK_HPP__

#ifndef WJR_ASSERT_HPP__
#define WJR_ASSERT_HPP__

/**
 * @file assert.hpp
 * @author wjr
 * @brief Assertion utilities
 *
 * @details WJR_DEBUG_LEVEL : 0 ~ 3 \n
 * 0 : Release \n
 * 1 : Beta \n
 * 2 : Runtime detect \n
 * 3 : Maximize runtime detect, for debug \n
 * If WJR_DEBUG_LEVEL is not defined, \n
 * If NDEBUG is defined, WJR_DEBUG_LEVEL is set to 0 by default. \n
 * Otherwise, WJR_DEBUG_LEVEL is set to 1 by default. \n
 * WJR_ASSERT_L(level, expr) : Specify the level of assertion, \n
 * if the WJR_DEBUG_LEVEL is greater than or equal to the level, \n
 * the assertion is executed. \n
 * WJR_ASSERT(expr) : Equivalent to WJR_ASSERT_L(1, expr) \n
 * WJR_ASSERT_0(expr) : Always execute the assertion \n
 *
 * @version 0.1
 * @date 2024-06-01
 *
 * @copyright Copyright (c) 2024
 *
 */

#include <iostream>

// Already included

#ifndef WJR_DEBUG_LEVEL
#if defined(NDEBUG)
#define WJR_DEBUG_LEVEL 0
#else
#define WJR_DEBUG_LEVEL 1
#endif
#endif

#if WJR_DEBUG_LEVEL < 0 || WJR_DEBUG_LEVEL > 3
#error "WJR_DEBUG_LEVEL must be 0 ~ 3"
#endif

namespace wjr {

#define WJR_DEBUG_IF(level, expr0, expr1)                                                \
    WJR_PP_BOOL_IF(WJR_PP_GT(WJR_DEBUG_LEVEL, level), expr0, expr1)

WJR_NORETURN extern void __assert_failed(const char *expr, const char *file,
                                         const char *func, int line) noexcept;

// LCOV_EXCL_START

/// @private
template <typename... Args>
WJR_NOINLINE void __assert_handler(const char *expr, const char *file, const char *func,
                                   int line, Args &&...args) noexcept {
    std::cerr << "Additional information: ";
    (void)(std::cerr << ... << std::forward<Args>(args));
    std::cerr << '\n';
    __assert_failed(expr, file, func, line);
}

/// @private
inline void __assert_handler(const char *expr, const char *file, const char *func,
                             int line) noexcept {
    __assert_failed(expr, file, func, line);
}

// LCOV_EXCL_STOP

#define WJR_ASSERT_CHECK_I(expr, ...)                                                    \
    do {                                                                                 \
        if (WJR_UNLIKELY(!(expr))) {                                                     \
            ::wjr::__assert_handler(#expr, WJR_FILE, WJR_CURRENT_FUNCTION, WJR_LINE,     \
                                    ##__VA_ARGS__);                                      \
        }                                                                                \
    } while (0)

// do nothing
#define WJR_ASSERT_UNCHECK_I(expr, ...)                                                  \
    do {                                                                                 \
    } while (0)

// level = [0, 2]
// The higher the level, the less likely it is to be detected
// Runtime detect  : 1
// Maximize detect : 2
#define WJR_ASSERT_L(level, ...)                                                         \
    WJR_DEBUG_IF(level, WJR_ASSERT_CHECK_I, WJR_ASSERT_UNCHECK_I)                        \
    (__VA_ARGS__)

// level of assert is zero at default.
#define WJR_ASSERT_L0(...) WJR_ASSERT_CHECK_I(__VA_ARGS__)
#define WJR_ASSERT_L1(...) WJR_ASSERT_L(1, __VA_ARGS__)
#define WJR_ASSERT_L2(...) WJR_ASSERT_L(2, __VA_ARGS__)
#define WJR_ASSERT_L3(...) WJR_ASSERT_L(3, __VA_ARGS__)
#define WJR_ASSERT(...) WJR_ASSERT_L1(__VA_ARGS__)

#define WJR_ASSERT_ASSUME_L(level, ...)                                                  \
    WJR_ASSERT_L(level, __VA_ARGS__);                                                    \
    __WJR_ASSERT_ASSUME_L_ASSUME(__VA_ARGS__)
#define __WJR_ASSERT_ASSUME_L_ASSUME(expr, ...) WJR_ASSUME(expr)

#define WJR_ASSERT_ASSUME_L0(...) WJR_ASSERT_ASSUME_L(0, __VA_ARGS__)
#define WJR_ASSERT_ASSUME_L1(...) WJR_ASSERT_ASSUME_L(1, __VA_ARGS__)
#define WJR_ASSERT_ASSUME_L2(...) WJR_ASSERT_ASSUME_L(2, __VA_ARGS__)
#define WJR_ASSERT_ASSUME_L3(...) WJR_ASSERT_ASSUME_L(3, __VA_ARGS__)
#define WJR_ASSERT_ASSUME(...) WJR_ASSERT_ASSUME_L1(__VA_ARGS__)

} // namespace wjr

#endif // WJR_ASSERT_HPP__
#ifndef WJR_MATH_CLZ_HPP__
#define WJR_MATH_CLZ_HPP__

// Already included
#ifndef WJR_MATH_POPCOUNT_HPP__
#define WJR_MATH_POPCOUNT_HPP__

#ifndef WJR_MATH_DETAIL_HPP__
#define WJR_MATH_DETAIL_HPP__

// Already included

namespace wjr {

/**
 * @brief
 *
 * @note `n & -n` is the lowest bit of n.
 */
template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr T lowbit(T n) noexcept {
    return n & -n;
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr T clear_lowbit(T n) noexcept {
    return n & (n - 1);
}

// preview :

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr bool is_zero_or_single_bit(T n) noexcept {
    return (n & (n - 1)) == 0;
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr bool __has_high_bit(T n) noexcept {
    return n >> (std::numeric_limits<T>::digits - 1);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr T __ceil_div(T n, type_identity_t<T> div) noexcept {
    return (n + div - 1) / div;
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr T __align_down(T n, type_identity_t<T> alignment) noexcept {
    WJR_ASSERT_ASSUME_L2(is_zero_or_single_bit(alignment));
    return n & (-alignment);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr T __align_down_offset(T n, type_identity_t<T> alignment) noexcept {
    WJR_ASSERT_ASSUME_L2(is_zero_or_single_bit(alignment));
    return n & (alignment - 1);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr T __align_up(T n, type_identity_t<T> alignment) noexcept {
    WJR_ASSERT_ASSUME_L2(is_zero_or_single_bit(alignment));
    return (n + alignment - 1) & (-alignment);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr T __align_up_offset(T n, type_identity_t<T> alignment) noexcept {
    WJR_ASSERT_ASSUME_L2(is_zero_or_single_bit(alignment));
    return (-n) & (alignment - 1);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST constexpr std::make_signed_t<T> __fasts_from_unsigned(T x) noexcept {
    const std::make_signed_t<T> ret = x;
    WJR_ASSERT_ASSUME_L2(ret >= 0, "overflow");
    return ret;
}

template <typename T, typename U = std::make_unsigned_t<T>,
          WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
WJR_CONST constexpr U __fasts_abs(T x) noexcept {
    return static_cast<U>(x < 0 ? -x : x);
}

template <typename T, WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
WJR_CONST constexpr T __fasts_negate(T x) noexcept {
    return -x;
}

template <typename T, typename U = std::make_unsigned_t<T>,
          WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
WJR_CONST constexpr T __fasts_conditional_negate(bool condition, T x) noexcept {
    return condition ? -x : x;
}

template <typename T, typename U = std::make_unsigned_t<T>,
          WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
WJR_CONST constexpr T __fasts_negate_with(T condition, T x) noexcept {
    return __fasts_conditional_negate(condition < 0, x);
}

template <typename T, WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
WJR_CONST constexpr T __fasts_increment(T x) noexcept {
    WJR_ASSERT_L2(x != std::numeric_limits<T>::min() &&
                      x != std::numeric_limits<T>::max(),
                  "overflow");

    return x < 0 ? x - 1 : x + 1;
}

template <typename T, WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
WJR_CONST constexpr T __fasts_decrement(T x) noexcept {
    WJR_ASSERT_L2(x != 0 && x + 1 != T(0), "overflow");

    return x < 0 ? x + 1 : x - 1;
}

template <typename T, WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
WJR_CONST constexpr T __fasts_add(T x, std::make_unsigned_t<T> y) noexcept {
    return x < 0 ? x - y : x + y;
}

template <typename T, WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
WJR_CONST constexpr T __fasts_sub(T x, std::make_unsigned_t<T> y) noexcept {
    return x < 0 ? x + y : x - y;
}

} // namespace wjr

#endif // WJR_MATH_DETAIL_HPP__

#if WJR_HAS_SIMD(POPCNT)

#if WJR_HAS_BUILTIN(__builtin_popcount)
#define WJR_HAS_BUILTIN_POPCOUNT WJR_HAS_DEF
#elif defined(WJR_COMPILER_MSVC)
#define WJR_HAS_BUILTIN_POPCOUNT WJR_HAS_DEF_VAR(2)
#endif

#if WJR_HAS_BUILTIN(POPCOUNT) == 2
#ifndef WJR_X86_SIMD_INTRIN_HPP__
#define WJR_X86_SIMD_INTRIN_HPP__

// Already included

#if defined(_MSC_VER)
/* Microsoft C/C++-compatible compiler */
#include <intrin.h>
#elif defined(__GNUC__)
/* GCC-compatible compiler, targeting x86/x86-64 */
#include <x86intrin.h>
#endif

#endif // WJR_X86_SIMD_INTRIN_HPP__
#endif

#endif

namespace wjr {

#if !WJR_HAS_BUILTIN(POPCOUNT)

namespace math_detail {

template <typename T, T seed>
class de_bruijn {
public:
    constexpr static uint8_t digits = std::numeric_limits<T>::digits;
    constexpr static uint8_t mv = digits == 32 ? 27 : 58;
    constexpr de_bruijn() noexcept : lookup(), lookupr() { initialize(); }

    constexpr int get(T idx) const noexcept { return lookup[(idx * seed) >> mv]; }
    constexpr int getr(T idx) const noexcept { return lookupr[(idx * seed) >> mv]; }

private:
    constexpr void initialize() noexcept {
        for (uint8_t i = 0; i < digits; ++i) {
            const auto idx = (seed << i) >> mv;
            lookup[idx] = i;
            lookupr[idx] = i == 0 ? 0u : digits - i;
        }
    }

    uint8_t lookup[digits];
    uint8_t lookupr[digits];
};

inline constexpr de_bruijn<uint32_t, 0x077C'B531> de_bruijn32 = {};
inline constexpr de_bruijn<uint64_t, 0x03f7'9d71'b4ca'8b09> de_bruijn64 = {};

} // namespace math_detail

#endif

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR int fallback_popcount(T x) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    if constexpr (nd < 32) {
        return fallback_popcount(static_cast<uint32_t>(x));
    } else {
        if constexpr (nd == 32) {
            x -= (x >> 1) & 0x5555'5555;
            x = (x & 0x3333'3333) + ((x >> 2) & 0x3333'3333);
            x = (x + (x >> 4)) & 0x0f0f'0f0f;
            return (x * 0x0101'0101) >> 24;
        } else {
            x -= (x >> 1) & 0x5555'5555'5555'5555;
            x = (x & 0x3333'3333'3333'3333) + ((x >> 2) & 0x3333'3333'3333'3333);
            x = (x + (x >> 4)) & 0x0f0f'0f0f'0f0f'0f0f;
            return (x * 0x0101'0101'0101'0101) >> 56;
        }
    }
}

#if WJR_HAS_BUILTIN(POPCOUNT)

template <typename T>
WJR_CONST WJR_INTRINSIC_INLINE int builtin_popcount(T x) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
#if WJR_HAS_BUILTIN(POPCOUNT) == 1
    if constexpr (nd < 32) {
        return builtin_popcount(static_cast<uint32_t>(x));
    } else {
        if constexpr (nd <= std::numeric_limits<unsigned int>::digits) {
            return __builtin_popcount(x);
        } else if constexpr (nd <= std::numeric_limits<unsigned long>::digits) {
            return __builtin_popcountl(x);
        } else if constexpr (nd <= std::numeric_limits<unsigned long long>::digits) {
            return __builtin_popcountll(x);
        } else {
            static_assert(nd <= 64, "not support yet");
        }
    }
#else
    if constexpr (nd < 32) {
        return builtin_popcount(static_cast<uint32_t>(x));
    } else {
        if constexpr (nd <= 32) {
            return static_cast<int>(__popcnt(x));
        } else if constexpr (nd <= 64) {
            return static_cast<int>(__popcnt64(x));
        } else {
            static_assert(nd <= 64, "not support yet");
        }
    }

#endif // WJR_HAS_BUILTIN(POPCOUNT)
}

#endif

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int popcount_impl(T x) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(is_zero_or_single_bit(x))) {
        return x != 0;
    }

#if WJR_HAS_BUILTIN(POPCOUNT)
    if (is_constant_evaluated() || WJR_BUILTIN_CONSTANT_P(x)) {
        return fallback_popcount(x);
    }

    return builtin_popcount(x);
#else
    return fallback_popcount(x);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int popcount(T x) noexcept {
    const int ret = popcount_impl(x);
    WJR_ASSUME(0 <= ret && ret <= std::numeric_limits<T>::digits);
    return ret;
}

} // namespace wjr

#endif // WJR_MATH_POPCOUNT_HPP__

#if WJR_HAS_BUILTIN(__builtin_clz)
#define WJR_HAS_BUILTIN_CLZ WJR_HAS_DEF
#elif defined(WJR_MSVC) && defined(WJR_X86)
#define WJR_HAS_BUILTIN_CLZ WJR_HAS_DEF_VAR(2)
#endif

#if WJR_HAS_BUILTIN(CLZ) == 2
// Already included
#endif

namespace wjr {

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR int constexpr_clz(T x) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;

    x |= (x >> 1);
    x |= (x >> 2);
    x |= (x >> 4);

    if constexpr (nd >= 16) {
        x |= (x >> 8);
    }

    if constexpr (nd >= 32) {
        x |= (x >> 16);
    }

    if constexpr (nd >= 64) {
        x |= (x >> 32);
    }

    return fallback_popcount(~x);
}

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int fallback_clz(T x) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;

#if !WJR_HAS_BUILTIN(POPCOUNT)
    if constexpr (nd >= 32) {
#endif
        x |= (x >> 1);
        x |= (x >> 2);
        x |= (x >> 4);

        if constexpr (nd >= 16) {
            x |= (x >> 8);
        }

        if constexpr (nd >= 32) {
            x |= (x >> 16);
        }

        if constexpr (nd >= 64) {
            x |= (x >> 32);
        }
#if !WJR_HAS_BUILTIN(POPCOUNT)
    }
#endif

#if WJR_HAS_BUILTIN(POPCOUNT)
    return popcount<T>(~x);
#else
    if constexpr (nd < 32) {
        return fallback_clz(static_cast<uint32_t>(x)) - (32 - nd);
    } else {
        ++x;

        if constexpr (nd <= 32) {
            return math_detail::de_bruijn32.getr(x);
        } else if constexpr (nd <= 64) {
            return math_detail::de_bruijn64.getr(x);
        } else {
            static_assert(nd <= 64, "not support yet");
        }
    }
#endif
}

#if WJR_HAS_BUILTIN(CLZ)

template <typename T>
WJR_CONST WJR_INTRINSIC_INLINE int builtin_clz(T x) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    if constexpr (nd < 32) {
        return builtin_clz(static_cast<uint32_t>(x)) - (32 - nd);
    } else {
#if WJR_HAS_BUILTIN(CLZ) == 1
        if constexpr (nd <= std::numeric_limits<unsigned int>::digits) {
            constexpr auto delta = std::numeric_limits<unsigned int>::digits - nd;
            return __builtin_clz(static_cast<unsigned int>(x)) - delta;
        } else if constexpr (nd <= std::numeric_limits<unsigned long>::digits) {
            constexpr auto delta = std::numeric_limits<unsigned long>::digits - nd;
            return __builtin_clzl(static_cast<unsigned long>(x)) - delta;
        } else if constexpr (nd <= std::numeric_limits<unsigned long long>::digits) {
            constexpr auto delta = std::numeric_limits<unsigned long long>::digits - nd;
            return __builtin_clzll(static_cast<unsigned long long>(x)) - delta;
        } else {
            static_assert(nd <= 64, "not supported yet");
        }
#else
        if constexpr (nd == 32) {
            unsigned long result;
            (void)_BitScanReverse(&result, x);
            return 31 - result;
        } else {
            unsigned long result;
            (void)_BitScanReverse64(&result, x);
            return 63 - result;
        }
#endif
    }
}

#endif

/**
 * @brief Fast count leading zeros
 *
 * @tparam T Must be an unsigned integral type
 */
template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int clz(T x) noexcept {
#if WJR_HAS_BUILTIN(CLZ)
    if (is_constant_evaluated() || WJR_BUILTIN_CONSTANT_P(x)) {
        return fallback_clz(x);
    }

    return builtin_clz(x);
#else
    return fallback_clz(x);
#endif
}

} // namespace wjr

#endif // WJR_MATH_CLZ_HPP__
#ifndef WJR_MATH_CTZ_HPP__
#define WJR_MATH_CTZ_HPP__

// Already included
// Already included

#if WJR_HAS_BUILTIN(__builtin_ctz)
#define WJR_HAS_BUILTIN_CTZ WJR_HAS_DEF
#elif defined(WJR_MSVC) && defined(WJR_X86)
#define WJR_HAS_BUILTIN_CTZ WJR_HAS_DEF_VAR(2)
#endif

#if WJR_HAS_BUILTIN(CTZ) == 2
// Already included
#endif

namespace wjr {

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR int constexpr_ctz(T x) noexcept {
    return fallback_popcount<T>(lowbit(x) - 1);
}

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int fallback_ctz(T x) noexcept {
#if WJR_HAS_BUILTIN(POPCOUNT)
    return popcount<T>(lowbit(x) - 1);
#else
    constexpr auto nd = std::numeric_limits<T>::digits;

    if constexpr (nd < 32) {
        return fallback_ctz(static_cast<uint32_t>(x));
    } else {
        x = lowbit(x);

        if constexpr (nd <= 32) {
            return math_detail::de_bruijn32.get(x);
        } else if constexpr (nd <= 64) {
            return math_detail::de_bruijn64.get(x);
        } else {
            static_assert(nd <= 64, "not support yet");
        }
    }
#endif //
}

#if WJR_HAS_BUILTIN(CTZ)

template <typename T>
WJR_CONST WJR_INTRINSIC_INLINE int builtin_ctz(T x) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;

    if constexpr (nd < 32) {
        return builtin_ctz(static_cast<uint32_t>(x));
    } else {
#if WJR_HAS_BUILTIN(CTZ) == 1
        if constexpr (nd <= std::numeric_limits<unsigned int>::digits) {
            return __builtin_ctz(static_cast<unsigned int>(x));
        } else if constexpr (nd <= std::numeric_limits<unsigned long>::digits) {
            return __builtin_ctzl(static_cast<unsigned long>(x));
        } else if constexpr (nd <= std::numeric_limits<unsigned long long>::digits) {
            return __builtin_ctzll(static_cast<unsigned long long>(x));
        } else {
            static_assert(nd <= 64, "not supported yet");
        }
#else
        if constexpr (nd == 32) {
            unsigned long result;
            (void)_BitScanForward(&result, x);
            return result;
        } else {
            unsigned long result;
            (void)_BitScanForward64(&result, x);
            return result;
        }
#endif
    }
}

#endif

/**
 * @brief Fast count trailing zeros
 *
 * @details Very fast even on non-optimized platforms by using a De Bruijn sequence. \n
 * Try __builtin_clz if available, otherwise fallback to a portable implementation. \n
 * In fallback_clz, use popcount and lowbit if POPCOUNT and POPCNT are available, make
 * sure popcount is fast. \n
 * Then use De Bruijn sequence, just a bit slower than popcount + lowbit.
 *
 * @tparam T Must be an unsigned integral type
 */
template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int ctz(T x) noexcept {
#if WJR_HAS_BUILTIN(CTZ)
    if (is_constant_evaluated() || WJR_BUILTIN_CONSTANT_P(x)) {
        return fallback_ctz(x);
    }

    return builtin_ctz(x);
#else
    return fallback_ctz(x);
#endif
}

} // namespace wjr

#endif // WJR_MATH_CTZ_HPP__
// Already included

namespace wjr::simd_detail {

template <typename T, size_t Size, size_t BitWidth>
class basic_simd_mask {
    using mask_type = uint_t<BitWidth>;
    constexpr static size_t __mask_bits = BitWidth / Size;
    constexpr static mask_type __half_mask =
        static_cast<uint_t<BitWidth / 2>>(in_place_max);
    constexpr static mask_type __full_mask = in_place_max;

public:
    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(basic_simd_mask);

    constexpr basic_simd_mask(mask_type mask) noexcept : m_mask(mask) {}

    WJR_PURE WJR_CONSTEXPR20 int clz() const noexcept {
        WJR_ASSERT_ASSUME(m_mask != 0);

        if constexpr (Size == 2) {
            constexpr auto high_mask = __half_mask << (BitWidth / 2);

            return (m_mask & high_mask) ? 0 : 1;
        } else {
            return ::wjr::clz(m_mask) / __mask_bits;
        }
    }

    WJR_PURE WJR_CONSTEXPR20 int ctz() const noexcept {
        WJR_ASSERT_ASSUME(m_mask != 0);

        if constexpr (Size == 2) {
            constexpr auto low_mask = __half_mask;

            return (m_mask & low_mask) ? 0 : 1;
        } else {
            return ::wjr::ctz(m_mask) / __mask_bits;
        }
    }

    WJR_PURE constexpr bool all() const noexcept { return m_mask == __full_mask; }

private:
    mask_type m_mask;
};

} // namespace wjr::simd_detail

#endif // WJR_SIMD_SIMD_MASK_HPP__

namespace wjr {

namespace simd_abi {

template <size_t N>
struct fixed_size {};

} // namespace simd_abi

struct element_aligned_t {};
inline constexpr element_aligned_t element_aligned{};

struct vector_aligned_t {};
inline constexpr vector_aligned_t vector_aligned{};

template <typename T, typename Abi>
class simd;

template <typename T, size_t N>
using fixed_size_simd = simd<T, simd_abi::fixed_size<N>>;

} // namespace wjr

#endif // WJR_SIMD_DETAIL_HPP__
// Already included

namespace wjr {

// simd type can't be directly used on template
template <typename T>
struct simd_wrapper {
    using type = T;
};

template <typename T>
using simd_wrapper_t = typename simd_wrapper<T>::type;

#if WJR_HAS_SIMD(SSE)

struct __m128_t {
    using type = __m128;
};

#endif // SSE

#if WJR_HAS_SIMD(SSE2)

struct __m128i_t {
    using type = __m128i;
};

struct __m128d_t {
    using type = __m128d;
};

template <>
struct simd_cast_fn<__m128_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(__m128 v) const {
        return _mm_castps_si128(v);
    }
};

template <>
struct simd_cast_fn<__m128_t, __m128d_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128d operator()(__m128 v) const {
        return _mm_castps_pd(v);
    }
};

template <>
struct simd_cast_fn<__m128i_t, __m128_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128 operator()(__m128i v) const {
        return _mm_castsi128_ps(v);
    }
};

template <>
struct simd_cast_fn<__m128i_t, __m128d_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128d operator()(__m128i v) const {
        return _mm_castsi128_pd(v);
    }
};

template <>
struct simd_cast_fn<__m128d_t, __m128_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128 operator()(__m128d v) const {
        return _mm_castpd_ps(v);
    }
};

template <>
struct simd_cast_fn<__m128d_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(__m128d v) const {
        return _mm_castpd_si128(v);
    }
};

template <>
struct simd_cast_fn<int8_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(int8_t v) const {
        return _mm_cvtsi32_si128(v);
    }
};

template <>
struct simd_cast_fn<uint8_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(uint8_t v) const {
        return _mm_cvtsi32_si128(v);
    }
};

template <>
struct simd_cast_fn<__m128i_t, int8_t> {
    WJR_CONST WJR_INTRINSIC_INLINE int8_t operator()(__m128i v) const {
        return static_cast<int8_t>(_mm_cvtsi128_si32(v));
    }
};

template <>
struct simd_cast_fn<__m128i_t, uint8_t> {
    WJR_CONST WJR_INTRINSIC_INLINE uint8_t operator()(__m128i v) const {
        return static_cast<uint8_t>(_mm_cvtsi128_si32(v));
    }
};

template <>
struct simd_cast_fn<int16_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(int16_t v) const {
        return _mm_cvtsi32_si128(v);
    }
};

template <>
struct simd_cast_fn<uint16_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(uint16_t v) const {
        return _mm_cvtsi32_si128(v);
    }
};

template <>
struct simd_cast_fn<__m128i_t, int16_t> {
    WJR_CONST WJR_INTRINSIC_INLINE int16_t operator()(__m128i v) const {
        return static_cast<int16_t>(_mm_cvtsi128_si32(v));
    }
};

template <>
struct simd_cast_fn<__m128i_t, uint16_t> {
    WJR_CONST WJR_INTRINSIC_INLINE uint16_t operator()(__m128i v) const {
        return static_cast<uint16_t>(_mm_cvtsi128_si32(v));
    }
};

template <>
struct simd_cast_fn<int32_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(int32_t v) const {
        return _mm_cvtsi32_si128(v);
    }
};

template <>
struct simd_cast_fn<uint32_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(uint32_t v) const {
        return _mm_cvtsi32_si128(v);
    }
};

template <>
struct simd_cast_fn<__m128i_t, int32_t> {
    WJR_CONST WJR_INTRINSIC_INLINE int32_t operator()(__m128i v) const {
        return _mm_cvtsi128_si32(v);
    }
};

template <>
struct simd_cast_fn<__m128i_t, uint32_t> {
    WJR_CONST WJR_INTRINSIC_INLINE uint32_t operator()(__m128i v) const {
        return static_cast<uint32_t>(_mm_cvtsi128_si32(v));
    }
};

template <>
struct simd_cast_fn<int64_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(int64_t v) const {
        return _mm_cvtsi64_si128(v);
    }
};

template <>
struct simd_cast_fn<uint64_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(uint64_t v) const {
        return _mm_cvtsi64_si128(static_cast<int64_t>(v));
    }
};

template <>
struct simd_cast_fn<__m128i_t, int64_t> {
    WJR_CONST WJR_INTRINSIC_INLINE int64_t operator()(__m128i v) const {
        return _mm_cvtsi128_si64(v);
    }
};

template <>
struct simd_cast_fn<__m128i_t, uint64_t> {
    WJR_CONST WJR_INTRINSIC_INLINE uint64_t operator()(__m128i v) const {
        return static_cast<uint64_t>(_mm_cvtsi128_si64(v));
    }
};

#endif // SSE2

#if WJR_HAS_SIMD(AVX)

struct __m256_t {
    using type = __m256;
};

struct __m256i_t {
    using type = __m256i;
};

struct __m256d_t {
    using type = __m256d;
};

template <>
struct simd_cast_fn<__m256_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(__m256 v) const {
        return _mm256_castps_si256(v);
    }
};

template <>
struct simd_cast_fn<__m256_t, __m256d_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256d operator()(__m256 v) const {
        return _mm256_castps_pd(v);
    }
};

template <>
struct simd_cast_fn<__m256i_t, __m256_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256 operator()(__m256i v) const {
        return _mm256_castsi256_ps(v);
    }
};

template <>
struct simd_cast_fn<__m256i_t, __m256d_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256d operator()(__m256i v) const {
        return _mm256_castsi256_pd(v);
    }
};

template <>
struct simd_cast_fn<__m256d_t, __m256_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256 operator()(__m256d v) const {
        return _mm256_castpd_ps(v);
    }
};

template <>
struct simd_cast_fn<__m256d_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(__m256d v) const {
        return _mm256_castpd_si256(v);
    }
};

template <>
struct simd_cast_fn<__m128i_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(__m128i v) const {
        return _mm256_castsi128_si256(v);
    }
};

template <>
struct simd_cast_fn<__m256i_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(__m256i v) const {
        return _mm256_castsi256_si128(v);
    }
};

template <>
struct simd_cast_fn<int8_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(int8_t v) const {
        return simd_cast<__m128i_t, __m256i_t>(simd_cast<int8_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<uint8_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(uint8_t v) const {
        return simd_cast<__m128i_t, __m256i_t>(simd_cast<uint8_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<__m256i_t, int8_t> {
    WJR_CONST WJR_INTRINSIC_INLINE int8_t operator()(__m256i v) const {
        return simd_cast<__m128i_t, int8_t>(simd_cast<__m256i_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<__m256i_t, uint8_t> {
    WJR_CONST WJR_INTRINSIC_INLINE uint8_t operator()(__m256i v) const {
        return simd_cast<__m128i_t, uint8_t>(simd_cast<__m256i_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<int16_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(int16_t v) const {
        return simd_cast<__m128i_t, __m256i_t>(simd_cast<int16_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<uint16_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(uint16_t v) const {
        return simd_cast<__m128i_t, __m256i_t>(simd_cast<uint16_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<__m256i_t, int16_t> {
    WJR_CONST WJR_INTRINSIC_INLINE int16_t operator()(__m256i v) const {
        return simd_cast<__m128i_t, int16_t>(simd_cast<__m256i_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<__m256i_t, uint16_t> {
    WJR_CONST WJR_INTRINSIC_INLINE uint16_t operator()(__m256i v) const {
        return simd_cast<__m128i_t, uint16_t>(simd_cast<__m256i_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<int32_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(int32_t v) const {
        return simd_cast<__m128i_t, __m256i_t>(simd_cast<int32_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<uint32_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(uint32_t v) const {
        return simd_cast<__m128i_t, __m256i_t>(simd_cast<uint32_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<__m256i_t, int32_t> {
    WJR_CONST WJR_INTRINSIC_INLINE int32_t operator()(__m256i v) const {
        return simd_cast<__m128i_t, int32_t>(simd_cast<__m256i_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<__m256i_t, uint32_t> {
    WJR_CONST WJR_INTRINSIC_INLINE uint32_t operator()(__m256i v) const {
        return simd_cast<__m128i_t, uint32_t>(simd_cast<__m256i_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<int64_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(int64_t v) const {
        return simd_cast<__m128i_t, __m256i_t>(simd_cast<int64_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<uint64_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(uint64_t v) const {
        return simd_cast<__m128i_t, __m256i_t>(simd_cast<uint64_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<__m256i_t, int64_t> {
    WJR_CONST WJR_INTRINSIC_INLINE int64_t operator()(__m256i v) const {
        return simd_cast<__m128i_t, int64_t>(simd_cast<__m256i_t, __m128i_t>(v));
    }
};

template <>
struct simd_cast_fn<__m256i_t, uint64_t> {
    WJR_CONST WJR_INTRINSIC_INLINE uint64_t operator()(__m256i v) const {
        return simd_cast<__m128i_t, uint64_t>(simd_cast<__m256i_t, __m128i_t>(v));
    }
};

#endif // AVX

} // namespace wjr

#endif // WJR_X86_SIMD_SIMD_CAST_HPP__

#include <cstring>

// Already included
// Already included

namespace wjr {

struct sse {
    using mask_type = uint16_t;

#if WJR_HAS_SIMD(SSE)

    using float_type = __m128;
    using float_tag_type = __m128_t;

#endif // SSE

#if WJR_HAS_SIMD(SSE2)

    using int_type = __m128i;
    using int_tag_type = __m128i_t;
    using double_type = __m128d;
    using double_tag_type = __m128d_t;

#endif // SSE2

    constexpr static size_t width();
    constexpr static mask_type mask();

#if WJR_HAS_SIMD(SSE)

    WJR_INTRINSIC_INLINE static mask_type movemask_ps(__m128 v);
    WJR_INTRINSIC_INLINE static void sfence();

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128 shuffle_ps(__m128 a, __m128 b);

#endif // SSE

#if WJR_HAS_SIMD(SSE2)

    WJR_INTRINSIC_INLINE static __m128i add_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i add_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i add_epi32(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i add_epi64(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i add(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i add(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i add(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i add(__m128i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m128i add(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i add(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i add(__m128i a, __m128i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i add(__m128i a, __m128i b, uint64_t);

    WJR_INTRINSIC_INLINE static int8_t add_epi8(__m128i a);
    WJR_INTRINSIC_INLINE static int16_t add_epi16(__m128i a);
    WJR_INTRINSIC_INLINE static int32_t add_epi32(__m128i a);
    WJR_INTRINSIC_INLINE static int64_t add_epi64(__m128i a);

    WJR_INTRINSIC_INLINE static uint8_t add_epu8(__m128i a);
    WJR_INTRINSIC_INLINE static uint16_t add_epu16(__m128i a);
    WJR_INTRINSIC_INLINE static uint32_t add_epu32(__m128i a);
    WJR_INTRINSIC_INLINE static uint64_t add_epu64(__m128i a);

    WJR_INTRINSIC_INLINE static int8_t add(__m128i a, int8_t);
    WJR_INTRINSIC_INLINE static int16_t add(__m128i a, int16_t);
    WJR_INTRINSIC_INLINE static int32_t add(__m128i a, int32_t);
    WJR_INTRINSIC_INLINE static int64_t add(__m128i a, int64_t);
    WJR_INTRINSIC_INLINE static uint8_t add(__m128i a, uint8_t);
    WJR_INTRINSIC_INLINE static uint16_t add(__m128i a, uint16_t);
    WJR_INTRINSIC_INLINE static uint32_t add(__m128i a, uint32_t);
    WJR_INTRINSIC_INLINE static uint64_t add(__m128i a, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i adds_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i adds_epi16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i adds_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i adds_epu16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i adds(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i adds(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i adds(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i adds(__m128i a, __m128i b, uint16_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i alignr(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i alignr_epi16(__m128i a, __m128i b, int c);
    WJR_INTRINSIC_INLINE static __m128i alignr_epi32(__m128i a, __m128i b, int c);
    WJR_INTRINSIC_INLINE static __m128i alignr_epi64(__m128i a, __m128i b, int c);

    WJR_INTRINSIC_INLINE static __m128i alignr(__m128i a, __m128i b, int c, int16_t);
    WJR_INTRINSIC_INLINE static __m128i alignr(__m128i a, __m128i b, int c, int32_t);
    WJR_INTRINSIC_INLINE static __m128i alignr(__m128i a, __m128i b, int c, int64_t);
    WJR_INTRINSIC_INLINE static __m128i alignr(__m128i a, __m128i b, int c, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i alignr(__m128i a, __m128i b, int c, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i alignr(__m128i a, __m128i b, int c, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i And(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i AndNot(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i avg_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i avg_epu16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i avg(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i avg(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i avg(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i avg(__m128i a, __m128i b, uint16_t);

    // notice that mask must be 0 or 255(every byte)
    WJR_INTRINSIC_INLINE static __m128i blendv_epi8(__m128i a, __m128i b, __m128i mask);
    WJR_INTRINSIC_INLINE static __m128i blendv_epi16(__m128i a, __m128i b, __m128i mask);
    WJR_INTRINSIC_INLINE static __m128i blendv_epi32(__m128i a, __m128i b, __m128i mask);

    WJR_INTRINSIC_INLINE static __m128i blendv(__m128i a, __m128i b, __m128i mask,
                                               int8_t);
    WJR_INTRINSIC_INLINE static __m128i blendv(__m128i a, __m128i b, __m128i mask,
                                               int16_t);
    WJR_INTRINSIC_INLINE static __m128i blendv(__m128i a, __m128i b, __m128i mask,
                                               int32_t);
    WJR_INTRINSIC_INLINE static __m128i blendv(__m128i a, __m128i b, __m128i mask,
                                               uint8_t);
    WJR_INTRINSIC_INLINE static __m128i blendv(__m128i a, __m128i b, __m128i mask,
                                               uint16_t);
    WJR_INTRINSIC_INLINE static __m128i blendv(__m128i a, __m128i b, __m128i mask,
                                               uint32_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i bslli(__m128i val);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i bsrli(__m128i val);

    WJR_INTRINSIC_INLINE static __m128i cmpeq_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpeq_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpeq_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpeq(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i cmpeq(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i cmpeq(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i cmpeq(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i cmpeq(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i cmpeq(__m128i a, __m128i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m128i cmpge_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpge_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpge_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpge_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpge_epu16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpge_epu32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpge(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i cmpge(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i cmpge(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i cmpge(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i cmpge(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i cmpge(__m128i a, __m128i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m128i cmpgt_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpgt_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpgt_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpgt_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpgt_epu16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpgt_epu32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpgt(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i cmpgt(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i cmpgt(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i cmpgt(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i cmpgt(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i cmpgt(__m128i a, __m128i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m128i cmple_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmple_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmple_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmple_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmple_epu16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmple_epu32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmple(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i cmple(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i cmple(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i cmple(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i cmple(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i cmple(__m128i a, __m128i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m128i cmplt_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmplt_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmplt_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmplt_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmplt_epu16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmplt_epu32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmplt(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i cmplt(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i cmplt(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i cmplt(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i cmplt(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i cmplt(__m128i a, __m128i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m128i cmpne_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpne_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i cmpne_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpne(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i cmpne(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i cmpne(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i cmpne(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i cmpne(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i cmpne(__m128i a, __m128i b, uint32_t);

    template <typename T>
    WJR_INTRINSIC_INLINE static __m128i cmp(__m128i a, __m128i b, std::equal_to<>, T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m128i cmp(__m128i a, __m128i b, std::not_equal_to<>, T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m128i cmp(__m128i a, __m128i b, std::greater<>, T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m128i cmp(__m128i a, __m128i b, std::greater_equal<>,
                                            T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m128i cmp(__m128i a, __m128i b, std::less<>, T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m128i cmp(__m128i a, __m128i b, std::less_equal<>, T);

    WJR_INTRINSIC_INLINE static __m128i concat(uint64_t lo, uint64_t hi);

    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract_epi8(__m128i a);

    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract_epi16(__m128i a);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract_epi32(__m128i a);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int64_t extract_epi64(__m128i a);

    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m128i a, int8_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m128i a, int16_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m128i a, int32_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int64_t extract(__m128i a, int64_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m128i a, uint8_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m128i a, uint16_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m128i a, uint32_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int64_t extract(__m128i a, uint64_t);

    WJR_INTRINSIC_INLINE static uint64_t getlow(__m128i v);
    WJR_INTRINSIC_INLINE static uint64_t gethigh(__m128i v);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert_epi16(__m128i a, int i);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert(__m128i a, int i, int16_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert(__m128i a, int i, uint16_t);

    WJR_INTRINSIC_INLINE static void lfence();

    WJR_INTRINSIC_INLINE static __m128i load(const void *ptr);
    WJR_INTRINSIC_INLINE static __m128i loadu(const void *ptr);
    WJR_INTRINSIC_INLINE static __m128i loadu_si16(const void *ptr);
    WJR_INTRINSIC_INLINE static __m128i loadu_si32(const void *ptr);
    WJR_INTRINSIC_INLINE static __m128i loadu_si64(const void *ptr);

    template <typename T,
              WJR_REQUIRES(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t, uint8_t,
                                       uint16_t, uint32_t, uint64_t>)>
    WJR_INTRINSIC_INLINE static __m128i logical_and(__m128i a, __m128i b, T);

    template <typename T,
              WJR_REQUIRES(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t, uint8_t,
                                       uint16_t, uint32_t, uint64_t>)>
    WJR_INTRINSIC_INLINE static __m128i logical_not(__m128i v, T);

    template <typename T,
              WJR_REQUIRES(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t, uint8_t,
                                       uint16_t, uint32_t, uint64_t>)>
    WJR_INTRINSIC_INLINE static __m128i logical_or(__m128i a, __m128i b, T);

    WJR_INTRINSIC_INLINE static __m128i madd_epi16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static void maskmoveu(__m128i a, __m128i mask, char *mem_addr);

    WJR_INTRINSIC_INLINE static __m128i max_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i max_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i max_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i max_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i max_epu16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i max_epu32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i max(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i max(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i max(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i max(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i max(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i max(__m128i a, __m128i b, uint32_t);

    WJR_INTRINSIC_INLINE static int8_t max_epi8(__m128i a);
    WJR_INTRINSIC_INLINE static int16_t max_epi16(__m128i a);
    WJR_INTRINSIC_INLINE static int32_t max_epi32(__m128i a);

    WJR_INTRINSIC_INLINE static uint8_t max_epu8(__m128i a);
    WJR_INTRINSIC_INLINE static uint16_t max_epu16(__m128i a);
    WJR_INTRINSIC_INLINE static uint32_t max_epu32(__m128i a);

    WJR_INTRINSIC_INLINE static int8_t max(__m128i a, int8_t);
    WJR_INTRINSIC_INLINE static int16_t max(__m128i a, int16_t);
    WJR_INTRINSIC_INLINE static int32_t max(__m128i a, int32_t);
    WJR_INTRINSIC_INLINE static uint8_t max(__m128i a, uint8_t);
    WJR_INTRINSIC_INLINE static uint16_t max(__m128i a, uint16_t);
    WJR_INTRINSIC_INLINE static uint32_t max(__m128i a, uint32_t);

    WJR_INTRINSIC_INLINE static void mfence();

    WJR_INTRINSIC_INLINE static __m128i min_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i min_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i min_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i min_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i min_epu16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i min_epu32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i min(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i min(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i min(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i min(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i min(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i min(__m128i a, __m128i b, uint32_t);

    WJR_INTRINSIC_INLINE static int8_t min_epi8(__m128i a);
    WJR_INTRINSIC_INLINE static int16_t min_epi16(__m128i a);
    WJR_INTRINSIC_INLINE static int32_t min_epi32(__m128i a);

    WJR_INTRINSIC_INLINE static uint8_t min_epu8(__m128i a);
    WJR_INTRINSIC_INLINE static uint16_t min_epu16(__m128i a);
    WJR_INTRINSIC_INLINE static uint32_t min_epu32(__m128i a);

    WJR_INTRINSIC_INLINE static int8_t min(__m128i a, int8_t);
    WJR_INTRINSIC_INLINE static int16_t min(__m128i a, int16_t);
    WJR_INTRINSIC_INLINE static int32_t min(__m128i a, int32_t);

    WJR_INTRINSIC_INLINE static uint8_t min(__m128i a, uint8_t);
    WJR_INTRINSIC_INLINE static uint16_t min(__m128i a, uint16_t);
    WJR_INTRINSIC_INLINE static uint32_t min(__m128i a, uint32_t);

    WJR_INTRINSIC_INLINE static __m128i move_epi64(__m128i a);

    WJR_INTRINSIC_INLINE static mask_type movemask_epi8(__m128i a);
    WJR_INTRINSIC_INLINE static mask_type movemask_pd(__m128d v);

    WJR_INTRINSIC_INLINE static mask_type movemask(__m128i v, int8_t);
    WJR_INTRINSIC_INLINE static mask_type movemask(__m128i v, int32_t);
    WJR_INTRINSIC_INLINE static mask_type movemask(__m128i v, int64_t);

    WJR_INTRINSIC_INLINE static mask_type movemask(__m128i v, uint8_t);
    WJR_INTRINSIC_INLINE static mask_type movemask(__m128i v, uint32_t);
    WJR_INTRINSIC_INLINE static mask_type movemask(__m128i v, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i mul_epu32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i mulhi_epi16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i mulhi_epu16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i mullo_epi16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i negate_epi8(__m128i a);
    WJR_INTRINSIC_INLINE static __m128i negate_epi16(__m128i a);
    WJR_INTRINSIC_INLINE static __m128i negate_epi32(__m128i a);
    WJR_INTRINSIC_INLINE static __m128i negate_epi64(__m128i a);

    WJR_INTRINSIC_INLINE static __m128i negate(__m128i a, int8_t);
    WJR_INTRINSIC_INLINE static __m128i negate(__m128i a, int16_t);
    WJR_INTRINSIC_INLINE static __m128i negate(__m128i a, int32_t);
    WJR_INTRINSIC_INLINE static __m128i negate(__m128i a, int64_t);
    WJR_INTRINSIC_INLINE static __m128i negate(__m128i a, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i negate(__m128i a, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i negate(__m128i a, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i negate(__m128i a, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i Not(__m128i v);

    WJR_INTRINSIC_INLINE static __m128i Or(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i packs_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i packs_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i packus_epi16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i loadu_si48(const void *ptr);
    WJR_INTRINSIC_INLINE static __m128i loadu_si80(const void *ptr);
    WJR_INTRINSIC_INLINE static __m128i loadu_si96(const void *ptr);
    WJR_INTRINSIC_INLINE static __m128i loadu_si112(const void *ptr);
    WJR_INTRINSIC_INLINE static __m128i loadu_si128(const void *ptr);

    WJR_INTRINSIC_INLINE static __m128i loadu_si16x(const void *ptr, int n);

    WJR_INTRINSIC_INLINE static __m128i sad_epu8(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i zeros();
    WJR_INTRINSIC_INLINE static __m128i ones();

    WJR_INTRINSIC_INLINE static __m128i set_epi8(char e15, char e14, char e13, char e12,
                                                 char e11, char e10, char e9, char e8,
                                                 char e7, char e6, char e5, char e4,
                                                 char e3, char e2, char e1, char e0);

    WJR_INTRINSIC_INLINE static __m128i set_epi16(short e7, short e6, short e5, short e4,
                                                  short e3, short e2, short e1, short e0);
    WJR_INTRINSIC_INLINE static __m128i set_epi32(int e3, int e2, int e1, int e0);
    WJR_INTRINSIC_INLINE static __m128i set_epi64x(long long e1, long long e0);

    WJR_INTRINSIC_INLINE static __m128i setr_epi8(char e15, char e14, char e13, char e12,
                                                  char e11, char e10, char e9, char e8,
                                                  char e7, char e6, char e5, char e4,
                                                  char e3, char e2, char e1, char e0);

    WJR_INTRINSIC_INLINE static __m128i setr_epi16(short e7, short e6, short e5, short e4,
                                                   short e3, short e2, short e1,
                                                   short e0);
    WJR_INTRINSIC_INLINE static __m128i setr_epi32(int e3, int e2, int e1, int e0);

    WJR_INTRINSIC_INLINE static __m128i set1_epi8(int8_t val);
    WJR_INTRINSIC_INLINE static __m128i set1_epi16(int16_t val);
    WJR_INTRINSIC_INLINE static __m128i set1_epi32(int32_t val);
    WJR_INTRINSIC_INLINE static __m128i set1_epi64(int64_t val);

    WJR_INTRINSIC_INLINE static __m128i set1(int8_t val, int8_t);
    WJR_INTRINSIC_INLINE static __m128i set1(int16_t val, int16_t);
    WJR_INTRINSIC_INLINE static __m128i set1(int32_t val, int32_t);
    WJR_INTRINSIC_INLINE static __m128i set1(int64_t val, int64_t);
    WJR_INTRINSIC_INLINE static __m128i set1(uint8_t val, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i set1(uint16_t val, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i set1(uint32_t val, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i set1(uint64_t val, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i setmin_epi8();
    WJR_INTRINSIC_INLINE static __m128i setmin_epi16();
    WJR_INTRINSIC_INLINE static __m128i setmin_epi32();

    WJR_INTRINSIC_INLINE static __m128i setmin(int8_t);
    WJR_INTRINSIC_INLINE static __m128i setmin(int16_t);
    WJR_INTRINSIC_INLINE static __m128i setmin(int32_t);
    WJR_INTRINSIC_INLINE static __m128i setmin(uint8_t);
    WJR_INTRINSIC_INLINE static __m128i setmin(uint16_t);
    WJR_INTRINSIC_INLINE static __m128i setmin(uint32_t);

    WJR_INTRINSIC_INLINE static __m128i setmax_epi8();
    WJR_INTRINSIC_INLINE static __m128i setmax_epi16();
    WJR_INTRINSIC_INLINE static __m128i setmax_epi32();

    WJR_INTRINSIC_INLINE static __m128i setmax(int8_t);
    WJR_INTRINSIC_INLINE static __m128i setmax(int16_t);
    WJR_INTRINSIC_INLINE static __m128i setmax(int32_t);
    WJR_INTRINSIC_INLINE static __m128i setmax(uint8_t);
    WJR_INTRINSIC_INLINE static __m128i setmax(uint16_t);
    WJR_INTRINSIC_INLINE static __m128i setmax(uint32_t);

    template <int imm>
    WJR_INTRINSIC_INLINE static __m128i shl(__m128i a);

    template <int imm>
    WJR_INTRINSIC_INLINE static __m128i shr(__m128i b);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i shuffle_epi32(__m128i v);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i shufflehi_epi16(__m128i v);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i shufflelo_epi16(__m128i v);

    WJR_INTRINSIC_INLINE static __m128i sll_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i sll_epi32(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i sll_epi64(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i sll(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i sll(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i sll(__m128i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m128i sll(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i sll(__m128i a, __m128i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i sll(__m128i a, __m128i b, uint64_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i slli(__m128i v);
    WJR_INTRINSIC_INLINE static __m128i slli_epi16(__m128i a, int imm8);
    WJR_INTRINSIC_INLINE static __m128i slli_epi32(__m128i a, int imm8);
    WJR_INTRINSIC_INLINE static __m128i slli_epi64(__m128i a, int imm8);

    WJR_INTRINSIC_INLINE static __m128i slli(__m128i a, int imm8, int16_t);
    WJR_INTRINSIC_INLINE static __m128i slli(__m128i a, int imm8, int32_t);
    WJR_INTRINSIC_INLINE static __m128i slli(__m128i a, int imm8, int64_t);
    WJR_INTRINSIC_INLINE static __m128i slli(__m128i a, int imm8, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i slli(__m128i a, int imm8, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i slli(__m128i a, int imm8, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i sra_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i sra_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i sra(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i sra(__m128i a, __m128i b, int32_t);

    WJR_INTRINSIC_INLINE static __m128i srai_epi16(__m128i a, int imm8);
    WJR_INTRINSIC_INLINE static __m128i srai_epi32(__m128i a, int imm8);

    WJR_INTRINSIC_INLINE static __m128i srai(__m128i a, int imm8, int16_t);
    WJR_INTRINSIC_INLINE static __m128i srai(__m128i a, int imm8, int32_t);

    WJR_INTRINSIC_INLINE static __m128i srl_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i srl_epi32(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i srl_epi64(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i srl(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i srl(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i srl(__m128i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m128i srl(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i srl(__m128i a, __m128i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i srl(__m128i a, __m128i b, uint64_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i srli(__m128i v);
    WJR_INTRINSIC_INLINE static __m128i srli_epi8(__m128i a, int imm8);
    WJR_INTRINSIC_INLINE static __m128i srli_epi16(__m128i a, int imm8);
    WJR_INTRINSIC_INLINE static __m128i srli_epi32(__m128i a, int imm8);
    WJR_INTRINSIC_INLINE static __m128i srli_epi64(__m128i a, int imm8);

    WJR_INTRINSIC_INLINE static __m128i srli(__m128i a, int imm8, int8_t);
    WJR_INTRINSIC_INLINE static __m128i srli(__m128i a, int imm8, int16_t);
    WJR_INTRINSIC_INLINE static __m128i srli(__m128i a, int imm8, int32_t);
    WJR_INTRINSIC_INLINE static __m128i srli(__m128i a, int imm8, int64_t);
    WJR_INTRINSIC_INLINE static __m128i srli(__m128i a, int imm8, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i srli(__m128i a, int imm8, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i srli(__m128i a, int imm8, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i srli(__m128i a, int imm8, uint64_t);

    WJR_INTRINSIC_INLINE static void stream(__m128i *ptr, __m128i v);

    WJR_INTRINSIC_INLINE static void store(void *ptr, __m128i val);
    WJR_INTRINSIC_INLINE static void storeu(void *ptr, __m128i val);

    WJR_INTRINSIC_INLINE static __m128i sub_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i sub_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i sub_epi32(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i sub_epi64(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i sub(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i sub(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i sub(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i sub(__m128i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m128i sub(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i sub(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i sub(__m128i a, __m128i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i sub(__m128i a, __m128i b, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i subs_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i subs_epi16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i subs_epu8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i subs_epu16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i subs(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i subs(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i subs(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i subs(__m128i a, __m128i b, uint16_t);

    WJR_INTRINSIC_INLINE static __m128i unpackhi_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i unpackhi_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i unpackhi_epi32(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i unpackhi_epi64(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i unpackhi(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i unpackhi(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i unpackhi(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i unpackhi(__m128i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m128i unpackhi(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i unpackhi(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i unpackhi(__m128i a, __m128i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m128i unpackhi(__m128i a, __m128i b, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i unpacklo_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i unpacklo_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i unpacklo_epi32(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i unpacklo_epi64(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i unpacklo(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i unpacklo(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i unpacklo(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i unpacklo(__m128i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m128i unpacklo(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i unpacklo(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i unpacklo(__m128i a, __m128i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m128i Xor(__m128i a, __m128i b);

#endif // SSE2

#if WJR_HAS_SIMD(SSE3)

    WJR_INTRINSIC_INLINE static __m128i lddqu(const __m128i *ptr);

#endif // SSE3

#if WJR_HAS_SIMD(SSSE3)

    WJR_INTRINSIC_INLINE static __m128i abs_epi8(__m128i val);
    WJR_INTRINSIC_INLINE static __m128i abs_epi16(__m128i val);
    WJR_INTRINSIC_INLINE static __m128i abs_epi32(__m128i val);

    WJR_INTRINSIC_INLINE static __m128i abs(__m128i val, int8_t);
    WJR_INTRINSIC_INLINE static __m128i abs(__m128i val, int16_t);
    WJR_INTRINSIC_INLINE static __m128i abs(__m128i val, int32_t);
    WJR_INTRINSIC_INLINE static __m128i abs(__m128i val, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i abs(__m128i val, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i abs(__m128i val, uint32_t);

    WJR_INTRINSIC_INLINE static __m128i shuffle_epi8(__m128i v, __m128i imm8);

    WJR_INTRINSIC_INLINE static __m128i sign_epi8(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i sign_epi16(__m128i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m128i sign_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i sign(__m128i a, __m128i b, int8_t);
    WJR_INTRINSIC_INLINE static __m128i sign(__m128i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m128i sign(__m128i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m128i sign(__m128i a, __m128i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m128i sign(__m128i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m128i sign(__m128i a, __m128i b, uint32_t);

#endif // SSSE3

#if WJR_HAS_SIMD(SSE4_1)

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i blend_epi16(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpeq_epi64(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpeq(__m128i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m128i cmpeq(__m128i a, __m128i b, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i cmpgt_epi64(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i cmpgt(__m128i a, __m128i b, int64_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert_epi8(__m128i a, int i);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert_epi32(__m128i a, int i);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert_epi64(__m128i a, int64_t i);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert(__m128i a, int i, int8_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert(__m128i a, int i, int32_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert(__m128i a, int64_t i, int64_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert(__m128i a, int i, uint8_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert(__m128i a, int i, uint32_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i insert(__m128i a, int64_t i, uint64_t);

    WJR_INTRINSIC_INLINE static __m128i minpos_epu16(__m128i a);

    WJR_INTRINSIC_INLINE static __m128i mul_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i mullo_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i packus_epi32(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m128i stream_load(void *p);

    WJR_INTRINSIC_INLINE static int test_all_ones(__m128i a);

    WJR_INTRINSIC_INLINE static int test_all_zeros(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static int test_all_zeros(__m128i a);

    WJR_INTRINSIC_INLINE static int test_mix_ones_zeros(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static int testc(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static int testnzc(__m128i a, __m128i b);

    WJR_INTRINSIC_INLINE static int testz(__m128i a, __m128i b);

#endif // SSE4_1
};

namespace sse_detail {
#if WJR_HAS_SIMD(SSE2)

const static __m128i srli_epi8_mask[8] = {
    sse::set1_epi16(0xFFFF), sse::set1_epi16(0x7F7F), sse::set1_epi16(0x3F3F),
    sse::set1_epi16(0x1F1F), sse::set1_epi16(0xF0F),  sse::set1_epi16(0x707),
    sse::set1_epi16(0x303),  sse::set1_epi16(0x101),
};

#endif
} // namespace sse_detail

#if WJR_HAS_SIMD(SSE2)

template <>
struct broadcast_fn<uint8_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(uint8_t v) const {
        return _mm_set1_epi8(v);
    }
};

template <>
struct broadcast_fn<uint16_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(uint16_t v) const {
        return _mm_set1_epi16(v);
    }
};

template <>
struct broadcast_fn<uint32_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(uint32_t v) const {
        return _mm_set1_epi32(v);
    }
};

template <>
struct broadcast_fn<uint64_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(uint64_t v) const {
        return _mm_set1_epi64x(v);
    }
};

template <>
struct broadcast_fn<__m128i_t, __m128i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m128i operator()(__m128i v) const { return v; }
};

#endif // SSE2

/*------------------------sse------------------------*/

constexpr size_t sse::width() { return 128; }

constexpr sse::mask_type sse::mask() { return 0xFFFF; }

#if WJR_HAS_SIMD(SSE)

sse::mask_type sse::movemask_ps(__m128 v) {
    return static_cast<sse::mask_type>(_mm_movemask_ps(v));
}

void sse::sfence() { return _mm_sfence(); }

template <int imm8>
__m128 sse::shuffle_ps(__m128 a, __m128 b) {
    static_assert(imm8 >= 0 && imm8 <= 255, "imm8 must be in range [0, 255]");
    return _mm_shuffle_ps(a, b, imm8);
}

#endif // SSE

#if WJR_HAS_SIMD(SSE2)

__m128i sse::add_epi8(__m128i a, __m128i b) { return _mm_add_epi8(a, b); }
__m128i sse::add_epi16(__m128i a, __m128i b) { return _mm_add_epi16(a, b); }
__m128i sse::add_epi32(__m128i a, __m128i b) { return _mm_add_epi32(a, b); }
__m128i sse::add_epi64(__m128i a, __m128i b) { return _mm_add_epi64(a, b); }

__m128i sse::add(__m128i a, __m128i b, int8_t) { return add_epi8(a, b); }
__m128i sse::add(__m128i a, __m128i b, int16_t) { return add_epi16(a, b); }
__m128i sse::add(__m128i a, __m128i b, int32_t) { return add_epi32(a, b); }
__m128i sse::add(__m128i a, __m128i b, int64_t) { return add_epi64(a, b); }
__m128i sse::add(__m128i a, __m128i b, uint8_t) { return add_epi8(a, b); }
__m128i sse::add(__m128i a, __m128i b, uint16_t) { return add_epi16(a, b); }
__m128i sse::add(__m128i a, __m128i b, uint32_t) { return add_epi32(a, b); }
__m128i sse::add(__m128i a, __m128i b, uint64_t) { return add_epi64(a, b); }

int8_t sse::add_epi8(__m128i a) { return static_cast<int8_t>(add_epu8(a)); }
int16_t sse::add_epi16(__m128i a) { return static_cast<int16_t>(add_epu16(a)); }
int32_t sse::add_epi32(__m128i a) { return static_cast<int32_t>(add_epu32(a)); }
int64_t sse::add_epi64(__m128i a) { return static_cast<int64_t>(add_epu64(a)); }

uint8_t sse::add_epu8(__m128i a) {
    auto b = shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a);
    a = add(a, b, uint8_t());
    b = zeros();
    a = sad_epu8(a, b);
    return simd_cast<__m128i_t, uint8_t>(a);
}

uint16_t sse::add_epu16(__m128i a) {
    a = add(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a), uint16_t());
    a = add(a, shuffle_epi32<_MM_SHUFFLE(1, 1, 1, 1)>(a), uint16_t());
    a = add(a, srli<2>(a), uint16_t());
    return simd_cast<__m128i_t, uint16_t>(a);
}

uint32_t sse::add_epu32(__m128i a) {
    a = add(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a), uint32_t());
    a = add(a, shuffle_epi32<_MM_SHUFFLE(1, 1, 1, 1)>(a), uint32_t());
    return simd_cast<__m128i_t, uint32_t>(a);
}

uint64_t sse::add_epu64(__m128i a) {
    a = add(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a), uint64_t());
    return simd_cast<__m128i_t, uint64_t>(a);
}

int8_t sse::add(__m128i a, int8_t) { return add_epi8(a); }
int16_t sse::add(__m128i a, int16_t) { return add_epi16(a); }
int32_t sse::add(__m128i a, int32_t) { return add_epi32(a); }
int64_t sse::add(__m128i a, int64_t) { return add_epi64(a); }
uint8_t sse::add(__m128i a, uint8_t) { return add_epu8(a); }
uint16_t sse::add(__m128i a, uint16_t) { return add_epu16(a); }
uint32_t sse::add(__m128i a, uint32_t) { return add_epu32(a); }
uint64_t sse::add(__m128i a, uint64_t) { return add_epu64(a); }

__m128i sse::adds_epi8(__m128i a, __m128i b) { return _mm_adds_epi8(a, b); }
__m128i sse::adds_epi16(__m128i a, __m128i b) { return _mm_adds_epi16(a, b); }

__m128i sse::adds_epu8(__m128i a, __m128i b) { return _mm_adds_epu8(a, b); }
__m128i sse::adds_epu16(__m128i a, __m128i b) { return _mm_adds_epu16(a, b); }

__m128i sse::adds(__m128i a, __m128i b, int8_t) { return adds_epi8(a, b); }
__m128i sse::adds(__m128i a, __m128i b, int16_t) { return adds_epi16(a, b); }
__m128i sse::adds(__m128i a, __m128i b, uint8_t) { return adds_epu8(a, b); }
__m128i sse::adds(__m128i a, __m128i b, uint16_t) { return adds_epu16(a, b); }

template <int imm8>
__m128i sse::alignr(__m128i a, __m128i b) {
    constexpr int s = imm8 & 0x1F;
#if WJR_HAS_SIMD(SSSE3)
    return _mm_alignr_epi8(a, b, s);
#else
    if constexpr (s == 0) {
        return b;
    }
    if constexpr (s == 16) {
        return a;
    }
    if constexpr (s < 16) {
        return Or(slli<16 - s>(a), srli<s>(b));
    }
    return srli<s - 16>(a);
#endif // SSSE3
}

__m128i sse::alignr_epi16(__m128i a, __m128i b, int c) {
    return Or(slli(a, 16 - c, uint16_t()), srli(b, c, uint16_t()));
}

__m128i sse::alignr_epi32(__m128i a, __m128i b, int c) {
    return Or(slli(a, 32 - c, uint32_t()), srli(b, c, uint32_t()));
}

__m128i sse::alignr_epi64(__m128i a, __m128i b, int c) {
    return Or(slli(a, 64 - c, uint64_t()), srli(b, c, uint64_t()));
}

__m128i sse::alignr(__m128i a, __m128i b, int c, int16_t) {
    return alignr_epi16(a, b, c);
}
__m128i sse::alignr(__m128i a, __m128i b, int c, int32_t) {
    return alignr_epi32(a, b, c);
}
__m128i sse::alignr(__m128i a, __m128i b, int c, int64_t) {
    return alignr_epi64(a, b, c);
}
__m128i sse::alignr(__m128i a, __m128i b, int c, uint16_t) {
    return alignr_epi16(a, b, c);
}
__m128i sse::alignr(__m128i a, __m128i b, int c, uint32_t) {
    return alignr_epi32(a, b, c);
}
__m128i sse::alignr(__m128i a, __m128i b, int c, uint64_t) {
    return alignr_epi64(a, b, c);
}

__m128i sse::And(__m128i a, __m128i b) { return _mm_and_si128(a, b); }

__m128i sse::AndNot(__m128i a, __m128i b) { return _mm_andnot_si128(a, b); }

__m128i sse::avg_epu8(__m128i a, __m128i b) { return _mm_avg_epu8(a, b); }
__m128i sse::avg_epu16(__m128i a, __m128i b) { return _mm_avg_epu16(a, b); }

__m128i sse::avg(__m128i a, __m128i b, int8_t) { return avg_epu8(a, b); }
__m128i sse::avg(__m128i a, __m128i b, int16_t) { return avg_epu16(a, b); }
__m128i sse::avg(__m128i a, __m128i b, uint8_t) { return avg_epu8(a, b); }
__m128i sse::avg(__m128i a, __m128i b, uint16_t) { return avg_epu16(a, b); }

// notice that mask must be 0 or 255(every byte)
__m128i sse::blendv_epi8(__m128i a, __m128i b, __m128i mask) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_blendv_epi8(a, b, mask);
#elif defined(WJR_COMPILER_GCC)
    return ((~mask) & a) | (mask & b);
#else
    return Or(AndNot(mask, a), And(mask, b));
#endif
}

__m128i sse::blendv_epi16(__m128i a, __m128i b, __m128i mask) {
    return blendv_epi8(b, a, logical_not(mask, uint16_t()));
}

__m128i sse::blendv_epi32(__m128i a, __m128i b, __m128i mask) {
    return blendv_epi8(b, a, logical_not(mask, uint32_t()));
}

__m128i sse::blendv(__m128i a, __m128i b, __m128i mask, int8_t) {
    return blendv_epi8(a, b, mask);
}

__m128i sse::blendv(__m128i a, __m128i b, __m128i mask, int16_t) {
    return blendv_epi16(a, b, mask);
}

__m128i sse::blendv(__m128i a, __m128i b, __m128i mask, int32_t) {
    return blendv_epi32(a, b, mask);
}

__m128i sse::blendv(__m128i a, __m128i b, __m128i mask, uint8_t) {
    return blendv_epi8(a, b, mask);
}

__m128i sse::blendv(__m128i a, __m128i b, __m128i mask, uint16_t) {
    return blendv_epi16(a, b, mask);
}

__m128i sse::blendv(__m128i a, __m128i b, __m128i mask, uint32_t) {
    return blendv_epi32(a, b, mask);
}

template <int imm8>
__m128i sse::bslli(__m128i val) {
    return _mm_bslli_si128(val, imm8);
}

template <int imm8>
__m128i sse::bsrli(__m128i val) {
    return _mm_bsrli_si128(val, imm8);
}

__m128i sse::cmpeq_epi8(__m128i a, __m128i b) { return _mm_cmpeq_epi8(a, b); }
__m128i sse::cmpeq_epi16(__m128i a, __m128i b) { return _mm_cmpeq_epi16(a, b); }
__m128i sse::cmpeq_epi32(__m128i a, __m128i b) { return _mm_cmpeq_epi32(a, b); }

__m128i sse::cmpeq(__m128i a, __m128i b, int8_t) { return cmpeq_epi8(a, b); }
__m128i sse::cmpeq(__m128i a, __m128i b, int16_t) { return cmpeq_epi16(a, b); }
__m128i sse::cmpeq(__m128i a, __m128i b, int32_t) { return cmpeq_epi32(a, b); }
__m128i sse::cmpeq(__m128i a, __m128i b, uint8_t) { return cmpeq_epi8(a, b); }
__m128i sse::cmpeq(__m128i a, __m128i b, uint16_t) { return cmpeq_epi16(a, b); }
__m128i sse::cmpeq(__m128i a, __m128i b, uint32_t) { return cmpeq_epi32(a, b); }

__m128i sse::cmpge_epi8(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comge_epi8(a, b);
#elif WJR_HAS_SIMD(SSE4_1)
    return cmpeq(min(a, b, int8_t()), b, uint8_t());
#else
    return Not(cmpgt(b, a, int8_t()));
#endif
}

__m128i sse::cmpge_epi16(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comge_epi16(a, b);
#else
    return cmpeq(min(a, b, int16_t()), b, uint16_t());
#endif
}

__m128i sse::cmpge_epi32(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comge_epi32(a, b);
#elif WJR_HAS_SIMD(SSE4_1)
    return cmpeq(min(a, b, int32_t()), b, uint32_t());
#else
    return Not(cmpgt(b, a, int32_t()));
#endif
}

__m128i sse::cmpge_epu8(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comge_epu8(a, b);
#else
    return cmpeq(min(a, b, uint8_t()), b, uint8_t());
#endif
}

__m128i sse::cmpge_epu16(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comge_epu16(a, b);
#elif WJR_HAS_SIMD(SSE4_1)
    return cmpeq(min(a, b, uint16_t()), b, uint16_t());
#else
    return logical_not(subs(b, a, uint16_t()), uint16_t());
#endif
}

__m128i sse::cmpge_epu32(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comge_epu32(a, b);
#elif WJR_HAS_SIMD(SSE4_1)
    return cmpeq(min(a, b, uint32_t()), b, uint32_t());
#else
    return Not(cmpgt(b, a, uint32_t()));
#endif
}

__m128i sse::cmpge(__m128i a, __m128i b, int8_t) { return cmpge_epi8(a, b); }
__m128i sse::cmpge(__m128i a, __m128i b, int16_t) { return cmpge_epi16(a, b); }
__m128i sse::cmpge(__m128i a, __m128i b, int32_t) { return cmpge_epi32(a, b); }
__m128i sse::cmpge(__m128i a, __m128i b, uint8_t) { return cmpge_epu8(a, b); }
__m128i sse::cmpge(__m128i a, __m128i b, uint16_t) { return cmpge_epu16(a, b); }
__m128i sse::cmpge(__m128i a, __m128i b, uint32_t) { return cmpge_epu32(a, b); }

__m128i sse::cmpgt_epi8(__m128i a, __m128i b) { return _mm_cmpgt_epi8(a, b); }
__m128i sse::cmpgt_epi16(__m128i a, __m128i b) { return _mm_cmpgt_epi16(a, b); }
__m128i sse::cmpgt_epi32(__m128i a, __m128i b) { return _mm_cmpgt_epi32(a, b); }

__m128i sse::cmpgt_epu8(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comgt_epu8(a, b);
#else
    return cmpgt_epi8(Xor(a, setmin_epi8()), Xor(b, setmin_epi8()));
#endif
}

__m128i sse::cmpgt_epu16(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comgt_epu16(a, b);
#else
    return cmpgt_epi16(Xor(a, setmin_epi16()), Xor(b, setmin_epi16()));
#endif
}

__m128i sse::cmpgt_epu32(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comgt_epu32(a, b);
#else
    return cmpgt_epi32(Xor(a, setmin_epi32()), Xor(b, setmin_epi32()));
#endif
}

__m128i sse::cmpgt(__m128i a, __m128i b, int8_t) { return cmpgt_epi8(a, b); }
__m128i sse::cmpgt(__m128i a, __m128i b, int16_t) { return cmpgt_epi16(a, b); }
__m128i sse::cmpgt(__m128i a, __m128i b, int32_t) { return cmpgt_epi32(a, b); }
__m128i sse::cmpgt(__m128i a, __m128i b, uint8_t) { return cmpgt_epu8(a, b); }
__m128i sse::cmpgt(__m128i a, __m128i b, uint16_t) { return cmpgt_epu16(a, b); }
__m128i sse::cmpgt(__m128i a, __m128i b, uint32_t) { return cmpgt_epu32(a, b); }

__m128i sse::cmple_epi8(__m128i a, __m128i b) { return cmpge_epi8(b, a); }
__m128i sse::cmple_epi16(__m128i a, __m128i b) { return cmpge_epi16(b, a); }
__m128i sse::cmple_epi32(__m128i a, __m128i b) { return cmpge_epi32(b, a); }

__m128i sse::cmple_epu8(__m128i a, __m128i b) { return cmpge_epu8(b, a); }
__m128i sse::cmple_epu16(__m128i a, __m128i b) { return cmpge_epu16(b, a); }
__m128i sse::cmple_epu32(__m128i a, __m128i b) { return cmpge_epu32(b, a); }

__m128i sse::cmple(__m128i a, __m128i b, int8_t) { return cmple_epi8(a, b); }
__m128i sse::cmple(__m128i a, __m128i b, int16_t) { return cmple_epi16(a, b); }
__m128i sse::cmple(__m128i a, __m128i b, int32_t) { return cmple_epi32(a, b); }
__m128i sse::cmple(__m128i a, __m128i b, uint8_t) { return cmple_epu8(a, b); }
__m128i sse::cmple(__m128i a, __m128i b, uint16_t) { return cmple_epu16(a, b); }
__m128i sse::cmple(__m128i a, __m128i b, uint32_t) { return cmple_epu32(a, b); }

__m128i sse::cmplt_epi8(__m128i a, __m128i b) { return _mm_cmplt_epi8(a, b); }
__m128i sse::cmplt_epi16(__m128i a, __m128i b) { return _mm_cmplt_epi16(a, b); }
__m128i sse::cmplt_epi32(__m128i a, __m128i b) { return _mm_cmplt_epi32(a, b); }

__m128i sse::cmplt_epu8(__m128i a, __m128i b) { return cmpgt_epu8(b, a); }
__m128i sse::cmplt_epu16(__m128i a, __m128i b) { return cmpgt_epu16(b, a); }
__m128i sse::cmplt_epu32(__m128i a, __m128i b) { return cmpgt_epu32(b, a); }

__m128i sse::cmplt(__m128i a, __m128i b, int8_t) { return cmplt_epi8(a, b); }
__m128i sse::cmplt(__m128i a, __m128i b, int16_t) { return cmplt_epi16(a, b); }
__m128i sse::cmplt(__m128i a, __m128i b, int32_t) { return cmplt_epi32(a, b); }
__m128i sse::cmplt(__m128i a, __m128i b, uint8_t) { return cmplt_epu8(a, b); }
__m128i sse::cmplt(__m128i a, __m128i b, uint16_t) { return cmplt_epu16(a, b); }
__m128i sse::cmplt(__m128i a, __m128i b, uint32_t) { return cmplt_epu32(a, b); }

__m128i sse::cmpne_epi8(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comneq_epi8(a, b);
#else
    return Not(cmpeq_epi8(a, b));
#endif
}

__m128i sse::cmpne_epi16(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comneq_epi16(a, b);
#else
    return Not(cmpeq_epi16(a, b));
#endif
}

__m128i sse::cmpne_epi32(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(XOP)
    return _mm_comneq_epi32(a, b);
#else
    return Not(cmpeq_epi32(a, b));
#endif
}

__m128i sse::cmpne(__m128i a, __m128i b, int8_t) { return cmpne_epi8(a, b); }
__m128i sse::cmpne(__m128i a, __m128i b, int16_t) { return cmpne_epi16(a, b); }
__m128i sse::cmpne(__m128i a, __m128i b, int32_t) { return cmpne_epi32(a, b); }
__m128i sse::cmpne(__m128i a, __m128i b, uint8_t) { return cmpne_epi8(a, b); }
__m128i sse::cmpne(__m128i a, __m128i b, uint16_t) { return cmpne_epi16(a, b); }
__m128i sse::cmpne(__m128i a, __m128i b, uint32_t) { return cmpne_epi32(a, b); }

template <typename T>
__m128i sse::cmp(__m128i a, __m128i b, std::equal_to<>, T) {
    return cmpeq(a, b, T());
}

template <typename T>
__m128i sse::cmp(__m128i a, __m128i b, std::not_equal_to<>, T) {
    return cmpne(a, b, T());
}

template <typename T>
__m128i sse::cmp(__m128i a, __m128i b, std::greater<>, T) {
    return cmpgt(a, b, T());
}

template <typename T>
__m128i sse::cmp(__m128i a, __m128i b, std::greater_equal<>, T) {
    return cmpge(a, b, T());
}

template <typename T>
__m128i sse::cmp(__m128i a, __m128i b, std::less<>, T) {
    return cmplt(a, b, T());
}

template <typename T>
__m128i sse::cmp(__m128i a, __m128i b, std::less_equal<>, T) {
    return cmple(a, b, T());
}

__m128i sse::concat(uint64_t lo, uint64_t hi) { return set_epi64x(hi, lo); }

template <int imm8>
int sse::extract_epi8(__m128i a) {
    static_assert(imm8 >= 0 && imm8 < 16, "imm8 must be in range [0, 15]");
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_extract_epi8(a, imm8);
#else
    if constexpr (imm8 & 1) {
        return extract_epi16<(imm8 >> 1)>(a) >> 8;
    } else {
        return extract_epi16<(imm8 >> 1)>(a) & 0xff;
    }
#endif
}

template <int imm8>
int sse::extract_epi16(__m128i a) {
    static_assert(imm8 >= 0 && imm8 < 8, "imm8 must be in range [0, 7]");
    return _mm_extract_epi16(a, imm8);
}

template <int imm8>
int sse::extract_epi32(__m128i a) {
    static_assert(imm8 >= 0 && imm8 < 4, "imm8 must be in range [0, 3]");
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_extract_epi32(a, imm8);
#else
    if constexpr (imm8 == 0) {
        return simd_cast<__m128i_t, uint32_t>(a);
    } else if constexpr (imm8 == 1) {
        return static_cast<uint32_t>(simd_cast<__m128i_t, uint64_t>(a) >> 32);
    } else if constexpr (imm8 == 2) {
        return simd_cast<__m128i_t, uint32_t>(shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    } else {
        return simd_cast<__m128i_t, uint32_t>(shuffle_epi32<_MM_SHUFFLE(3, 3, 3, 3)>(a));
    }
#endif
}

template <int imm8>
int64_t sse::extract_epi64(__m128i a) {
    static_assert(imm8 >= 0 && imm8 < 2, "imm8 must be in range [0, 1]");
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_extract_epi64(a, imm8);
#else
    if constexpr (imm8 == 0) {
        return simd_cast<__m128i_t, uint64_t>(a);
    } else {
        return simd_cast<__m128i_t, uint64_t>(shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    }
#endif
}

template <int imm8>
int sse::extract(__m128i a, int8_t) {
    return extract_epi8<imm8>(a);
}

template <int imm8>
int sse::extract(__m128i a, int16_t) {
    return extract_epi16<imm8>(a);
}

template <int imm8>
int sse::extract(__m128i a, int32_t) {
    return extract_epi32<imm8>(a);
}

template <int imm8>
int64_t sse::extract(__m128i a, int64_t) {
    return extract_epi64<imm8>(a);
}

template <int imm8>
int sse::extract(__m128i a, uint8_t) {
    return extract_epi8<imm8>(a);
}

template <int imm8>
int sse::extract(__m128i a, uint16_t) {
    return extract_epi16<imm8>(a);
}

template <int imm8>
int sse::extract(__m128i a, uint32_t) {
    return extract_epi32<imm8>(a);
}

template <int imm8>
int64_t sse::extract(__m128i a, uint64_t) {
    return extract_epi64<imm8>(a);
}

uint64_t sse::getlow(__m128i v) { return simd_cast<__m128i_t, uint64_t>(v); }
uint64_t sse::gethigh(__m128i v) { return extract_epi64<1>(v); }

template <int imm8>
__m128i sse::insert_epi16(__m128i a, int i) {
    return _mm_insert_epi16(a, i, imm8);
}

template <int imm8>
__m128i sse::insert(__m128i a, int i, int16_t) {
    return insert_epi16<imm8>(a, i);
}

template <int imm8>
__m128i sse::insert(__m128i a, int i, uint16_t) {
    return insert_epi16<imm8>(a, i);
}

void sse::lfence() { _mm_lfence(); }

__m128i sse::load(const void *ptr) {
    return _mm_load_si128(static_cast<const __m128i *>(ptr));
}
__m128i sse::loadu(const void *ptr) {
    return _mm_loadu_si128(static_cast<const __m128i *>(ptr));
}
__m128i sse::loadu_si16(const void *ptr) {
    return simd_cast<uint16_t, __m128i_t>(read_memory<uint16_t>(ptr));
}

__m128i sse::loadu_si32(const void *ptr) {
    return simd_cast<uint32_t, __m128i_t>(read_memory<uint32_t>(ptr));
}

__m128i sse::loadu_si64(const void *ptr) {
    return simd_cast<uint64_t, __m128i_t>(read_memory<uint64_t>(ptr));
}

template <typename T, WJR_REQUIRES_I(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t,
                                                 uint8_t, uint16_t, uint32_t, uint64_t>)>
__m128i sse::logical_and(__m128i a, __m128i b, T) {
    return Not(Or(logical_not(a, T()), logical_not(b, T())));
}

template <typename T, WJR_REQUIRES_I(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t,
                                                 uint8_t, uint16_t, uint32_t, uint64_t>)>
__m128i sse::logical_not(__m128i v, T) {
    auto Zero = zeros();
    return cmpeq(v, Zero, T());
}

template <typename T, WJR_REQUIRES_I(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t,
                                                 uint8_t, uint16_t, uint32_t, uint64_t>)>
__m128i sse::logical_or(__m128i a, __m128i b, T) {
    return Not(logical_not(Or(a, b), T()));
}

__m128i sse::madd_epi16(__m128i a, __m128i b) { return _mm_madd_epi16(a, b); }

void sse::maskmoveu(__m128i a, __m128i mask, char *mem_addr) {
    return _mm_maskmoveu_si128(a, mask, mem_addr);
}

__m128i sse::max_epi8(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_max_epi8(a, b);
#else
    return blendv_epi8(b, a, cmpgt_epi8(a, b));
#endif
}

__m128i sse::max_epi16(__m128i a, __m128i b) { return _mm_max_epi16(a, b); }

__m128i sse::max_epi32(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_max_epi32(a, b);
#else
    return blendv_epi8(b, a, cmpgt_epi32(a, b));
#endif
}

__m128i sse::max_epu8(__m128i a, __m128i b) { return _mm_max_epu8(a, b); }

__m128i sse::max_epu16(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_max_epu16(a, b);
#else
    return add(subs_epu16(b, a), a, uint16_t());
#endif
}

__m128i sse::max_epu32(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_max_epu32(a, b);
#else
    return blendv_epi8(b, a, cmpgt_epu32(a, b));
#endif
}

__m128i sse::max(__m128i a, __m128i b, int8_t) { return max_epi8(a, b); }
__m128i sse::max(__m128i a, __m128i b, int16_t) { return max_epi16(a, b); }
__m128i sse::max(__m128i a, __m128i b, int32_t) { return max_epi32(a, b); }
__m128i sse::max(__m128i a, __m128i b, uint8_t) { return max_epu8(a, b); }
__m128i sse::max(__m128i a, __m128i b, uint16_t) { return max_epu16(a, b); }
__m128i sse::max(__m128i a, __m128i b, uint32_t) { return max_epu32(a, b); }

int8_t sse::max_epi8(__m128i a) { return 0x7fu ^ min_epu8(Xor(a, set1_epi8(0x7fu))); }

int16_t sse::max_epi16(__m128i a) {
#if WJR_HAS_SIMD(SSE4_1)
    return 0x7fffu ^ min_epu16(Xor(a, set1_epi16(0x7fffu)));
#else
    a = max_epi16(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = max_epi16(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    a = max_epi16(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 1, 0)>(a));
    return simd_cast<__m128i_t, int16_t>(a);
#endif
}

int32_t sse::max_epi32(__m128i a) {
    a = max_epi32(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = max_epi32(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    return simd_cast<__m128i_t, int32_t>(a);
}

uint8_t sse::max_epu8(__m128i a) {
#if WJR_HAS_SIMD(SSE4_1)
    return 0xffu ^ min_epu8(Xor(a, ones()));
#else
    a = max_epu8(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = max_epu8(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    a = max_epu8(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 1, 0)>(a));
    auto X = simd_cast<__m128i_t, uint32_t>(a);
    return std::max((uint8_t)X, (uint8_t)(X >> 8));
#endif
}

uint16_t sse::max_epu16(__m128i a) {
#if WJR_HAS_SIMD(SSE4_1)
    return 0xffffu ^ min_epu16(Xor(a, ones()));
#else
    a = max_epu16(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = max_epu16(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    a = max_epu16(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 1, 0)>(a));
    return simd_cast<__m128i_t, uint16_t>(a);
#endif
}

uint32_t sse::max_epu32(__m128i a) {
    a = max_epu32(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = max_epu32(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    return simd_cast<__m128i_t, uint32_t>(a);
}

int8_t sse::max(__m128i a, int8_t) { return max_epi8(a); }
int16_t sse::max(__m128i a, int16_t) { return max_epi16(a); }
int32_t sse::max(__m128i a, int32_t) { return max_epi32(a); }
uint8_t sse::max(__m128i a, uint8_t) { return max_epu8(a); }
uint16_t sse::max(__m128i a, uint16_t) { return max_epu16(a); }
uint32_t sse::max(__m128i a, uint32_t) { return max_epu32(a); }

void sse::mfence() { _mm_mfence(); }

__m128i sse::min_epi8(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_min_epi8(a, b);
#else
    return blendv_epi8(a, b, cmpgt_epi8(a, b));
#endif
}

__m128i sse::min_epi16(__m128i a, __m128i b) { return _mm_min_epi16(a, b); }

__m128i sse::min_epi32(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_min_epi32(a, b);
#else
    return blendv_epi8(a, b, cmpgt_epi32(a, b));
#endif
}

__m128i sse::min_epu8(__m128i a, __m128i b) { return _mm_min_epu8(a, b); }

__m128i sse::min_epu16(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_min_epu16(a, b);
#else
    return blendv_epi8(a, b, cmpgt_epu16(a, b));
#endif
}

__m128i sse::min_epu32(__m128i a, __m128i b) {
#if WJR_HAS_SIMD(SSE4_1)
    return _mm_min_epu32(a, b);
#else
    return blendv_epi8(a, b, cmpgt_epu32(a, b));
#endif
}

__m128i sse::min(__m128i a, __m128i b, int8_t) { return min_epi8(a, b); }
__m128i sse::min(__m128i a, __m128i b, int16_t) { return min_epi16(a, b); }
__m128i sse::min(__m128i a, __m128i b, int32_t) { return min_epi32(a, b); }
__m128i sse::min(__m128i a, __m128i b, uint8_t) { return min_epu8(a, b); }
__m128i sse::min(__m128i a, __m128i b, uint16_t) { return min_epu16(a, b); }
__m128i sse::min(__m128i a, __m128i b, uint32_t) { return min_epu32(a, b); }

int8_t sse::min_epi8(__m128i a) { return 0x80u ^ min_epu8(Xor(a, setmin_epi8())); }

int16_t sse::min_epi16(__m128i a) {
#if WJR_HAS_SIMD(SSE4_1)
    return 0x8000u ^ min_epu16(Xor(a, setmin_epi16()));
#else
    a = min_epi16(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = min_epi16(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    a = min_epi16(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 1, 0)>(a));
    return simd_cast<__m128i_t, int16_t>(a);
#endif
}

int32_t sse::min_epi32(__m128i a) {
    a = min_epi32(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = min_epi32(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    return simd_cast<__m128i_t, int32_t>(a);
}

uint8_t sse::min_epu8(__m128i a) {
#if WJR_HAS_SIMD(SSE4_1)
    a = min_epu8(a, srli_epi16(a, 8));
    a = _mm_minpos_epu16(a);
    return simd_cast<__m128i_t, uint8_t>(a);
#else
    a = min_epu8(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = min_epu8(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    a = min_epu8(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 1, 0)>(a));
    auto X = simd_cast<__m128i_t, uint32_t>(a);
    return std::min((uint8_t)X, (uint8_t)(X >> 8));
#endif
}

uint16_t sse::min_epu16(__m128i a) {
#if WJR_HAS_SIMD(SSE4_1)
    return simd_cast<__m128i_t, uint16_t>(_mm_minpos_epu16(a));
#else
    a = min_epu16(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = min_epu16(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    a = min_epu16(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 1, 0)>(a));
    return simd_cast<__m128i_t, uint16_t>(a);
#endif
}

uint32_t sse::min_epu32(__m128i a) {
    a = min_epu32(a, shuffle_epi32<_MM_SHUFFLE(3, 2, 3, 2)>(a));
    a = min_epu32(a, shufflelo_epi16<_MM_SHUFFLE(1, 0, 3, 2)>(a));
    return simd_cast<__m128i_t, uint32_t>(a);
}

int8_t sse::min(__m128i a, int8_t) { return min_epi8(a); }
int16_t sse::min(__m128i a, int16_t) { return min_epi16(a); }
int32_t sse::min(__m128i a, int32_t) { return min_epi32(a); }
uint8_t sse::min(__m128i a, uint8_t) { return min_epu8(a); }
uint16_t sse::min(__m128i a, uint16_t) { return min_epu16(a); }
uint32_t sse::min(__m128i a, uint32_t) { return min_epu32(a); }

__m128i sse::move_epi64(__m128i a) { return _mm_move_epi64(a); }

sse::mask_type sse::movemask_epi8(__m128i a) {
    return static_cast<mask_type>(_mm_movemask_epi8(a));
}
sse::mask_type sse::movemask_pd(__m128d v) {
    return static_cast<mask_type>(_mm_movemask_pd(v));
}

sse::mask_type sse::movemask(__m128i v, int8_t) { return movemask_epi8(v); }
sse::mask_type sse::movemask(__m128i v, int32_t) {
    return movemask_ps(simd_cast<__m128i_t, __m128_t>(v));
}
sse::mask_type sse::movemask(__m128i v, int64_t) {
    return movemask_pd(simd_cast<__m128i_t, __m128d_t>(v));
}
sse::mask_type sse::movemask(__m128i v, uint8_t) { return movemask(v, int8_t()); }
sse::mask_type sse::movemask(__m128i v, uint32_t) { return movemask(v, int32_t()); }
sse::mask_type sse::movemask(__m128i v, uint64_t) { return movemask(v, int64_t()); }

__m128i sse::mul_epu32(__m128i a, __m128i b) { return _mm_mul_epu32(a, b); }

__m128i sse::mulhi_epi16(__m128i a, __m128i b) { return _mm_mulhi_epi16(a, b); }

__m128i sse::mulhi_epu16(__m128i a, __m128i b) { return _mm_mulhi_epu16(a, b); }

__m128i sse::mullo_epi16(__m128i a, __m128i b) { return _mm_mullo_epi16(a, b); }

__m128i sse::negate_epi8(__m128i a) {
#if WJR_HAS_SIMD(SSSE3)
    return sign_epi8(a, ones());
#else
    return sub_epi8(zeros(), a);
#endif
}

__m128i sse::negate_epi16(__m128i a) {
#if WJR_HAS_SIMD(SSSE3)
    return sign_epi16(a, ones());
#else
    return sub_epi16(zeros(), a);
#endif
}

__m128i sse::negate_epi32(__m128i a) {
#if WJR_HAS_SIMD(SSSE3)
    return sign_epi32(a, ones());
#else
    return sub_epi32(zeros(), a);
#endif
}

__m128i sse::negate_epi64(__m128i a) { return sub_epi64(zeros(), a); }

__m128i sse::negate(__m128i a, int8_t) { return negate_epi8(a); }
__m128i sse::negate(__m128i a, int16_t) { return negate_epi16(a); }
__m128i sse::negate(__m128i a, int32_t) { return negate_epi32(a); }
__m128i sse::negate(__m128i a, int64_t) { return negate_epi64(a); }
__m128i sse::negate(__m128i a, uint8_t) { return negate_epi8(a); }
__m128i sse::negate(__m128i a, uint16_t) { return negate_epi16(a); }
__m128i sse::negate(__m128i a, uint32_t) { return negate_epi32(a); }
__m128i sse::negate(__m128i a, uint64_t) { return negate_epi64(a); }

__m128i sse::Not(__m128i v) { return Xor(v, ones()); }

__m128i sse::Or(__m128i a, __m128i b) { return _mm_or_si128(a, b); }

__m128i sse::packs_epi16(__m128i a, __m128i b) { return _mm_packs_epi16(a, b); }
__m128i sse::packs_epi32(__m128i a, __m128i b) { return _mm_packs_epi32(a, b); }

__m128i sse::packus_epi16(__m128i a, __m128i b) { return _mm_packus_epi16(a, b); }

__m128i sse::loadu_si48(const void *ptr) {
    return insert_epi16<2>(loadu_si32(ptr), reinterpret_cast<const uint16_t *>(ptr)[2]);
}

__m128i sse::loadu_si80(const void *ptr) {
    return insert_epi16<4>(loadu_si64(ptr), reinterpret_cast<const uint16_t *>(ptr)[4]);
}

__m128i sse::loadu_si96(const void *ptr) {
#if WJR_HAS_SIMD(SSE4_1)
    return insert_epi32<2>(loadu_si64(ptr), reinterpret_cast<const uint32_t *>(ptr)[2]);
#else
    return insert_epi16<5>(loadu_si80(ptr), reinterpret_cast<const uint16_t *>(ptr)[5]);
#endif
}

__m128i sse::loadu_si112(const void *ptr) {
    return insert_epi16<6>(loadu_si96(ptr), reinterpret_cast<const uint16_t *>(ptr)[6]);
}

__m128i sse::loadu_si128(const void *ptr) { return loadu(ptr); }

__m128i sse::loadu_si16x(const void *ptr, int n) {
    switch (n) {
    case 0:
        return zeros();
    case 1:
        return loadu_si16(ptr);
    case 2:
        return loadu_si32(ptr);
    case 3:
        return loadu_si48(ptr);
    case 4:
        return loadu_si64(ptr);
    case 5:
        return loadu_si80(ptr);
    case 6:
        return loadu_si96(ptr);
    case 7:
        return loadu_si112(ptr);
    default:
        return loadu_si128(ptr);
    }
}

__m128i sse::sad_epu8(__m128i a, __m128i b) { return _mm_sad_epu8(a, b); }

__m128i sse::zeros() { return _mm_setzero_si128(); }
__m128i sse::ones() { return _mm_set1_epi32(-1); }

__m128i sse::set_epi8(char e15, char e14, char e13, char e12, char e11, char e10, char e9,
                      char e8, char e7, char e6, char e5, char e4, char e3, char e2,
                      char e1, char e0) {
    return _mm_set_epi8(e15, e14, e13, e12, e11, e10, e9, e8, e7, e6, e5, e4, e3, e2, e1,
                        e0);
}

__m128i sse::set_epi16(short e7, short e6, short e5, short e4, short e3, short e2,
                       short e1, short e0) {
    return _mm_set_epi16(e7, e6, e5, e4, e3, e2, e1, e0);
}
__m128i sse::set_epi32(int e3, int e2, int e1, int e0) {
    return _mm_set_epi32(e3, e2, e1, e0);
}
__m128i sse::set_epi64x(long long e1, long long e0) { return _mm_set_epi64x(e1, e0); }

__m128i sse::setr_epi8(char e15, char e14, char e13, char e12, char e11, char e10,
                       char e9, char e8, char e7, char e6, char e5, char e4, char e3,
                       char e2, char e1, char e0) {
    return _mm_setr_epi8(e15, e14, e13, e12, e11, e10, e9, e8, e7, e6, e5, e4, e3, e2, e1,
                         e0);
}

__m128i sse::setr_epi16(short e7, short e6, short e5, short e4, short e3, short e2,
                        short e1, short e0) {
    return _mm_setr_epi16(e7, e6, e5, e4, e3, e2, e1, e0);
}
__m128i sse::setr_epi32(int e3, int e2, int e1, int e0) {
    return _mm_setr_epi32(e3, e2, e1, e0);
}

__m128i sse::set1_epi8(int8_t val) { return _mm_set1_epi8(val); }
__m128i sse::set1_epi16(int16_t val) { return _mm_set1_epi16(val); }
__m128i sse::set1_epi32(int32_t val) { return _mm_set1_epi32(val); }
__m128i sse::set1_epi64(int64_t val) { return _mm_set1_epi64x(val); }

__m128i sse::set1(int8_t val, int8_t) { return set1_epi8(val); }
__m128i sse::set1(int16_t val, int16_t) { return set1_epi16(val); }
__m128i sse::set1(int32_t val, int32_t) { return set1_epi32(val); }
__m128i sse::set1(int64_t val, int64_t) { return set1_epi64(val); }
__m128i sse::set1(uint8_t val, uint8_t) { return set1_epi8(val); }
__m128i sse::set1(uint16_t val, uint16_t) { return set1_epi16(val); }
__m128i sse::set1(uint32_t val, uint32_t) { return set1_epi32(val); }
__m128i sse::set1(uint64_t val, uint64_t) { return set1_epi64(val); }

__m128i sse::setmin_epi8() { return set1_epi8(0x80u); }
__m128i sse::setmin_epi16() { return set1_epi16(0x8000u); }
__m128i sse::setmin_epi32() { return set1_epi32(0x80000000u); }

__m128i sse::setmin(int8_t) { return setmin_epi8(); }
__m128i sse::setmin(int16_t) { return setmin_epi16(); }
__m128i sse::setmin(int32_t) { return setmin_epi32(); }
__m128i sse::setmin(uint8_t) { return set1_epi32(0); }
__m128i sse::setmin(uint16_t) { return set1_epi32(0); }
__m128i sse::setmin(uint32_t) { return set1_epi32(0); }

__m128i sse::setmax_epi8() { return set1_epi8(0x7F); }
__m128i sse::setmax_epi16() { return set1_epi16(0x7FFF); }
__m128i sse::setmax_epi32() { return set1_epi32(0x7FFFFFFF); }

__m128i sse::setmax(int8_t) { return setmax_epi8(); }
__m128i sse::setmax(int16_t) { return setmax_epi16(); }
__m128i sse::setmax(int32_t) { return setmax_epi32(); }
__m128i sse::setmax(uint8_t) { return set1_epi32(0xFFFFFFFF); }
__m128i sse::setmax(uint16_t) { return set1_epi32(0xFFFFFFFF); }
__m128i sse::setmax(uint32_t) { return set1_epi32(0xFFFFFFFF); }

template <int imm>
__m128i sse::shl(__m128i a) {
    if constexpr (imm >= 64) {
        a = slli<8>(a);
        a = slli_epi64(a, imm - 64);
        return a;
    } else {
        auto b = slli_epi64(a, imm);
        auto c = slli<8>(a);
        c = srli_epi64(c, 64 - imm);
        return Or(b, c);
    }
}

template <int imm>
__m128i sse::shr(__m128i a) {
    if constexpr (imm >= 64) {
        a = srli<8>(a);
        a = srli_epi64(a, imm - 64);
        return a;
    } else {
        auto b = srli_epi64(a, imm);
        auto c = srli<8>(a);
        c = slli_epi64(c, 64 - imm);
        return Or(b, c);
    }
}

template <int imm8>
__m128i sse::shuffle_epi32(__m128i v) {
    static_assert(imm8 >= 0 && imm8 <= 255, "imm8 must be in range [0, 255]");
    return _mm_shuffle_epi32(v, imm8);
}

template <int imm8>
__m128i sse::shufflehi_epi16(__m128i v) {
    return _mm_shufflehi_epi16(v, imm8);
}

template <int imm8>
__m128i sse::shufflelo_epi16(__m128i v) {
    return _mm_shufflelo_epi16(v, imm8);
}

__m128i sse::sll_epi16(__m128i a, __m128i b) { return _mm_sll_epi16(a, b); }
__m128i sse::sll_epi32(__m128i a, __m128i b) { return _mm_sll_epi32(a, b); }
__m128i sse::sll_epi64(__m128i a, __m128i b) { return _mm_sll_epi64(a, b); }

__m128i sse::sll(__m128i a, __m128i b, int16_t) { return sll_epi16(a, b); }
__m128i sse::sll(__m128i a, __m128i b, int32_t) { return sll_epi32(a, b); }
__m128i sse::sll(__m128i a, __m128i b, int64_t) { return sll_epi64(a, b); }
__m128i sse::sll(__m128i a, __m128i b, uint16_t) { return sll_epi16(a, b); }
__m128i sse::sll(__m128i a, __m128i b, uint32_t) { return sll_epi32(a, b); }
__m128i sse::sll(__m128i a, __m128i b, uint64_t) { return sll_epi64(a, b); }

template <int imm8>
__m128i sse::slli(__m128i v) {
    return _mm_slli_si128(v, imm8);
}
__m128i sse::slli_epi16(__m128i a, int imm8) {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(imm8 == 1)) {
        return sse::add_epi16(a, a);
    }

    return _mm_slli_epi16(a, imm8);
}
__m128i sse::slli_epi32(__m128i a, int imm8) {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(imm8 == 1)) {
        return sse::add_epi32(a, a);
    }

    return _mm_slli_epi32(a, imm8);
}
__m128i sse::slli_epi64(__m128i a, int imm8) {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(imm8 == 1)) {
        return sse::add_epi64(a, a);
    }

    return _mm_slli_epi64(a, imm8);
}

__m128i sse::slli(__m128i a, int imm8, int16_t) { return slli_epi16(a, imm8); }
__m128i sse::slli(__m128i a, int imm8, int32_t) { return slli_epi32(a, imm8); }
__m128i sse::slli(__m128i a, int imm8, int64_t) { return slli_epi64(a, imm8); }
__m128i sse::slli(__m128i a, int imm8, uint16_t) { return slli_epi16(a, imm8); }
__m128i sse::slli(__m128i a, int imm8, uint32_t) { return slli_epi32(a, imm8); }
__m128i sse::slli(__m128i a, int imm8, uint64_t) { return slli_epi64(a, imm8); }

__m128i sse::sra_epi16(__m128i a, __m128i b) { return _mm_sra_epi16(a, b); }
__m128i sse::sra_epi32(__m128i a, __m128i b) { return _mm_sra_epi32(a, b); }

__m128i sse::sra(__m128i a, __m128i b, int16_t) { return sra_epi16(a, b); }
__m128i sse::sra(__m128i a, __m128i b, int32_t) { return sra_epi32(a, b); }

__m128i sse::srai_epi16(__m128i a, int imm8) { return _mm_srai_epi16(a, imm8); }
__m128i sse::srai_epi32(__m128i a, int imm8) { return _mm_srai_epi32(a, imm8); }

__m128i sse::srai(__m128i a, int imm8, int16_t) { return srai_epi16(a, imm8); }
__m128i sse::srai(__m128i a, int imm8, int32_t) { return srai_epi32(a, imm8); }

__m128i sse::srl_epi16(__m128i a, __m128i b) { return _mm_srl_epi16(a, b); }
__m128i sse::srl_epi32(__m128i a, __m128i b) { return _mm_srl_epi32(a, b); }
__m128i sse::srl_epi64(__m128i a, __m128i b) { return _mm_srl_epi64(a, b); }

__m128i sse::srl(__m128i a, __m128i b, int16_t) { return srl_epi16(a, b); }
__m128i sse::srl(__m128i a, __m128i b, int32_t) { return srl_epi32(a, b); }
__m128i sse::srl(__m128i a, __m128i b, int64_t) { return srl_epi64(a, b); }
__m128i sse::srl(__m128i a, __m128i b, uint16_t) { return srl_epi16(a, b); }
__m128i sse::srl(__m128i a, __m128i b, uint32_t) { return srl_epi32(a, b); }
__m128i sse::srl(__m128i a, __m128i b, uint64_t) { return srl_epi64(a, b); }

template <int imm8>
__m128i sse::srli(__m128i v) {
    return _mm_srli_si128(v, imm8);
}
__m128i sse::srli_epi8(__m128i a, int imm8) {
    return And(srli_epi16(a, imm8), sse_detail::srli_epi8_mask[imm8]);
}
__m128i sse::srli_epi16(__m128i a, int imm8) { return _mm_srli_epi16(a, imm8); }
__m128i sse::srli_epi32(__m128i a, int imm8) { return _mm_srli_epi32(a, imm8); }
__m128i sse::srli_epi64(__m128i a, int imm8) { return _mm_srli_epi64(a, imm8); }

__m128i sse::srli(__m128i a, int imm8, int8_t) { return srli_epi8(a, imm8); }
__m128i sse::srli(__m128i a, int imm8, int16_t) { return srli_epi16(a, imm8); }
__m128i sse::srli(__m128i a, int imm8, int32_t) { return srli_epi32(a, imm8); }
__m128i sse::srli(__m128i a, int imm8, int64_t) { return srli_epi64(a, imm8); }
__m128i sse::srli(__m128i a, int imm8, uint8_t) { return srli_epi8(a, imm8); }
__m128i sse::srli(__m128i a, int imm8, uint16_t) { return srli_epi16(a, imm8); }
__m128i sse::srli(__m128i a, int imm8, uint32_t) { return srli_epi32(a, imm8); }
__m128i sse::srli(__m128i a, int imm8, uint64_t) { return srli_epi64(a, imm8); }

void sse::stream(__m128i *ptr, __m128i v) { _mm_stream_si128(ptr, v); }

void sse::store(void *ptr, __m128i val) {
    _mm_store_si128(static_cast<__m128i *>(ptr), val);
}
void sse::storeu(void *ptr, __m128i val) {
    _mm_storeu_si128(static_cast<__m128i *>(ptr), val);
}

__m128i sse::sub_epi8(__m128i a, __m128i b) { return _mm_sub_epi8(a, b); }
__m128i sse::sub_epi16(__m128i a, __m128i b) { return _mm_sub_epi16(a, b); }
__m128i sse::sub_epi32(__m128i a, __m128i b) { return _mm_sub_epi32(a, b); }
__m128i sse::sub_epi64(__m128i a, __m128i b) { return _mm_sub_epi64(a, b); }

__m128i sse::sub(__m128i a, __m128i b, int8_t) { return sub_epi8(a, b); }
__m128i sse::sub(__m128i a, __m128i b, int16_t) { return sub_epi16(a, b); }
__m128i sse::sub(__m128i a, __m128i b, int32_t) { return sub_epi32(a, b); }
__m128i sse::sub(__m128i a, __m128i b, int64_t) { return sub_epi64(a, b); }
__m128i sse::sub(__m128i a, __m128i b, uint8_t) { return sub_epi8(a, b); }
__m128i sse::sub(__m128i a, __m128i b, uint16_t) { return sub_epi16(a, b); }
__m128i sse::sub(__m128i a, __m128i b, uint32_t) { return sub_epi32(a, b); }
__m128i sse::sub(__m128i a, __m128i b, uint64_t) { return sub_epi64(a, b); }

__m128i sse::subs_epi8(__m128i a, __m128i b) { return _mm_subs_epi8(a, b); }
__m128i sse::subs_epi16(__m128i a, __m128i b) { return _mm_subs_epi16(a, b); }

__m128i sse::subs_epu8(__m128i a, __m128i b) { return _mm_subs_epu8(a, b); }
__m128i sse::subs_epu16(__m128i a, __m128i b) { return _mm_subs_epu16(a, b); }

__m128i sse::subs(__m128i a, __m128i b, int8_t) { return subs_epi8(a, b); }
__m128i sse::subs(__m128i a, __m128i b, int16_t) { return subs_epi16(a, b); }
__m128i sse::subs(__m128i a, __m128i b, uint8_t) { return subs_epu8(a, b); }
__m128i sse::subs(__m128i a, __m128i b, uint16_t) { return subs_epu16(a, b); }

__m128i sse::unpackhi_epi8(__m128i a, __m128i b) { return _mm_unpackhi_epi8(a, b); }
__m128i sse::unpackhi_epi16(__m128i a, __m128i b) { return _mm_unpackhi_epi16(a, b); }
__m128i sse::unpackhi_epi32(__m128i a, __m128i b) { return _mm_unpackhi_epi32(a, b); }
__m128i sse::unpackhi_epi64(__m128i a, __m128i b) { return _mm_unpackhi_epi64(a, b); }

__m128i sse::unpackhi(__m128i a, __m128i b, int8_t) { return unpackhi_epi8(a, b); }
__m128i sse::unpackhi(__m128i a, __m128i b, int16_t) { return unpackhi_epi16(a, b); }
__m128i sse::unpackhi(__m128i a, __m128i b, int32_t) { return unpackhi_epi32(a, b); }
__m128i sse::unpackhi(__m128i a, __m128i b, int64_t) { return unpackhi_epi64(a, b); }
__m128i sse::unpackhi(__m128i a, __m128i b, uint8_t) { return unpackhi_epi8(a, b); }
__m128i sse::unpackhi(__m128i a, __m128i b, uint16_t) { return unpackhi_epi16(a, b); }
__m128i sse::unpackhi(__m128i a, __m128i b, uint32_t) { return unpackhi_epi32(a, b); }
__m128i sse::unpackhi(__m128i a, __m128i b, uint64_t) { return unpackhi_epi64(a, b); }

__m128i sse::unpacklo_epi8(__m128i a, __m128i b) { return _mm_unpacklo_epi8(a, b); }
__m128i sse::unpacklo_epi16(__m128i a, __m128i b) { return _mm_unpacklo_epi16(a, b); }
__m128i sse::unpacklo_epi32(__m128i a, __m128i b) { return _mm_unpacklo_epi32(a, b); }
__m128i sse::unpacklo_epi64(__m128i a, __m128i b) { return _mm_unpacklo_epi64(a, b); }

__m128i sse::unpacklo(__m128i a, __m128i b, int8_t) { return unpacklo_epi8(a, b); }
__m128i sse::unpacklo(__m128i a, __m128i b, int16_t) { return unpacklo_epi16(a, b); }
__m128i sse::unpacklo(__m128i a, __m128i b, int32_t) { return unpacklo_epi32(a, b); }
__m128i sse::unpacklo(__m128i a, __m128i b, int64_t) { return unpacklo_epi64(a, b); }
__m128i sse::unpacklo(__m128i a, __m128i b, uint8_t) { return unpacklo_epi8(a, b); }
__m128i sse::unpacklo(__m128i a, __m128i b, uint16_t) { return unpacklo_epi16(a, b); }
__m128i sse::unpacklo(__m128i a, __m128i b, uint32_t) { return unpacklo_epi32(a, b); }

__m128i sse::Xor(__m128i a, __m128i b) { return _mm_xor_si128(a, b); }

#endif

#if WJR_HAS_SIMD(SSE3)

__m128i sse::lddqu(const __m128i *ptr) { return _mm_lddqu_si128(ptr); }

#endif

#if WJR_HAS_SIMD(SSSE3)

__m128i sse::abs_epi8(__m128i val) { return _mm_abs_epi8(val); }
__m128i sse::abs_epi16(__m128i val) { return _mm_abs_epi16(val); }
__m128i sse::abs_epi32(__m128i val) { return _mm_abs_epi32(val); }

__m128i sse::abs(__m128i val, int8_t) { return abs_epi8(val); }
__m128i sse::abs(__m128i val, int16_t) { return abs_epi16(val); }
__m128i sse::abs(__m128i val, int32_t) { return abs_epi32(val); }
__m128i sse::abs(__m128i val, uint8_t) { return val; }
__m128i sse::abs(__m128i val, uint16_t) { return val; }
__m128i sse::abs(__m128i val, uint32_t) { return val; }

__m128i sse::shuffle_epi8(__m128i v, __m128i imm8) { return _mm_shuffle_epi8(v, imm8); }

__m128i sse::sign_epi8(__m128i a, __m128i b) { return _mm_sign_epi8(a, b); }
__m128i sse::sign_epi16(__m128i a, __m128i b) { return _mm_sign_epi16(a, b); }
__m128i sse::sign_epi32(__m128i a, __m128i b) { return _mm_sign_epi32(a, b); }

__m128i sse::sign(__m128i a, __m128i b, int8_t) { return sign_epi8(a, b); }
__m128i sse::sign(__m128i a, __m128i b, int16_t) { return sign_epi16(a, b); }
__m128i sse::sign(__m128i a, __m128i b, int32_t) { return sign_epi32(a, b); }
__m128i sse::sign(__m128i a, __m128i b, uint8_t) { return sign_epi8(a, b); }
__m128i sse::sign(__m128i a, __m128i b, uint16_t) { return sign_epi16(a, b); }
__m128i sse::sign(__m128i a, __m128i b, uint32_t) { return sign_epi32(a, b); }

#endif

#if WJR_HAS_SIMD(SSE4_1)

template <int imm8>
__m128i sse::blend_epi16(__m128i a, __m128i b) {
    return _mm_blend_epi16(a, b, imm8);
}

__m128i sse::cmpeq_epi64(__m128i a, __m128i b) { return _mm_cmpeq_epi64(a, b); }

__m128i sse::cmpeq(__m128i a, __m128i b, int64_t) { return cmpeq_epi64(a, b); }
__m128i sse::cmpeq(__m128i a, __m128i b, uint64_t) { return cmpeq_epi64(a, b); }

__m128i sse::cmpgt_epi64(__m128i a, __m128i b) { return _mm_cmpgt_epi64(a, b); }

__m128i sse::cmpgt(__m128i a, __m128i b, int64_t) { return cmpgt_epi64(a, b); }

template <int imm8>
__m128i sse::insert_epi8(__m128i a, int i) {
    return _mm_insert_epi8(a, i, imm8);
}

template <int imm8>
__m128i sse::insert_epi32(__m128i a, int i) {
    return _mm_insert_epi32(a, i, imm8);
}

template <int imm8>
__m128i sse::insert_epi64(__m128i a, int64_t i) {
    return _mm_insert_epi64(a, i, imm8);
}

template <int imm8>
__m128i sse::insert(__m128i a, int i, int8_t) {
    return insert_epi8<imm8>(a, i);
}

template <int imm8>
__m128i sse::insert(__m128i a, int i, int32_t) {
    return insert_epi32<imm8>(a, i);
}

template <int imm8>
__m128i sse::insert(__m128i a, int64_t i, int64_t) {
    return insert_epi64<imm8>(a, i);
}

template <int imm8>
__m128i sse::insert(__m128i a, int i, uint8_t) {
    return insert_epi8<imm8>(a, i);
}

template <int imm8>
__m128i sse::insert(__m128i a, int i, uint32_t) {
    return insert_epi32<imm8>(a, i);
}

template <int imm8>
__m128i sse::insert(__m128i a, int64_t i, uint64_t) {
    return insert_epi64<imm8>(a, i);
}

__m128i sse::minpos_epu16(__m128i a) { return _mm_minpos_epu16(a); }

__m128i sse::mul_epi32(__m128i a, __m128i b) { return _mm_mul_epi32(a, b); }

__m128i sse::mullo_epi32(__m128i a, __m128i b) { return _mm_mullo_epi32(a, b); }

__m128i sse::packus_epi32(__m128i a, __m128i b) { return _mm_packus_epi32(a, b); }

__m128i sse::stream_load(void *p) {
    return _mm_stream_load_si128(static_cast<__m128i *>(p));
}

int sse::test_all_ones(__m128i a) { return _mm_test_all_ones(a); }

int sse::test_all_zeros(__m128i a, __m128i b) { return _mm_test_all_zeros(a, b); }

int sse::test_all_zeros(__m128i a) { return _mm_test_all_zeros(a, a); }

int sse::test_mix_ones_zeros(__m128i a, __m128i b) {
    return _mm_test_mix_ones_zeros(a, b);
}

int sse::testc(__m128i a, __m128i b) { return _mm_testc_si128(a, b); }

int sse::testnzc(__m128i a, __m128i b) { return _mm_testnzc_si128(a, b); }

int sse::testz(__m128i a, __m128i b) { return _mm_testz_si128(a, b); }

#endif

} // namespace wjr

#endif // WJR_X86_SIMD_SSE_HPP__

namespace wjr {

struct avx {
    using mask_type = uint32_t;

#if WJR_HAS_SIMD(AVX)

    using float_type = __m256;
    using float_tag_type = __m256_t;
    using int_type = __m256i;
    using int_tag_type = __m256i_t;
    using double_type = __m256d;
    using double_tag_type = __m256d_t;

#endif // AVX

    constexpr static size_t width();
    constexpr static mask_type mask();

#if WJR_HAS_SIMD(AVX)

    WJR_INTRINSIC_INLINE static __m256i concat(__m128i a, __m128i b);

    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract_epi32(__m256i v);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int64_t extract_epi64(__m256i v);

    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m256i v, int32_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int64_t extract(__m256i v, int64_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m128i extract_si128(__m256i v);

    WJR_INTRINSIC_INLINE static __m128i getlow(__m256i a);

    WJR_INTRINSIC_INLINE static __m128i gethigh(__m256i a);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i insert_epi8(__m256i v, int8_t i);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i insert_epi16(__m256i v, int16_t i);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i insert_epi32(__m256i v, int32_t i);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i insert_epi64(__m256i v, int64_t i);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i insert_si128(__m256i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m256i load(const void *p);
    WJR_INTRINSIC_INLINE static __m256i loadu(const void *p);

    WJR_INTRINSIC_INLINE static __m256i ones();

    WJR_INTRINSIC_INLINE static __m256i loadu_si16(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si32(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si48(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si64(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si80(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si96(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si112(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si128(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si144(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si160(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si176(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si192(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si208(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si224(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si240(const void *ptr);
    WJR_INTRINSIC_INLINE static __m256i loadu_si256(const void *ptr);

    WJR_INTRINSIC_INLINE static __m256i loadu_si16x(const void *ptr, int n);

    WJR_INTRINSIC_INLINE static __m256i
    set_epi8(char e31, char e30, char e29, char e28, char e27, char e26, char e25,
             char e24, char e23, char e22, char e21, char e20, char e19, char e18,
             char e17, char e16, char e15, char e14, char e13, char e12, char e11,
             char e10, char e9, char e8, char e7, char e6, char e5, char e4, char e3,
             char e2, char e1, char e0);

    WJR_INTRINSIC_INLINE static __m256i set_epi16(short e15, short e14, short e13,
                                                  short e12, short e11, short e10,
                                                  short e9, short e8, short e7, short e6,
                                                  short e5, short e4, short e3, short e2,
                                                  short e1, short e0);

    WJR_INTRINSIC_INLINE static __m256i set_epi32(int e7, int e6, int e5, int e4, int e3,
                                                  int e2, int e1, int e0);

    WJR_INTRINSIC_INLINE static __m256i set_epi64x(long long e3, long long e2,
                                                   long long e1, long long e0);

    WJR_INTRINSIC_INLINE static __m256i
    setr_epi8(char e31, char e30, char e29, char e28, char e27, char e26, char e25,
              char e24, char e23, char e22, char e21, char e20, char e19, char e18,
              char e17, char e16, char e15, char e14, char e13, char e12, char e11,
              char e10, char e9, char e8, char e7, char e6, char e5, char e4, char e3,
              char e2, char e1, char e0);

    WJR_INTRINSIC_INLINE static __m256i setr_epi16(short e15, short e14, short e13,
                                                   short e12, short e11, short e10,
                                                   short e9, short e8, short e7, short e6,
                                                   short e5, short e4, short e3, short e2,
                                                   short e1, short e0);

    WJR_INTRINSIC_INLINE static __m256i setr_epi32(int e7, int e6, int e5, int e4, int e3,
                                                   int e2, int e1, int e0);

    WJR_INTRINSIC_INLINE static __m256i setr_epi64x(long long e3, long long e2,
                                                    long long e1, long long e0);

    WJR_INTRINSIC_INLINE static __m256i set1_epi8(int8_t a);
    WJR_INTRINSIC_INLINE static __m256i set1_epi16(int16_t a);
    WJR_INTRINSIC_INLINE static __m256i set1_epi32(int32_t a);
    WJR_INTRINSIC_INLINE static __m256i set1_epi64(int64_t a);

    WJR_INTRINSIC_INLINE static __m256i set1(int8_t a, int8_t);
    WJR_INTRINSIC_INLINE static __m256i set1(int16_t a, int16_t);
    WJR_INTRINSIC_INLINE static __m256i set1(int32_t a, int32_t);
    WJR_INTRINSIC_INLINE static __m256i set1(int64_t a, int64_t);
    WJR_INTRINSIC_INLINE static __m256i set1(uint8_t a, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i set1(uint16_t a, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i set1(uint32_t a, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i set1(uint64_t a, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i setmin_epi8();
    WJR_INTRINSIC_INLINE static __m256i setmin_epi16();
    WJR_INTRINSIC_INLINE static __m256i setmin_epi32();
    WJR_INTRINSIC_INLINE static __m256i setmin_epi64();

    WJR_INTRINSIC_INLINE static __m256i setmin(int8_t);
    WJR_INTRINSIC_INLINE static __m256i setmin(int16_t);
    WJR_INTRINSIC_INLINE static __m256i setmin(int32_t);
    WJR_INTRINSIC_INLINE static __m256i setmin(int64_t);

    WJR_INTRINSIC_INLINE static __m256i setmax_epi8();
    WJR_INTRINSIC_INLINE static __m256i setmax_epi16();
    WJR_INTRINSIC_INLINE static __m256i setmax_epi32();
    WJR_INTRINSIC_INLINE static __m256i setmax_epi64();

    WJR_INTRINSIC_INLINE static __m256i setmax(int8_t);
    WJR_INTRINSIC_INLINE static __m256i setmax(int16_t);
    WJR_INTRINSIC_INLINE static __m256i setmax(int32_t);
    WJR_INTRINSIC_INLINE static __m256i setmax(int64_t);

    WJR_INTRINSIC_INLINE static void stream(__m256i *p, __m256i a);

    WJR_INTRINSIC_INLINE static void store(void *p, __m256i a);
    WJR_INTRINSIC_INLINE static void storeu(void *p, __m256i a);

    WJR_INTRINSIC_INLINE static int test_all_zeros(__m256i a);

    WJR_INTRINSIC_INLINE static int testc(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static int testnzc(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static int testz(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i zeros();

#endif // AVX

#if WJR_HAS_SIMD(AVX2)

    WJR_INTRINSIC_INLINE static __m256i And(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i AndNot(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i Or(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i Xor(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i Not(__m256i v);

    WJR_INTRINSIC_INLINE static __m256i abs_epi8(__m256i v);
    WJR_INTRINSIC_INLINE static __m256i abs_epi16(__m256i v);
    WJR_INTRINSIC_INLINE static __m256i abs_epi32(__m256i v);

    WJR_INTRINSIC_INLINE static __m256i abs(__m256i v, int8_t);
    WJR_INTRINSIC_INLINE static __m256i abs(__m256i v, int16_t);
    WJR_INTRINSIC_INLINE static __m256i abs(__m256i v, int32_t);
    WJR_INTRINSIC_INLINE static __m256i abs(__m256i v, int64_t);

    WJR_INTRINSIC_INLINE static __m256i add_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i add_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i add_epi32(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i add_epi64(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i add(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i add(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i add(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i add(__m256i a, __m256i b, int64_t);
    WJR_INTRINSIC_INLINE static __m256i add(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i add(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i add(__m256i a, __m256i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i add(__m256i a, __m256i b, uint64_t);

    WJR_INTRINSIC_INLINE static uint8_t add_epu8(__m256i v);
    WJR_INTRINSIC_INLINE static uint16_t add_epu16(__m256i v);
    WJR_INTRINSIC_INLINE static uint32_t add_epu32(__m256i v);
    WJR_INTRINSIC_INLINE static uint64_t add_epu64(__m256i v);

    WJR_INTRINSIC_INLINE static int8_t add_epi8(__m256i v);
    WJR_INTRINSIC_INLINE static int16_t add_epi16(__m256i v);
    WJR_INTRINSIC_INLINE static int32_t add_epi32(__m256i v);
    WJR_INTRINSIC_INLINE static int64_t add_epi64(__m256i v);

    WJR_INTRINSIC_INLINE static int8_t add(__m256i v, int8_t);
    WJR_INTRINSIC_INLINE static int16_t add(__m256i v, int16_t);
    WJR_INTRINSIC_INLINE static int32_t add(__m256i v, int32_t);
    WJR_INTRINSIC_INLINE static int64_t add(__m256i v, int64_t);
    WJR_INTRINSIC_INLINE static uint8_t add(__m256i v, uint8_t);
    WJR_INTRINSIC_INLINE static uint16_t add(__m256i v, uint16_t);
    WJR_INTRINSIC_INLINE static uint32_t add(__m256i v, uint32_t);
    WJR_INTRINSIC_INLINE static uint64_t add(__m256i v, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i adds_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i adds_epi16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i adds_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i adds_epu16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i adds(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i adds(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i adds(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i adds(__m256i a, __m256i b, uint16_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i alignr(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i alignr_epi16(__m256i a, __m256i b, int c);
    WJR_INTRINSIC_INLINE static __m256i alignr_epi32(__m256i a, __m256i b, int c);
    WJR_INTRINSIC_INLINE static __m256i alignr_epi64(__m256i a, __m256i b, int c);

    WJR_INTRINSIC_INLINE static __m256i alignr(__m256i a, __m256i b, int c, int16_t);
    WJR_INTRINSIC_INLINE static __m256i alignr(__m256i a, __m256i b, int c, int32_t);
    WJR_INTRINSIC_INLINE static __m256i alignr(__m256i a, __m256i b, int c, int64_t);
    WJR_INTRINSIC_INLINE static __m256i alignr(__m256i a, __m256i b, int c, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i alignr(__m256i a, __m256i b, int c, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i alignr(__m256i a, __m256i b, int c, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i avg_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i avg_epu16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i avg(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i avg(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i avg(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i avg(__m256i a, __m256i b, uint16_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i blend_epi16(__m256i a, __m256i b);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i blend_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i blendv_epi8(__m256i a, __m256i b, __m256i mask);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i bslli_epi128(__m256i a);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i bsrli_epi128(__m256i a);

    WJR_INTRINSIC_INLINE static __m256i cmpeq_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpeq_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpeq_epi32(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpeq_epi64(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmpeq(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i cmpeq(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i cmpeq(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i cmpeq(__m256i a, __m256i b, int64_t);
    WJR_INTRINSIC_INLINE static __m256i cmpeq(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i cmpeq(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i cmpeq(__m256i a, __m256i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i cmpeq(__m256i a, __m256i b, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i cmpge_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpge_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpge_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmpge_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpge_epu16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpge_epu32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmpge(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i cmpge(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i cmpge(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i cmpge(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i cmpge(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i cmpge(__m256i a, __m256i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m256i cmpgt_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpgt_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpgt_epi32(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpgt_epi64(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmpgt_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpgt_epu16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpgt_epu32(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpgt_epu64(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmpgt(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i cmpgt(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i cmpgt(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i cmpgt(__m256i a, __m256i b, int64_t);
    WJR_INTRINSIC_INLINE static __m256i cmpgt(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i cmpgt(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i cmpgt(__m256i a, __m256i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i cmpgt(__m256i a, __m256i b, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i cmple_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmple_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmple_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmple_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmple_epu16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmple_epu32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmple(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i cmple(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i cmple(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i cmple(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i cmple(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i cmple(__m256i a, __m256i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m256i cmplt_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmplt_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmplt_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmplt_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmplt_epu16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmplt_epu32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmplt(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i cmplt(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i cmplt(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i cmplt(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i cmplt(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i cmplt(__m256i a, __m256i b, uint32_t);

    WJR_INTRINSIC_INLINE static __m256i cmpne_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpne_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i cmpne_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i cmpne(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i cmpne(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i cmpne(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i cmpne(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i cmpne(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i cmpne(__m256i a, __m256i b, uint32_t);

    template <typename T>
    WJR_INTRINSIC_INLINE static __m256i cmp(__m256i a, __m256i b, std::equal_to<>, T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m256i cmp(__m256i a, __m256i b, std::not_equal_to<>, T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m256i cmp(__m256i a, __m256i b, std::greater<>, T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m256i cmp(__m256i a, __m256i b, std::greater_equal<>,
                                            T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m256i cmp(__m256i a, __m256i b, std::less<>, T);
    template <typename T>
    WJR_INTRINSIC_INLINE static __m256i cmp(__m256i a, __m256i b, std::less_equal<>, T);

    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract_epi8(__m256i v);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract_epi16(__m256i v);

    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m256i v, int8_t);
    template <int imm8>
    WJR_INTRINSIC_INLINE static int extract(__m256i v, int16_t);

    WJR_INTRINSIC_INLINE static __m256i hadd_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i hadd_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i hadd(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i hadd(__m256i a, __m256i b, int32_t);

    WJR_INTRINSIC_INLINE static __m256i hadds_epi16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i hsub_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i hsub_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i hsub(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i hsub(__m256i a, __m256i b, int32_t);

    WJR_INTRINSIC_INLINE static __m256i hsubs_epi16(__m256i a, __m256i b);

    template <typename T,
              WJR_REQUIRES(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t, uint8_t,
                                       uint16_t, uint32_t, uint64_t>)>
    WJR_INTRINSIC_INLINE static __m256i logical_and(__m256i a, __m256i b, T);

    template <typename T,
              WJR_REQUIRES(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t, uint8_t,
                                       uint16_t, uint32_t, uint64_t>)>
    WJR_INTRINSIC_INLINE static __m256i logical_not(__m256i v, T);

    template <typename T,
              WJR_REQUIRES(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t, uint8_t,
                                       uint16_t, uint32_t, uint64_t>)>
    WJR_INTRINSIC_INLINE static __m256i logical_or(__m256i a, __m256i b, T);

    WJR_INTRINSIC_INLINE static __m256i madd_epi16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i max_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i max_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i max_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i max_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i max_epu16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i max_epu32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i max(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i max(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i max(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i max(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i max(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i max(__m256i a, __m256i b, uint32_t);

    WJR_INTRINSIC_INLINE static int8_t max_epi8(__m256i a);
    WJR_INTRINSIC_INLINE static int16_t max_epi16(__m256i a);
    WJR_INTRINSIC_INLINE static int32_t max_epi32(__m256i a);
    WJR_INTRINSIC_INLINE static uint8_t max_epu8(__m256i a);
    WJR_INTRINSIC_INLINE static uint16_t max_epu16(__m256i a);
    WJR_INTRINSIC_INLINE static uint32_t max_epu32(__m256i a);

    WJR_INTRINSIC_INLINE static int8_t max(__m256i a, int8_t);
    WJR_INTRINSIC_INLINE static int16_t max(__m256i a, int16_t);
    WJR_INTRINSIC_INLINE static int32_t max(__m256i a, int32_t);

    WJR_INTRINSIC_INLINE static uint8_t max(__m256i a, uint8_t);
    WJR_INTRINSIC_INLINE static uint16_t max(__m256i a, uint16_t);
    WJR_INTRINSIC_INLINE static uint32_t max(__m256i a, uint32_t);

    WJR_INTRINSIC_INLINE static __m256i min_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i min_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i min_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i min_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i min_epu16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i min_epu32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i min(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i min(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i min(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i min(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i min(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i min(__m256i a, __m256i b, uint32_t);

    WJR_INTRINSIC_INLINE static int8_t min_epi8(__m256i a);
    WJR_INTRINSIC_INLINE static int16_t min_epi16(__m256i a);
    WJR_INTRINSIC_INLINE static int32_t min_epi32(__m256i a);

    WJR_INTRINSIC_INLINE static uint8_t min_epu8(__m256i a);
    WJR_INTRINSIC_INLINE static uint16_t min_epu16(__m256i a);
    WJR_INTRINSIC_INLINE static uint32_t min_epu32(__m256i a);

    WJR_INTRINSIC_INLINE static int8_t min(__m256i a, int8_t);
    WJR_INTRINSIC_INLINE static int16_t min(__m256i a, int16_t);
    WJR_INTRINSIC_INLINE static int32_t min(__m256i a, int32_t);
    WJR_INTRINSIC_INLINE static uint8_t min(__m256i a, uint8_t);
    WJR_INTRINSIC_INLINE static uint16_t min(__m256i a, uint16_t);
    WJR_INTRINSIC_INLINE static uint32_t min(__m256i a, uint32_t);

    WJR_INTRINSIC_INLINE static mask_type movemask_epi8(__m256i a);

    WJR_INTRINSIC_INLINE static __m256i mul_epi32(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i mul_epu32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i mulhi_epi16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i mulhi_epu16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i mullo_epi16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i packs_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i packs_epi32(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i packus_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i packus_epi32(__m256i a, __m256i b);

    template <int imm>
    WJR_INTRINSIC_INLINE static __m256i shl(__m256i a);

    template <int imm>
    WJR_INTRINSIC_INLINE static __m256i shr(__m256i a);

    WJR_INTRINSIC_INLINE static __m256i shuffle_epi8(__m256i a, __m256i b);
    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i shuffle_epi32(__m256i a);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i shufflehi_epi16(__m256i a);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i shufflelo_epi16(__m256i a);

    WJR_INTRINSIC_INLINE static __m256i sll_epi16(__m256i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m256i sll_epi32(__m256i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m256i sll_epi64(__m256i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m256i sll(__m256i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i sll(__m256i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i sll(__m256i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m256i sll(__m256i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i sll(__m256i a, __m128i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i sll(__m256i a, __m128i b, uint64_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i slli(__m256i a);
    WJR_INTRINSIC_INLINE static __m256i slli_epi16(__m256i a, int imm8);
    WJR_INTRINSIC_INLINE static __m256i slli_epi32(__m256i a, int imm8);
    WJR_INTRINSIC_INLINE static __m256i slli_epi64(__m256i a, int imm8);

    WJR_INTRINSIC_INLINE static __m256i slli(__m256i a, int imm8, int16_t);
    WJR_INTRINSIC_INLINE static __m256i slli(__m256i a, int imm8, int32_t);
    WJR_INTRINSIC_INLINE static __m256i slli(__m256i a, int imm8, int64_t);
    WJR_INTRINSIC_INLINE static __m256i slli(__m256i a, int imm8, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i slli(__m256i a, int imm8, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i slli(__m256i a, int imm8, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i sra_epi16(__m256i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m256i sra_epi32(__m256i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m256i sra(__m256i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i sra(__m256i a, __m128i b, int32_t);

    WJR_INTRINSIC_INLINE static __m256i srai_epi16(__m256i a, int imm8);
    WJR_INTRINSIC_INLINE static __m256i srai_epi32(__m256i a, int imm8);

    WJR_INTRINSIC_INLINE static __m256i srai(__m256i a, int imm8, int16_t);
    WJR_INTRINSIC_INLINE static __m256i srai(__m256i a, int imm8, int32_t);

    WJR_INTRINSIC_INLINE static __m256i stream_load(const void *p);

    WJR_INTRINSIC_INLINE static __m256i srl_epi16(__m256i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m256i srl_epi32(__m256i a, __m128i b);
    WJR_INTRINSIC_INLINE static __m256i srl_epi64(__m256i a, __m128i b);

    WJR_INTRINSIC_INLINE static __m256i srl(__m256i a, __m128i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i srl(__m256i a, __m128i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i srl(__m256i a, __m128i b, int64_t);
    WJR_INTRINSIC_INLINE static __m256i srl(__m256i a, __m128i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i srl(__m256i a, __m128i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i srl(__m256i a, __m128i b, uint64_t);

    template <int imm8>
    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a);
    WJR_INTRINSIC_INLINE static __m256i srli_epi8(__m256i a, int imm8);
    WJR_INTRINSIC_INLINE static __m256i srli_epi16(__m256i a, int imm8);
    WJR_INTRINSIC_INLINE static __m256i srli_epi32(__m256i a, int imm8);
    WJR_INTRINSIC_INLINE static __m256i srli_epi64(__m256i a, int imm8);

    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a, int imm8, int8_t);
    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a, int imm8, int16_t);
    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a, int imm8, int32_t);
    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a, int imm8, int64_t);
    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a, int imm8, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a, int imm8, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a, int imm8, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i srli(__m256i a, int imm8, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i sub_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i sub_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i sub_epi32(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i sub_epi64(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i sub(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i sub(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i sub(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i sub(__m256i a, __m256i b, int64_t);
    WJR_INTRINSIC_INLINE static __m256i sub(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i sub(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i sub(__m256i a, __m256i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i sub(__m256i a, __m256i b, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i subs_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i subs_epi16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i subs_epu8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i subs_epu16(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i subs(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i subs(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i subs(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i subs(__m256i a, __m256i b, uint16_t);

    WJR_INTRINSIC_INLINE static int test_all_ones(__m256i a);

    WJR_INTRINSIC_INLINE static __m256i unpackhi_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i unpackhi_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i unpackhi_epi32(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i unpackhi_epi64(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i unpackhi(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i unpackhi(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i unpackhi(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i unpackhi(__m256i a, __m256i b, int64_t);
    WJR_INTRINSIC_INLINE static __m256i unpackhi(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i unpackhi(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i unpackhi(__m256i a, __m256i b, uint32_t);
    WJR_INTRINSIC_INLINE static __m256i unpackhi(__m256i a, __m256i b, uint64_t);

    WJR_INTRINSIC_INLINE static __m256i unpacklo_epi8(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i unpacklo_epi16(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i unpacklo_epi32(__m256i a, __m256i b);
    WJR_INTRINSIC_INLINE static __m256i unpacklo_epi64(__m256i a, __m256i b);

    WJR_INTRINSIC_INLINE static __m256i unpacklo(__m256i a, __m256i b, int8_t);
    WJR_INTRINSIC_INLINE static __m256i unpacklo(__m256i a, __m256i b, int16_t);
    WJR_INTRINSIC_INLINE static __m256i unpacklo(__m256i a, __m256i b, int32_t);
    WJR_INTRINSIC_INLINE static __m256i unpacklo(__m256i a, __m256i b, int64_t);
    WJR_INTRINSIC_INLINE static __m256i unpacklo(__m256i a, __m256i b, uint8_t);
    WJR_INTRINSIC_INLINE static __m256i unpacklo(__m256i a, __m256i b, uint16_t);
    WJR_INTRINSIC_INLINE static __m256i unpacklo(__m256i a, __m256i b, uint32_t);

#endif // AVX2
};

namespace avx_detail {
#if WJR_HAS_SIMD(AVX2)

const static __m256i srli_epi8_mask[8] = {
    avx::set1_epi16(0xFFFF), avx::set1_epi16(0x7F7F), avx::set1_epi16(0x3F3F),
    avx::set1_epi16(0x1F1F), avx::set1_epi16(0xF0F),  avx::set1_epi16(0x707),
    avx::set1_epi16(0x303),  avx::set1_epi16(0x101),
};

#endif
} // namespace avx_detail

#if WJR_HAS_SIMD(AVX)

template <>
struct broadcast_fn<uint8_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(uint8_t v) const {
        return _mm256_set1_epi8(v);
    }
};

template <>
struct broadcast_fn<uint16_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(uint16_t v) const {
        return _mm256_set1_epi16(v);
    }
};

template <>
struct broadcast_fn<uint32_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(uint32_t v) const {
        return _mm256_set1_epi32(v);
    }
};

template <>
struct broadcast_fn<uint64_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(uint64_t v) const {
        return _mm256_set1_epi64x(v);
    }
};

template <>
struct broadcast_fn<__m256i_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(__m256i v) const { return v; }
};

template <>
struct broadcast_fn<__m128i_t, __m256i_t> {
    WJR_CONST WJR_INTRINSIC_INLINE __m256i operator()(__m128i v) const {
#if WJR_HAS_SIMD(AVX2)
        return _mm256_broadcastsi128_si256(v);
#else
        return _mm256_insertf128_si256(_mm256_castsi128_si256(v), v, 1);
#endif
    }
};

#endif // AVX

/*------------------------avx------------------------*/

constexpr size_t avx::width() { return 256; }

constexpr avx::mask_type avx::mask() { return 0xffffffff; }

#if WJR_HAS_SIMD(AVX)

__m256i avx::concat(__m128i a, __m128i b) {
    return insert_si128<1>(simd_cast<__m128i_t, __m256i_t>(a), b);
}

template <int imm8>
int avx::extract_epi32(__m256i v) {
    return _mm256_extract_epi32(v, imm8);
}

template <int imm8>
int64_t avx::extract_epi64(__m256i v) {
    return _mm256_extract_epi64(v, imm8);
}

template <int imm8>
int avx::extract(__m256i v, int32_t) {
    return extract_epi32<imm8>(v);
}

template <int imm8>
int64_t avx::extract(__m256i v, int64_t) {
    return extract_epi64<imm8>(v);
}

template <int imm8>
__m128i avx::extract_si128(__m256i v) {
#if WJR_HAS_SIMD(AV2)
    return _mm256_extracti128_si256(v, imm8);
#else
    return _mm256_extractf128_si256(v, imm8);
#endif
}

__m128i avx::getlow(__m256i a) { return simd_cast<__m256i_t, __m128i_t>(a); }

__m128i avx::gethigh(__m256i a) { return extract_si128<1>(a); }

template <int imm8>
__m256i avx::insert_epi8(__m256i v, int8_t i) {
    return _mm256_insert_epi8(v, i, imm8);
}

template <int imm8>
__m256i avx::insert_epi16(__m256i v, int16_t i) {
    return _mm256_insert_epi16(v, i, imm8);
}

template <int imm8>
__m256i avx::insert_epi32(__m256i v, int32_t i) {
    return _mm256_insert_epi32(v, i, imm8);
}

template <int imm8>
__m256i avx::insert_epi64(__m256i v, int64_t i) {
    return _mm256_insert_epi64(v, i, imm8);
}

template <int imm8>
__m256i avx::insert_si128(__m256i a, __m128i b) {
#if WJR_HAS_SIMD(AVX2)
    return _mm256_inserti128_si256(a, b, imm8);
#else
    return _mm256_insertf128_si256(a, b, imm8);
#endif
}

__m256i avx::load(const void *p) {
    return _mm256_load_si256(static_cast<const __m256i *>(p));
}
__m256i avx::loadu(const void *p) {
    return _mm256_loadu_si256(static_cast<const __m256i *>(p));
}

__m256i avx::ones() { return _mm256_set1_epi32(-1); }

__m256i avx::loadu_si16(const void *ptr) {
    return simd_cast<__m128i_t, __m256i_t>(sse::loadu_si16(ptr));
}

__m256i avx::loadu_si32(const void *ptr) {
    return simd_cast<__m128i_t, __m256i_t>(sse::loadu_si32(ptr));
}

__m256i avx::loadu_si48(const void *ptr) {
    return simd_cast<__m128i_t, __m256i_t>(sse::loadu_si48(ptr));
}

__m256i avx::loadu_si64(const void *ptr) {
    return simd_cast<__m128i_t, __m256i_t>(sse::loadu_si64(ptr));
}

__m256i avx::loadu_si80(const void *ptr) {
    return simd_cast<__m128i_t, __m256i_t>(sse::loadu_si80(ptr));
}

__m256i avx::loadu_si96(const void *ptr) {
    return simd_cast<__m128i_t, __m256i_t>(sse::loadu_si96(ptr));
}

__m256i avx::loadu_si112(const void *ptr) {
    return simd_cast<__m128i_t, __m256i_t>(sse::loadu_si112(ptr));
}

__m256i avx::loadu_si128(const void *ptr) {
    return simd_cast<__m128i_t, __m256i_t>(sse::loadu_si128(ptr));
}

__m256i avx::loadu_si144(const void *ptr) {
    return concat(sse::loadu_si128(ptr),
                  sse::loadu_si16(static_cast<const char *>(ptr) + 16));
}

__m256i avx::loadu_si160(const void *ptr) {
    return concat(sse::loadu_si128(ptr),
                  sse::loadu_si32(static_cast<const char *>(ptr) + 16));
}

__m256i avx::loadu_si176(const void *ptr) {
    return concat(sse::loadu_si128(ptr),
                  sse::loadu_si48(static_cast<const char *>(ptr) + 16));
}

__m256i avx::loadu_si192(const void *ptr) {
    return concat(sse::loadu_si128(ptr),
                  sse::loadu_si64(static_cast<const char *>(ptr) + 16));
}

__m256i avx::loadu_si208(const void *ptr) {
    return concat(sse::loadu_si128(ptr),
                  sse::loadu_si80(static_cast<const char *>(ptr) + 16));
}

__m256i avx::loadu_si224(const void *ptr) {
    return concat(sse::loadu_si128(ptr),
                  sse::loadu_si96(static_cast<const char *>(ptr) + 16));
}
__m256i avx::loadu_si240(const void *ptr) {
    return concat(sse::loadu_si128(ptr),
                  sse::loadu_si112(static_cast<const char *>(ptr) + 16));
}

__m256i avx::loadu_si256(const void *ptr) {
    return loadu(static_cast<const __m256i *>(ptr));
}

__m256i avx::loadu_si16x(const void *ptr, int n) {
    switch (n) {
    case 0:
        return zeros();
    case 1:
        return loadu_si16(ptr);
    case 2:
        return loadu_si32(ptr);
    case 3:
        return loadu_si48(ptr);
    case 4:
        return loadu_si64(ptr);
    case 5:
        return loadu_si80(ptr);
    case 6:
        return loadu_si96(ptr);
    case 7:
        return loadu_si112(ptr);
    case 8:
        return loadu_si128(ptr);
    case 9:
        return loadu_si144(ptr);
    case 10:
        return loadu_si160(ptr);
    case 11:
        return loadu_si176(ptr);
    case 12:
        return loadu_si192(ptr);
    case 13:
        return loadu_si208(ptr);
    case 14:
        return loadu_si224(ptr);
    case 15:
        return loadu_si240(ptr);
    default:
        return loadu_si256(ptr);
    }
}

__m256i avx::set_epi8(char e31, char e30, char e29, char e28, char e27, char e26,
                      char e25, char e24, char e23, char e22, char e21, char e20,
                      char e19, char e18, char e17, char e16, char e15, char e14,
                      char e13, char e12, char e11, char e10, char e9, char e8, char e7,
                      char e6, char e5, char e4, char e3, char e2, char e1, char e0) {
    return _mm256_set_epi8(e31, e30, e29, e28, e27, e26, e25, e24, e23, e22, e21, e20,
                           e19, e18, e17, e16, e15, e14, e13, e12, e11, e10, e9, e8, e7,
                           e6, e5, e4, e3, e2, e1, e0);
}

__m256i avx::set_epi16(short e15, short e14, short e13, short e12, short e11, short e10,
                       short e9, short e8, short e7, short e6, short e5, short e4,
                       short e3, short e2, short e1, short e0) {
    return _mm256_set_epi16(e15, e14, e13, e12, e11, e10, e9, e8, e7, e6, e5, e4, e3, e2,
                            e1, e0);
}

__m256i avx::set_epi32(int e7, int e6, int e5, int e4, int e3, int e2, int e1, int e0) {
    return _mm256_set_epi32(e7, e6, e5, e4, e3, e2, e1, e0);
}

__m256i avx::set_epi64x(long long e3, long long e2, long long e1, long long e0) {
    return _mm256_set_epi64x(e3, e2, e1, e0);
}

__m256i avx::setr_epi8(char e31, char e30, char e29, char e28, char e27, char e26,
                       char e25, char e24, char e23, char e22, char e21, char e20,
                       char e19, char e18, char e17, char e16, char e15, char e14,
                       char e13, char e12, char e11, char e10, char e9, char e8, char e7,
                       char e6, char e5, char e4, char e3, char e2, char e1, char e0) {
    return _mm256_setr_epi8(e31, e30, e29, e28, e27, e26, e25, e24, e23, e22, e21, e20,
                            e19, e18, e17, e16, e15, e14, e13, e12, e11, e10, e9, e8, e7,
                            e6, e5, e4, e3, e2, e1, e0);
}

__m256i avx::setr_epi16(short e15, short e14, short e13, short e12, short e11, short e10,
                        short e9, short e8, short e7, short e6, short e5, short e4,
                        short e3, short e2, short e1, short e0) {
    return _mm256_setr_epi16(e15, e14, e13, e12, e11, e10, e9, e8, e7, e6, e5, e4, e3, e2,
                             e1, e0);
}

__m256i avx::setr_epi32(int e7, int e6, int e5, int e4, int e3, int e2, int e1, int e0) {
    return _mm256_setr_epi32(e7, e6, e5, e4, e3, e2, e1, e0);
}

__m256i avx::setr_epi64x(long long e3, long long e2, long long e1, long long e0) {
    return _mm256_setr_epi64x(e3, e2, e1, e0);
}

__m256i avx::set1_epi8(int8_t a) { return _mm256_set1_epi8(a); }
__m256i avx::set1_epi16(int16_t a) { return _mm256_set1_epi16(a); }
__m256i avx::set1_epi32(int32_t a) { return _mm256_set1_epi32(a); }
__m256i avx::set1_epi64(int64_t a) { return _mm256_set1_epi64x(a); }

__m256i avx::set1(int8_t a, int8_t) { return set1_epi8(a); }
__m256i avx::set1(int16_t a, int16_t) { return set1_epi16(a); }
__m256i avx::set1(int32_t a, int32_t) { return set1_epi32(a); }
__m256i avx::set1(int64_t a, int64_t) { return set1_epi64(a); }
__m256i avx::set1(uint8_t a, uint8_t) { return set1_epi8(a); }
__m256i avx::set1(uint16_t a, uint16_t) { return set1_epi16(a); }
__m256i avx::set1(uint32_t a, uint32_t) { return set1_epi32(a); }
__m256i avx::set1(uint64_t a, uint64_t) { return set1_epi64(a); }

__m256i avx::setmin_epi8() { return set1_epi8(0x80u); }
__m256i avx::setmin_epi16() { return set1_epi16(0x8000u); }
__m256i avx::setmin_epi32() { return set1_epi32(0x80000000u); }
__m256i avx::setmin_epi64() { return set1_epi64(0x8000000000000000ull); }

__m256i avx::setmin(int8_t) { return setmin_epi8(); }
__m256i avx::setmin(int16_t) { return setmin_epi16(); }
__m256i avx::setmin(int32_t) { return setmin_epi32(); }
__m256i avx::setmin(int64_t) { return setmin_epi64(); }

__m256i avx::setmax_epi8() { return set1_epi8(0x7f); }
__m256i avx::setmax_epi16() { return set1_epi16(0x7fff); }
__m256i avx::setmax_epi32() { return set1_epi32(0x7fffffff); }
__m256i avx::setmax_epi64() { return set1_epi64(0x7fffffffffffffff); }

__m256i avx::setmax(int8_t) { return setmax_epi8(); }
__m256i avx::setmax(int16_t) { return setmax_epi16(); }
__m256i avx::setmax(int32_t) { return setmax_epi32(); }
__m256i avx::setmax(int64_t) { return setmax_epi64(); }

void avx::stream(__m256i *p, __m256i a) { _mm256_stream_si256(p, a); }

void avx::store(void *p, __m256i a) { _mm256_store_si256(static_cast<__m256i *>(p), a); }
void avx::storeu(void *p, __m256i a) {
    _mm256_storeu_si256(static_cast<__m256i *>(p), a);
}

int avx::test_all_zeros(__m256i a) { return testz(a, a); }

int avx::testc(__m256i a, __m256i b) { return _mm256_testc_si256(a, b); }

int avx::testnzc(__m256i a, __m256i b) { return _mm256_testnzc_si256(a, b); }

int avx::testz(__m256i a, __m256i b) { return _mm256_testz_si256(a, b); }

__m256i avx::zeros() { return _mm256_setzero_si256(); }

#endif

#if WJR_HAS_SIMD(AVX2)

__m256i avx::And(__m256i a, __m256i b) { return _mm256_and_si256(a, b); }

__m256i avx::AndNot(__m256i a, __m256i b) { return _mm256_andnot_si256(a, b); }

__m256i avx::Or(__m256i a, __m256i b) { return _mm256_or_si256(a, b); }

__m256i avx::Xor(__m256i a, __m256i b) { return _mm256_xor_si256(a, b); }

__m256i avx::Not(__m256i v) { return _mm256_xor_si256(v, ones()); }

__m256i avx::abs_epi8(__m256i v) { return _mm256_abs_epi8(v); }
__m256i avx::abs_epi16(__m256i v) { return _mm256_abs_epi16(v); }
__m256i avx::abs_epi32(__m256i v) { return _mm256_abs_epi32(v); }

__m256i avx::abs(__m256i v, int8_t) { return abs_epi8(v); }
__m256i avx::abs(__m256i v, int16_t) { return abs_epi16(v); }
__m256i avx::abs(__m256i v, int32_t) { return abs_epi32(v); }
__m256i avx::abs(__m256i v, int64_t) { return abs_epi32(v); }

__m256i avx::add_epi8(__m256i a, __m256i b) { return _mm256_add_epi8(a, b); }
__m256i avx::add_epi16(__m256i a, __m256i b) { return _mm256_add_epi16(a, b); }
__m256i avx::add_epi32(__m256i a, __m256i b) { return _mm256_add_epi32(a, b); }
__m256i avx::add_epi64(__m256i a, __m256i b) { return _mm256_add_epi64(a, b); }

__m256i avx::add(__m256i a, __m256i b, int8_t) { return add_epi8(a, b); }
__m256i avx::add(__m256i a, __m256i b, int16_t) { return add_epi16(a, b); }
__m256i avx::add(__m256i a, __m256i b, int32_t) { return add_epi32(a, b); }
__m256i avx::add(__m256i a, __m256i b, int64_t) { return add_epi64(a, b); }
__m256i avx::add(__m256i a, __m256i b, uint8_t) { return add_epi8(a, b); }
__m256i avx::add(__m256i a, __m256i b, uint16_t) { return add_epi16(a, b); }
__m256i avx::add(__m256i a, __m256i b, uint32_t) { return add_epi32(a, b); }
__m256i avx::add(__m256i a, __m256i b, uint64_t) { return add_epi64(a, b); }

uint8_t avx::add_epu8(__m256i v) {
    return sse::add_epu8(sse::add_epi8(getlow(v), gethigh(v)));
}

uint16_t avx::add_epu16(__m256i v) {
    return sse::add_epu16(sse::add_epi16(getlow(v), gethigh(v)));
}

uint32_t avx::add_epu32(__m256i v) {
    return sse::add_epu32(sse::add_epi32(getlow(v), gethigh(v)));
}

uint64_t avx::add_epu64(__m256i v) {
    return sse::add_epu64(sse::add_epi64(getlow(v), gethigh(v)));
}

int8_t avx::add_epi8(__m256i v) { return add_epu8(v); }
int16_t avx::add_epi16(__m256i v) { return add_epu16(v); }
int32_t avx::add_epi32(__m256i v) { return add_epu32(v); }
int64_t avx::add_epi64(__m256i v) { return add_epu64(v); }

int8_t avx::add(__m256i v, int8_t) { return add_epi8(v); }
int16_t avx::add(__m256i v, int16_t) { return add_epi16(v); }
int32_t avx::add(__m256i v, int32_t) { return add_epi32(v); }
int64_t avx::add(__m256i v, int64_t) { return add_epi64(v); }
uint8_t avx::add(__m256i v, uint8_t) { return add_epu8(v); }
uint16_t avx::add(__m256i v, uint16_t) { return add_epu16(v); }
uint32_t avx::add(__m256i v, uint32_t) { return add_epu32(v); }
uint64_t avx::add(__m256i v, uint64_t) { return add_epu64(v); }

__m256i avx::adds_epi8(__m256i a, __m256i b) { return _mm256_adds_epi8(a, b); }
__m256i avx::adds_epi16(__m256i a, __m256i b) { return _mm256_adds_epi16(a, b); }

__m256i avx::adds_epu8(__m256i a, __m256i b) { return _mm256_adds_epu8(a, b); }
__m256i avx::adds_epu16(__m256i a, __m256i b) { return _mm256_adds_epu16(a, b); }

__m256i avx::adds(__m256i a, __m256i b, int8_t) { return adds_epi8(a, b); }
__m256i avx::adds(__m256i a, __m256i b, int16_t) { return adds_epi16(a, b); }
__m256i avx::adds(__m256i a, __m256i b, uint8_t) { return adds_epu8(a, b); }
__m256i avx::adds(__m256i a, __m256i b, uint16_t) { return adds_epu16(a, b); }

template <int imm8>
__m256i avx::alignr(__m256i a, __m256i b) {
    return _mm256_alignr_epi8(a, b, imm8);
}

__m256i avx::alignr_epi16(__m256i a, __m256i b, int c) {
    return Or(slli_epi16(a, 16 - c), srli_epi16(b, c));
}

__m256i avx::alignr_epi32(__m256i a, __m256i b, int c) {
    return Or(slli_epi32(a, 32 - c), srli_epi32(b, c));
}

__m256i avx::alignr_epi64(__m256i a, __m256i b, int c) {
    return Or(slli_epi64(a, 64 - c), srli_epi64(b, c));
}

__m256i avx::alignr(__m256i a, __m256i b, int c, int16_t) {
    return alignr_epi16(a, b, c);
}

__m256i avx::alignr(__m256i a, __m256i b, int c, int32_t) {
    return alignr_epi32(a, b, c);
}

__m256i avx::alignr(__m256i a, __m256i b, int c, int64_t) {
    return alignr_epi64(a, b, c);
}

__m256i avx::alignr(__m256i a, __m256i b, int c, uint16_t) {
    return alignr_epi16(a, b, c);
}

__m256i avx::alignr(__m256i a, __m256i b, int c, uint32_t) {
    return alignr_epi32(a, b, c);
}

__m256i avx::alignr(__m256i a, __m256i b, int c, uint64_t) {
    return alignr_epi64(a, b, c);
}

__m256i avx::avg_epu8(__m256i a, __m256i b) { return _mm256_avg_epu8(a, b); }
__m256i avx::avg_epu16(__m256i a, __m256i b) { return _mm256_avg_epu16(a, b); }

__m256i avx::avg(__m256i a, __m256i b, int8_t) { return avg_epu8(a, b); }
__m256i avx::avg(__m256i a, __m256i b, int16_t) { return avg_epu16(a, b); }
__m256i avx::avg(__m256i a, __m256i b, uint8_t) { return avg_epu8(a, b); }
__m256i avx::avg(__m256i a, __m256i b, uint16_t) { return avg_epu16(a, b); }

template <int imm8>
__m256i avx::blend_epi16(__m256i a, __m256i b) {
    return _mm256_blend_epi16(a, b, imm8);
}

template <int imm8>
__m256i avx::blend_epi32(__m256i a, __m256i b) {
    return _mm256_blend_epi32(a, b, imm8);
}

__m256i avx::blendv_epi8(__m256i a, __m256i b, __m256i mask) {
    return _mm256_blendv_epi8(a, b, mask);
}

template <int imm8>
__m256i avx::bslli_epi128(__m256i a) {
    return _mm256_bslli_epi128(a, imm8);
}

template <int imm8>
__m256i avx::bsrli_epi128(__m256i a) {
    return _mm256_bsrli_epi128(a, imm8);
}

__m256i avx::cmpeq_epi8(__m256i a, __m256i b) { return _mm256_cmpeq_epi8(a, b); }
__m256i avx::cmpeq_epi16(__m256i a, __m256i b) { return _mm256_cmpeq_epi16(a, b); }
__m256i avx::cmpeq_epi32(__m256i a, __m256i b) { return _mm256_cmpeq_epi32(a, b); }
__m256i avx::cmpeq_epi64(__m256i a, __m256i b) { return _mm256_cmpeq_epi64(a, b); }

__m256i avx::cmpeq(__m256i a, __m256i b, int8_t) { return cmpeq_epi8(a, b); }
__m256i avx::cmpeq(__m256i a, __m256i b, int16_t) { return cmpeq_epi16(a, b); }
__m256i avx::cmpeq(__m256i a, __m256i b, int32_t) { return cmpeq_epi32(a, b); }
__m256i avx::cmpeq(__m256i a, __m256i b, int64_t) { return cmpeq_epi64(a, b); }
__m256i avx::cmpeq(__m256i a, __m256i b, uint8_t) { return cmpeq_epi8(a, b); }
__m256i avx::cmpeq(__m256i a, __m256i b, uint16_t) { return cmpeq_epi16(a, b); }
__m256i avx::cmpeq(__m256i a, __m256i b, uint32_t) { return cmpeq_epi32(a, b); }
__m256i avx::cmpeq(__m256i a, __m256i b, uint64_t) { return cmpeq_epi64(a, b); }

__m256i avx::cmpge_epi8(__m256i a, __m256i b) {
    return cmpeq(min(a, b, int8_t()), b, uint8_t());
}

__m256i avx::cmpge_epi16(__m256i a, __m256i b) {
    return cmpeq(min(a, b, int16_t()), b, uint16_t());
}

__m256i avx::cmpge_epi32(__m256i a, __m256i b) {
    return cmpeq(min(a, b, int32_t()), b, uint8_t());
}

__m256i avx::cmpge_epu8(__m256i a, __m256i b) {
    return cmpeq(min(a, b, uint8_t()), b, uint8_t());
}

__m256i avx::cmpge_epu16(__m256i a, __m256i b) {
    return cmpeq(min(a, b, uint16_t()), b, uint16_t());
}

__m256i avx::cmpge_epu32(__m256i a, __m256i b) {
    return cmpeq(min(a, b, uint32_t()), b, uint32_t());
}

__m256i avx::cmpge(__m256i a, __m256i b, int8_t) { return cmpge_epi8(a, b); }
__m256i avx::cmpge(__m256i a, __m256i b, int16_t) { return cmpge_epi16(a, b); }
__m256i avx::cmpge(__m256i a, __m256i b, int32_t) { return cmpge_epi32(a, b); }
__m256i avx::cmpge(__m256i a, __m256i b, uint8_t) { return cmpge_epu8(a, b); }
__m256i avx::cmpge(__m256i a, __m256i b, uint16_t) { return cmpge_epu16(a, b); }
__m256i avx::cmpge(__m256i a, __m256i b, uint32_t) { return cmpge_epu32(a, b); }

__m256i avx::cmpgt_epi8(__m256i a, __m256i b) { return _mm256_cmpgt_epi8(a, b); }
__m256i avx::cmpgt_epi16(__m256i a, __m256i b) { return _mm256_cmpgt_epi16(a, b); }
__m256i avx::cmpgt_epi32(__m256i a, __m256i b) { return _mm256_cmpgt_epi32(a, b); }
__m256i avx::cmpgt_epi64(__m256i a, __m256i b) { return _mm256_cmpgt_epi64(a, b); }

__m256i avx::cmpgt_epu8(__m256i a, __m256i b) {
    return cmpgt_epi8(Xor(a, setmin_epi8()), Xor(b, setmin_epi8()));
}

__m256i avx::cmpgt_epu16(__m256i a, __m256i b) {
    return cmpgt_epi16(Xor(a, setmin_epi16()), Xor(b, setmin_epi16()));
}

__m256i avx::cmpgt_epu32(__m256i a, __m256i b) {
    return cmpgt_epi32(Xor(a, setmin_epi32()), Xor(b, setmin_epi32()));
}

__m256i avx::cmpgt_epu64(__m256i a, __m256i b) {
    return cmpgt_epi64(Xor(a, setmin_epi64()), Xor(b, setmin_epi64()));
}

__m256i avx::cmpgt(__m256i a, __m256i b, int8_t) { return cmpgt_epi8(a, b); }
__m256i avx::cmpgt(__m256i a, __m256i b, int16_t) { return cmpgt_epi16(a, b); }
__m256i avx::cmpgt(__m256i a, __m256i b, int32_t) { return cmpgt_epi32(a, b); }
__m256i avx::cmpgt(__m256i a, __m256i b, int64_t) { return cmpgt_epi64(a, b); }
__m256i avx::cmpgt(__m256i a, __m256i b, uint8_t) { return cmpgt_epu8(a, b); }
__m256i avx::cmpgt(__m256i a, __m256i b, uint16_t) { return cmpgt_epu16(a, b); }
__m256i avx::cmpgt(__m256i a, __m256i b, uint32_t) { return cmpgt_epu32(a, b); }
__m256i avx::cmpgt(__m256i a, __m256i b, uint64_t) { return cmpgt_epu64(a, b); }

__m256i avx::cmple_epi8(__m256i a, __m256i b) { return cmpge_epi8(b, a); }

__m256i avx::cmple_epi16(__m256i a, __m256i b) { return cmpge_epi16(b, a); }

__m256i avx::cmple_epi32(__m256i a, __m256i b) { return cmpge_epi32(b, a); }

__m256i avx::cmple_epu8(__m256i a, __m256i b) { return cmpge_epu8(b, a); }

__m256i avx::cmple_epu16(__m256i a, __m256i b) { return cmpge_epu16(b, a); }

__m256i avx::cmple_epu32(__m256i a, __m256i b) { return cmpge_epu32(b, a); }

__m256i avx::cmple(__m256i a, __m256i b, int8_t) { return cmple_epi8(a, b); }
__m256i avx::cmple(__m256i a, __m256i b, int16_t) { return cmple_epi16(a, b); }
__m256i avx::cmple(__m256i a, __m256i b, int32_t) { return cmple_epi32(a, b); }
__m256i avx::cmple(__m256i a, __m256i b, uint8_t) { return cmple_epu8(a, b); }
__m256i avx::cmple(__m256i a, __m256i b, uint16_t) { return cmple_epu16(a, b); }
__m256i avx::cmple(__m256i a, __m256i b, uint32_t) { return cmple_epu32(a, b); }

__m256i avx::cmplt_epi8(__m256i a, __m256i b) { return cmpgt_epi8(b, a); }
__m256i avx::cmplt_epi16(__m256i a, __m256i b) { return cmpgt_epi16(b, a); }
__m256i avx::cmplt_epi32(__m256i a, __m256i b) { return cmpgt_epi32(b, a); }

__m256i avx::cmplt_epu8(__m256i a, __m256i b) { return cmpgt_epu8(b, a); }
__m256i avx::cmplt_epu16(__m256i a, __m256i b) { return cmpgt_epu16(b, a); }
__m256i avx::cmplt_epu32(__m256i a, __m256i b) { return cmpgt_epu32(b, a); }

__m256i avx::cmplt(__m256i a, __m256i b, int8_t) { return cmplt_epi8(a, b); }
__m256i avx::cmplt(__m256i a, __m256i b, int16_t) { return cmplt_epi16(a, b); }
__m256i avx::cmplt(__m256i a, __m256i b, int32_t) { return cmplt_epi32(a, b); }
__m256i avx::cmplt(__m256i a, __m256i b, uint8_t) { return cmplt_epu8(a, b); }
__m256i avx::cmplt(__m256i a, __m256i b, uint16_t) { return cmplt_epu16(a, b); }
__m256i avx::cmplt(__m256i a, __m256i b, uint32_t) { return cmplt_epu32(a, b); }

__m256i avx::cmpne_epi8(__m256i a, __m256i b) { return Not(cmpeq_epi8(a, b)); }
__m256i avx::cmpne_epi16(__m256i a, __m256i b) { return Not(cmpeq_epi16(a, b)); }
__m256i avx::cmpne_epi32(__m256i a, __m256i b) { return Not(cmpeq_epi32(a, b)); }

__m256i avx::cmpne(__m256i a, __m256i b, int8_t) { return cmpne_epi8(a, b); }
__m256i avx::cmpne(__m256i a, __m256i b, int16_t) { return cmpne_epi16(a, b); }
__m256i avx::cmpne(__m256i a, __m256i b, int32_t) { return cmpne_epi32(a, b); }
__m256i avx::cmpne(__m256i a, __m256i b, uint8_t) { return cmpne_epi8(a, b); }
__m256i avx::cmpne(__m256i a, __m256i b, uint16_t) { return cmpne_epi16(a, b); }
__m256i avx::cmpne(__m256i a, __m256i b, uint32_t) { return cmpne_epi32(a, b); }

template <typename T>
__m256i avx::cmp(__m256i a, __m256i b, std::equal_to<>, T) {
    return cmpeq(a, b, T());
}

template <typename T>
__m256i avx::cmp(__m256i a, __m256i b, std::not_equal_to<>, T) {
    return cmpne(a, b, T());
}

template <typename T>
__m256i avx::cmp(__m256i a, __m256i b, std::greater<>, T) {
    return cmpgt(a, b, T());
}

template <typename T>
__m256i avx::cmp(__m256i a, __m256i b, std::greater_equal<>, T) {
    return cmpge(a, b, T());
}

template <typename T>
__m256i avx::cmp(__m256i a, __m256i b, std::less<>, T) {
    return cmplt(a, b, T());
}

template <typename T>
__m256i avx::cmp(__m256i a, __m256i b, std::less_equal<>, T) {
    return cmple(a, b, T());
}

template <int imm8>
int avx::extract_epi8(__m256i v) {
    return _mm256_extract_epi8(v, imm8);
}

template <int imm8>
int avx::extract_epi16(__m256i v) {
    return _mm256_extract_epi16(v, imm8);
}

template <int imm8>
int avx::extract(__m256i v, int8_t) {
    return extract_epi8<imm8>(v);
}

template <int imm8>
int avx::extract(__m256i v, int16_t) {
    return extract_epi16<imm8>(v);
}

__m256i avx::hadd_epi16(__m256i a, __m256i b) { return _mm256_hadd_epi16(a, b); }
__m256i avx::hadd_epi32(__m256i a, __m256i b) { return _mm256_hadd_epi32(a, b); }

__m256i avx::hadd(__m256i a, __m256i b, int16_t) { return hadd_epi16(a, b); }
__m256i avx::hadd(__m256i a, __m256i b, int32_t) { return hadd_epi32(a, b); }

__m256i avx::hadds_epi16(__m256i a, __m256i b) { return _mm256_hadds_epi16(a, b); }

__m256i avx::hsub_epi16(__m256i a, __m256i b) { return _mm256_hsub_epi16(a, b); }
__m256i avx::hsub_epi32(__m256i a, __m256i b) { return _mm256_hsub_epi32(a, b); }

__m256i avx::hsub(__m256i a, __m256i b, int16_t) { return hsub_epi16(a, b); }
__m256i avx::hsub(__m256i a, __m256i b, int32_t) { return hsub_epi32(a, b); }

__m256i avx::hsubs_epi16(__m256i a, __m256i b) { return _mm256_hsubs_epi16(a, b); }

template <typename T, WJR_REQUIRES_I(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t,
                                                 uint8_t, uint16_t, uint32_t, uint64_t>)>
__m256i avx::logical_and(__m256i a, __m256i b, T) {
    return Not(Or(logical_not(a, T()), logical_not(b, T())));
}

template <typename T, WJR_REQUIRES_I(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t,
                                                 uint8_t, uint16_t, uint32_t, uint64_t>)>
__m256i avx::logical_not(__m256i v, T) {
    auto Zero = zeros();
    return cmpeq(v, Zero, T());
}

template <typename T, WJR_REQUIRES_I(is_any_of_v<T, int8_t, int16_t, int32_t, int64_t,
                                                 uint8_t, uint16_t, uint32_t, uint64_t>)>
__m256i avx::logical_or(__m256i a, __m256i b, T) {
    return Not(logical_not(Or(a, b), T()));
}

__m256i avx::madd_epi16(__m256i a, __m256i b) { return _mm256_madd_epi16(a, b); }

__m256i avx::max_epi8(__m256i a, __m256i b) { return _mm256_max_epi8(a, b); }
__m256i avx::max_epi16(__m256i a, __m256i b) { return _mm256_max_epi16(a, b); }
__m256i avx::max_epi32(__m256i a, __m256i b) { return _mm256_max_epi32(a, b); }

__m256i avx::max_epu8(__m256i a, __m256i b) { return _mm256_max_epu8(a, b); }
__m256i avx::max_epu16(__m256i a, __m256i b) { return _mm256_max_epu16(a, b); }
__m256i avx::max_epu32(__m256i a, __m256i b) { return _mm256_max_epu32(a, b); }

__m256i avx::max(__m256i a, __m256i b, int8_t) { return max_epi8(a, b); }
__m256i avx::max(__m256i a, __m256i b, int16_t) { return max_epi16(a, b); }
__m256i avx::max(__m256i a, __m256i b, uint8_t) { return max_epu8(a, b); }
__m256i avx::max(__m256i a, __m256i b, uint16_t) { return max_epu16(a, b); }
__m256i avx::max(__m256i a, __m256i b, int32_t) { return max_epi32(a, b); }
__m256i avx::max(__m256i a, __m256i b, uint32_t) { return max_epu32(a, b); }

int8_t avx::max_epi8(__m256i a) {
    return sse::max_epi8(sse::max_epi8(getlow(a), gethigh(a)));
}

int16_t avx::max_epi16(__m256i a) {
    return sse::max_epi16(sse::max_epi16(getlow(a), gethigh(a)));
}

int32_t avx::max_epi32(__m256i a) {
    return sse::max_epi32(sse::max_epi32(getlow(a), gethigh(a)));
}

uint8_t avx::max_epu8(__m256i a) {
    return sse::max_epu8(sse::max_epu8(getlow(a), gethigh(a)));
}

uint16_t avx::max_epu16(__m256i a) {
    return sse::max_epu16(sse::max_epu16(getlow(a), gethigh(a)));
}

uint32_t avx::max_epu32(__m256i a) {
    return sse::max_epu32(sse::max_epu32(getlow(a), gethigh(a)));
}

int8_t avx::max(__m256i a, int8_t) { return max_epi8(a); }
int16_t avx::max(__m256i a, int16_t) { return max_epi16(a); }
int32_t avx::max(__m256i a, int32_t) { return max_epi32(a); }
uint8_t avx::max(__m256i a, uint8_t) { return max_epu8(a); }
uint16_t avx::max(__m256i a, uint16_t) { return max_epu16(a); }
uint32_t avx::max(__m256i a, uint32_t) { return max_epu32(a); }

__m256i avx::min_epi8(__m256i a, __m256i b) { return _mm256_min_epi8(a, b); }
__m256i avx::min_epi16(__m256i a, __m256i b) { return _mm256_min_epi16(a, b); }
__m256i avx::min_epi32(__m256i a, __m256i b) { return _mm256_min_epi32(a, b); }

__m256i avx::min_epu8(__m256i a, __m256i b) { return _mm256_min_epu8(a, b); }
__m256i avx::min_epu16(__m256i a, __m256i b) { return _mm256_min_epu16(a, b); }
__m256i avx::min_epu32(__m256i a, __m256i b) { return _mm256_min_epu32(a, b); }

__m256i avx::min(__m256i a, __m256i b, int8_t) { return min_epi8(a, b); }
__m256i avx::min(__m256i a, __m256i b, int16_t) { return min_epi16(a, b); }
__m256i avx::min(__m256i a, __m256i b, uint8_t) { return min_epu8(a, b); }
__m256i avx::min(__m256i a, __m256i b, uint16_t) { return min_epu16(a, b); }
__m256i avx::min(__m256i a, __m256i b, int32_t) { return min_epi32(a, b); }
__m256i avx::min(__m256i a, __m256i b, uint32_t) { return min_epu32(a, b); }

int8_t avx::min_epi8(__m256i a) {
    return sse::min_epi8(sse::min_epi8(getlow(a), gethigh(a)));
}

int16_t avx::min_epi16(__m256i a) {
    return sse::min_epi16(sse::min_epi16(getlow(a), gethigh(a)));
}

int32_t avx::min_epi32(__m256i a) {
    return sse::min_epi32(sse::min_epi32(getlow(a), gethigh(a)));
}

uint8_t avx::min_epu8(__m256i a) {
    return sse::min_epu8(sse::min_epu8(getlow(a), gethigh(a)));
}

uint16_t avx::min_epu16(__m256i a) {
    return sse::min_epu16(sse::min_epu16(getlow(a), gethigh(a)));
}

uint32_t avx::min_epu32(__m256i a) {
    return sse::min_epu32(sse::min_epu32(getlow(a), gethigh(a)));
}

int8_t avx::min(__m256i a, int8_t) { return min_epi8(a); }
int16_t avx::min(__m256i a, int16_t) { return min_epi16(a); }
int32_t avx::min(__m256i a, int32_t) { return min_epi32(a); }
uint8_t avx::min(__m256i a, uint8_t) { return min_epu8(a); }
uint16_t avx::min(__m256i a, uint16_t) { return min_epu16(a); }
uint32_t avx::min(__m256i a, uint32_t) { return min_epu32(a); }

avx::mask_type avx::movemask_epi8(__m256i a) { return _mm256_movemask_epi8(a); }

__m256i avx::mul_epi32(__m256i a, __m256i b) { return _mm256_mul_epi32(a, b); }
__m256i avx::mul_epu32(__m256i a, __m256i b) { return _mm256_mul_epu32(a, b); }

__m256i avx::mulhi_epi16(__m256i a, __m256i b) { return _mm256_mulhi_epi16(a, b); }

__m256i avx::mulhi_epu16(__m256i a, __m256i b) { return _mm256_mulhi_epu16(a, b); }

__m256i avx::mullo_epi16(__m256i a, __m256i b) { return _mm256_mullo_epi16(a, b); }

__m256i avx::packs_epi16(__m256i a, __m256i b) { return _mm256_packs_epi16(a, b); }
__m256i avx::packs_epi32(__m256i a, __m256i b) { return _mm256_packs_epi32(a, b); }

__m256i avx::packus_epi16(__m256i a, __m256i b) { return _mm256_packus_epi16(a, b); }
__m256i avx::packus_epi32(__m256i a, __m256i b) { return _mm256_packus_epi32(a, b); }

template <int imm>
__m256i avx::shl(__m256i a) {
    if constexpr (imm >= 64 * 3) {
        a = slli<8 * 3>(a);
        a = slli_epi64(a, imm - 64 * 3);
        return a;
    } else if constexpr (imm >= 64 * 2) {
        a = slli<8 * 2>(a);
        constexpr auto I = imm - 64 * 2;
        auto b = slli_epi64(a, I);
        auto c = slli<8>(a);
        c = srli_epi64(c, 64 - I);
        return Or(b, c);
    } else if constexpr (imm >= 64) {
        a = slli<8>(a);
        constexpr auto I = imm - 64;
        auto b = slli_epi64(a, I);
        auto c = slli<8>(a);
        c = srli_epi64(c, 64 - I);
        return Or(b, c);
    } else {
        auto b = slli_epi64(a, imm);
        auto c = slli<8>(a);
        c = srli_epi64(c, 64 - imm);
        return Or(b, c);
    }
}

template <int imm>
__m256i avx::shr(__m256i a) {
    if constexpr (imm >= 64 * 3) {
        a = srli<8 * 3>(a);
        a = srli_epi64(a, imm - 64 * 3);
        return a;
    } else if constexpr (imm >= 64 * 2) {
        a = srli<8 * 2>(a);
        constexpr auto I = imm - 64 * 2;
        auto b = srli_epi64(a, I);
        auto c = srli<8>(a);
        c = slli_epi64(c, 64 - I);
        return Or(b, c);
    } else if constexpr (imm >= 64) {
        a = srli<8>(a);
        constexpr auto I = imm - 64;
        auto b = srli_epi64(a, I);
        auto c = srli<8>(a);
        c = slli_epi64(c, 64 - I);
        return Or(b, c);
    } else {
        auto b = srli_epi64(a, imm);
        auto c = srli<8>(a);
        c = slli_epi64(c, 64 - imm);
        return Or(b, c);
    }
}

__m256i avx::shuffle_epi8(__m256i a, __m256i b) { return _mm256_shuffle_epi8(a, b); }

template <int imm8>
__m256i avx::shuffle_epi32(__m256i a) {
    return _mm256_shuffle_epi32(a, imm8);
}

template <int imm8>
__m256i avx::shufflehi_epi16(__m256i a) {
    return _mm256_shufflehi_epi16(a, imm8);
}

template <int imm8>
__m256i avx::shufflelo_epi16(__m256i a) {
    return _mm256_shufflelo_epi16(a, imm8);
}

__m256i avx::sll_epi16(__m256i a, __m128i b) { return _mm256_sll_epi16(a, b); }
__m256i avx::sll_epi32(__m256i a, __m128i b) { return _mm256_sll_epi32(a, b); }
__m256i avx::sll_epi64(__m256i a, __m128i b) { return _mm256_sll_epi64(a, b); }

__m256i avx::sll(__m256i a, __m128i b, int16_t) { return sll_epi16(a, b); }
__m256i avx::sll(__m256i a, __m128i b, int32_t) { return sll_epi32(a, b); }
__m256i avx::sll(__m256i a, __m128i b, int64_t) { return sll_epi64(a, b); }
__m256i avx::sll(__m256i a, __m128i b, uint16_t) { return sll_epi16(a, b); }
__m256i avx::sll(__m256i a, __m128i b, uint32_t) { return sll_epi32(a, b); }
__m256i avx::sll(__m256i a, __m128i b, uint64_t) { return sll_epi64(a, b); }

template <int imm8>
__m256i avx::slli(__m256i a) {
    return _mm256_slli_si256(a, imm8);
}
__m256i avx::slli_epi16(__m256i a, int imm8) { return _mm256_slli_epi16(a, imm8); }
__m256i avx::slli_epi32(__m256i a, int imm8) { return _mm256_slli_epi32(a, imm8); }
__m256i avx::slli_epi64(__m256i a, int imm8) { return _mm256_slli_epi64(a, imm8); }

__m256i avx::slli(__m256i a, int imm8, int16_t) { return slli_epi16(a, imm8); }
__m256i avx::slli(__m256i a, int imm8, int32_t) { return slli_epi32(a, imm8); }
__m256i avx::slli(__m256i a, int imm8, int64_t) { return slli_epi64(a, imm8); }
__m256i avx::slli(__m256i a, int imm8, uint16_t) { return slli_epi16(a, imm8); }
__m256i avx::slli(__m256i a, int imm8, uint32_t) { return slli_epi32(a, imm8); }
__m256i avx::slli(__m256i a, int imm8, uint64_t) { return slli_epi64(a, imm8); }

__m256i avx::sra_epi16(__m256i a, __m128i b) { return _mm256_sra_epi16(a, b); }
__m256i avx::sra_epi32(__m256i a, __m128i b) { return _mm256_sra_epi32(a, b); }

__m256i avx::sra(__m256i a, __m128i b, int16_t) { return sra_epi16(a, b); }
__m256i avx::sra(__m256i a, __m128i b, int32_t) { return sra_epi32(a, b); }

__m256i avx::srai_epi16(__m256i a, int imm8) { return _mm256_srai_epi16(a, imm8); }
__m256i avx::srai_epi32(__m256i a, int imm8) { return _mm256_srai_epi32(a, imm8); }

__m256i avx::srai(__m256i a, int imm8, int16_t) { return srai_epi16(a, imm8); }
__m256i avx::srai(__m256i a, int imm8, int32_t) { return srai_epi32(a, imm8); }

__m256i avx::stream_load(const void *p) {
    return _mm256_stream_load_si256(static_cast<const __m256i *>(p));
}

__m256i avx::srl_epi16(__m256i a, __m128i b) { return _mm256_srl_epi16(a, b); }
__m256i avx::srl_epi32(__m256i a, __m128i b) { return _mm256_srl_epi32(a, b); }
__m256i avx::srl_epi64(__m256i a, __m128i b) { return _mm256_srl_epi64(a, b); }

__m256i avx::srl(__m256i a, __m128i b, int16_t) { return srl_epi16(a, b); }
__m256i avx::srl(__m256i a, __m128i b, int32_t) { return srl_epi32(a, b); }
__m256i avx::srl(__m256i a, __m128i b, int64_t) { return srl_epi64(a, b); }
__m256i avx::srl(__m256i a, __m128i b, uint16_t) { return srl_epi16(a, b); }
__m256i avx::srl(__m256i a, __m128i b, uint32_t) { return srl_epi32(a, b); }
__m256i avx::srl(__m256i a, __m128i b, uint64_t) { return srl_epi64(a, b); }

template <int imm8>
__m256i avx::srli(__m256i a) {
    return _mm256_srli_si256(a, imm8);
}

__m256i avx::srli_epi8(__m256i a, int imm8) {
    return And(srli_epi16(a, imm8), avx_detail::srli_epi8_mask[imm8]);
}
__m256i avx::srli_epi16(__m256i a, int imm8) { return _mm256_srli_epi16(a, imm8); }
__m256i avx::srli_epi32(__m256i a, int imm8) { return _mm256_srli_epi32(a, imm8); }
__m256i avx::srli_epi64(__m256i a, int imm8) { return _mm256_srli_epi64(a, imm8); }

__m256i avx::srli(__m256i a, int imm8, int8_t) { return srli_epi8(a, imm8); }
__m256i avx::srli(__m256i a, int imm8, int16_t) { return srli_epi16(a, imm8); }
__m256i avx::srli(__m256i a, int imm8, int32_t) { return srli_epi32(a, imm8); }
__m256i avx::srli(__m256i a, int imm8, int64_t) { return srli_epi64(a, imm8); }
__m256i avx::srli(__m256i a, int imm8, uint8_t) { return srli_epi8(a, imm8); }
__m256i avx::srli(__m256i a, int imm8, uint16_t) { return srli_epi16(a, imm8); }
__m256i avx::srli(__m256i a, int imm8, uint32_t) { return srli_epi32(a, imm8); }
__m256i avx::srli(__m256i a, int imm8, uint64_t) { return srli_epi64(a, imm8); }

__m256i avx::sub_epi8(__m256i a, __m256i b) { return _mm256_sub_epi8(a, b); }
__m256i avx::sub_epi16(__m256i a, __m256i b) { return _mm256_sub_epi16(a, b); }
__m256i avx::sub_epi32(__m256i a, __m256i b) { return _mm256_sub_epi32(a, b); }
__m256i avx::sub_epi64(__m256i a, __m256i b) { return _mm256_sub_epi64(a, b); }

__m256i avx::sub(__m256i a, __m256i b, int8_t) { return sub_epi8(a, b); }
__m256i avx::sub(__m256i a, __m256i b, int16_t) { return sub_epi16(a, b); }
__m256i avx::sub(__m256i a, __m256i b, int32_t) { return sub_epi32(a, b); }
__m256i avx::sub(__m256i a, __m256i b, int64_t) { return sub_epi64(a, b); }
__m256i avx::sub(__m256i a, __m256i b, uint8_t) { return sub_epi8(a, b); }
__m256i avx::sub(__m256i a, __m256i b, uint16_t) { return sub_epi16(a, b); }
__m256i avx::sub(__m256i a, __m256i b, uint32_t) { return sub_epi32(a, b); }
__m256i avx::sub(__m256i a, __m256i b, uint64_t) { return sub_epi64(a, b); }

__m256i avx::subs_epi8(__m256i a, __m256i b) { return _mm256_subs_epi8(a, b); }
__m256i avx::subs_epi16(__m256i a, __m256i b) { return _mm256_subs_epi16(a, b); }

__m256i avx::subs_epu8(__m256i a, __m256i b) { return _mm256_subs_epu8(a, b); }
__m256i avx::subs_epu16(__m256i a, __m256i b) { return _mm256_subs_epu16(a, b); }

__m256i avx::subs(__m256i a, __m256i b, int8_t) { return subs_epi8(a, b); }
__m256i avx::subs(__m256i a, __m256i b, int16_t) { return subs_epi16(a, b); }
__m256i avx::subs(__m256i a, __m256i b, uint8_t) { return subs_epu8(a, b); }
__m256i avx::subs(__m256i a, __m256i b, uint16_t) { return subs_epu16(a, b); }

int avx::test_all_ones(__m256i a) { return testc(a, cmpeq_epi32(a, a)); }

__m256i avx::unpackhi_epi8(__m256i a, __m256i b) { return _mm256_unpackhi_epi8(a, b); }
__m256i avx::unpackhi_epi16(__m256i a, __m256i b) { return _mm256_unpackhi_epi16(a, b); }
__m256i avx::unpackhi_epi32(__m256i a, __m256i b) { return _mm256_unpackhi_epi32(a, b); }
__m256i avx::unpackhi_epi64(__m256i a, __m256i b) { return _mm256_unpackhi_epi64(a, b); }

__m256i avx::unpackhi(__m256i a, __m256i b, int8_t) { return unpackhi_epi8(a, b); }
__m256i avx::unpackhi(__m256i a, __m256i b, int16_t) { return unpackhi_epi16(a, b); }
__m256i avx::unpackhi(__m256i a, __m256i b, int32_t) { return unpackhi_epi32(a, b); }
__m256i avx::unpackhi(__m256i a, __m256i b, int64_t) { return unpackhi_epi64(a, b); }
__m256i avx::unpackhi(__m256i a, __m256i b, uint8_t) { return unpackhi_epi8(a, b); }
__m256i avx::unpackhi(__m256i a, __m256i b, uint16_t) { return unpackhi_epi16(a, b); }
__m256i avx::unpackhi(__m256i a, __m256i b, uint32_t) { return unpackhi_epi32(a, b); }
__m256i avx::unpackhi(__m256i a, __m256i b, uint64_t) { return unpackhi_epi64(a, b); }

__m256i avx::unpacklo_epi8(__m256i a, __m256i b) { return _mm256_unpacklo_epi8(a, b); }
__m256i avx::unpacklo_epi16(__m256i a, __m256i b) { return _mm256_unpacklo_epi16(a, b); }
__m256i avx::unpacklo_epi32(__m256i a, __m256i b) { return _mm256_unpacklo_epi32(a, b); }
__m256i avx::unpacklo_epi64(__m256i a, __m256i b) { return _mm256_unpacklo_epi64(a, b); }

__m256i avx::unpacklo(__m256i a, __m256i b, int8_t) { return unpacklo_epi8(a, b); }
__m256i avx::unpacklo(__m256i a, __m256i b, int16_t) { return unpacklo_epi16(a, b); }
__m256i avx::unpacklo(__m256i a, __m256i b, int32_t) { return unpacklo_epi32(a, b); }
__m256i avx::unpacklo(__m256i a, __m256i b, int64_t) { return unpacklo_epi64(a, b); }
__m256i avx::unpacklo(__m256i a, __m256i b, uint8_t) { return unpacklo_epi8(a, b); }
__m256i avx::unpacklo(__m256i a, __m256i b, uint16_t) { return unpacklo_epi16(a, b); }
__m256i avx::unpacklo(__m256i a, __m256i b, uint32_t) { return unpacklo_epi32(a, b); }

#endif

} // namespace wjr

#endif // WJR_X86_SIMD_AVX_HPP__

namespace wjr {

#define WJR_REGISTER_X86_NORMAL_SIMD_FUNCTION(N, UNROLL2, UNROLL4, IS_UNROLL_8, ADVANCE, \
                                              INIT, RET)                                 \
    if (WJR_UNLIKELY(N <= 16)) {                                                         \
        if (WJR_UNLIKELY(N <= 4)) {                                                      \
            UNROLL2(N - 2);                                                              \
            return RET(N);                                                               \
        }                                                                                \
                                                                                         \
        UNROLL2(2);                                                                      \
                                                                                         \
        if (WJR_LIKELY(N > 8)) {                                                         \
            UNROLL4(4);                                                                  \
                                                                                         \
            if (N > 12) {                                                                \
                UNROLL4(8);                                                              \
            }                                                                            \
        }                                                                                \
                                                                                         \
        UNROLL4(N - 4);                                                                  \
        return RET(N);                                                                   \
    }                                                                                    \
                                                                                         \
    N -= 3;                                                                              \
    const size_t __rem = N & 7;                                                          \
    N &= ~7;                                                                             \
                                                                                         \
    if (WJR_LIKELY(__rem >= 2)) {                                                        \
        UNROLL4(2);                                                                      \
        UNROLL4(__rem - 1);                                                              \
    } else {                                                                             \
        UNROLL2(__rem + 1);                                                              \
    }                                                                                    \
                                                                                         \
    INIT;                                                                                \
    WJR_PP_BOOL_IF(                                                                      \
        IS_UNROLL_8,                                                                     \
        if (N & 8) {                                                                     \
            UNROLL4(__rem + 3);                                                          \
            UNROLL4(__rem + 7);                                                          \
                                                                                         \
            if (WJR_UNLIKELY(N == 8)) {                                                  \
                return RET(N + __rem + 3);                                               \
            }                                                                            \
                                                                                         \
            ADVANCE(__rem + 11);                                                         \
            N -= 8;                                                                      \
        } else {, ) \
            ADVANCE(__rem + 3);                                                          \
    WJR_PP_BOOL_IF(IS_UNROLL_8,                                                          \
        }, )

#define WJR_REGISTER_X86_NORMAL_REVERSE_SIMD_FUNCTION(N, UNROLL2, UNROLL4, IS_UNROLL_8,  \
                                                      ADVANCE, INIT, RET)                \
    if (WJR_UNLIKELY(N <= 16)) {                                                         \
        if (WJR_UNLIKELY(N <= 4)) {                                                      \
            UNROLL2(0);                                                                  \
            return RET(0);                                                               \
        }                                                                                \
                                                                                         \
        UNROLL2(N - 4);                                                                  \
                                                                                         \
        if (WJR_LIKELY(N > 8)) {                                                         \
            UNROLL4(N - 8);                                                              \
                                                                                         \
            if (N > 12) {                                                                \
                UNROLL4(N - 12);                                                         \
            }                                                                            \
        }                                                                                \
                                                                                         \
        UNROLL4(0);                                                                      \
        return RET(0);                                                                   \
    }                                                                                    \
                                                                                         \
    N -= 3;                                                                              \
    const size_t __rem = N & 7;                                                          \
    N &= ~7;                                                                             \
                                                                                         \
    if (WJR_LIKELY(__rem >= 2)) {                                                        \
        UNROLL4(N + __rem - 3);                                                          \
        UNROLL4(N);                                                                      \
    } else {                                                                             \
        UNROLL2(N);                                                                      \
    }                                                                                    \
                                                                                         \
    INIT;                                                                                \
    WJR_PP_BOOL_IF(                                                                      \
        IS_UNROLL_8,                                                                     \
        if (N & 8) {                                                                     \
            UNROLL4(N - 4);                                                              \
            UNROLL4(N - 8);                                                              \
                                                                                         \
            if (WJR_UNLIKELY(N == 8)) {                                                  \
                return RET(0);                                                           \
            }                                                                            \
                                                                                         \
            ADVANCE(N - 8);                                                              \
            N -= 8;                                                                      \
        } else {, ) \
            ADVANCE(N);                                                                  \
    WJR_PP_BOOL_IF(IS_UNROLL_8,                                                          \
        }, )

template <typename T, size_t N, typename Simd>
class __x86_simd_base {
    static constexpr size_t BitWidth = Simd::width();
    using int_type = typename Simd::int_type;
    using Mybase = fixed_size_simd<T, N>;

public:
    using mask_type = simd_detail::basic_simd_mask<T, N, BitWidth / 8>;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(__x86_simd_base);

    template <typename U, WJR_REQUIRES(is_value_preserving_or_int_v<U, T>)>
    __x86_simd_base(U value) noexcept : m_data(Simd::set1(value, U())) {}

    template <typename Flags = element_aligned_t>
    __x86_simd_base(const T *mem, Flags flags = {}) noexcept {
        copy_from(mem, flags);
    }

    void copy_from(const T *mem, element_aligned_t = {}) noexcept {
        m_data = Simd::loadu(mem);
    }

    void copy_from(const T *mem, vector_aligned_t) noexcept { m_data = Simd::load(mem); }

    void copy_to(T *mem, element_aligned_t = {}) noexcept { Simd::storeu(mem, m_data); }

    void copy_to(T *mem, vector_aligned_t) noexcept { Simd::store(mem, m_data); }

    Mybase &operator&=(const Mybase &other) noexcept {
        m_data = Simd::And(m_data, other.m_data);
        return static_cast<Mybase &>(*this);
    }

    friend Mybase operator&(const Mybase &lhs, const Mybase &rhs) noexcept {
        Mybase ret(lhs);
        ret &= rhs;
        return ret;
    }

    Mybase &operator|=(const Mybase &other) noexcept {
        m_data = Simd::Or(m_data, other.m_data);
        return static_cast<Mybase &>(*this);
    }

    friend Mybase operator|(const Mybase &lhs, const Mybase &rhs) noexcept {
        Mybase ret(lhs);
        ret |= rhs;
        return ret;
    }

    Mybase &operator^=(const Mybase &other) noexcept {
        m_data = Simd::Xor(m_data, other.m_data);
        return static_cast<Mybase &>(*this);
    }

    friend Mybase operator^(const Mybase &lhs, const Mybase &rhs) noexcept {
        Mybase ret(lhs);
        ret ^= rhs;
        return ret;
    }

    friend constexpr mask_type operator==(const Mybase &lhs, const Mybase &rhs) noexcept {
        return Simd::movemask_epi8(Simd::cmpeq(lhs.m_data, rhs.m_data, T()));
    }

private:
    int_type m_data;
};

#if WJR_HAS_SIMD(SSE2)
#define WJR_HAS_SIMD_NATIVE_128BIT WJR_HAS_DEF

template <>
class simd<uint8_t, simd_abi::fixed_size<16>> : public __x86_simd_base<uint8_t, 16, sse> {
    using Mybase = __x86_simd_base<uint8_t, 16, sse>;

public:
    using Mybase::Mybase;
};

template <>
class simd<uint16_t, simd_abi::fixed_size<8>> : public __x86_simd_base<uint16_t, 8, sse> {
    using Mybase = __x86_simd_base<uint16_t, 8, sse>;

public:
    using Mybase::Mybase;
};

template <>
class simd<uint32_t, simd_abi::fixed_size<4>> : public __x86_simd_base<uint32_t, 4, sse> {
    using Mybase = __x86_simd_base<uint32_t, 4, sse>;

public:
    using Mybase::Mybase;
};

template <>
class simd<uint64_t, simd_abi::fixed_size<2>> : public __x86_simd_base<uint64_t, 2, sse> {
    using Mybase = __x86_simd_base<uint64_t, 2, sse>;

public:
    using Mybase::Mybase;
};

#endif

#if WJR_HAS_SIMD(AVX2)
#define WJR_HAS_SIMD_NATIVE_256BIT WJR_HAS_DEF

template <>
class simd<uint8_t, simd_abi::fixed_size<32>> : public __x86_simd_base<uint8_t, 32, avx> {
    using Mybase = __x86_simd_base<uint8_t, 32, avx>;

public:
    using Mybase::Mybase;
};

template <>
class simd<uint16_t, simd_abi::fixed_size<16>>
    : public __x86_simd_base<uint16_t, 16, avx> {
    using Mybase = __x86_simd_base<uint16_t, 16, avx>;

public:
    using Mybase::Mybase;
};

template <>
class simd<uint32_t, simd_abi::fixed_size<8>> : public __x86_simd_base<uint32_t, 8, avx> {
    using Mybase = __x86_simd_base<uint32_t, 8, avx>;

public:
    using Mybase::Mybase;
};

template <>
class simd<uint64_t, simd_abi::fixed_size<4>> : public __x86_simd_base<uint64_t, 4, avx> {
    using Mybase = __x86_simd_base<uint64_t, 4, avx>;

public:
    using Mybase::Mybase;
};

#endif

} // namespace wjr

#endif // WJR_X86_SIMD_SIMD_HPP__

namespace wjr {

#if WJR_HAS_SIMD(PCLMUL)
#define WJR_HAS_BUILTIN_PREFIX_XOR WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(PREFIX_XOR)

template <typename T>
T __builtin_prefix_xor(T x) noexcept {
    const __m128i __result =
        _mm_clmulepi64_si128((simd_cast<T, __m128i_t>(x)), sse::set1_epi8(0xFF), 0);
    return simd_cast<__m128i_t, T>(__result);
}

template <typename T>
T builtin_prefix_xor(T x) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    if constexpr (nd < 32) {
        return static_cast<T>(__builtin_prefix_xor(static_cast<uint32_t>(x)));
    } else {
        return __builtin_prefix_xor(x);
    }
}

#endif

} // namespace wjr

#endif // WJR_X86_MATH_PREFIX_XOR_HPP__
#endif

namespace wjr {

template <typename T>
constexpr T fallback_prefix_xor(T x) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    static_assert(nd <= 64, "Type T has more than 64 bits");

    x ^= x << 1;
    x ^= x << 2;
    x ^= x << 4;
    if constexpr (nd > 8) {
        x ^= x << 8;
    }
    if constexpr (nd > 16) {
        x ^= x << 16;
    }
    if constexpr (nd > 32) {
        x ^= x << 32;
    }

    return x;
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 T prefix_xor(T x) noexcept {
#if WJR_HAS_BUILTIN(PREFIX_XOR)
    if (is_constant_evaluated() || WJR_BUILTIN_CONSTANT_P(x)) {
        return fallback_prefix_xor(x);
    }

    return builtin_prefix_xor(x);
#else
    return fallback_prefix_xor(x);
#endif
}

} // namespace wjr

#endif // WJR_MATH_PREFIX_XOR_HPP__

#ifndef WJR_BIGINTEGER_HPP__
#define WJR_BIGINTEGER_HPP__

#ifndef WJR_BIGINTEGER_BIGINTEGER_HPP__
#define WJR_BIGINTEGER_BIGINTEGER_HPP__

#include <istream>
#include <optional>

#ifndef WJR_FORMAT_OSTREAM_INSERT_HPP__
#define WJR_FORMAT_OSTREAM_INSERT_HPP__

#include <ostream>

namespace wjr {

/// @private
template <typename CharT, typename Tratis>
void __ostream_write_unchecked(std::basic_ostream<CharT, Tratis> &os, const CharT *str,
                               std::streamsize n) noexcept {
    const auto __put = os.rdbuf()->sputn(str, n);
    if (__put != n) {
        os.setstate(std::ios_base::badbit);
    }
}

/// @private
template <typename CharT, typename Tratis>
void __ostream_fill_unchecked(std::basic_ostream<CharT, Tratis> &os,
                              std::streamsize n) noexcept {
    const auto ch = os.fill();
    while (n--) {
        const auto __put = os.rdbuf()->sputc(ch);
        if (Tratis::eq_int_type(__put, Tratis::eof())) {
            os.setstate(std::ios_base::badbit);
            break;
        }
    }
}

/// @private
template <typename CharT, typename Tratis>
void __ostream_insert_unchecked(std::basic_ostream<CharT, Tratis> &os, const CharT *str,
                                std::streamsize n) noexcept {
    const std::streamsize __w = os.width();
    if (__w > n) {
        const std::streamsize __pad = __w - n;
        const bool __left =
            ((os.flags() & std::ios_base::adjustfield) == std::ios_base::left);

        if (!__left) {
            __ostream_fill_unchecked(os, __pad);
        }
        if (os.good()) {
            __ostream_write_unchecked(os, str, n);
        }
        if (__left && os.good()) {
            __ostream_fill_unchecked(os, __pad);
        }
    } else {
        __ostream_write_unchecked(os, str, n);
    }

    os.width(0);
}

/**
 * @brief Fast output a string to the output stream.
 *
 */
template <typename CharT, typename Tratis>
std::basic_ostream<CharT, Tratis> &__ostream_insert(std::basic_ostream<CharT, Tratis> &os,
                                                    const CharT *str,
                                                    std::streamsize n) noexcept {
    const std::ostream::sentry ok(os);
    if (ok) {
        __ostream_insert_unchecked(os, str, n);
    }

    return os;
}

} // namespace wjr

#endif // WJR_FORMAT_OSTREAM_INSERT_HPP__
#ifndef WJR_MATH_HPP__
#define WJR_MATH_HPP__

#ifndef WJR_MATH_CONVERT_HPP__
#define WJR_MATH_CONVERT_HPP__

#ifndef WJR_FORMAT_CHARCONV_HPP__
#define WJR_FORMAT_CHARCONV_HPP__

#include <array>

// Already included
#ifndef WJR_CONTAINER_GENERIC_TYPE_TRAITS_HPP__
#define WJR_CONTAINER_GENERIC_TYPE_TRAITS_HPP__

#include <array>
#include <vector>

#ifndef WJR_VECTOR_HPP__
#define WJR_VECTOR_HPP__

#ifndef WJR_CONTAINER_GENERIC_CONTAINER_VECTOR_HPP__
#define WJR_CONTAINER_GENERIC_CONTAINER_VECTOR_HPP__

/**
 * @file vector.hpp
 * @brief Vector container with definable internal structure
 *
 * @details
 * Customized internal structure needs to follow the following function signature: \n
 * -# storage() noexcept
 * -# ~storage() noexcept
 * -# void destroy(_Alty& al) noexcept(optional)
 * -# void destroy_and_deallocate(_Alty& al) noexcept(optional)
 * -# void uninitialized_construct(storage_type &other, size_type size, size_type
 * capacity, _Alty& al) noexcept
 * -# void take_storage(storage& other, _Alty& al) noexcept(optional)
 * -# void swap_storage(storage& other, _Alty& al) noexcept(optional)
 * -# decltype(auto) size() noexcept
 * -# size_type capacity() const noexcept
 * -# pointer data() noexcept
 * -# const_pointer data() const noexcept
 *
 * 1 : should not allocate memory. \n
 * 2 : don't need to destroy or deallocate. \n
 * 3 : destroy all elements. don't change ptr, size and capacity. \n
 * 4 : destroy and deallocate. \n
 * 5 : uninitialized construct the storage. allocate memory and set the size and
 * capacity. \n
 * 6 : take the storage from other. set other to empty. \n
 * 7 : swap the storage with other. \n
 * 8 : get the size. the return type must be reference,
 * such as size_type&, std::reference_wrapper<size_type> and so on. \n
 * 9 : get the capacity. \n
 * 10-11 : get the pointer. \n
 *
 * the size type of 8 need to implement the following function signature: \n
 * -# auto& operator=(size_type) noexcept
 * -# operator size_type() const noexcept
 * -# size_type operator++() noexcept
 * -# size_type operator--() noexcept
 * -# size_type operator+=(size_type) noexcept
 * -# size_type operator-=(size_type) noexcept
 *
 * @version 0.2
 * @date 2024-04-29
 *
 */

#ifndef WJR_COMPRESSED_PAIR_HPP__
#define WJR_COMPRESSED_PAIR_HPP__

#ifndef WJR_TUPLE_HPP__
#define WJR_TUPLE_HPP__

#include <tuple>

#ifndef WJR_CAPTURE_LEAF_HPP__
#define WJR_CAPTURE_LEAF_HPP__

#include <tuple>

#ifndef WJR_CRTP_CLASS_BASE_HPP__
#define WJR_CRTP_CLASS_BASE_HPP__

#include <cstddef>
#include <type_traits>

// Already included

namespace wjr {

struct enable_default_constructor_t {
    explicit enable_default_constructor_t() = default;
};

inline constexpr enable_default_constructor_t enable_default_constructor{};

template <bool Enable, typename Tag>
struct enable_default_constructor_base {
    enable_default_constructor_base() = default;
    enable_default_constructor_base(const enable_default_constructor_base &) = default;
    enable_default_constructor_base(enable_default_constructor_base &&) = default;
    enable_default_constructor_base &
    operator=(const enable_default_constructor_base &) = default;
    enable_default_constructor_base &
    operator=(enable_default_constructor_base &&) = default;

protected:
    constexpr explicit enable_default_constructor_base(
        enable_default_constructor_t) noexcept {}
};

template <typename Tag>
struct enable_default_constructor_base<false, Tag> {
    enable_default_constructor_base() = delete;
    enable_default_constructor_base(const enable_default_constructor_base &) = default;
    enable_default_constructor_base(enable_default_constructor_base &&) = default;
    enable_default_constructor_base &
    operator=(const enable_default_constructor_base &) = default;
    enable_default_constructor_base &
    operator=(enable_default_constructor_base &&) = default;

protected:
    constexpr explicit enable_default_constructor_base(
        enable_default_constructor_t) noexcept {}
};

template <bool Enable, typename Tag>
struct enable_copy_constructor_base {
    enable_copy_constructor_base() = default;
    enable_copy_constructor_base(const enable_copy_constructor_base &) = default;
    enable_copy_constructor_base(enable_copy_constructor_base &&) = default;
    enable_copy_constructor_base &
    operator=(const enable_copy_constructor_base &) = default;
    enable_copy_constructor_base &operator=(enable_copy_constructor_base &&) = default;

protected:
    constexpr explicit enable_copy_constructor_base(
        enable_default_constructor_t) noexcept {}
};

template <typename Tag>
struct enable_copy_constructor_base<false, Tag> {
    enable_copy_constructor_base() = default;
    enable_copy_constructor_base(const enable_copy_constructor_base &) = delete;
    enable_copy_constructor_base(enable_copy_constructor_base &&) = default;
    enable_copy_constructor_base &
    operator=(const enable_copy_constructor_base &) = default;
    enable_copy_constructor_base &operator=(enable_copy_constructor_base &&) = default;

protected:
    constexpr explicit enable_copy_constructor_base(
        enable_default_constructor_t) noexcept {}
};

template <bool Enable, typename Tag>
struct enable_move_constructor_base {
    enable_move_constructor_base() = default;
    enable_move_constructor_base(const enable_move_constructor_base &) = default;
    enable_move_constructor_base(enable_move_constructor_base &&) = default;
    enable_move_constructor_base &
    operator=(const enable_move_constructor_base &) = default;
    enable_move_constructor_base &operator=(enable_move_constructor_base &&) = default;

protected:
    constexpr explicit enable_move_constructor_base(
        enable_default_constructor_t) noexcept {}
};

template <typename Tag>
struct enable_move_constructor_base<false, Tag> {
    enable_move_constructor_base() = default;
    enable_move_constructor_base(const enable_move_constructor_base &) = default;
    enable_move_constructor_base(enable_move_constructor_base &&) = delete;
    enable_move_constructor_base &
    operator=(const enable_move_constructor_base &) = default;
    enable_move_constructor_base &operator=(enable_move_constructor_base &&) = default;

protected:
    constexpr explicit enable_move_constructor_base(
        enable_default_constructor_t) noexcept {}
};

template <bool Enable, typename Tag>
struct enable_copy_assignment_base {
    enable_copy_assignment_base() = default;
    enable_copy_assignment_base(const enable_copy_assignment_base &) = default;
    enable_copy_assignment_base(enable_copy_assignment_base &&) = default;
    enable_copy_assignment_base &operator=(const enable_copy_assignment_base &) = default;
    enable_copy_assignment_base &operator=(enable_copy_assignment_base &&) = default;

protected:
    constexpr explicit enable_copy_assignment_base(
        enable_default_constructor_t) noexcept {}
};

template <typename Tag>
struct enable_copy_assignment_base<false, Tag> {
    enable_copy_assignment_base() = default;
    enable_copy_assignment_base(const enable_copy_assignment_base &) = default;
    enable_copy_assignment_base(enable_copy_assignment_base &&) = default;
    enable_copy_assignment_base &operator=(const enable_copy_assignment_base &) = delete;
    enable_copy_assignment_base &operator=(enable_copy_assignment_base &&) = default;

protected:
    constexpr explicit enable_copy_assignment_base(
        enable_default_constructor_t) noexcept {}
};

template <bool Enable, typename Tag>
struct enable_move_assignment_base {
    enable_move_assignment_base() = default;
    enable_move_assignment_base(const enable_move_assignment_base &) = default;
    enable_move_assignment_base(enable_move_assignment_base &&) = default;
    enable_move_assignment_base &operator=(const enable_move_assignment_base &) = default;
    enable_move_assignment_base &operator=(enable_move_assignment_base &&) = default;

protected:
    constexpr explicit enable_move_assignment_base(
        enable_default_constructor_t) noexcept {}
};

template <typename Tag>
struct enable_move_assignment_base<false, Tag> {
    enable_move_assignment_base() = default;
    enable_move_assignment_base(const enable_move_assignment_base &) = default;
    enable_move_assignment_base(enable_move_assignment_base &&) = default;
    enable_move_assignment_base &operator=(const enable_move_assignment_base &) = default;
    enable_move_assignment_base &operator=(enable_move_assignment_base &&) = delete;

protected:
    constexpr explicit enable_move_assignment_base(
        enable_default_constructor_t) noexcept {}
};

template <bool Enable, typename Tag>
struct enable_destructor_base {
    enable_destructor_base() = default;
    enable_destructor_base(const enable_destructor_base &) = default;
    enable_destructor_base(enable_destructor_base &&) = default;
    enable_destructor_base &operator=(const enable_destructor_base &) = default;
    enable_destructor_base &operator=(enable_destructor_base &&) = default;
    ~enable_destructor_base() = default;

protected:
    constexpr explicit enable_destructor_base(enable_default_constructor_t) noexcept {}
};

template <typename Tag>
struct enable_destructor_base<false, Tag> {
    enable_destructor_base() = default;
    enable_destructor_base(const enable_destructor_base &) = default;
    enable_destructor_base(enable_destructor_base &&) = default;
    enable_destructor_base &operator=(const enable_destructor_base &) = default;
    enable_destructor_base &operator=(enable_destructor_base &&) = default;
    ~enable_destructor_base() = delete;

protected:
    constexpr explicit enable_destructor_base(enable_default_constructor_t) noexcept {}
};

template <bool Default, bool Destructor, bool Copy, bool Move, bool CopyAssign,
          bool MoveAssign, typename Tag = void>
struct WJR_EMPTY_BASES enable_special_members_base
    : enable_default_constructor_base<Default, Tag>,
      enable_destructor_base<Destructor, Tag>,
      enable_copy_constructor_base<Copy, Tag>,
      enable_move_constructor_base<Move, Tag>,
      enable_copy_assignment_base<CopyAssign, Tag>,
      enable_move_assignment_base<MoveAssign, Tag> {

private:
    using Mybase = enable_default_constructor_base<Default, Tag>;

public:
    enable_special_members_base() = default;
    enable_special_members_base(const enable_special_members_base &) = default;
    enable_special_members_base(enable_special_members_base &&) = default;
    enable_special_members_base &operator=(const enable_special_members_base &) = default;
    enable_special_members_base &operator=(enable_special_members_base &&) = default;

protected:
    constexpr explicit enable_special_members_base(enable_default_constructor_t) noexcept
        : Mybase(enable_default_constructor) {}
};

template <bool Copy, bool Move, bool CopyAssign, bool MoveAssign, typename Tag = void>
using enable_copy_move_base =
    enable_special_members_base<true, true, Copy, Move, CopyAssign, MoveAssign, Tag>;

template <typename Tag = void>
using noncopyable = enable_copy_move_base<false, true, false, true, Tag>;

template <typename Tag = void>
using nonmoveable = enable_copy_move_base<false, true, false, true, Tag>;

template <typename Tag = void, typename... Args>
using enable_special_members_of_args_base = enable_special_members_base<
    std::conjunction_v<std::is_default_constructible<Args>...>,
    std::conjunction_v<std::is_destructible<Args>...>,
    std::conjunction_v<std::is_copy_constructible<Args>...>,
    std::conjunction_v<std::is_move_constructible<Args>...>,
    std::conjunction_v<std::is_copy_assignable<Args>...>,
    std::conjunction_v<std::is_move_assignable<Args>...>, Tag>;

template <typename Tag = void, typename... Args>
using enable_trivially_special_members_of_args_base = enable_special_members_base<
    std::conjunction_v<std::is_trivially_default_constructible<Args>...>,
    std::conjunction_v<std::is_destructible<Args>...>,
    std::conjunction_v<std::is_trivially_copy_constructible<Args>...>,
    std::conjunction_v<std::is_trivially_move_constructible<Args>...>,
    std::conjunction_v<std::is_trivially_copy_assignable<Args>...>,
    std::conjunction_v<std::is_trivially_move_assignable<Args>...>, Tag>;

template <size_t I, typename T>
struct enable_base_identity_t {};

template <typename Mybase>
struct control_copy_ctor_base : Mybase {
    using Mybase ::Mybase;
    control_copy_ctor_base() = default;
    constexpr control_copy_ctor_base(const control_copy_ctor_base &other) noexcept(
        noexcept(Mybase::__copy_construct(static_cast<const Mybase &>(other))))
        : Mybase(enable_default_constructor) {
        Mybase::__copy_construct(static_cast<const Mybase &>(other));
    }
    control_copy_ctor_base(control_copy_ctor_base &&) = default;
    control_copy_ctor_base &operator=(const control_copy_ctor_base &) = default;
    control_copy_ctor_base &operator=(control_copy_ctor_base &&) = default;

protected:
    constexpr explicit control_copy_ctor_base(enable_default_constructor_t) noexcept
        : Mybase(enable_default_constructor) {}
};

template <typename Mybase>
struct control_move_ctor_base : Mybase {
    using Mybase ::Mybase;
    control_move_ctor_base() = default;
    control_move_ctor_base(const control_move_ctor_base &) = default;
    constexpr control_move_ctor_base(control_move_ctor_base &&other) noexcept(
        noexcept(Mybase::__move_construct(static_cast<Mybase &&>(other))))
        : Mybase(enable_default_constructor) {
        Mybase::__move_construct(static_cast<Mybase &&>(other));
    }
    control_move_ctor_base &operator=(const control_move_ctor_base &) = default;
    control_move_ctor_base &operator=(control_move_ctor_base &&) = default;

protected:
    constexpr explicit control_move_ctor_base(enable_default_constructor_t) noexcept
        : Mybase(enable_default_constructor) {}
};

template <typename Mybase>
struct control_copy_assign_base : Mybase {
    using Mybase ::Mybase;
    control_copy_assign_base() = default;
    control_copy_assign_base(const control_copy_assign_base &) = default;
    control_copy_assign_base(control_copy_assign_base &&) = default;
    constexpr control_copy_assign_base &
    operator=(const control_copy_assign_base &other) noexcept(
        noexcept(Mybase::__copy_assign(static_cast<const Mybase &>(other)))) {
        Mybase::__copy_assign(static_cast<const Mybase &>(other));
        return *this;
    }
    control_copy_assign_base &operator=(control_copy_assign_base &&) = default;

protected:
    constexpr explicit control_copy_assign_base(enable_default_constructor_t) noexcept
        : Mybase(enable_default_constructor) {}
};

template <typename Mybase>
struct control_move_assign_base : Mybase {
    using Mybase ::Mybase;
    control_move_assign_base() = default;
    control_move_assign_base(const control_move_assign_base &) = default;
    control_move_assign_base(control_move_assign_base &&) = default;
    control_move_assign_base &operator=(const control_move_assign_base &) = default;
    constexpr control_move_assign_base &
    operator=(control_move_assign_base &&other) noexcept(
        noexcept(Mybase::__move_assign(static_cast<Mybase &&>(other)))) {
        Mybase::__move_assign(static_cast<Mybase &&>(other));
        return *this;
    }

protected:
    constexpr explicit control_move_assign_base(enable_default_constructor_t) noexcept
        : Mybase(enable_default_constructor) {}
};

template <bool F, template <typename> typename Control, typename Mybase>
using __control_base_selector = std::conditional_t<F, Mybase, Control<Mybase>>;

template <typename Mybase, bool Copy, bool Move, bool CopyAssign, bool MoveAssign>
using control_special_members_base = __control_base_selector<
    Copy, control_copy_ctor_base,
    __control_base_selector<
        Move, control_move_ctor_base,
        __control_base_selector<
            CopyAssign, control_copy_assign_base,
            __control_base_selector<MoveAssign, control_move_assign_base, Mybase>>>>;

} // namespace wjr

#endif // WJR_CRTP_CLASS_BASE_HPP__
#ifndef WJR_TP_LIST_HPP__
#define WJR_TP_LIST_HPP__

// Already included

namespace wjr {

template <typename... Args>
struct tp_list {};

template <typename T>
struct tp_is_list : std::false_type {};

template <typename... Args>
struct tp_is_list<tp_list<Args...>> : std::true_type {};

// check if is tp_list
template <typename T>
inline constexpr bool tp_is_list_v = tp_is_list<T>::value;

template <typename T>
struct tp_is_container : std::false_type {};

template <template <typename...> typename C, typename... Args>
struct tp_is_container<C<Args...>> : std::true_type {};

template <typename T>
inline constexpr bool tp_is_container_v = tp_is_container<T>::value;

template <typename T>
struct tp_size;

template <template <typename...> typename C, typename... Args>
struct tp_size<C<Args...>> : std::integral_constant<size_t, sizeof...(Args)> {};

// get size of C<Args...>
template <typename T>
inline constexpr size_t tp_size_v = tp_size<T>::value;

template <typename T>
struct tp_is_fn : std::false_type {};

template <typename T>
inline constexpr bool tp_is_fn_v = tp_is_fn<T>::value;

/// @private
template <typename _Enable, template <typename...> typename F, typename... Args>
struct __tp_is_valid_helper : std::false_type {};

/// @private
template <template <typename...> typename F, typename... Args>
struct __tp_is_valid_helper<std::void_t<F<Args...>>, F, Args...> : std::true_type {};

template <template <typename...> typename F, typename... Args>
struct tp_is_valid : __tp_is_valid_helper<void, F, Args...> {};

template <template <typename...> typename F, typename... Args>
inline constexpr bool tp_is_valid_v = tp_is_valid<F, Args...>::value;

template <typename F, typename... Args>
inline constexpr bool tp_is_valid_f = tp_is_valid_v<F::template fn, Args...>;

/// @private
template <template <typename...> typename F, typename... Args>
struct __tp_defer_helper {
    using type = F<Args...>;
};

template <template <typename...> typename F, typename... Args>
struct tp_defer {
    using type = std::enable_if_t<tp_is_valid_v<F, Args...>,
                                  typename __tp_defer_helper<F, Args...>::type>;
};

// use std::enable_if_t to defer the instantiation of F<Args...>
template <template <typename...> typename F, typename... Args>
using tp_defer_t = typename tp_defer<F, Args...>::type;

template <typename F, typename... Args>
using tp_defer_f = tp_defer_t<F::template fn, Args...>;

template <typename T>
struct tp_type_identity {
    using type = T;
};

// tp_type_identity_t<T> is T
template <typename T>
using tp_type_identity_t = typename tp_type_identity<T>::type;

// F1<F2<Args...>>
template <template <typename...> typename F1, template <typename...> typename F2>
struct tp_bind_fn {
    template <typename... Args>
    using fn = tp_defer_t<F1, tp_defer_t<F2, Args...>>;
};

// make F can be used as fn
template <template <typename...> typename F>
struct tp_make_fn {
    template <typename... Args>
    using fn = tp_defer_t<F, Args...>;
};

// std::negation<F<Args...>>
template <template <typename...> typename F>
struct tp_not_fn {
    template <typename... Args>
    using fn = typename tp_bind_fn<std::negation, F>::template fn<Args...>;
};

template <typename... Args>
using tp_true_type = std::true_type;

template <typename... Args>
using tp_false_type = std::false_type;

template <typename T>
struct tp_is_empty : std::bool_constant<tp_size_v<T> == 0> {};

template <typename T>
inline constexpr bool tp_is_empty_v = tp_is_empty<T>::value;

template <typename T, typename U>
struct tp_assign;

template <typename... Args1, template <typename...> typename T1, typename... Args2,
          template <typename...> typename T2>
struct tp_assign<T1<Args1...>, T2<Args2...>> {
    using type = T1<Args2...>;
};

// f(L1<Args1...>, L2<Args2...>) -> L1<Args2...>
template <typename T, typename U>
using tp_assign_t = typename tp_assign<T, U>::type;

template <typename T>
struct tp_clear;

template <template <typename...> typename T, typename... Args>
struct tp_clear<T<Args...>> {
    using type = T<>;
};

// f(L<Args...>) -> L<>
template <typename T>
using tp_clear_t = typename tp_clear<T>::type;

template <typename T, typename... Args>
struct tp_push_front;

template <template <typename...> typename C, typename... Args1, typename... Args2>
struct tp_push_front<C<Args1...>, Args2...> {
    using type = C<Args2..., Args1...>;
};

// f(L<Args1...>, Args2...) -> L<Args1..., Args2...)
template <typename T, typename... Args>
using tp_push_front_t = typename tp_push_front<T, Args...>::type;

template <typename T, typename... Args>
struct tp_push_back;

template <template <typename...> typename C, typename... Args1, typename... Args2>
struct tp_push_back<C<Args1...>, Args2...> {
    using type = C<Args1..., Args2...>;
};

// f(L<Args1...>, Args2...) -> L<Args2..., Args1...)
template <typename T, typename... Args>
using tp_push_back_t = typename tp_push_back<T, Args...>::type;

/// @private
template <typename _Enable, size_t I, size_t N, typename... Args>
struct __tp_cut_helper;

/// @private
template <size_t I, size_t N, typename T, typename... Args>
struct __tp_cut_helper<std::enable_if_t<N != 0, void>, I, N, T, Args...> {
    using type = typename __tp_cut_helper<void, I - 1, N, Args...>::type;
};

/// @private
template <size_t I, size_t N, typename T, typename... Args>
struct __tp_cut_helper<std::enable_if_t<N == 0, void>, I, N, T, Args...> {
    using type = tp_list<>;
};

/// @private
template <size_t N, typename... Args2>
struct __tp_cut_helper2;

/// @private
template <size_t N, typename T, typename... Args>
struct __tp_cut_helper2<N, T, Args...> {
    using type = tp_push_front_t<typename __tp_cut_helper2<N - 1, Args...>::type, T>;
};

/// @private
template <typename... Args>
struct __tp_cut_helper2<0, Args...> {
    using type = tp_list<>;
};

/// @private
template <typename T, typename... Args>
struct __tp_cut_helper2<0, T, Args...> {
    using type = tp_list<>;
};

/// @private
template <size_t N, typename... Args>
struct __tp_cut_helper<std::enable_if_t<N != 0>, 0, N, Args...> {
    using type = typename __tp_cut_helper2<N, Args...>::type;
};

/// @private
template <size_t N, typename T, typename... Args>
struct __tp_cut_helper<std::enable_if_t<N != 0>, 0, N, T, Args...> {
    using type = typename __tp_cut_helper2<N, T, Args...>::type;
};

template <typename T, template <typename...> typename U>
struct tp_rename;

template <template <typename...> typename C, typename... Args,
          template <typename...> typename U>
struct tp_rename<C<Args...>, U> {
    using type = U<Args...>;
};

// f(L1<Args1...>, L2) -> L2<Args1...>
template <typename T, template <typename...> typename U>
using tp_rename_t = typename tp_rename<T, U>::type;

template <typename T, size_t I, size_t N>
struct tp_cut;

template <template <typename...> typename C, typename... Args, size_t I, size_t N>
struct tp_cut<C<Args...>, I, N> {
    static_assert(N <= sizeof...(Args) && I <= (sizeof...(Args) - N),
                  "tp_cut: invalid index");
    using type = tp_rename_t<typename __tp_cut_helper<void, I, N, Args...>::type, C>;
};

// f(L<Args...>, I, N) -> L<Args[I ~ I + N - 1]>
template <typename T, size_t I, size_t N>
using tp_cut_t = typename tp_cut<T, I, N>::type;

template <typename T>
struct tp_pop_front : tp_cut<T, 1, tp_size_v<T> - 1> {};

// f(L<T, Args...>) -> L<Args...>
template <typename T>
using tp_pop_front_t = typename tp_pop_front<T>::type;

template <typename T>
struct tp_pop_back : tp_cut<T, 0, tp_size_v<T> - 1> {};

// f(L<Args..., T>) -> L<Args...>
template <typename T>
using tp_pop_back_t = typename tp_pop_back<T>::type;

/// @private
template <size_t index, typename... Args>
struct __tp_at_helper;

/// @private
template <size_t index, typename T, typename... Args>
struct __tp_at_helper<index, T, Args...> {
    using type = typename __tp_at_helper<index - 1, Args...>::type;
};

/// @private
template <typename T, typename... Args>
struct __tp_at_helper<0, T, Args...> {
    using type = T;
};

//
template <typename T, size_t index>
struct tp_at;

template <template <typename... Args> typename C, typename... Args, size_t index>
struct tp_at<C<Args...>, index> {
    static_assert(index < sizeof...(Args), "tp_at: invalid index");
    using type = typename __tp_at_helper<index, Args...>::type;
};

// f(L<Args...>, index) - > Args(index)
template <typename T, size_t index>
using tp_at_t = typename tp_at<T, index>::type;

template <typename T>
struct tp_front {
    using type = tp_at_t<T, 0>;
};

// tp_at_t(T, 0)
template <typename T>
using tp_front_t = typename tp_front<T>::type;

template <typename T>
struct tp_back {
    using type = tp_at_t<T, tp_size_v<T> - 1>;
};

// tp_at_t(T, tp_size_v<T> - 1)
template <typename T>
using tp_back_t = typename tp_back<T>::type;

template <typename T, size_t idx>
struct tp_prefix {
    using type = tp_cut_t<T, 0, idx>;
};

// f(L<Args...>, idx) -> L<Args[0 ~ idx - 1]>
template <typename T, size_t idx>
using tp_prefix_t = typename tp_prefix<T, idx>::type;

template <typename T, size_t idx>
struct tp_suffix {
    using type = tp_cut_t<T, tp_size_v<T> - idx, idx>;
};

// f(L<Args...>, idx) -> L<Args[tp_size_v<T> - idx ~ tp_size_v<T> - 1]>
template <typename T, size_t idx>
using tp_suffix_t = typename tp_suffix<T, idx>::type;

template <typename T, size_t idx>
struct tp_remove_prefix {
    using type = tp_suffix_t<T, tp_size_v<T> - idx>;
};

template <typename T, size_t idx>
using tp_remove_prefix_t = typename tp_remove_prefix<T, idx>::type;

template <typename T, size_t idx>
struct tp_remove_suffix {
    using type = tp_prefix_t<T, tp_size_v<T> - idx>;
};

template <typename T, size_t idx>
using tp_remove_suffix_t = typename tp_remove_suffix<T, idx>::type;

template <typename... Args>
struct tp_concat;

template <typename T>
struct tp_concat<T> {
    using type = T;
};

template <template <typename...> typename C1, typename... Args1,
          template <typename...> typename C2, typename... Args2>
struct tp_concat<C1<Args1...>, C2<Args2...>> {
    using type = C1<Args1..., Args2...>;
};

template <typename T, typename U, typename... Args3>
struct tp_concat<T, U, Args3...> {
    using type = typename tp_concat<typename tp_concat<T, U>::type, Args3...>::type;
};

// f(L1<Args...>, L2<Args2...>, ... Ln<Argsn...>) -> L1<Args..., Args2..., Argsn...>
template <typename... Args>
using tp_concat_t = typename tp_concat<Args...>::type;

template <typename T, size_t idx, typename U>
struct tp_replace_at {
    using type = tp_concat_t<tp_push_back_t<tp_cut_t<T, 0, idx>, U>,
                             tp_cut_t<T, idx + 1, tp_size_v<T> - idx - 1>>;
};

template <typename T, typename U>
struct tp_replace_at<T, 0, U> {
    using type = tp_push_front_t<tp_pop_front_t<T>, U>;
};

// f(L<Args...>, idx, U) -> L<Args[0 ~ idx - 1], U, Args[idx + 1 ~ tp_size_v<T> - 1]>
template <typename T, size_t idx, typename U>
using tp_replace_at_t = typename tp_replace_at<T, idx, U>::type;

template <typename T, typename U>
struct tp_replace_front_at {
    using type = tp_replace_at_t<T, 0, U>;
};

template <typename T, typename U>
using tp_replace_front_at_t = typename tp_replace_front_at<T, U>::type;

template <typename T, typename U>
struct tp_replace_back_at {
    using type = tp_replace_at_t<T, tp_size_v<T> - 1, U>;
};

template <typename T, typename U>
using tp_replace_back_at_t = typename tp_replace_back_at<T, U>::type;

template <typename V, typename T, typename... Args>
struct tp_conditional {
    using type = std::conditional_t<V::value, T, typename tp_conditional<Args...>::type>;
};

template <typename V, typename T1, typename T2>
struct tp_conditional<V, T1, T2> {
    using type = std::conditional_t<V::value, T1, T2>;
};

// f(V, T, U) -> std::conditional_t<V::value, T, U>
// f(V, T, Args...) -> std::conditional_t<V::value, T, f(Args...)>
template <typename V, typename T, typename... Args>
using tp_conditional_t = typename tp_conditional<V, T, Args...>::type;

template <size_t idx>
struct tp_arg;

template <template <typename...> typename F, typename... Args>
struct tp_bind;

template <template <typename...> typename F, typename... Args>
struct tp_bind_front;

template <template <typename...> typename F, typename... Args>
struct tp_bind_back;

template <size_t idx>
struct tp_is_fn<tp_arg<idx>> : std::true_type {};

template <template <typename...> typename F, typename... Args>
struct tp_is_fn<tp_bind<F, Args...>> : std::true_type {};

template <template <typename...> typename F, typename... Args>
struct tp_is_fn<tp_bind_front<F, Args...>> : std::true_type {};

template <template <typename...> typename F, typename... Args>
struct tp_is_fn<tp_bind_back<F, Args...>> : std::true_type {};

template <size_t idx>
struct tp_arg {
    template <typename... Args>
    using fn = tp_at_t<tp_list<Args...>, idx>;
};

template <template <typename...> typename F, typename T>
struct tp_apply {
    using type = tp_rename_t<T, F>;
};

// f(F, L<Args...>) -> F<Args...>
// same as tp_rename_t(L<Args...>, F)
template <template <typename...> typename F, typename T>
using tp_apply_t = typename tp_apply<F, T>::type;

template <typename F, typename T>
using tp_apply_f = tp_apply_t<F::template fn, T>;

/// @private
template <typename _Enable, typename T, typename... Args>
struct __tp_bind_helper {
    using type = T;
};

/// @private
template <typename F, typename... Args>
struct __tp_bind_helper<std::enable_if_t<tp_is_fn_v<F>, void>, F, Args...> {
    using type = typename F::template fn<Args...>;
};

template <template <typename...> typename F, typename... Args>
struct tp_bind {
    template <typename... Args2>
    using fn = F<typename __tp_bind_helper<void, Args, Args2...>::type...>;
};

template <typename F, typename... Args>
using tp_bind_f = tp_bind<F::template fn, Args...>;

template <template <typename...> typename F, typename... Args>
struct tp_bind_front {
    template <typename... Args2>
    using fn = tp_defer_t<F, Args..., Args2...>;
};

template <typename F, typename... Args>
using tp_bind_front_f = tp_bind_front<F::template fn, Args...>;

template <template <typename...> typename F, typename... Args>
struct tp_bind_back {
    template <typename... Args2>
    using fn = tp_defer_t<F, Args2..., Args...>;
};

template <typename F, typename... Args>
using tp_bind_back_f = tp_bind_back<F::template fn, Args...>;

template <typename T, template <typename...> typename F>
struct tp_transform;

template <template <typename...> typename C, typename... Args,
          template <typename...> typename F>
struct tp_transform<C<Args...>, F> {
    using type = C<F<Args>...>;
};

// f(L<Args...>, Fn) -> L<Fn(Args)...>
// use with apply, bind, bind_front, bind_back...
// for example:
// tp_transform_f<tp_bind_front<tp_apply_f, tp_bind_front<std::is_same>>,
// tp_list<tp_list<int, float>, tp_list<float, float>, tp_list<int, double>>>
// -> tp_list<std::is_same<int, float>, std::is_same<float, float>, std::is_same<int,
// double>>
template <typename T, template <typename...> typename F>
using tp_transform_t = typename tp_transform<T, F>::type;

template <typename T, typename F>
using tp_transform_f = typename tp_transform<T, F::template fn>::type;

template <template <typename...> typename C, typename... Args>
struct tp_zip;

/// @private
template <template <typename...> typename C, typename T>
struct __tp_zip_helper;

/// @private
template <template <typename...> typename C, size_t... Idxs>
struct __tp_zip_helper<C, std::index_sequence<Idxs...>> {
    template <size_t I, typename... Args>
    using __type = C<tp_at_t<Args, I>...>;
    template <typename... Args>
    using type = tp_list<__type<Idxs, Args...>...>;
};

template <template <typename...> typename C>
struct tp_zip<C> {
    using type = tp_list<>;
};

template <template <typename...> typename C, typename T>
struct tp_zip<C, T> {
    using type = typename __tp_zip_helper<
        C, std::make_index_sequence<tp_size_v<T>>>::template type<T>;
};

template <template <typename...> typename C, typename T, typename... Args>
struct tp_zip<C, T, Args...> {
    constexpr static size_t size = tp_size_v<T>;
    static_assert(((size == tp_size_v<Args>)&&...),
                  "tp_zip arguments must have same size, \
		you can make all arguments have same size by tp_");
    using type = typename __tp_zip_helper<
        C, std::make_index_sequence<tp_size_v<T>>>::template type<T, Args...>;
};

// f(C, L<A1, A2, ... An>, L<B1, B2, ..., Bn> ...)
// -> L<C<A1, B1, ...>, C<A2, B2, ...>, ..., C<An, Bn, ...>>
template <template <typename...> typename C, typename... Args>
using tp_zip_t = typename tp_zip<C, Args...>::type;

/// @private
template <typename... Args>
struct __tp_max_size_helper;

/// @private
template <typename T>
struct __tp_max_size_helper<T> {
    constexpr static size_t value = tp_size_v<T>;
};

/// @private
template <typename T, typename... Args>
struct __tp_max_size_helper<T, Args...> {
    constexpr static size_t value =
        std::max(tp_size_v<T>, __tp_max_size_helper<Args...>::value);
};

template <typename T, typename... Args>
struct tp_max_size {
    constexpr static size_t value = __tp_max_size_helper<T, Args...>::value;
};

// tp_max_size_v<T, Args...> -> size_t
template <typename T, typename... Args>
inline constexpr size_t tp_max_size_v = tp_max_size<T, Args...>::value;

template <typename T>
struct tp_unwrap {
    static_assert(tp_size_v<T> == 1, "only container that size = 1 can use unwrap");
};

template <template <typename...> typename C, typename T>
struct tp_unwrap<C<T>> {
    using type = T;
};

// f(C<T>) -> T
template <typename T>
using tp_unwrap_t = typename tp_unwrap<T>::type;

template <typename T, template <typename...> typename P, typename U>
struct tp_replace_if;

template <template <typename...> typename C, typename... Args,
          template <typename...> typename P, typename U>
struct tp_replace_if<C<Args...>, P, U> {
    using type = C<tp_conditional_t<P<Args>, U, Args>...>;
};

// f(L<Args...>, P, U) -> L<if P(Args)::value then U else Args...>
template <typename T, template <typename...> typename P, typename U>
using tp_replace_if_t = typename tp_replace_if<T, P, U>::type;

template <typename T, typename P, typename U>
using tp_replace_if_f = tp_replace_if_t<T, P::template fn, U>;

template <typename T, typename U>
struct tp_replace_if_true {
    using type = tp_replace_if_t<T, tp_type_identity_t, U>;
};

template <typename T, typename U>
using tp_replace_if_true_t = typename tp_replace_if_true<T, U>::type;

template <typename T, typename U>
struct tp_replace_if_false {
    using type = tp_replace_if_f<T, tp_not_fn<tp_type_identity_t>, U>;
};

template <typename T, typename U>
using tp_replace_if_false_t = typename tp_replace_if_false<T, U>::type;

template <typename T, typename O, typename N>
struct tp_replace {
    using type = tp_replace_if_f<T, tp_bind_front<std::is_same, O>, N>;
};

template <typename T, typename O, typename N>
using tp_replace_t = typename tp_replace<T, O, N>::type;

template <typename T, typename U>
struct tp_fill {
    using type = tp_replace_if_t<T, tp_true_type, U>;
};

// f(L<Args...>, U) -> L<U, U, ..., U>
template <typename T, typename U>
using tp_fill_t = typename tp_fill<T, U>::type;

template <typename T, template <typename...> typename P>
struct tp_count_if;

template <template <typename...> typename C, template <typename...> typename P>
struct tp_count_if<C<>, P> {
    static constexpr size_t value = 0;
};

template <template <typename...> typename C, typename... Args,
          template <typename...> typename P>
struct tp_count_if<C<Args...>, P> {
    static constexpr size_t value = (P<Args>::value + ...);
};

// f(L<Args...>, P) -> count(P(Args)::value)
template <typename T, template <typename...> typename P>
constexpr size_t tp_count_if_v = tp_count_if<T, P>::value;

template <typename T, typename P>
constexpr size_t tp_count_if_f_v = tp_count_if_v<T, P::template fn>;

template <typename T, typename V>
struct tp_count {
    static constexpr size_t value = tp_count_if_f_v<T, tp_bind_front<std::is_same, V>>;
};

template <typename T, typename V>
constexpr size_t tp_count_v = tp_count<T, V>::value;

template <typename T, typename V>
struct tp_contains {
    static constexpr bool value = tp_count_v<T, V> != 0;
};

template <typename T, typename V>
constexpr bool tp_contains_v = tp_contains<T, V>::value;

template <typename T, template <typename...> typename P>
struct tp_remove_if;

template <template <typename...> typename C, typename... Args,
          template <typename...> typename P>
struct tp_remove_if<C<Args...>, P> {
    using type = tp_concat_t<C<>, tp_conditional_t<P<Args>, C<>, C<Args>>...>;
};

// f(L<Args...>, P) -> L<if P(Args)::value then L<> else L<Args>...>
template <typename T, template <typename...> typename P>
using tp_remove_if_t = typename tp_remove_if<T, P>::type;

template <typename T, typename P>
using tp_remove_if_f = tp_remove_if_t<T, P::template fn>;

template <typename T, typename V>
struct tp_remove {
    using type = tp_remove_if_f<T, tp_bind_front<std::is_same, V>>;
};

template <typename T, typename V>
using tp_remove_t = typename tp_remove<T, V>::type;

template <typename T, template <typename...> typename P>
struct tp_filter {
    using type = tp_remove_if_f<T, tp_not_fn<P>>;
};

template <typename T, template <typename...> typename P>
using tp_filter_t = typename tp_filter<T, P>::type;

template <typename T, typename P>
using tp_filter_f = tp_filter_t<T, P::template fn>;

template <typename T, typename U>
struct tp_equal;

/// @private
template <typename _Enable, typename T, typename U>
struct __tp_equal_helper : std::false_type {};

/// @private
template <template <typename...> typename C, typename... Args,
          template <typename...> typename D, typename... Args2>
struct __tp_equal_helper<std::enable_if_t<sizeof...(Args) == sizeof...(Args2), void>,
                         C<Args...>, D<Args2...>>
    : std::conjunction<std::is_same<Args, Args2>...> {};

template <typename T, typename U>
struct tp_equal : __tp_equal_helper<void, T, U> {};

template <typename T, typename U>
inline constexpr bool tp_equal_v = tp_equal<T, U>::value;

template <typename T, size_t N>
struct tp_repeat {
    using type = tp_concat_t<T, typename tp_repeat<T, N - 1>::type>;
};

template <typename T>
struct tp_repeat<T, 0> {
    using type = tp_clear_t<T>;
};

template <typename C, size_t N>
using tp_repeat_t = typename tp_repeat<C, N>::type;

/// @private
template <typename _Enable, typename C, size_t N, typename V>
struct __tp_resize_helper {
    using type = tp_cut_t<C, 0, N>;
};

/// @private
template <typename C, size_t N, typename V>
struct __tp_resize_helper<std::enable_if_t<N >= tp_size_v<C>, void>, C, N, V> {
    using type = tp_concat_t<C, tp_repeat_t<V, N - tp_size_v<C>>>;
};

template <typename C, size_t N, typename V>
struct tp_resize {
    using tyep = typename __tp_resize_helper<void, C, N, V>::type;
};

template <typename C, size_t N, typename V>
using tp_resize_t = typename tp_resize<C, N, V>::type;

template <template <typename...> typename C, typename... Args>
struct tp_product;

/// @private
template <typename _Enable, template <typename...> typename C, typename... Args>
struct __tp_product_helper {
    using type = tp_list<>;
};

/// @private
template <typename _Enable, template <typename...> typename C, typename T>
struct __tp_product_helper<_Enable, C, T> {
    using type = tp_list<tp_rename_t<T, C>>;
};

/// @private
template <template <typename...> typename C, typename T,
          template <typename...> typename C1, typename... Args1, typename... Args>
struct __tp_product_helper<std::enable_if_t<sizeof...(Args1) != 0, void>, C, T,
                           C1<Args1...>, Args...> {
    using type =
        tp_concat_t<typename __tp_product_helper<void, C, tp_push_back_t<T, Args1>,
                                                 Args...>::type...>;
};

template <template <typename...> typename C, typename... Args>
struct tp_product {
    using type = typename __tp_product_helper<void, C, tp_list<>, Args...>::type;
};

// for example
// f(C, L<A1, A2>, L<B1, B2, B3>) -> L<C<A1, B1>, C<A1, B2>, C<A1, B3>, C<A2, B1>, C<A2,
// B2>, C<A2, B3>>
template <template <typename...> typename C, typename... Args>
using tp_product_t = typename tp_product<C, Args...>::type;

template <typename C, size_t I, typename... Args>
struct tp_insert {
    static_assert(I <= tp_size_v<C>, "tp insert index out of range");
    using type = tp_concat_t<tp_push_back_t<tp_prefix_t<C, I>, Args...>,
                             tp_suffix_t<C, tp_size_v<C> - I>>;
};

template <typename C, size_t I, typename... Args>
using tp_insert_t = typename tp_insert<C, I, Args...>::type;

template <typename C, size_t I, size_t N>
struct tp_erase {
    static_assert(N <= tp_size_v<C> && I <= tp_size_v<C> - N,
                  "tp erase index out of range");
    using type = tp_concat_t<tp_prefix_t<C, I>, tp_suffix_t<C, tp_size_v<C> - I - N>>;
};

template <typename C, size_t I, size_t N>
using tp_erase_t = typename tp_erase<C, I, N>::type;

template <typename C>
struct tp_reverse;

template <template <typename...> typename C>
struct tp_reverse<C<>> {
    using type = C<>;
};

template <template <typename...> typename C, typename T, typename... Args>
struct tp_reverse<C<T, Args...>> {
    using type = tp_push_back_t<typename tp_reverse<C<Args...>>::type, T>;
};

template <typename C>
using tp_reverse_t = typename tp_reverse<C>::type;

/// @private
template <typename _Enable, size_t idx, typename C, template <typename...> typename P>
struct __tp_find_if_helper;

/// @private
template <typename _Enable, size_t idx, template <typename...> typename C, typename T,
          typename... Args, template <typename...> typename P>
struct __tp_find_if_helper<_Enable, idx, C<T, Args...>, P> {
    constexpr static size_t value =
        __tp_find_if_helper<void, idx + 1, C<Args...>, P>::value;
};

/// @private
template <typename _Enable, size_t idx, template <typename...> typename C,
          template <typename...> typename P>
struct __tp_find_if_helper<_Enable, idx, C<>, P> {
    constexpr static size_t value = -1;
};

/// @private
template <size_t idx, template <typename...> typename C, typename T, typename... Args,
          template <typename...> typename P>
struct __tp_find_if_helper<std::enable_if_t<P<T>::value, void>, idx, C<T, Args...>, P> {
    constexpr static size_t value = idx;
};

template <typename C, template <typename...> typename P>
struct tp_find_if {
    constexpr static size_t value = __tp_find_if_helper<void, 0, C, P>::value;
};

template <typename C, template <typename...> typename P>
inline constexpr size_t tp_find_if_v = tp_find_if<C, P>::value;

template <typename C, typename P>
inline constexpr size_t tp_find_if_f = tp_find_if<C, P::template fn>::value;

template <typename C, template <typename...> typename P>
struct tp_find_if_not {
    constexpr static size_t value = tp_find_if_f<C, tp_not_fn<P>>;
};

template <typename C, template <typename...> typename P>
inline constexpr size_t tp_find_if_not_v = tp_find_if_not<C, P>::value;

template <typename C, typename P>
inline constexpr size_t tp_find_if_not_f = tp_find_if_not<C, P::template fn>::value;

template <typename C, typename V>
struct tp_find {
    constexpr static size_t value = tp_find_if_f<C, tp_bind_front<std::is_same, V>>;
};

template <typename C, typename V>
inline constexpr size_t tp_find_v = tp_find<C, V>::value;

template <typename C, typename E, template <typename...> typename F>
struct tp_left_fold;

template <template <typename...> typename C, typename E,
          template <typename...> typename F>
struct tp_left_fold<C<>, E, F> {
    using type = E;
};

template <template <typename...> typename C, typename T, typename... Args, typename E,
          template <typename...> typename F>
struct tp_left_fold<C<T, Args...>, E, F> {
    using type = typename tp_left_fold<C<Args...>, F<E, T>, F>::type;
};

// f(L<A1, A2, ... An>, E, F) -> F<F<F...<F<E, A1>, A2>, ...>, An>
template <typename C, typename E, template <typename...> typename F>
using tp_left_fold_t = typename tp_left_fold<C, E, F>::type;

template <typename C, typename E, typename F>
using tp_left_fold_f = typename tp_left_fold<C, E, F::template fn>::type;

template <typename C, typename E, template <typename...> typename F>
struct tp_right_fold;

template <template <typename...> typename C, typename E,
          template <typename...> typename F>
struct tp_right_fold<C<>, E, F> {
    using type = E;
};

template <template <typename...> typename C, typename T, typename... Args, typename E,
          template <typename...> typename F>
struct tp_right_fold<C<T, Args...>, E, F> {
    using next_type = typename tp_right_fold<C<Args...>, E, F>::type;
    using type = F<T, next_type>;
};

// f(L<A1, A2, ... An>, E, F) -> F<A1, F<A2, ... F<An, E>...>>
template <typename C, typename E, template <typename...> typename F>
using tp_right_fold_t = typename tp_right_fold<C, E, F>::type;

template <typename C, typename E, typename F>
using tp_right_fold_f = typename tp_right_fold<C, E, F::template fn>::type;

template <typename C, template <typename...> typename P>
struct tp_unique_if {
    using type = tp_left_fold_f<C, tp_clear_t<C>,
                                tp_bind<tp_conditional_t, tp_bind_front<P>, tp_arg<0>,
                                        tp_bind_front<tp_push_back_t>>>;
};

// using NOW_LIST = tp_prefix_t<C, I + 1>;
// using PRE_LIST = tp_prefix_t<C, I>;
// using PRE_UNIQUE_IF_LIST = tp_unique_if_t<PRE_LIST>;
// then :
// tp_unique_if_t<NOW_LIST, P>
// = tp_conditonal_t<
// P<PRE_UNIQUE_IF_LIST, tp_at_t<C, I>>,
// PRE_UNIQUE_IF_LIST,
// tp_push_back_t<PRE_UNIQUE_IF_LIST, tp_at_t<C, I>>>
//
// It is equivalent to calling P every time on the results
// of the previous processing and the new value.
// If P is false, the new value is added
template <typename C, template <typename...> typename P>
using tp_unique_if_t = typename tp_unique_if<C, P>::type;

template <typename C, typename P>
using tp_unique_if_f = typename tp_unique_if<C, P::template fn>::type;

template <typename C>
struct tp_unique {
    using type = tp_unique_if_t<C, tp_contains>;
};

// same as tp_unique_if_t<C, tp_contains>
// remove the same type
template <typename C>
using tp_unique_t = typename tp_unique<C>::type;

/// @private
template <typename _Enable, typename C, typename C1, typename C2,
          template <typename...> typename P>
struct __tp_merge_helper;

/// @private
template <typename _Enable, template <typename...> typename C, typename... Args,
          template <typename...> typename C1, template <typename...> typename C2,
          typename... Args2, template <typename...> typename P>
struct __tp_merge_helper<_Enable, C<Args...>, C1<>, C2<Args2...>, P> {
    using type = tp_list<Args..., Args2...>;
};

/// @private
template <typename _Enable, template <typename...> typename C, typename... Args,
          template <typename...> typename C1, typename... Args1,
          template <typename...> typename C2, template <typename...> typename P>
struct __tp_merge_helper<_Enable, C<Args...>, C1<Args1...>, C2<>, P> {
    using type = tp_list<Args..., Args1...>;
};

/// @private
template <typename _Enable, template <typename...> typename C, typename... Args,
          template <typename...> typename C1, template <typename...> typename C2,
          template <typename...> typename P>
struct __tp_merge_helper<_Enable, C<Args...>, C1<>, C2<>, P> {
    using type = tp_list<Args...>;
};

/// @private
template <template <typename...> typename C, typename... Args,
          template <typename...> typename C1, typename T1, typename... Args1,
          template <typename...> typename C2, typename T2, typename... Args2,
          template <typename...> typename P>
struct __tp_merge_helper<std::enable_if_t<P<T1, T2>::value, void>, C<Args...>,
                         C1<T1, Args1...>, C2<T2, Args2...>, P> {
    using type = typename __tp_merge_helper<void, C<Args..., T1>, C1<Args1...>,
                                            C2<T2, Args2...>, P>::type;
};

/// @private
template <template <typename...> typename C, typename... Args,
          template <typename...> typename C1, typename T1, typename... Args1,
          template <typename...> typename C2, typename T2, typename... Args2,
          template <typename...> typename P>
struct __tp_merge_helper<std::enable_if_t<!P<T1, T2>::value, void>, C<Args...>,
                         C1<T1, Args1...>, C2<T2, Args2...>, P> {
    using type = typename __tp_merge_helper<void, C<Args..., T2>, C1<T1, Args1...>,
                                            C2<Args2...>, P>::type;
};

template <typename C1, typename C2, template <typename...> typename P>
struct tp_merge {
    using type = typename __tp_merge_helper<void, tp_list<>, C1, C2, P>::type;
};

// like std::merge
// merge two list with P
template <typename C1, typename C2, template <typename...> typename P>
using tp_merge_t = typename tp_merge<C1, C2, P>::type;

template <typename C1, typename C2, typename P>
using tp_merge_f = typename tp_merge<C1, C2, P::template fn>::type;

template <typename C, template <typename...> typename P>
struct tp_sort;

/// @private
template <typename C, template <typename...> typename P>
struct __tp_sort_helper;

/// @private
template <template <typename...> typename C, typename... Args,
          template <typename...> typename P>
struct __tp_sort_helper<C<Args...>, P> {
    using _Container = C<Args...>;
    constexpr static size_t size = tp_size_v<_Container>;
    constexpr static size_t mid = size / 2;
    using type1 = typename __tp_sort_helper<tp_prefix_t<_Container, mid>, P>::type;
    using type2 = typename __tp_sort_helper<tp_suffix_t<_Container, size - mid>, P>::type;
    using type = tp_merge_t<type1, type2, P>;
};

/// @private
template <template <typename...> typename C, typename T,
          template <typename...> typename P>
struct __tp_sort_helper<C<T>, P> {
    using type = C<T>;
};

/// @private
template <template <typename...> typename C, template <typename...> typename P>
struct __tp_sort_helper<C<>, P> {
    using type = C<>;
};

template <template <typename...> typename C, typename... Args,
          template <typename...> typename P>
struct tp_sort<C<Args...>, P> {
    using type = tp_rename_t<typename __tp_sort_helper<C<Args...>, P>::type, C>;
};

// list std::sort
template <typename C, template <typename...> typename P>
using tp_sort_t = typename tp_sort<C, P>::type;

template <typename C, typename P>
using tp_sort_f = typename tp_sort<C, P::template fn>::type;

/// @private
template <typename T, typename S>
struct __tp_make_integer_sequence_helper;

/// @private
template <typename T, T... Idxs>
struct __tp_make_integer_sequence_helper<T, std::integer_sequence<T, Idxs...>> {
    using type = tp_list<std::integral_constant<T, Idxs>...>;
};

template <typename T, T N>
using tp_make_integer_sequence =
    typename __tp_make_integer_sequence_helper<T, std::make_integer_sequence<T, N>>::type;

template <size_t N>
using tp_make_index_sequence = tp_make_integer_sequence<size_t, N>;

template <typename... Args>
using tp_index_sequence_for = tp_make_index_sequence<sizeof...(Args)>;

/// @private
template <typename T, typename S>
struct __tp_make_std_integer_sequence_helper;

/// @private
template <typename T, T... Idxs>
struct __tp_make_std_integer_sequence_helper<
    T, tp_list<std::integral_constant<T, Idxs>...>> {
    using type = std::integer_sequence<T, Idxs...>;
};

template <typename S>
using tp_make_std_index_sequence =
    typename __tp_make_std_integer_sequence_helper<size_t, S>::type;

} // namespace wjr

#endif // WJR_TP_LIST_HPP__
// Already included

namespace wjr {

/**
 * @class capture_leaf
 *
 * @brief Capture any type as a new type. Can be used as a class base.
 *
 */
template <typename T, typename Tag = void>
class capture_leaf : enable_special_members_of_args_base<Tag, T> {
    using Mybase = enable_special_members_of_args_base<Tag, T>;

public:
    using value_type = T;

    template <typename Ty = T, WJR_REQUIRES(std::is_default_constructible_v<Ty>)>
    constexpr capture_leaf() noexcept(std::is_nothrow_constructible_v<T>)
        : Mybase(enable_default_constructor), m_value() {}

    template <typename... Args, WJR_REQUIRES(std::is_constructible_v<T, Args...>)>
    constexpr capture_leaf(Args &&...args) noexcept(
        std::is_constructible_v<T, Args...>)
        : Mybase(enable_default_constructor), m_value(std::forward<Args>(args)...) {}

    template <typename Ty = T, WJR_REQUIRES(std::is_default_constructible_v<Ty>)>
    constexpr explicit capture_leaf(dctor_t) noexcept(
        std::is_nothrow_default_constructible_v<T>)
        : Mybase(enable_default_constructor) {}

    constexpr T &get() noexcept { return m_value; }
    constexpr const T &get() const noexcept { return m_value; }

private:
    T m_value;
};

/**
 * @class compressed_capture_leaf
 *
 * @brief Compressed capture any type as a new type.
 *
 * @details Use `EBO`(empty base optimization) to compress the size of the object.
 *
 */
template <typename T, typename Tag = void>
class compressed_capture_leaf : T {
    using Mybase = T;

public:
    using value_type = T;

    template <typename Ty = T, WJR_REQUIRES(std::is_default_constructible_v<Ty>)>
    constexpr compressed_capture_leaf() noexcept(std::is_nothrow_constructible_v<T>)
        : Mybase() {}

    template <typename... Args, WJR_REQUIRES(std::is_constructible_v<T, Args...>)>
    constexpr compressed_capture_leaf(Args &&...args) noexcept(
        std::is_constructible_v<T, Args...>)
        : Mybase(std::forward<Args>(args)...) {}

    template <typename Ty = T, WJR_REQUIRES(std::is_default_constructible_v<Ty>)>
    constexpr explicit compressed_capture_leaf(dctor_t) noexcept(
        std::is_nothrow_default_constructible_v<T>) {}

    constexpr T &get() noexcept { return *this; }
    constexpr const T &get() const noexcept { return *this; }
};

/**
 * @struct is_compressed
 *
 * @brief Check if a class can be compressed.
 *
 * @details A class can be compressed if it is a `empty` `class`, and it is not `final`.
 *
 */
template <typename T>
struct is_compressed : std::conjunction<std::is_class<T>, std::is_empty<T>,
                                        std::negation<std::is_final<T>>> {};

/**
 * @brief Value of @ref is_compressed.
 *
 */
template <typename T>
inline constexpr bool is_compressed_v = is_compressed<T>::value;

/// @private
template <typename LP, typename RP, typename = void>
struct __is_tuple_like_impl : std::false_type {};

/// @private
template <typename LP, typename RP>
struct __is_tuple_like_impl<
    LP, RP,
    std::enable_if_t<!std::is_same_v<LP, RP> &&
                     std::tuple_size_v<LP> == tp_defer_t<std::tuple_size, RP>::value>>
    : std::true_type {};

/**
 * @brief Use template<...>typename like to like all element of LP and RP.
 *
 * @details For example, like is std::is_assignable, LP is std::tuple<T0, U0>, RP is
 * std::tuple<T1, U1>. \n
 * Then __is_tuple_like = std::conjunction<std::is_assignable<T0,
 * T1>, std::is_assignable<U0, U1>>.
 *
 */
template <typename LP, typename RP>
struct __is_tuple_like : __is_tuple_like_impl<LP, remove_cvref_t<RP>> {};

/**
 * @brief Value of @ref __is_tuple_like.
 *
 */
template <typename LP, typename RP>
inline constexpr bool __is_tuple_like_v = __is_tuple_like<LP, RP>::value;

/// @private
template <template <typename...> typename Test, typename Seq, typename LP, typename RP,
          typename = void>
struct __is_tuple_test_impl : std::false_type {};

/// @private
template <template <typename...> typename Test, size_t... Idxs, typename LP, typename RP>
struct __is_tuple_test_impl<Test, std::index_sequence<Idxs...>, LP, RP,
                            std::enable_if_t<__is_tuple_like_v<LP, RP>>>
    : std::conjunction<Test<std::tuple_element_t<Idxs, LP>,
                            decltype(std::get<Idxs>(std::declval<RP>()))>...> {};

/**
 * @brief Use template<...>typename Test to test all element of LP and RP.
 *
 * @details For example, Test is std::is_assignable, LP is std::tuple<T0, U0>, RP is
 * std::tuple<T1, U1>. \n
 * Then __is_tuple_test = std::conjunction<std::is_assignable<T0,
 * T1>, std::is_assignable<U0, U1>>.
 *
 */
template <template <typename...> typename Test, typename LP, typename RP>
struct __is_tuple_test
    : __is_tuple_test_impl<Test, std::make_index_sequence<std::tuple_size_v<LP>>, LP,
                           RP> {};

/**
 * @brief Value of @ref __is_tuple_test.
 *
 */
template <template <typename...> typename Test, typename LP, typename RP>
inline constexpr bool __is_tuple_test_v = __is_tuple_test<Test, LP, RP>::value;

/// @private
template <typename T, typename U>
struct __is_tuple_assignable : std::is_assignable<T &, U> {};

} // namespace wjr

#endif // WJR_CAPTURE_LEAF_HPP__
#ifndef WJR_MATH_INTEGRAL_CONSTANT_HPP__
#define WJR_MATH_INTEGRAL_CONSTANT_HPP__

// Already included

namespace wjr {

template <typename T, T val>
struct integral_constant {
    static constexpr T value = val;

    using value_type = T;
    using type = integral_constant;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(integral_constant);

    constexpr integral_constant(std::integral_constant<T, val>) noexcept {}

    constexpr operator value_type() const noexcept { return value; }
    WJR_NODISCARD constexpr value_type operator()() const noexcept { return value; }

    WJR_NODISCARD constexpr operator std::integral_constant<T, val>() const noexcept {
        return {};
    }

    template <typename U, U u>
    constexpr auto operator+(integral_constant<U, u>) const noexcept {
        constexpr auto result = value + u;
        return integral_constant<decltype(result), result>{};
    }

    template <typename U, U u>
    constexpr auto operator-(integral_constant<U, u>) const noexcept {
        constexpr auto result = value - u;
        return integral_constant<decltype(result), result>{};
    }
};

namespace digits_literal_detail {

template <uint64_t Base>
WJR_CONST WJR_INTRINSIC_CONSTEXPR static uint32_t __fast_conv_4(uint32_t val) noexcept {
    constexpr uint32_t Base2 = Base * Base;

    constexpr uint32_t mul1 = 1 + (Base << 8);
    constexpr uint32_t mul2 = 1 + (Base2 << 16);

    val = ((val * mul1) >> 8) & 0x00FF00FF;
    return (val * mul2) >> 16;
}

template <uint64_t Base>
WJR_CONST WJR_INTRINSIC_CONSTEXPR static uint32_t __fast_conv_8(uint64_t val) noexcept {
    constexpr uint64_t Base2 = Base * Base;
    constexpr uint64_t Base4 = Base2 * Base2;

    constexpr uint64_t mul1 = 1 + (Base << 8);
    constexpr uint64_t mul2 = 1 + (Base2 << 16);
    constexpr uint64_t mul3 = 1 + (Base4 << 32);

    val = ((val * mul1) >> 8) & 0x00FF00FF00FF00FF;
    val = ((val * mul2) >> 16) & 0x0000FFFF0000FFFF;
    return (val * mul3) >> 32;
}

template <typename T>
struct parse_result {
    T result;
    T pow;
};

template <typename T>
WJR_CONST constexpr parse_result<T> __parse_impl() noexcept {
    return {0, 1};
}

template <typename T, char c0>
WJR_CONST constexpr parse_result<T> __parse_impl() noexcept {
    return {c0 - '0', 10};
}

template <typename T, char c0, char c1>
WJR_CONST constexpr parse_result<T> __parse_impl() noexcept {
    constexpr T result = (c0 - '0') * 10 + c1 - '0';
    return {result, 100};
}

template <typename T, char c0, char c1, char c2>
WJR_CONST constexpr parse_result<T> __parse_impl() noexcept {
    constexpr T result = (c0 - '0') * 100 + (c1 - '0') * 10 + c2 - '0';
    return {result, 1000};
}

template <typename T, char c0, char c1, char c2, char c3, char... Chars>
WJR_CONST constexpr parse_result<T> __parse_impl() noexcept {
    constexpr uint32_t mem = (c0 | (c1 << 8) | (c2 << 16) | (c3 << 24)) - 0x30303030;
    constexpr uint32_t val = __fast_conv_4<10>(mem);
    constexpr auto result = __parse_impl<T, Chars...>();
    return {static_cast<T>(result.result * result.pow + val),
            static_cast<T>(result.pow * 10000)};
}

template <typename T, char c0, char c1, char c2, char c3, char c4, char c5, char c6,
          char c7, char... Chars>
WJR_CONST constexpr parse_result<T> __parse_impl() noexcept {
    constexpr uint64_t mem =
        (c0 | (c1 << 8) | (c2 << 16) | (c3 << 24) | ((uint64_t)c4 << 32) |
         ((uint64_t)c5 << 40) | ((uint64_t)c6 << 48) | ((uint64_t)c7 << 56)) -
        0x3030303030303030;
    constexpr uint64_t val = __fast_conv_8<10>(mem);
    constexpr auto result = __parse_impl<T, Chars...>();
    return {static_cast<T>(result.result * result.pow + val),
            static_cast<T>(result.pow * 100000000)};
}

template <typename T, char... Chars>
WJR_CONST constexpr T parse() noexcept {
    return __parse_impl<T, Chars...>().result;
}

} // namespace digits_literal_detail

#define WJR_REGISTER_INTEGRAL_LITERALS(NAME, TYPE)                                       \
    template <char... Chars>                                                             \
    WJR_CONST WJR_INTRINSIC_CONSTEXPR auto operator"" _##NAME() noexcept                 \
        -> integral_constant<TYPE, digits_literal_detail::parse<TYPE, Chars...>()> {     \
        return {};                                                                       \
    }

namespace literals {

WJR_REGISTER_INTEGRAL_LITERALS(u, unsigned int);
WJR_REGISTER_INTEGRAL_LITERALS(ul, unsigned long);
WJR_REGISTER_INTEGRAL_LITERALS(ull, unsigned long long);
WJR_REGISTER_INTEGRAL_LITERALS(i, int);
WJR_REGISTER_INTEGRAL_LITERALS(l, long);
WJR_REGISTER_INTEGRAL_LITERALS(ll, long long);

WJR_REGISTER_INTEGRAL_LITERALS(i8, int8_t);
WJR_REGISTER_INTEGRAL_LITERALS(i16, int16_t);
WJR_REGISTER_INTEGRAL_LITERALS(i32, int32_t);
WJR_REGISTER_INTEGRAL_LITERALS(i64, int64_t);
WJR_REGISTER_INTEGRAL_LITERALS(u8, uint8_t);
WJR_REGISTER_INTEGRAL_LITERALS(u16, uint16_t);
WJR_REGISTER_INTEGRAL_LITERALS(u32, uint32_t);
WJR_REGISTER_INTEGRAL_LITERALS(u64, uint64_t);

WJR_REGISTER_INTEGRAL_LITERALS(zu, size_t);
WJR_REGISTER_INTEGRAL_LITERALS(z, ssize_t);

#undef WJR_REGISTER_INTEGRAL_LITERALS

} // namespace literals

using namespace literals;

} // namespace wjr

#endif // WJR_MATH_INTEGRAL_CONSTANT_HPP__

namespace wjr {

template <typename... Args>
class tuple;

} // namespace wjr

namespace std {

template <typename... Args>
struct tuple_size<wjr::tuple<Args...>> : std::integral_constant<size_t, sizeof...(Args)> {
};

template <size_t I, typename... Args>
struct tuple_element<I, wjr::tuple<Args...>> {
    using type = wjr::tp_at_t<wjr::tuple<Args...>, I>;
};

template <typename... Args, WJR_REQUIRES(std::conjunction_v<wjr::is_swappable<Args>...>)>
constexpr void swap(wjr::tuple<Args...> &lhs,
                    wjr::tuple<Args...> &rhs) noexcept(noexcept(lhs.swap(rhs)));

template <size_t I, typename... Args>
constexpr tuple_element_t<I, wjr::tuple<Args...>> &get(wjr::tuple<Args...> &t) noexcept;

template <size_t I, typename... Args>
constexpr tuple_element_t<I, wjr::tuple<Args...>> &
get(const wjr::tuple<Args...> &t) noexcept;

template <size_t I, typename... Args>
constexpr tuple_element_t<I, wjr::tuple<Args...>> &&get(wjr::tuple<Args...> &&t) noexcept;

template <size_t I, typename... Args>
constexpr tuple_element_t<I, wjr::tuple<Args...>> &&
get(const wjr::tuple<Args...> &&t) noexcept;

template <typename T, typename... Args>
constexpr T &get(wjr::tuple<Args...> &t) noexcept;

template <typename T, typename... Args>
constexpr T &get(const wjr::tuple<Args...> &t) noexcept;

template <typename T, typename... Args>
constexpr T &&get(wjr::tuple<Args...> &&t) noexcept;

template <typename T, typename... Args>
constexpr T &&get(const wjr::tuple<Args...> &&t) noexcept;

} // namespace std

namespace wjr {

template <typename Indexs, typename... Args>
class tuple_impl;

template <size_t... Indexs, typename... Args>
class WJR_EMPTY_BASES tuple_impl<std::index_sequence<Indexs...>, Args...>
    : capture_leaf<Args,
                   enable_base_identity_t<
                       Indexs, tuple_impl<std::index_sequence<Indexs...>, Args...>>>... {
    using Tuple = tuple<Args...>;

    template <size_t Idx>
    using Mybase = capture_leaf<std::tuple_element_t<Idx, Tuple>,
                                enable_base_identity_t<Idx, tuple_impl>>;

    constexpr static size_t Size = sizeof...(Args);

public:
    template <typename S = void,
              WJR_REQUIRES(std::conjunction_v<std::is_same<S, void>,
                                              std::is_default_constructible<Args>...>)>
    constexpr tuple_impl() noexcept(
        std::conjunction_v<std::is_nothrow_constructible<Args>...>) {}

    template <
        typename... _Args,
        WJR_REQUIRES(std::conjunction_v<std::is_constructible<Mybase<Indexs>, _Args>...>)>
    constexpr tuple_impl(_Args &&...args) noexcept(
        std::conjunction_v<std::is_nothrow_constructible<Args, _Args &&>...>)
        : Mybase<Indexs>(std::forward<_Args>(args))... {}

    template <typename TupleLike>
    constexpr tuple_impl(in_place_empty_t, TupleLike &&other) noexcept(
        std::is_nothrow_constructible_v<
            tuple_impl, decltype(std::get<Indexs>(std::forward<TupleLike>(other)))...>)
        : tuple_impl(std::get<Indexs>(std::forward<TupleLike>(other))...) {}

    template <size_t I>
    constexpr std::tuple_element_t<I, Tuple> &get() noexcept {
        return Mybase<I>::get();
    }

    template <size_t I>
    constexpr const std::tuple_element_t<I, Tuple> &get() const noexcept {
        return Mybase<I>::get();
    }
};

template <typename Tuple>
struct __tuple_like;

template <template <typename...> typename Tuple, typename... Args>
struct __tuple_like<Tuple<Args...>>
    : std::disjunction<std::is_same<Tuple<Args...>, std::tuple<Args...>>,
                       std::is_same<Tuple<Args...>, std::pair<Args...>>> {};

template <>
class tuple<> {
public:
    constexpr void swap(tuple &) noexcept {}
};

template <typename This, typename... Args>
class tuple<This, Args...> {
    using Sequence = std::index_sequence_for<This, Args...>;
    using Impl = tuple_impl<Sequence, This, Args...>;

    constexpr static size_t Size = sizeof...(Args) + 1;

    template <typename Other, typename... _Args>
#if !WJR_HAS_MSVC(19, 37)
    using __is_all_convertible =
#else
    struct __is_all_convertible :
#endif
        std::conjunction<std::is_convertible<Other, This>,
                         std::is_convertible<_Args, Args>...>
#if !WJR_HAS_MSVC(19, 37)
        ;
#else
    {
    };
#endif

public:
#if defined(__cpp_conditional_explicit)
    template <typename T = This,
              WJR_REQUIRES(std::conjunction_v<std::is_default_constructible<T>,
                                              std::is_default_constructible<Args>...>)>
    constexpr explicit(
        !std::conjunction_v<is_default_convertible<T>, is_default_convertible<Args>...>)
        tuple() noexcept(std::is_nothrow_constructible_v<Impl>)
        : m_impl() {}
#else
    template <typename T = This,
              WJR_REQUIRES(std::conjunction_v<std::is_default_constructible<T>,
                                              std::is_default_constructible<Args>...>
                               &&std::conjunction_v<is_default_convertible<T>,
                                                    is_default_convertible<Args>...>)>
    constexpr tuple() noexcept(std::is_nothrow_constructible_v<Impl>) : m_impl() {}

    template <typename T = This,
              WJR_REQUIRES(std::conjunction_v<std::is_default_constructible<T>,
                                              std::is_default_constructible<Args>...> &&
                           !std::conjunction_v<is_default_convertible<T>,
                                               is_default_convertible<Args>...>)>
    constexpr explicit tuple() noexcept(std::is_nothrow_constructible_v<Impl>)
        : m_impl() {}
#endif

#if defined(__cpp_conditional_explicit)
    template <typename Other = This,
              WJR_REQUIRES(std::is_constructible_v<Impl, const Other &, const Args &...>)>
    constexpr explicit(!__is_all_convertible<Other, Args...>::value)
        tuple(const Other &first, const Args &...rest) noexcept(
            std::is_nothrow_constructible_v<Impl, const Other &, const Args &...>)
        : m_impl(first, rest...) {}
#else
    template <
        typename Other = This,
        WJR_REQUIRES(std::is_constructible_v<Impl, const Other &, const Args &...>
                         &&__is_all_convertible<const Other &, const Args &...>::value)>
    constexpr tuple(const Other &first, const Args &...rest) noexcept(
        std::is_nothrow_constructible_v<Impl, const Other &, const Args &...>)
        : m_impl(first, rest...) {}

    template <
        typename Other = This,
        WJR_REQUIRES(std::is_constructible_v<Impl, const Other &, const Args &...> &&
                     !__is_all_convertible<const Other &, const Args &...>::value)>
    constexpr explicit tuple(const Other &first, const Args &...rest) noexcept(
        std::is_nothrow_constructible_v<Impl, const Other &, const Args &...>)
        : m_impl(first, rest...) {}
#endif

    template <
        typename Other, typename... _Args,
        WJR_REQUIRES(sizeof...(_Args) + 1 == Size &&
                     std::conjunction_v<
                         std::negation<std::conjunction<
                             std::is_same<This, std::remove_reference_t<Other>>,
                             std::is_same<Args, std::remove_reference_t<_Args>>...>>,
                         std::is_constructible<Impl, Other &&, _Args...>>)>
    constexpr tuple(Other &&other, _Args &&...args) noexcept(
        std::is_nothrow_constructible_v<Impl, Other &&, _Args...>)
        : m_impl(std::forward<Other>(other), std::forward<_Args>(args)...) {}

    template <typename TupleLike,
              WJR_REQUIRES(__is_tuple_test_v<std::is_constructible, tuple, TupleLike &&>)>
    constexpr tuple(TupleLike &&other) noexcept(
        std::is_nothrow_constructible_v<Impl, in_place_empty_t, TupleLike &&>)
        : m_impl(in_place_empty, std::forward<TupleLike>(other)) {}

private:
    template <size_t... _Indexs, typename Container>
    constexpr void __assign(std::index_sequence<_Indexs...>, Container &&other) noexcept(
        noexcept(((this->template get<_Indexs>() =
                       std::get<_Indexs>(std::forward<Container>(other))),
                  ...))) {
        ((this->template get<_Indexs>() =
              std::get<_Indexs>(std::forward<Container>(other))),
         ...);
    }

public:
    template <typename TupleLike,
              WJR_REQUIRES(__is_tuple_test_v<__is_tuple_assignable, tuple, TupleLike &&>)>
    constexpr tuple &operator=(TupleLike &&other) noexcept(
        noexcept(__assign(Sequence(), std::forward<TupleLike>(other)))) {
        __assign(Sequence(), std::forward<TupleLike>(other));
        return *this;
    }

private:
    template <size_t... _Indexs>
    constexpr void
    __swap(std::index_sequence<_Indexs...>, tuple &other) noexcept(noexcept(((
        std::swap(this->template get<_Indexs>(), other.template get<_Indexs>()), ...)))) {
        ((std::swap(this->template get<_Indexs>(), other.template get<_Indexs>()), ...));
    }

public:
    constexpr void swap(tuple &other) noexcept(noexcept(__swap(Sequence(), other))) {
        __swap(Sequence(), other);
    }

    template <size_t I, WJR_REQUIRES(I < Size)>
    constexpr std::tuple_element_t<I, tuple> &get() & noexcept {
        return m_impl.template get<I>();
    }

    template <size_t I, WJR_REQUIRES(I < Size)>
    constexpr const std::tuple_element_t<I, tuple> &get() const & noexcept {
        return m_impl.template get<I>();
    }

    template <size_t I, WJR_REQUIRES(I < Size)>
    constexpr std::tuple_element_t<I, tuple> &&get() && noexcept {
        return static_cast<std::tuple_element_t<I, tuple> &&>(get<I>());
    }

    template <size_t I, WJR_REQUIRES(I < Size)>
    constexpr const std::tuple_element_t<I, tuple> &&get() const && noexcept {
        return static_cast<const std::tuple_element_t<I, tuple> &&>(get<I>());
    }

    template <size_t I, WJR_REQUIRES(I >= 0 && I < Size)>
    constexpr std::tuple_element_t<I, tuple> &
    operator[](integral_constant<size_t, I>) & noexcept {
        return get<I>();
    }

    template <size_t I, WJR_REQUIRES(I >= 0 && I < Size)>
    constexpr const std::tuple_element_t<I, tuple> &
    operator[](integral_constant<size_t, I>) const & noexcept {
        return get<I>();
    }

    template <size_t I, WJR_REQUIRES(I >= 0 && I < Size)>
    constexpr std::tuple_element_t<I, tuple> &&
    operator[](integral_constant<size_t, I>) && noexcept {
        return static_cast<std::tuple_element_t<I, tuple> &&>(get<I>());
    }

    template <size_t I, WJR_REQUIRES(I >= 0 && I < Size)>
    constexpr const std::tuple_element_t<I, tuple> &&
    operator[](integral_constant<size_t, I>) const && noexcept {
        return static_cast<const std::tuple_element_t<I, tuple> &&>(get<I>());
    }

private:
    Impl m_impl;
};

template <typename... Args>
tuple(Args...) -> tuple<Args...>;

template <typename T1, typename T2>
tuple(std::pair<T1, T2>) -> tuple<T1, T2>;

template <typename... Args>
tuple(std::tuple<Args...>) -> tuple<Args...>;

template <typename... Args>
constexpr tuple<unref_wrapper_t<Args>...> make_tuple(Args &&...args) noexcept(
    std::conjunction_v<
        std::is_nothrow_constructible<unref_wrapper_t<Args>, Args &&>...>) {
    return tuple<unref_wrapper_t<Args>...>(std::forward<Args>(args)...);
}

template <typename... Args>
constexpr tuple<Args &...> tie(Args &...args) noexcept {
    return tuple<Args &...>(args...);
}

template <typename... Args>
constexpr tuple<Args...> forward_as_tuple(Args &&...args) noexcept(
    std::conjunction_v<std::is_nothrow_constructible<Args &&, Args &&>...>) {
    return tuple<Args...>(std::forward<Args>(args)...);
}

/// @private
template <typename Func, typename Tuple, size_t... Indexs>
constexpr decltype(auto)
apply_impl(Func &&fn, Tuple &&tp, std::index_sequence<Indexs...>) noexcept(noexcept(
    std::invoke(std::forward<Func>(fn), std::get<Indexs>(std::forward<Tuple>(tp))...))) {
    return std::invoke(std::forward<Func>(fn),
                       std::get<Indexs>(std::forward<Tuple>(tp))...);
}

template <typename Func, typename Tuple>
constexpr decltype(auto) apply(Func &&fn, Tuple &&tp) noexcept(noexcept(
    apply_impl(std::forward<Func>(fn), std::forward<Tuple>(tp),
               std::make_index_sequence<std::tuple_size_v<remove_cvref_t<Tuple>>>{}))) {
    return apply_impl(
        std::forward<Func>(fn), std::forward<Tuple>(tp),
        std::make_index_sequence<std::tuple_size_v<remove_cvref_t<Tuple>>>{});
}

/// @private
template <size_t I, typename Tuple>
struct __tuple_cat_single_helper {
    static constexpr size_t Size = std::tuple_size_v<Tuple>;
    using type0 = tp_repeat_t<tp_list<std::integral_constant<size_t, I>>, Size>;
    using type1 = tp_make_index_sequence<Size>;
};

/// @private
template <typename S, typename... Tuples>
struct __tuple_cat_helper_impl;

/// @private
template <size_t... Indexs, typename... Tuples>
struct __tuple_cat_helper_impl<std::index_sequence<Indexs...>, Tuples...> {
    using type0 =
        tp_concat_t<typename __tuple_cat_single_helper<Indexs, Tuples>::type0...>;
    using type1 =
        tp_concat_t<typename __tuple_cat_single_helper<Indexs, Tuples>::type1...>;
};

/// @private
template <typename... Tuples>
struct __tuple_cat_helper {
    using Sequence = std::index_sequence_for<Tuples...>;
    using Impl = __tuple_cat_helper_impl<Sequence, Tuples...>;
    using type0 = tp_make_std_index_sequence<typename Impl::type0>;
    using type1 = tp_make_std_index_sequence<typename Impl::type1>;
};

/// @private
template <size_t... I0, size_t... I1, typename... Tuples>
constexpr decltype(auto) __tuple_cat_impl(std::index_sequence<I0...>,
                                          std::index_sequence<I1...>,
                                          tuple<Tuples...> &&tuples) {
    return tuple(std::get<I1>(std::get<I0>(std::move(tuples)))...);
}

template <typename... Tuples>
constexpr decltype(auto) tuple_cat(Tuples &&...tuples) {
    using Helper = __tuple_cat_helper<remove_cvref_t<Tuples>...>;
    return __tuple_cat_impl(typename Helper::type0{}, typename Helper::type1{},
                            wjr::forward_as_tuple(std::forward<Tuples>(tuples)...));
}

template <typename... TArgs, typename... UArgs>
constexpr bool
operator==(const tuple<TArgs...> &lhs, const tuple<UArgs...> &rhs) noexcept(
    std::conjunction_v<has_noexcept_equal_to<const TArgs &, const UArgs &>...>) {
    return apply(
        [&rhs](const auto &...lhs_args) {
            return apply(
                [&lhs_args...](const auto &...rhs_args) {
                    return ((lhs_args == rhs_args) && ...);
                },
                rhs);
        },
        lhs);
}

template <typename... TArgs, typename... UArgs>
constexpr bool operator!=(const tuple<TArgs...> &lhs,
                          const tuple<UArgs...> &rhs) noexcept(noexcept(lhs == rhs)) {
    return !(lhs == rhs);
}

template <typename... TArgs, typename... UArgs>
constexpr bool operator<(const tuple<TArgs...> &lhs, const tuple<UArgs...> &rhs) noexcept(
    std::conjunction_v<
        std::conjunction<has_noexcept_less<const TArgs &, const UArgs &>,
                         has_noexcept_less<const UArgs &, const TArgs &>>...>) {
    bool ret = false;
    apply(
        [&rhs, &ret](const auto &...lhs_args) {
            return apply(
                [&lhs_args..., &ret](const auto &...rhs_args) {
                    (void)((lhs_args < rhs_args ? (ret = true, false)
                                                : (rhs_args < lhs_args ? false : true)) &&
                           ...);
                },
                rhs);
        },
        lhs);
    return ret;
}

template <typename... TArgs, typename... UArgs>
constexpr bool operator<=(const tuple<TArgs...> &lhs,
                          const tuple<UArgs...> &rhs) noexcept(noexcept(rhs < lhs)) {
    return !(rhs < lhs);
}

template <typename... TArgs, typename... UArgs>
constexpr bool operator>(const tuple<TArgs...> &lhs,
                         const tuple<UArgs...> &rhs) noexcept(noexcept(rhs < lhs)) {
    return rhs < lhs;
}

template <typename... TArgs, typename... UArgs>
constexpr bool operator>=(const tuple<TArgs...> &lhs,
                          const tuple<UArgs...> &rhs) noexcept(noexcept(lhs < rhs)) {
    return !(lhs < rhs);
}

} // namespace wjr

namespace std {

template <typename... Args,
          WJR_REQUIRES_I(std::conjunction_v<wjr::is_swappable<Args>...>)>
constexpr void swap(wjr::tuple<Args...> &lhs,
                    wjr::tuple<Args...> &rhs) noexcept(noexcept(lhs.swap(rhs))) {
    lhs.swap(rhs);
}

template <size_t I, typename... Args>
constexpr tuple_element_t<I, wjr::tuple<Args...>> &get(wjr::tuple<Args...> &t) noexcept {
    return t.template get<I>();
}

template <size_t I, typename... Args>
constexpr tuple_element_t<I, wjr::tuple<Args...>> &
get(const wjr::tuple<Args...> &t) noexcept {
    return t.template get<I>();
}

template <size_t I, typename... Args>
constexpr tuple_element_t<I, wjr::tuple<Args...>> &&
get(wjr::tuple<Args...> &&t) noexcept {
    return std::move(t).template get<I>();
}

template <size_t I, typename... Args>
constexpr tuple_element_t<I, wjr::tuple<Args...>> &&
get(const wjr::tuple<Args...> &&t) noexcept {
    return std::move(t).template get<I>();
}

template <typename T, typename... Args>
constexpr T &get(wjr::tuple<Args...> &t) noexcept {
    return get<wjr::tp_find_v<wjr::tuple<Args...>, T>>(t);
}

template <typename T, typename... Args>
constexpr T &get(const wjr::tuple<Args...> &t) noexcept {
    return get<wjr::tp_find_v<wjr::tuple<Args...>, T>>(t);
}

template <typename T, typename... Args>
constexpr T &&get(wjr::tuple<Args...> &&t) noexcept {
    return get<wjr::tp_find_v<wjr::tuple<Args...>, T>>(std::move(t));
}

template <typename T, typename... Args>
constexpr T &&get(const wjr::tuple<Args...> &&t) noexcept {
    return get<wjr::tp_find_v<wjr::tuple<Args...>, T>>(std::move(t));
}

} // namespace std

#endif // WJR_TUPLE_HPP__

namespace wjr {

template <typename T, typename U>
class compressed_pair;

} // namespace wjr

namespace std {

template <typename T, typename U>
struct tuple_size<wjr::compressed_pair<T, U>> : std::integral_constant<size_t, 2> {};

template <size_t I, typename T, typename U>
struct tuple_element<I, wjr::compressed_pair<T, U>> {
    using type = wjr::tp_at_t<wjr::compressed_pair<T, U>, I>;
};

} // namespace std

namespace wjr {

/**
 * @brief Select the base class of compressed_pair.
 *
 * @details For compressed_pair<T, U> : \n
 * If `T` is @ref is_compressed_v "compressed" and `U` is not ref is_compressed_v
 * "compressed", then the base class is
 * @ref compressed_capture_leaf \<T> and @ref capture_leaf \<U>. \n
 * If `T` is not ref is_compressed_v "compressed" and `U` is ref is_compressed_v
 * "compressed", then the base class is
 * @ref capture_leaf \<T> and @ref compressed_capture_leaf \<U>. \n
 * If `T` and `U` are both ref is_compressed_v "compressed", then the base class is
 * @ref compressed_capture_leaf \<T> and @ref capture_leaf \<U>. \n
 * Otherwise, the base class is @ref capture_leaf \<T> and @ref capture_leaf \<U>. \n
 * Notice that both `T` and `U` are ref is_compressed_v "compressed" is not allowed.
 *
 */
template <size_t index, typename T, typename U, typename Tag = void>
using compressed_pair_wrapper =
    std::conditional_t<is_compressed_v<T> && (index == 0 || !is_compressed_v<U>),
                       compressed_capture_leaf<T, enable_base_identity_t<index, Tag>>,
                       capture_leaf<T, enable_base_identity_t<index, Tag>>>;

/// @private
template <typename T, typename U>
struct __compressed_pair1 {};

/// @private
template <typename T, typename U>
struct __compressed_pair2 {};

/// @private
template <typename T, typename U>
struct __compressed_pair3 {};

/// @private
template <typename T, typename U>
using __compressed_pair_base1 =
    compressed_pair_wrapper<0, T, U, __compressed_pair1<T, U>>;

/// @private
template <typename T, typename U>
using __compressed_pair_base2 =
    compressed_pair_wrapper<1, U, T, __compressed_pair2<T, U>>;

/**
 * @class compressed_pair
 *
 * @brief A pair used empty base optimization to reduce the size of the pair.
 *
 * @details See @ref compressed_pair_wrapper for the base class of compressed_pair. \n
 * compressed_pair is final, so it can't be derived from. \n
 * For example : \n
 * @code
 * static_assert(sizeof(compressed_pair<int, double>) == sizeof(int) + sizeof(double));
 * static_assert(sizeof(compressed_pair<std::allocator<int>, int>) == sizeof(int));
 * static_assert(sizeof(compressed_pair<int, std::allocator<int>>) == sizeof(int));
 * @endcode
 */
template <typename T, typename U>
class WJR_EMPTY_BASES compressed_pair final : __compressed_pair_base1<T, U>,
                                              __compressed_pair_base2<T, U> {

    using Mybase1 = __compressed_pair_base1<T, U>;
    using Mybase2 = __compressed_pair_base2<T, U>;

    template <typename Ty, typename Uy>
    using __is_all_copy_constructible =
        std::conjunction<std::is_copy_constructible<Ty>, std::is_copy_constructible<Uy>>;

    template <typename Vty, typename Wuy>
    using __is_all_convertible =
        std::conjunction<std::is_convertible<Vty, T>, std::is_convertible<Wuy, U>>;

    template <typename Vty, typename Wuy>
    using __is_all_constructible = std::conjunction<std::is_constructible<Mybase1, Vty>,
                                                    std::is_constructible<Mybase2, Wuy>>;

public:
    using first_type = T;
    using second_type = U;

#if defined(__cpp_conditional_explicit)
    template <typename Ty = T, typename Uy = U,
              WJR_REQUIRES(std::conjunction_v<std::is_default_constructible<Ty>,
                                              std::is_default_constructible<Uy>>)>
    constexpr explicit(
        !std::conjunction_v<is_default_convertible<Ty>, is_default_convertible<Uy>>)
        compressed_pair() noexcept(
            std::conjunction_v<std::is_nothrow_constructible<Ty>,
                               std::is_nothrow_constructible<Uy>>) {}
#else
    template <typename Ty = T, typename Uy = U,
              WJR_REQUIRES(std::conjunction_v<std::is_default_constructible<Ty>,
                                              std::is_default_constructible<Uy>>
                               &&std::conjunction_v<is_default_convertible<Ty>,
                                                    is_default_convertible<Uy>>)>
    constexpr compressed_pair() noexcept(
        std::conjunction_v<std::is_nothrow_constructible<Ty>,
                           std::is_nothrow_constructible<Uy>>) {}

    template <typename Ty = T, typename Uy = U,
              WJR_REQUIRES(std::conjunction_v<std::is_default_constructible<Ty>,
                                              std::is_default_constructible<Uy>> &&
                           !std::conjunction_v<is_default_convertible<Ty>,
                                               is_default_convertible<Uy>>)>
    constexpr explicit compressed_pair() noexcept(
        std::conjunction_v<std::is_nothrow_constructible<Ty>,
                           std::is_nothrow_constructible<Uy>>) {}
#endif

#if defined(__cpp_conditional_explicit)
    template <typename Ty = T, typename Uy = U,
              WJR_REQUIRES(__is_all_copy_constructible<Ty, Uy>::value)>
    constexpr explicit(!__is_all_convertible<const Ty &, const Uy &>::value)
        compressed_pair(const T &_First, const U &_Second) noexcept(
            std::conjunction_v<std::is_nothrow_copy_constructible<Ty>,
                               std::is_nothrow_copy_constructible<Uy>>)
        : Mybase1(_First), Mybase2(_Second) {}
#else
    template <
        typename Ty = T, typename Uy = U,
        WJR_REQUIRES(std::conjunction_v<__is_all_copy_constructible<Ty, Uy>,
                                        __is_all_convertible<const Ty &, const Uy &>>)>
    constexpr compressed_pair(const T &_First, const U &_Second) noexcept(
        std::conjunction_v<std::is_nothrow_copy_constructible<Ty>,
                           std::is_nothrow_copy_constructible<Uy>>)
        : Mybase1(_First), Mybase2(_Second) {}

    template <typename Ty = T, typename Uy = U,
              WJR_REQUIRES(std::conjunction_v<
                           __is_all_copy_constructible<Ty, Uy>,
                           std::negation<__is_all_convertible<const Ty &, const Uy &>>>)>
    constexpr explicit compressed_pair(const T &_First, const U &_Second) noexcept(
        std::conjunction_v<std::is_nothrow_copy_constructible<Ty>,
                           std::is_nothrow_copy_constructible<Uy>>)
        : Mybase1(_First), Mybase2(_Second) {}
#endif

#if defined(__cpp_conditional_explicit)
    template <typename Other1, typename Other2,
              WJR_REQUIRES(__is_all_constructible<Other1 &&, Other2 &&>::value)>
    constexpr explicit(!__is_all_convertible<Other1 &&, Other2 &&>::value)
        compressed_pair(Other1 &&_First, Other2 &&_Second) noexcept(
            std::conjunction_v<std::is_nothrow_constructible<Mybase1, Other1 &&>,
                               std::is_nothrow_constructible<Mybase2, Other2 &&>>)
        : Mybase1(std::forward<Other1>(_First)), Mybase2(std::forward<Other2>(_Second)) {}
#else
    template <
        typename Other1, typename Other2,
        WJR_REQUIRES(std::conjunction_v<__is_all_constructible<Other1 &&, Other2 &&>,
                                        __is_all_convertible<Other1 &&, Other2 &&>>)>
    constexpr compressed_pair(Other1 &&_First, Other2 &&_Second) noexcept(
        std::conjunction_v<std::is_nothrow_constructible<Mybase1, Other1 &&>,
                           std::is_nothrow_constructible<Mybase2, Other2 &&>>)
        : Mybase1(std::forward<Other1>(_First)), Mybase2(std::forward<Other2>(_Second)) {}

    template <typename Other1, typename Other2,
              WJR_REQUIRES(std::conjunction_v<
                           __is_all_constructible<Other1 &&, Other2 &&>,
                           std::negation<__is_all_convertible<Other1 &&, Other2 &&>>>)>
    constexpr explicit compressed_pair(Other1 &&_First, Other2 &&_Second) noexcept(
        std::conjunction_v<std::is_nothrow_constructible<Mybase1, Other1 &&>,
                           std::is_nothrow_constructible<Mybase2, Other2 &&>>)
        : Mybase1(std::forward<Other1>(_First)), Mybase2(std::forward<Other2>(_Second)) {}
#endif

private:
    template <typename Tuple1, typename Tuple2, size_t... N1, size_t... N2>
    constexpr compressed_pair(
        Tuple1 &tp1, Tuple2 &tp2, std::index_sequence<N1...>,
        std::index_sequence<
            N2...>) noexcept(noexcept(Mybase1(std::get<N1>(std::move(tp1))...))
                                 && noexcept(Mybase2(std::get<N2>(std::move(tp2))...)))
        : Mybase1(std::get<N1>(std::move(tp1))...),
          Mybase2(std::get<N2>(std::move(tp2))...) {}

public:
    template <typename... Args1, typename... Args2>
    constexpr compressed_pair(
        std::piecewise_construct_t, tuple<Args1...> tp1,
        tuple<Args2...>
            tp2) noexcept(noexcept(compressed_pair(tp1, tp2,
                                                   std::index_sequence_for<Args1...>{},
                                                   std::index_sequence_for<Args2...>{})))
        : compressed_pair(tp1, tp2, std::index_sequence_for<Args1...>{},
                          std::index_sequence_for<Args2...>{}) {}

#if defined(__cpp_conditional_explicit)
    template <typename PairLike,
              WJR_REQUIRES(
                  __is_tuple_test_v<std::is_constructible, compressed_pair, PairLike &&>)>
    constexpr explicit(
        !__is_tuple_test_v<std::is_convertible, compressed_pair, PairLike &&>)
        compressed_pair(PairLike &&pr) noexcept(
            std::conjunction_v<std::is_nothrow_constructible<
                                   T, decltype(std::get<0>(std::forward<PairLike>(pr)))>,
                               std::is_nothrow_constructible<
                                   U, decltype(std::get<1>(std::forward<PairLike>(pr)))>>)
        : Mybase1(std::get<0>(std::forward<PairLike>(pr))),
          Mybase2(std::get<1>(std::forward<PairLike>(pr))) {}
#else
    template <
        typename PairLike,
        WJR_REQUIRES(
            __is_tuple_test_v<std::is_constructible, compressed_pair, PairLike &&>
                &&__is_tuple_test_v<std::is_convertible, compressed_pair, PairLike &&>)>
    constexpr compressed_pair(PairLike &&pr) noexcept(
        std::conjunction_v<std::is_nothrow_constructible<
                               T, decltype(std::get<0>(std::forward<PairLike>(pr)))>,
                           std::is_nothrow_constructible<
                               U, decltype(std::get<1>(std::forward<PairLike>(pr)))>>)
        : Mybase1(std::get<0>(std::forward<PairLike>(pr))),
          Mybase2(std::get<1>(std::forward<PairLike>(pr))) {}

    template <
        typename PairLike,
        WJR_REQUIRES(
            __is_tuple_test_v<std::is_constructible, compressed_pair, PairLike &&> &&
            !__is_tuple_test_v<std::is_convertible, compressed_pair, PairLike &&>)>
    constexpr explicit compressed_pair(PairLike &&pr) noexcept(
        std::conjunction_v<std::is_nothrow_constructible<
                               T, decltype(std::get<0>(std::forward<PairLike>(pr)))>,
                           std::is_nothrow_constructible<
                               U, decltype(std::get<1>(std::forward<PairLike>(pr)))>>)
        : Mybase1(std::get<0>(std::forward<PairLike>(pr))),
          Mybase2(std::get<1>(std::forward<PairLike>(pr))) {}
#endif

    template <typename PairLike,
              WJR_REQUIRES(
                  __is_tuple_test_v<__is_tuple_assignable, compressed_pair, PairLike &&>)>
    constexpr compressed_pair &operator=(PairLike &&pr) noexcept(
        std::conjunction_v<std::is_nothrow_assignable<T, decltype(std::get<0>(pr))>,
                           std::is_nothrow_assignable<U, decltype(std::get<1>(pr))>>) {
        first() = std::get<0>(std::forward<PairLike>(pr));
        second() = std::get<1>(std::forward<PairLike>(pr));
        return *this;
    }

    template <typename Myself = compressed_pair, typename _T = T,
              WJR_REQUIRES(std::conjunction_v<is_swappable<_T>, is_swappable<U>>)>
    constexpr void swap(type_identity_t<compressed_pair &> other) noexcept(
        std::conjunction_v<is_nothrow_swappable<T>, is_nothrow_swappable<U>>) {
        std::swap(first(), other.first());
        std::swap(second(), other.second());
    }

    constexpr T &first() noexcept { return Mybase1::get(); }
    constexpr const T &first() const noexcept { return Mybase1::get(); }
    constexpr U &second() noexcept { return Mybase2::get(); }
    constexpr const U &second() const noexcept { return Mybase2::get(); }

    // extension

    template <size_t I, WJR_REQUIRES(I < 2)>
    constexpr std::tuple_element_t<I, compressed_pair> &get() & noexcept {
        if constexpr (I == 0) {
            return first();
        } else {
            return second();
        }
    }

    template <size_t I, WJR_REQUIRES(I < 2)>
    constexpr const std::tuple_element_t<I, compressed_pair> &get() const & noexcept {
        if constexpr (I == 0) {
            return first();
        } else {
            return second();
        }
    }

    template <size_t I, WJR_REQUIRES(I < 2)>
    constexpr std::tuple_element_t<I, compressed_pair> &&get() && noexcept {
        return static_cast<std::tuple_element_t<I, compressed_pair> &&>(get());
    }

    template <size_t I, WJR_REQUIRES(I < 2)>
    constexpr const std::tuple_element_t<I, compressed_pair> &&get() const && noexcept {
        return static_cast<const std::tuple_element_t<I, compressed_pair> &&>(get());
    }

    template <size_t I, WJR_REQUIRES(I >= 0 && I < 2)>
    constexpr std::tuple_element_t<I, compressed_pair> &
    operator[](integral_constant<size_t, I>) & noexcept {
        return get<I>();
    }

    template <size_t I, WJR_REQUIRES(I >= 0 && I < 2)>
    constexpr const std::tuple_element_t<I, compressed_pair> &
    operator[](integral_constant<size_t, I>) const & noexcept {
        return get<I>();
    }

    template <size_t I, WJR_REQUIRES(I >= 0 && I < 2)>
    constexpr std::tuple_element_t<I, compressed_pair> &&
    operator[](integral_constant<size_t, I>) && noexcept {
        return static_cast<std::tuple_element_t<I, compressed_pair> &&>(get<I>());
    }

    template <size_t I, WJR_REQUIRES(I >= 0 && I < 2)>
    constexpr const std::tuple_element_t<I, compressed_pair> &&
    operator[](integral_constant<size_t, I>) const && noexcept {
        return static_cast<const std::tuple_element_t<I, compressed_pair> &&>(get<I>());
    }
};

template <typename T, typename U>
compressed_pair(T, U) -> compressed_pair<T, U>;

template <typename T1, typename U1, typename T2, typename U2>
WJR_CONST constexpr bool operator==(
    const compressed_pair<T1, U1> &lhs,
    const compressed_pair<T2, U2> &
        rhs) noexcept(std::conjunction_v<has_noexcept_equal_to<const T1 &, const T2 &>,
                                         has_noexcept_equal_to<const U1 &, const U2 &>>) {
    return lhs.first() == rhs.first() && lhs.second() == rhs.second();
}

template <typename T1, typename U1, typename T2, typename U2>
WJR_CONST constexpr bool
operator!=(const compressed_pair<T1, U1> &lhs,
           const compressed_pair<T2, U2> &rhs) noexcept(noexcept(lhs == rhs)) {
    return !(lhs == rhs);
}

template <typename T1, typename U1, typename T2, typename U2>
WJR_CONST constexpr bool operator<(
    const compressed_pair<T1, U1> &lhs,
    const compressed_pair<T2, U2>
        &rhs) noexcept(std::conjunction_v<has_noexcept_less<const T1 &, const T2 &>,
                                          has_noexcept_less<const T2 &, const T1 &>,
                                          has_noexcept_less<const U1 &, const U2 &>>) {
    return lhs.first() < rhs.first() ||
           (!(rhs.first() < lhs.first()) && lhs.second() < rhs.second());
}

template <typename T1, typename U1, typename T2, typename U2>
WJR_CONST constexpr bool
operator>(const compressed_pair<T1, U1> &lhs,
          const compressed_pair<T2, U2> &rhs) noexcept(noexcept(rhs < lhs)) {
    return rhs < lhs;
}

template <typename T1, typename U1, typename T2, typename U2>
WJR_CONST constexpr bool
operator<=(const compressed_pair<T1, U1> &lhs,
           const compressed_pair<T2, U2> &rhs) noexcept(noexcept(rhs < lhs)) {
    return !(rhs < lhs);
}

template <typename T1, typename U1, typename T2, typename U2>
WJR_CONST constexpr bool
operator>=(const compressed_pair<T1, U1> &lhs,
           const compressed_pair<T2, U2> &rhs) noexcept(noexcept(lhs < rhs)) {
    return !(lhs < rhs);
}

template <typename T, typename U>
constexpr compressed_pair<unref_wrapper_t<T>, unref_wrapper_t<U>>
make_compressed_pair(T &&t, U &&u) noexcept(
    std::conjunction_v<std::is_nothrow_constructible<unref_wrapper_t<T>, T &&>,
                       std::is_nothrow_constructible<unref_wrapper_t<U>, U &&>>) {
    return compressed_pair<unref_wrapper_t<T>, unref_wrapper_t<U>>(std::forward<T>(t),
                                                                   std::forward<U>(u));
}

} // namespace wjr

namespace std {

template <typename T, typename U,
          WJR_REQUIRES(std::conjunction_v<wjr::is_swappable<T>, wjr::is_swappable<U>>)>
constexpr void swap(wjr::compressed_pair<T, U> &lhs,
                    wjr::compressed_pair<T, U> &rhs) noexcept(noexcept(lhs.swap(rhs))) {
    lhs.swap(rhs);
}

template <size_t I, typename T, typename U, WJR_REQUIRES(I < 2)>
WJR_NODISCARD constexpr tuple_element_t<I, wjr::compressed_pair<T, U>> &
get(wjr::compressed_pair<T, U> &pr) noexcept {
    if constexpr (I == 0) {
        return pr.first();
    } else {
        return pr.second();
    }
}

template <size_t I, typename T, typename U, WJR_REQUIRES(I < 2)>
WJR_NODISCARD constexpr const tuple_element_t<I, wjr::compressed_pair<T, U>> &
get(const wjr::compressed_pair<T, U> &pr) noexcept {
    if constexpr (I == 0) {
        return pr.first();
    } else {
        return pr.second();
    }
}

template <size_t I, typename T, typename U, WJR_REQUIRES(I < 2)>
WJR_NODISCARD constexpr tuple_element_t<I, wjr::compressed_pair<T, U>> &&
get(wjr::compressed_pair<T, U> &&pr) noexcept {
    if constexpr (I == 0) {
        return std::forward<T>(pr.first());
    } else {
        return std::forward<U>(pr.second());
    }
}

template <size_t I, typename T, typename U, WJR_REQUIRES(I < 2)>
WJR_NODISCARD constexpr const tuple_element_t<I, wjr::compressed_pair<T, U>> &&
get(const wjr::compressed_pair<T, U> &&pr) noexcept {
    if constexpr (I == 0) {
        return std::forward<T>(pr.first());
    } else {
        return std::forward<U>(pr.second());
    }
}

template <typename T, typename U>
WJR_NODISCARD constexpr T &get(wjr::compressed_pair<T, U> &pr) noexcept {
    return std::get<0>(pr);
}

template <typename T, typename U>
WJR_NODISCARD constexpr const T &get(const wjr::compressed_pair<T, U> &pr) noexcept {
    return get<0>(pr);
}

template <typename T, typename U>
WJR_NODISCARD constexpr T &&get(wjr::compressed_pair<T, U> &&pr) noexcept {
    return get<0>(std::move(pr));
}

template <typename T, typename U>
WJR_NODISCARD constexpr const T &&get(const wjr::compressed_pair<T, U> &&pr) noexcept {
    return get<0>(std::move(pr));
}

template <typename T, typename U>
WJR_NODISCARD constexpr T &get(wjr::compressed_pair<U, T> &pr) noexcept {
    return get<1>(pr);
}

template <typename T, typename U>
WJR_NODISCARD constexpr const T &get(const wjr::compressed_pair<U, T> &pr) noexcept {
    return get<1>(pr);
}

template <typename T, typename U>
WJR_NODISCARD constexpr T &&get(wjr::compressed_pair<U, T> &&pr) noexcept {
    return get<1>(std::move(pr));
}

template <typename T, typename U>
WJR_NODISCARD constexpr const T &&get(const wjr::compressed_pair<U, T> &&pr) noexcept {
    return get<1>(std::move(pr));
}

} // namespace std

#endif // WJR_COMPRESSED_PAIR_HPP__
#ifndef WJR_CONTAINER_GENERIC_CONTAINER_TRAITS_HPP__
#define WJR_CONTAINER_GENERIC_CONTAINER_TRAITS_HPP__

#include <memory>
#include <type_traits>

// Already included

namespace wjr {

/**
 * @class container_fn<Alloc>
 * @brief The same characteristics and behavior of all allocator containers
 *
 * @details container must have the following member functions:
 * -# auto& __get_allocator() noexcept
 * -# void __destroy() noexcept
 * -# void __destroy_and_deallocate() noexcept
 * -# void __copy_element(const container& other)
 * -# void __take_storage(container&& other)
 * -# void __move_element(container&& other)
 * -# void __swap_storage(container& other)
 *
 * 1 : is used to manage the allocator of the container. \n
 * 2-3 : is used to destroy the container and deallocate the memory. \n
 * 4-7 : is used to assign the container data. Shouldn't change the allocator.
 *
 */
template <typename Alloc>
class container_fn {
private:
    using allocator_type = Alloc;
    using allocator_traits = std::allocator_traits<allocator_type>;
    using is_always_equal = typename allocator_traits::is_always_equal;
    using propagate_on_container_copy_assignment =
        typename allocator_traits::propagate_on_container_copy_assignment;
    using propagate_on_container_move_assignment =
        typename allocator_traits::propagate_on_container_move_assignment;
    using propagate_on_container_swap =
        typename allocator_traits::propagate_on_container_swap;

public:
    template <typename Container>
    WJR_CONSTEXPR20 static void
    copy_assign(Container &lhs, const Container &rhs) noexcept(
        noexcept(lhs.__copy_element(rhs)) &&
                !propagate_on_container_copy_assignment::value
            ? true
            : (noexcept(lhs.__get_allocator() = rhs.__get_allocator()) &&
                       is_always_equal::value
                   ? true
                   : noexcept(lhs.__destroy_and_deallocate()))) {
        if constexpr (propagate_on_container_copy_assignment::value) {
            auto &lhs_allocator = lhs.__get_allocator();
            auto &rhs_allocator = rhs.__get_allocator();
            if constexpr (!is_always_equal::value) {
                if (lhs_allocator != rhs_allocator) {
                    lhs.__destroy_and_deallocate();
                }
            }

            lhs_allocator = rhs_allocator;
        }

        lhs.__copy_element(rhs);
    }

    template <typename Container>
    WJR_CONSTEXPR20 static void move_assign(Container &lhs, Container &&rhs) noexcept(
        noexcept(lhs.__destroy_and_deallocate()) && noexcept(
            lhs.__take_storage(std::move(rhs))) &&
                std::disjunction_v<propagate_on_container_move_assignment,
                                   is_always_equal>
            ? (!propagate_on_container_move_assignment::value
                   ? true
                   : noexcept(lhs.__get_allocator() = std::move(rhs.__get_allocator())))
            : (noexcept(lhs.__destroy()) && noexcept(
                  lhs.__move_element(std::move(rhs))))) {
        if constexpr (std::disjunction_v<propagate_on_container_move_assignment,
                                         is_always_equal>) {
            lhs.__destroy_and_deallocate();
            if constexpr (propagate_on_container_move_assignment::value) {
                lhs.__get_allocator() = std::move(rhs.__get_allocator());
            }
            lhs.__take_storage(std::move(rhs));
        } else {
            if (lhs.__get_allocator() != rhs.__get_allocator()) {
                lhs.__destroy();
                lhs.__move_element(std::move(rhs));
            } else {
                lhs.__destroy_and_deallocate();
                lhs.__take_storage(std::move(rhs));
            }
        }
    }

    template <typename Container>
    WJR_CONSTEXPR20 static void swap(Container &lhs, Container &rhs) noexcept(
        noexcept(lhs.__swap_storage(rhs)) &&
                !std::conjunction_v<propagate_on_container_swap,
                                    std::negation<is_always_equal>>
            ? true
            : noexcept(std::swap(lhs.__get_allocator(), rhs.__get_allocator()))) {
        if constexpr (std::conjunction_v<propagate_on_container_swap,
                                         std::negation<is_always_equal>>) {
            auto &lhs_allocator = lhs.__get_allocator();
            auto &rhs_allocator = rhs.__get_allocator();
            if (lhs_allocator != rhs_allocator) {
                std::swap(lhs_allocator, rhs_allocator);
            }
        }

        lhs.__swap_storage(rhs);
    }
};

} // namespace wjr

#endif // WJR_CONTAINER_GENERIC_CONTAINER_TRAITS_HPP__
#ifndef WJR_ITERATOR_CONTIGUOUS_ITERATOR_ADAPTER_HPP__
#define WJR_ITERATOR_CONTIGUOUS_ITERATOR_ADAPTER_HPP__

// Already included
// Already included

namespace wjr {

template <typename Container, typename Traits>
class contiguous_const_iterator_adapter {
    using __pointer = typename Traits::pointer;

public:
#if defined(WJR_CXX_20)
    using iterator_concept = std::contiguous_iterator_tag;
#endif
    using iterator_category = std::random_access_iterator_tag;
    using value_type = typename Traits::value_type;
    using difference_type = typename Traits::difference_type;
    using pointer = typename Traits::const_pointer;
    using reference = typename Traits::const_reference;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(contiguous_const_iterator_adapter);

    WJR_CONSTEXPR20
    contiguous_const_iterator_adapter(__pointer ptr, const Container *container) noexcept(
        std::is_nothrow_copy_constructible_v<__pointer>)
        : m_ptr(ptr) {
        __set_container(container);
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 pointer operator->() const noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(m_container != nullptr,
                      "Can't dereference an value-initialized iterator.");
        WJR_ASSERT_L0(m_ptr != nullptr, "Can't dereference an invalid iterator.");
        WJR_ASSERT_L0(m_ptr >= __begin() && m_ptr < __end(),
                      "Can't dereference an out-of-range iterator.");
#endif
        return const_cast<pointer>(m_ptr);
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 reference operator*() const noexcept {
        return *operator->();
    }

    WJR_CONSTEXPR20 contiguous_const_iterator_adapter &operator++() noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(m_container != nullptr,
                      "Can't increment an value-initialized iterator.");
        WJR_ASSERT_L0(m_ptr != nullptr, "Can't increment an invalid iterator.");
        WJR_ASSERT_L0(m_ptr < __end(),
                      "Can't increment an iterator that is already at/after the end.");
#endif
        ++m_ptr;
        return *this;
    }

    WJR_CONSTEXPR20 contiguous_const_iterator_adapter operator++(int) noexcept {
        auto tmp = *this;
        ++*this;
        return tmp;
    }

    WJR_CONSTEXPR20 contiguous_const_iterator_adapter &operator--() noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(m_container != nullptr,
                      "Can't decrement an value-initialized iterator.");
        WJR_ASSERT_L0(m_ptr != nullptr, "Can't decrement an invalid iterator.");
        WJR_ASSERT_L0(
            m_ptr > __begin(),
            "Can't decrement an iterator that is already at/before the beginning.");
#endif
        --m_ptr;
        return *this;
    }

    WJR_CONSTEXPR20 contiguous_const_iterator_adapter operator--(int) noexcept {
        auto tmp = *this;
        --*this;
        return tmp;
    }

    WJR_CONSTEXPR20 contiguous_const_iterator_adapter &
    operator+=(difference_type n) noexcept {
        __check_offset(n);
        m_ptr += n;
        return *this;
    }

    WJR_NODISCARD WJR_CONSTEXPR20 contiguous_const_iterator_adapter
    operator+(difference_type n) const noexcept {
        auto tmp = *this;
        return tmp += n;
    }

    WJR_NODISCARD friend WJR_CONSTEXPR20 contiguous_const_iterator_adapter
    operator+(difference_type n, const contiguous_const_iterator_adapter &rhs) noexcept {
        return rhs + n;
    }

    WJR_CONSTEXPR20 contiguous_const_iterator_adapter &
    operator-=(difference_type n) noexcept {
        __check_offset(-n);
        m_ptr -= n;
        return *this;
    }

    WJR_NODISCARD WJR_CONSTEXPR20 contiguous_const_iterator_adapter
    operator-(difference_type n) const noexcept {
        auto tmp = *this;
        return tmp -= n;
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 difference_type
    operator-(const contiguous_const_iterator_adapter &rhs) const noexcept {
        __check_same_container(rhs);
        return m_ptr - rhs.m_ptr;
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 reference
    operator[](difference_type n) const noexcept {
        return *(*this + n);
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 bool
    operator==(const contiguous_const_iterator_adapter &rhs) const noexcept {
        __check_same_container(rhs);
        return m_ptr == rhs.m_ptr;
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 bool
    operator!=(const contiguous_const_iterator_adapter &rhs) const noexcept {
        return !(*this == rhs);
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 bool
    operator<(const contiguous_const_iterator_adapter &rhs) const noexcept {
        __check_same_container(rhs);
        return m_ptr < rhs.m_ptr;
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 bool
    operator>(const contiguous_const_iterator_adapter &rhs) const noexcept {
        return rhs < *this;
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 bool
    operator<=(const contiguous_const_iterator_adapter &rhs) const noexcept {
        return !(rhs < *this);
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 bool
    operator>=(const contiguous_const_iterator_adapter &rhs) const noexcept {
        return !(*this < rhs);
    }

    WJR_CONSTEXPR20 void
    check_same_container(WJR_MAYBE_UNUSED const Container *cont) const noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(m_container == cont,
                      "Can't compare iterators from different containers.");
#else
        (void)(cont);
#endif
    }

private:
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
    /// @private
    WJR_CONSTEXPR20 void __set_container(const Container *container) noexcept {
        m_container = container;
    }

    /// @private
    WJR_CONSTEXPR20 void __check_offset(difference_type offset) const noexcept {
        if (offset == 0) {
            return;
        }
        WJR_ASSERT_L0(m_container != nullptr,
                      "Can't seek an value-initialized iterator.");
        WJR_ASSERT_L0(m_ptr != nullptr, "Can't seek an invalid iterator.");
        if (offset < 0) {
            WJR_ASSERT_L0(offset >= __begin() - m_ptr,
                          "Can't seek an iterator that before the beginning.");
        } else {
            WJR_ASSERT_L0(offset <= __end() - m_ptr,
                          "Can't seek an iterator that after the end.");
        }
    }

    /// @private
    WJR_CONSTEXPR20 void
    __check_same_container(const contiguous_const_iterator_adapter &rhs) const noexcept {
        WJR_ASSERT_L0(m_container == rhs.m_container,
                      "Can't compare iterators from different containers.");
    }

public:
    /// @private
    WJR_PURE WJR_CONSTEXPR20 pointer __begin() const noexcept {
        return m_container->data();
    }

    /// @private
    WJR_PURE WJR_CONSTEXPR20 pointer __end() const noexcept {
        return m_container->data() + m_container->size();
    }
#else
    /// @private
    constexpr static void __set_container(const Container *) noexcept {}

    /// @private
    constexpr static void __check_offset(difference_type) noexcept {}

    /// @private
    constexpr static void
    __check_same_container(const contiguous_const_iterator_adapter &) noexcept {}

public:
#endif

    __pointer m_ptr;
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
    const Container *m_container;
#endif
};

template <typename Container, typename Traits>
class contiguous_iterator_adapter
    : public contiguous_const_iterator_adapter<Container, Traits> {
    using Mybase = contiguous_const_iterator_adapter<Container, Traits>;
    using __pointer = typename Traits::pointer;

public:
#if defined(WJR_CXX_20)
    using iterator_concept = typename Mybase::iterator_concept;
#endif
    using iterator_category = typename Mybase::iterator_category;
    using value_type = typename Mybase::value_type;
    using difference_type = typename Mybase::difference_type;
    using pointer = typename Traits::pointer;
    using reference = typename Traits::reference;

    using Mybase::Mybase;

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 pointer operator->() const noexcept {
        return const_cast<pointer>(Mybase::operator->());
    }

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 reference operator*() const noexcept {
        return *operator->();
    }

    WJR_CONSTEXPR20 contiguous_iterator_adapter &operator++() noexcept {
        Mybase::operator++();
        return *this;
    }

    WJR_CONSTEXPR20 contiguous_iterator_adapter operator++(int) noexcept {
        auto tmp = *this;
        ++*this;
        return tmp;
    }

    WJR_CONSTEXPR20 contiguous_iterator_adapter &operator--() noexcept {
        Mybase::operator--();
        return *this;
    }

    WJR_CONSTEXPR20 contiguous_iterator_adapter operator--(int) noexcept {
        auto tmp = *this;
        --*this;
        return tmp;
    }

    WJR_CONSTEXPR20 contiguous_iterator_adapter &operator+=(difference_type n) noexcept {
        Mybase::operator+=(n);
        return *this;
    }

    WJR_NODISCARD WJR_CONSTEXPR20 contiguous_iterator_adapter
    operator+(difference_type n) const noexcept {
        auto tmp = *this;
        return tmp += n;
    }

    WJR_NODISCARD friend WJR_CONSTEXPR20 contiguous_iterator_adapter
    operator+(difference_type n, const contiguous_iterator_adapter &rhs) noexcept {
        return rhs + n;
    }

    WJR_CONSTEXPR20 contiguous_iterator_adapter &operator-=(difference_type n) noexcept {
        Mybase::operator-=(n);
        return *this;
    }

    WJR_NODISCARD WJR_CONSTEXPR20 contiguous_iterator_adapter
    operator-(difference_type n) const noexcept {
        auto tmp = *this;
        return tmp -= n;
    }

    using Mybase::operator-;

    WJR_NODISCARD WJR_PURE WJR_CONSTEXPR20 reference
    operator[](difference_type n) const noexcept {
        return *(*this + n);
    }

    using Mybase::check_same_container;
};

template <typename Container, typename Traits>
struct __is_contiguous_iterator_impl<contiguous_const_iterator_adapter<Container, Traits>>
    : std::true_type {};

template <typename Container, typename Traits>
struct __is_contiguous_iterator_impl<contiguous_iterator_adapter<Container, Traits>>
    : std::true_type {};

} // namespace wjr

namespace std {

template <typename Container, typename Traits>
struct pointer_traits<wjr::contiguous_const_iterator_adapter<Container, Traits>> {
    using pointer = wjr::contiguous_const_iterator_adapter<Container, Traits>;
    using element_type = const typename pointer::value_type;
    using difference_type = typename pointer::difference_type;

    WJR_NODISCARD constexpr static element_type *to_address(const pointer &ptr) noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        const auto cont = ptr.m_container;
        if (cont) {
            WJR_ASSERT_L0(ptr.m_ptr >= ptr.__begin() && ptr.m_ptr <= ptr.__end(),
                          "can't convert out-of-range vector iterator to pointer");
        } else {
            WJR_ASSERT_L0(ptr.m_ptr == nullptr,
                          "can't convert invalid vector iterator to pointer");
        }
#endif
        return wjr::to_address(ptr.m_ptr);
    }
};

template <typename Container, typename Traits>
struct pointer_traits<wjr::contiguous_iterator_adapter<Container, Traits>> {
    using pointer = wjr::contiguous_iterator_adapter<Container, Traits>;
    using element_type = typename pointer::value_type;
    using difference_type = typename pointer::difference_type;

    WJR_NODISCARD constexpr static element_type *to_address(const pointer &ptr) noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        const auto cont = ptr.m_container;
        if (cont) {
            WJR_ASSERT_L0(ptr.m_ptr >= ptr.__begin() && ptr.m_ptr <= ptr.__end(),
                          "can't convert out-of-range vector iterator to pointer");
        } else {
            WJR_ASSERT_L0(ptr.m_ptr == nullptr,
                          "can't convert invalid vector iterator to pointer");
        }
#endif
        return wjr::to_address(ptr.m_ptr);
    }
};

} // namespace std

#endif // WJR_ITERATOR_CONTIGUOUS_ITERATOR_ADAPTER_HPP__
// Already included
#ifndef WJR_MEMORY_COPY_HPP__
#define WJR_MEMORY_COPY_HPP__

#include <algorithm>

#ifndef WJR_CONTAINER_GENERIC_DETAIL_HPP__
#define WJR_CONTAINER_GENERIC_DETAIL_HPP__

#include <string>

// Already included

namespace wjr {

WJR_REGISTER_HAS_TYPE(__container_resize,
                      std::declval<std::add_lvalue_reference_t<Container>>().resize(
                          std::declval<Size>(), std::declval<Args>()...),
                      Container, Size);
WJR_REGISTER_HAS_TYPE(__container_append,
                      std::declval<Container>().append(std::declval<Args>()...),
                      Container);

template <typename Container>
struct resize_fn_impl_base {
    template <typename... Args,
              WJR_REQUIRES(has___container_resize_v<Container, Args...>)>
    WJR_INTRINSIC_INLINE static void
    resize(Container &cont,
           Args &&...args) noexcept(noexcept(cont.resize(std::forward<Args>(args)...))) {
        cont.resize(std::forward<Args>(args)...);
    }
};

template <typename Container>
struct resize_fn_impl : resize_fn_impl_base<Container> {};

struct resize_fn {
    template <typename Container, typename... Args>
    void operator()(Container &cont, Args &&...args) const noexcept(
        noexcept(resize_fn_impl<Container>::resize(cont, std::forward<Args>(args)...))) {
        resize_fn_impl<Container>::resize(cont, std::forward<Args>(args)...);
    }
};

inline constexpr resize_fn resize{};

template <typename Container>
struct append_fn_impl_base {
    template <typename... Args,
              WJR_REQUIRES(has___container_append_v<Container, Args...>)>
    WJR_INTRINSIC_INLINE static void
    append(Container &cont,
           Args &&...args) noexcept(noexcept(cont.append(std::forward<Args>(args)...))) {
        cont.append(std::forward<Args>(args)...);
    }
};

template <typename Container>
struct append_fn_impl : append_fn_impl_base<Container> {};

struct append_fn {
    template <typename Container, typename... Args>
    void operator()(Container &cont, Args &&...args) const noexcept(
        noexcept(append_fn_impl<Container>::append(cont, std::forward<Args>(args)...))) {
        append_fn_impl<Container>::append(cont, std::forward<Args>(args)...);
    }
};

inline constexpr append_fn append{};

#define WJR_HAS_FEATURE_STRING_UNINITIALIZED_RESIZE WJR_HAS_DEF

#ifdef __cpp_lib_string_resize_and_overwrite
#define WJR_STRINF_RESIZE_AND_OVERWRITE __cpp_lib_string_resize_and_overwrite
#else
#define WJR_STRINF_RESIZE_AND_OVERWRITE 0
#endif

#if WJR_STRINF_RESIZE_AND_OVERWRITE >= 202110L
template <typename CharT, typename Traits, typename Alloc>
WJR_INTRINSIC_INLINE void
__uninitialized_resize(std::basic_string<CharT, Traits, Alloc> &str,
                       typename std::basic_string<CharT, Traits, Alloc>::size_type sz) {
    using Size = typename std::basic_string<CharT, Traits, Alloc>::size_type;
    str.resize_and_overwrite(sz, [](char *, Size sz) { return sz; });
}

#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_CLASS(...)
#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_TEMPLATE(...)
#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_HACKER(...)

#elif (defined(__clang_major__) && __clang_major__ <= 11) ||                             \
    (defined(_MSC_VER) && _MSC_VER <= 1920)
#undef WJR_HAS_FEATURE_STRING_UNINITIALIZED_RESIZE
#elif defined(__GLIBCXX__) || defined(_LIBCPP_VERSION) || defined(_MSVC_STL_VERSION)

template <typename Container>
void string_set_length_hacker(Container &bank, typename Container::size_type sz);

#if defined(__GLIBCXX__) || defined(_LIBCPP_VERSION)
#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_CLASS(Name, Container)                \
    inline void WJR_PP_CONCAT(string_set_length_hacker_of_,                              \
                              Name)(Container & bank, typename Container::size_type sz); \
    template <typename Money_t, Money_t Container::*p>                                   \
    struct WJR_PP_CONCAT(string_thief_of_, Name) {                                       \
        friend void WJR_PP_CONCAT(string_set_length_hacker_of_,                          \
                                  Name)(Container & bank,                                \
                                        typename Container::size_type sz) {              \
            (bank.*p)(sz);                                                               \
        }                                                                                \
    }
#else
#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_CLASS(Name, Container)                \
    inline void WJR_PP_CONCAT(string_set_length_hacker_of_,                              \
                              Name)(Container & bank, typename Container::size_type sz); \
    template <typename Money_t, Money_t Container::*p>                                   \
    struct WJR_PP_CONCAT(string_thief_of_, Name) {                                       \
        friend void WJR_PP_CONCAT(string_set_length_hacker_of_,                          \
                                  Name)(Container & bank,                                \
                                        typename Container::size_type sz) {              \
            (bank.*p)._Myval2._Mysize = sz;                                              \
        }                                                                                \
    }
#endif

#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_HACKER(Name, Container)               \
    template <>                                                                          \
    inline void string_set_length_hacker<Container>(Container & bank,                    \
                                                    typename Container::size_type sz) {  \
        WJR_PP_CONCAT(string_set_length_hacker_of_, Name)(bank, sz);                     \
    };

#if defined(__GLIBCXX__)
#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_TEMPLATE(Name, Container)             \
    template struct WJR_PP_CONCAT(                                                       \
        string_thief_of_, Name)<void(Container::size_type), &Container::_M_set_length>
#elif defined(_LIBCPP_VERSION)
#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_TEMPLATE(Name, Container)             \
    template struct WJR_PP_CONCAT(                                                       \
        string_thief_of_, Name)<void(Container::size_type), &Container::__set_size>
#else
#define __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_TEMPLATE(Name, Container)             \
    template struct WJR_PP_CONCAT(                                                       \
        string_thief_of_, Name)<decltype(Container::_Mypair), &Container::_Mypair>
#endif

template <typename CharT, typename Traits, typename Alloc>
WJR_INTRINSIC_INLINE void
__uninitialized_resize(std::basic_string<CharT, Traits, Alloc> &str,
                       typename std::basic_string<CharT, Traits, Alloc>::size_type sz) {
    str.reserve(sz);
    string_set_length_hacker(str, sz);
    WJR_ASSERT_L2(str.size() == sz);
    str[sz] = '\0';
}

#else
#undef WJR_HAS_FEATURE_STRING_UNINITIALIZED_RESIZE
#define WJR_REGISTER_STRING_UNINITIALIZED_RESIZE(Name, Container)
#endif

#if WJR_HAS_FEATURE(STRING_UNINITIALIZED_RESIZE)

template <typename Container>
struct __uninitialized_resize_fn_impl : resize_fn_impl_base<Container> {
    using resize_fn_impl_base<Container>::resize;
    WJR_INTRINSIC_INLINE static void resize(Container &cont,
                                            typename Container::size_type sz, dctor_t) {
        __uninitialized_resize(cont, sz);
    }
};

template <typename Container>
struct __uninitialized_append_fn_impl : append_fn_impl_base<Container> {
    using append_fn_impl_base<Container>::append;
    WJR_INTRINSIC_INLINE static void append(Container &cont,
                                            typename Container::size_type sz, dctor_t) {
        __uninitialized_resize(cont, cont.size() + sz);
    }
};

#define WJR_REGISTER_STRING_UNINITIALIZED_RESIZE(Name, Container)                        \
    __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_CLASS(Name, Container);                   \
    __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_TEMPLATE(Name, Container);                \
    __WJR_REGISTER_STRING_UNINITIALIZED_RESIZE_HACKER(Name, Container);                  \
    template <>                                                                          \
    struct resize_fn_impl<Container> : __uninitialized_resize_fn_impl<Container> {};     \
    template <>                                                                          \
    struct append_fn_impl<Container> : __uninitialized_append_fn_impl<Container> {}
#else
#define WJR_REGISTER_STRING_UNINITIALIZED_RESIZE(Name, Container)
#endif

WJR_REGISTER_STRING_UNINITIALIZED_RESIZE(std_string, std::string);

WJR_REGISTER_HAS_TYPE(container_resize,
                      resize_fn_impl<Container>::resize(std::declval<Container &>(),
                                                        std::declval<Size>(),
                                                        std::declval<Args>()...),
                      Container, Size);

WJR_REGISTER_HAS_TYPE(container_reserve,
                      std::declval<Container>().reserve(std::declval<Size>()), Container,
                      Size);
WJR_REGISTER_HAS_TYPE(container_append,
                      append_fn_impl<Container>::append(std::declval<Container &>(),
                                                        std::declval<Args>()...),
                      Container);
WJR_REGISTER_HAS_TYPE(container_insert,
                      (std::declval<Container>().insert(
                           std::declval<Container>().cbegin(), std::declval<Args>()...),
                       std::declval<Container>().insert(std::declval<Container>().cend(),
                                                        std::declval<Args>()...)),
                      Container);

template <typename Container, typename Size,
          WJR_REQUIRES(has_container_resize_v<Container, Size>)>
WJR_INTRINSIC_INLINE void try_uninitialized_resize(Container &cont, Size sz) {
    if constexpr (has_container_resize_v<Container, Size, dctor_t>) {
        resize(cont, sz, dctor);
    } else {
        resize(cont, sz);
    }
}

/// @private
template <typename T, typename = void>
struct __container_traits_base_iterator_helper {
    using iterator = T;
};

/// @private
template <typename T>
struct __container_traits_base_iterator_helper<T, std::void_t<typename T::iterator>> {
    using iterator = typename T::iterator;
};

/// @private
template <typename T, typename = void>
struct __container_traits_base_size_type_helper {
    using size_type = size_t;
};

/// @private
template <typename T>
struct __container_traits_base_size_type_helper<T, std::void_t<typename T::size_type>> {
    using size_type = typename T::size_type;
};

/// @private
template <typename Container>
struct __container_traits_base {
private:
    using iterator =
        typename __container_traits_base_iterator_helper<Container>::iterator;
    using size_type =
        typename __container_traits_base_size_type_helper<Container>::size_type;

public:
    constexpr static bool is_contiguous_v = is_contiguous_iterator_v<iterator>;

    /**
     * @details Trivially contiguous means that the container can be resized and then
     * filled, and the result should be consistent with the element by element push_back
     * result. It does not verify whether the element is trial. Because different
     * containers may have different ways of constructing elements. The main purpose is
     * for types like std::basic_string<CharT, Traits, Alloc>, and for unknown
     * Traits, it should not be assumed that filling after resizing yields the same
     * result as using Traits::copy.
     *
     */
    constexpr static bool is_trivially_contiguous_v = false;
};

template <typename Container>
struct container_traits;

} // namespace wjr

#endif // WJR_CONTAINER_GENERIC_DETAIL_HPP__
#ifndef WJR_ITERATOR_INSERTER_HPP__
#define WJR_ITERATOR_INSERTER_HPP__

// Already included

namespace wjr {

template <typename T>
struct is_insert_iterator : std::false_type {};

template <typename Container>
struct is_insert_iterator<std::insert_iterator<Container>> : std::true_type {};

template <typename T>
inline constexpr bool is_insert_iterator_v = is_insert_iterator<T>::value;

template <typename T>
struct is_back_insert_iterator : std::false_type {};

template <typename Container>
struct is_back_insert_iterator<std::back_insert_iterator<Container>> : std::true_type {};

template <typename T>
inline constexpr bool is_back_insert_iterator_v = is_back_insert_iterator<T>::value;

template <typename T>
struct is_front_insert_iterator : std::false_type {};

template <typename Container>
struct is_front_insert_iterator<std::front_insert_iterator<Container>> : std::true_type {
};

template <typename T>
inline constexpr bool is_front_insert_iterator_v = is_front_insert_iterator<T>::value;

template <typename T>
struct is_any_insert_iterator
    : std::bool_constant<is_insert_iterator_v<T> || is_back_insert_iterator_v<T> ||
                         is_front_insert_iterator_v<T>> {};

template <typename T>
inline constexpr bool is_any_insert_iterator_v = is_any_insert_iterator<T>::value;

/// @private
template <typename Iter>
struct __inserter_container_accessor : Iter {
    __inserter_container_accessor(Iter it) noexcept(
        std::is_nothrow_copy_constructible_v<Iter>)
        : Iter(it) {}
    using Iter::container;
};

/// @private
template <typename Iter>
__inserter_container_accessor(Iter) -> __inserter_container_accessor<Iter>;

/// @private
template <typename Iter>
struct __inserter_iterator_accessor : Iter {
    __inserter_iterator_accessor(Iter it) noexcept(
        std::is_nothrow_copy_constructible_v<Iter>)
        : Iter(it) {}
    using Iter::iter;
};

template <typename Iter>
__inserter_iterator_accessor(Iter) -> __inserter_iterator_accessor<Iter>;

template <typename Container>
Container &get_inserter_container(std::insert_iterator<Container> it) noexcept(
    std::is_nothrow_copy_constructible_v<std::insert_iterator<Container>>) {
    __inserter_container_accessor tmp(it);
    return *(tmp.container);
}

template <typename Container>
Container &get_inserter_container(std::back_insert_iterator<Container> it) noexcept(
    std::is_nothrow_copy_constructible_v<std::back_insert_iterator<Container>>) {
    __inserter_container_accessor tmp(it);
    return *(tmp.container);
}

template <typename Container>
Container &get_inserter_container(std::front_insert_iterator<Container> it) noexcept(
    std::is_nothrow_copy_constructible_v<std::front_insert_iterator<Container>>) {
    __inserter_container_accessor tmp(it);
    return *(tmp.container);
}

template <typename Container>
typename Container::iterator
get_inserter_iterator(std::insert_iterator<Container> it) noexcept(
    std::is_nothrow_copy_constructible_v<std::insert_iterator<Container>>) {
    __inserter_iterator_accessor tmp(it);
    return *(tmp.iter);
}

} // namespace wjr

#endif // WJR_ITERATOR_INSERTER_HPP__
// Already included

namespace wjr {

/**
 * @fn copy
 *
 * @details Optimized for back_insert_iterator and insert_iterator.
 *
 */
template <typename InputIt, typename OutputIt>
constexpr OutputIt copy(InputIt first, InputIt last, OutputIt d_first) {
    using Out = remove_cvref_t<OutputIt>;

    if constexpr (is_back_insert_iterator_v<Out> || is_insert_iterator_v<Out>) {
        using Container = typename Out::container_type;

        if constexpr (is_back_insert_iterator_v<Out>) {
            if constexpr (has_container_append_v<Container, InputIt, InputIt>) {
                append(get_inserter_container(d_first), first, last);
                return d_first;
            } else if constexpr (has_container_insert_v<Container, InputIt, InputIt>) {
                auto &cont = get_inserter_container(d_first);
                cont.insert(cont.cend(), first, last);
                return d_first;
            } else {
                return std::copy(first, last, d_first);
            }
        } else {
            if constexpr (has_container_insert_v<Container, InputIt, InputIt>) {
                auto &cont = get_inserter_container(d_first);
                const auto pos = get_inserter_iterator(d_first);
                cont.insert(pos, first, last);
                return d_first;
            } else {
                return std::copy(first, last, d_first);
            }
        }
    } else {
        return std::copy(first, last, d_first);
    }
}

/// @private
template <typename InputIt, typename OutputIt>
constexpr OutputIt __copy_restrict_impl_aux(add_restrict_t<InputIt> first,
                                            add_restrict_t<InputIt> last,
                                            add_restrict_t<OutputIt> d_first) {
    return wjr::copy(first, last, d_first);
}

/// @private
template <typename InputIt, typename OutputIt>
constexpr OutputIt __copy_restrict_impl(InputIt first, InputIt last,
                                        OutputIt d_first) noexcept {
    return __copy_restrict_impl_aux<InputIt, OutputIt>(first, last, d_first);
}

/**
 * @brief Copy elements from a range to another range with restricted pointers.
 *
 * @details Use @ref wjr::copy. \n
 * If iterator is contiguouse, then get restricted pointer
 * by iterator to optimize.
 */
template <typename InputIt, typename OutputIt>
constexpr OutputIt copy_restrict(InputIt first, InputIt last, OutputIt d_first) {
    const auto __first = to_contiguous_address(std::move(first));
    const auto __last = to_contiguous_address(std::move(last));
    if constexpr (is_contiguous_iterator_v<OutputIt>) {
        const auto __d_first = wjr::to_address(d_first);
        const auto __d_last = __copy_restrict_impl(__first, __last, __d_first);
        return std::next(d_first, std::distance(__d_first, __d_last));
    } else {
        return __copy_restrict_impl(__first, __last, d_first);
    }
}

/**
 * @fn wjr::copy_n
 *
 * @details Optimized for back_insert_iterator and insert_iterator.
 *
 */
template <typename InputIt, typename Size, typename OutputIt>
constexpr OutputIt copy_n(InputIt first, Size count, OutputIt d_first) {
    using Out = remove_cvref_t<OutputIt>;

    if constexpr (is_random_access_iterator_v<InputIt> &&
                  (is_back_insert_iterator_v<Out> || is_insert_iterator_v<Out>)) {
        using Container = typename Out::container_type;

        if constexpr (is_back_insert_iterator_v<Out>) {
            if constexpr (has_container_append_v<Container, InputIt, InputIt>) {
                append(get_inserter_container(d_first), first, std::next(first, count));
                return d_first;
            } else if constexpr (has_container_insert_v<Container, InputIt, InputIt>) {
                auto &cont = get_inserter_container(d_first);
                cont.insert(cont.cend(), first, std::next(first, count));
                return d_first;
            } else {
                return std::copy_n(first, count, d_first);
            }
        } else {
            if constexpr (has_container_insert_v<Container, InputIt, InputIt>) {
                auto &cont = get_inserter_container(d_first);
                const auto pos = get_inserter_iterator(d_first);
                cont.insert(pos, first, std::next(first, count));
                return d_first;
            } else {
                return std::copy_n(first, std::next(first, count), d_first);
            }
        }
    } else {
        return std::copy_n(first, count, d_first);
    }
}

/// @private
template <typename InputIt, typename Size, typename OutputIt>
constexpr OutputIt __copy_n_restrict_impl_aux(add_restrict_t<InputIt> first, Size count,
                                              add_restrict_t<OutputIt> d_first) {
    return wjr::copy_n(first, count, d_first);
}

/// @private
template <typename InputIt, typename Size, typename OutputIt>
constexpr OutputIt __copy_n_restrict_impl(InputIt first, Size count, OutputIt d_first) {
    return __copy_n_restrict_impl_aux<InputIt, Size, OutputIt>(first, count, d_first);
}

/**
 * @brief Copy elements from a range to another range with restricted pointers.
 *
 * @details @see wjr::copy_restrict. \n
 *
 */
template <typename InputIt, typename Size, typename OutputIt>
constexpr OutputIt copy_n_restrict(InputIt first, Size count, OutputIt d_first) {
    const auto __first = to_contiguous_address(std::move(first));
    if constexpr (is_contiguous_iterator_v<OutputIt>) {
        const auto __d_first = wjr::to_address(d_first);
        const auto __d_last = __copy_n_restrict_impl(__first, count, __d_first);
        return std::next(d_first, std::distance(__d_first, __d_last));
    } else {
        return __copy_n_restrict_impl(__first, count, d_first);
    }
}

template <typename InputIt, typename OutputIt>
constexpr OutputIt move(InputIt first, InputIt last, OutputIt d_first) {
    return wjr::copy(std::make_move_iterator(first), std::make_move_iterator(last),
                     d_first);
}

template <typename InputIt, typename OutputIt>
constexpr OutputIt move_restrict(InputIt first, InputIt last, OutputIt d_first) {
    return wjr::copy_restrict(std::make_move_iterator(first),
                              std::make_move_iterator(last), d_first);
}

template <typename InputIt, typename Size, typename OutputIt>
constexpr OutputIt move_n(InputIt first, Size count, OutputIt d_first) {
    return wjr::copy_n(std::make_move_iterator(first), count, d_first);
}

template <typename InputIt, typename Size, typename OutputIt>
constexpr OutputIt move_n_restrict(InputIt first, Size count, OutputIt d_first) {
    return wjr::copy_n_restrict(std::make_move_iterator(first), count, d_first);
}

} // namespace wjr

#endif // WJR_MEMORY_COPY_HPP__
#ifndef WJR_MEMORY_MEMORY_POOL_HPP__
#define WJR_MEMORY_MEMORY_POOL_HPP__

#ifndef WJR_CONTAINER_INTRUSIVE_LIST_HPP__
#define WJR_CONTAINER_INTRUSIVE_LIST_HPP__

#ifndef WJR_CONTAINER_INTRUSIVE_DETAIL_HPP__
#define WJR_CONTAINER_INTRUSIVE_DETAIL_HPP__

// Already included

namespace wjr {

struct default_intrusive_tag {};

template <typename Hook = void, typename Tag = void>
struct intrusive_tag {
    using hook_type = Hook;
    static constexpr bool use_hook = !std::is_same_v<Hook, void>;
};

template <typename Tag>
struct is_intrusive_tag : std::false_type {};

template <typename Hook, typename Tag>
struct is_intrusive_tag<intrusive_tag<Hook, Tag>> : std::true_type {};

template <typename Tag>
inline constexpr bool is_intrusive_tag_v = intrusive_tag<Tag>::value;

template <typename Tag>
using intrusive_hook_t = typename Tag::hook_type;

template <typename Tag>
inline constexpr bool intrusive_use_hook_v = Tag::use_hook;

} // namespace wjr

#endif // WJR_CONTAINER_INTRUSIVE_DETAIL_HPP__

namespace wjr {

template <typename Tag = intrusive_tag<>>
struct list_node;

template <typename T>
constexpr void init(list_node<T> *node) noexcept;

template <typename T>
constexpr void insert(list_node<T> *prev, list_node<T> *next,
                      list_node<T> *node) noexcept;

template <typename T>
constexpr void push_back(list_node<T> *head, list_node<T> *node) noexcept;

template <typename T>
constexpr void push_front(list_node<T> *head, list_node<T> *node) noexcept;

template <typename T>
constexpr void remove_uninit(list_node<T> *node) noexcept;

template <typename T>
constexpr bool empty(const list_node<T> *node) noexcept;

template <typename T>
constexpr list_node<T> *next(list_node<T> *node) noexcept;

template <typename T>
constexpr const list_node<T> *next(const list_node<T> *node) noexcept;

template <typename T>
constexpr list_node<T> *prev(list_node<T> *node) noexcept;

template <typename T>
constexpr const list_node<T> *prev(const list_node<T> *node) noexcept;

template <typename T>
constexpr void replace_uninit(list_node<T> *from, list_node<T> *to) noexcept;

template <typename T>
class list_node_const_iterator {
    using node_type = list_node<T>;

public:
    using iterator_category = std::bidirectional_iterator_tag;
    using value_type = node_type;
    using reference = const node_type &;
    using pointer = const node_type *;
    using difference_type = std::ptrdiff_t;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(list_node_const_iterator);

    constexpr list_node_const_iterator(pointer node) noexcept
        : m_node(const_cast<node_type *>(node)) {}

    constexpr reference operator*() const noexcept { return *m_node; }
    constexpr pointer operator->() const noexcept { return m_node; }

    constexpr list_node_const_iterator &operator++() noexcept {
        m_node = next(m_node);
        return *this;
    }

    constexpr list_node_const_iterator operator++(int) noexcept {
        list_node_const_iterator tmp(*this);
        ++(*this);
        return tmp;
    }

    constexpr list_node_const_iterator &operator--() noexcept {
        m_node = prev(m_node);
        return *this;
    }

    constexpr list_node_const_iterator operator--(int) noexcept {
        list_node_const_iterator tmp(*this);
        --(*this);
        return tmp;
    }

    constexpr bool operator==(const list_node_const_iterator &other) const noexcept {
        return m_node == other.m_node;
    }

    constexpr bool operator!=(const list_node_const_iterator &other) const noexcept {
        return !(*this == other);
    }

private:
    node_type *m_node{};
};

template <typename T>
class list_node_iterator : public list_node_const_iterator<T> {
    using Mybase = list_node_const_iterator<T>;
    using node_type = list_node<T>;

public:
    using iterator_category = typename Mybase::iterator_category;
    using value_type = typename Mybase::value_type;
    using reference = node_type &;
    using pointer = node_type *;
    using difference_type = typename Mybase::difference_type;

    using Mybase::Mybase;

    constexpr reference operator*() const noexcept {
        return const_cast<reference>(Mybase::operator*());
    }

    constexpr pointer operator->() const noexcept {
        return const_cast<pointer>(Mybase::operator->());
    }

    constexpr list_node_iterator &operator++() noexcept {
        Mybase::operator++();
        return *this;
    }

    constexpr list_node_iterator operator++(int) noexcept {
        list_node_iterator tmp(*this);
        ++(*this);
        return tmp;
    }

    constexpr list_node_iterator &operator--() noexcept {
        Mybase::operator--();
        return *this;
    }

    constexpr list_node_iterator operator--(int) noexcept {
        list_node_iterator tmp(*this);
        --(*this);
        return tmp;
    }
};

template <typename Tag>
struct list_node {
    using iterator = list_node_iterator<Tag>;
    using const_iterator = list_node_const_iterator<Tag>;
    using reverse_iterator = std::reverse_iterator<iterator>;
    using const_reverse_iterator = std::reverse_iterator<const_iterator>;

    list_node() = default;
    list_node(const list_node &) = delete;
    list_node(list_node &&) = delete;
    list_node &operator=(const list_node &) = delete;
    list_node &operator=(list_node &&) = delete;
    ~list_node() = default;

    constexpr iterator begin() noexcept { return iterator(wjr::next(this)); }
    constexpr const_iterator begin() const noexcept {
        return const_iterator(wjr::next(this));
    }
    constexpr const_iterator cbegin() const noexcept {
        return const_iterator(wjr::next(this));
    }

    constexpr iterator end() noexcept { return iterator(this); }
    constexpr const_iterator end() const noexcept { return const_iterator(this); }
    constexpr const_iterator cend() const noexcept { return const_iterator(this); }

    constexpr reverse_iterator rbegin() noexcept { return reverse_iterator(end()); }
    constexpr const_reverse_iterator rbegin() const noexcept {
        return const_reverse_iterator(end());
    }
    constexpr const_reverse_iterator crbegin() const noexcept {
        return const_reverse_iterator(end());
    }

    constexpr reverse_iterator rend() noexcept { return reverse_iterator(begin()); }
    constexpr const_reverse_iterator rend() const noexcept {
        return const_reverse_iterator(begin());
    }
    constexpr const_reverse_iterator crend() const noexcept {
        return const_reverse_iterator(begin());
    }

    constexpr list_node *next() noexcept { return wjr::next(this); }
    constexpr const list_node *next() const noexcept { return wjr::next(this); }

    constexpr list_node *prev() noexcept { return wjr::prev(this); }
    constexpr const list_node *prev() const noexcept { return wjr::prev(this); }

    constexpr bool empty() const noexcept { return wjr::empty(this); }

    template <typename U = Tag, WJR_REQUIRES(intrusive_use_hook_v<U>)>
    constexpr intrusive_hook_t<U> *operator->() noexcept {
        return static_cast<intrusive_hook_t<U> *>(this);
    }

    template <typename U = Tag, WJR_REQUIRES(intrusive_use_hook_v<U>)>
    constexpr const intrusive_hook_t<U> *operator->() const noexcept {
        return static_cast<const intrusive_hook_t<U> *>(this);
    }

    template <typename U = Tag, WJR_REQUIRES(intrusive_use_hook_v<U>)>
    constexpr intrusive_hook_t<U> &operator*() noexcept {
        return *operator->();
    }

    template <typename U = Tag, WJR_REQUIRES(intrusive_use_hook_v<U>)>
    constexpr const intrusive_hook_t<U> &operator*() const noexcept {
        return *operator->();
    }

    list_node *m_prev;
    list_node *m_next;
};

template <typename T>
constexpr void init(list_node<T> *node) noexcept {
    node->m_prev = node;
    node->m_next = node;
}

template <typename T>
constexpr void insert(list_node<T> *prev, list_node<T> *next,
                      list_node<T> *node) noexcept {
    prev->m_next = node;
    node->m_prev = prev;
    next->m_prev = node;
    node->m_next = next;
}

template <typename T>
constexpr void push_back(list_node<T> *head, list_node<T> *node) noexcept {
    insert(head->m_prev, head, node);
}

template <typename T>
constexpr void push_front(list_node<T> *head, list_node<T> *node) noexcept {
    insert(head, head->m_next, node);
}

template <typename T>
constexpr void remove_uninit(list_node<T> *node) noexcept {
    node->m_prev->m_next = node->m_next;
    node->m_next->m_prev = node->m_prev;
}

template <typename T>
constexpr bool empty(const list_node<T> *node) noexcept {
    return node->m_next == node;
}

template <typename T>
constexpr list_node<T> *next(list_node<T> *node) noexcept {
    return node->m_next;
}

template <typename T>
constexpr const list_node<T> *next(const list_node<T> *node) noexcept {
    return node->m_next;
}

template <typename T>
constexpr list_node<T> *prev(list_node<T> *node) noexcept {
    return node->m_prev;
}

template <typename T>
constexpr const list_node<T> *prev(const list_node<T> *node) noexcept {
    return node->m_prev;
}

template <typename T>
constexpr void replace_uninit(list_node<T> *from, list_node<T> *to) noexcept {
    to->m_prev = from->m_prev;
    to->m_next = from->m_next;
    from->m_prev->m_next = to;
    from->m_next->m_prev = to;
}

} // namespace wjr

#endif // WJR_CONTAINER_INTRUSIVE_LIST_HPP__
#ifndef WJR_MATH_BIT_HPP__
#define WJR_MATH_BIT_HPP__

// Already included
// Already included
// Already included

namespace wjr {

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR bool has_single_bit(T n) noexcept {
    return (n != 0) && is_zero_or_single_bit(n);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int countl_zero(T x) noexcept {
    // If not use __builtin_clz and use popcount, then don't need to handle zero.
#if WJR_HAS_BUILTIN(CLZ) || !WJR_HAS_BUILTIN(POPCOUNT) 
    if (WJR_UNLIKELY(x == 0)) {
        return std::numeric_limits<T>::digits;
    }
#endif

    return clz(x);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int countr_zero(T x) noexcept {
    // If not use __builtin_ctz and use popcount, then don't need to handle zero.
#if WJR_HAS_BUILTIN(CTZ) || !WJR_HAS_BUILTIN(POPCOUNT) 
    if (WJR_UNLIKELY(x == 0)) {
        return std::numeric_limits<T>::digits;
    }
#endif

    return ctz(x);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int countl_one(T x) noexcept {
    return countl_zero(static_cast<T>(~x));
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int countr_one(T x) noexcept {
    return countr_zero(static_cast<T>(~x));
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int bit_width(T x) noexcept {
    return std::numeric_limits<T>::digits - countl_zero(x);
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 T bit_ceil(T x) noexcept {
    if (x <= 1) {
        return T(1);
    }
    if constexpr (std::is_same_v<T, decltype(+x)>) {
        return T(1) << bit_width(T(x - 1));
    } else {
        constexpr int offset_for_ub =
            std::numeric_limits<unsigned>::digits - std::numeric_limits<T>::digits;
        return T(1 << (bit_width(T(x - 1)) + offset_for_ub) >> offset_for_ub);
    }
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 T bit_floor(T x) noexcept {
    if (x != 0) {
        return T{1} << (bit_width(x) - 1);
    }
    return 0;
}

template <typename To, typename From,
          WJR_REQUIRES(sizeof(To) == sizeof(From) && std::is_trivially_copyable_v<From> &&
                       std::is_trivially_copyable_v<To>)>
WJR_PURE WJR_INTRINSIC_INLINE To bit_cast(const From &src) noexcept {
    static_assert(std::is_trivially_constructible_v<To>, "");
    To dst;
    std::memcpy(&dst, &src, sizeof(To));
    return dst;
}

} // namespace wjr

#endif // WJR_MATH_BIT_HPP__
// Already included

namespace wjr {

struct automatic_free_pool {
    struct chunk : list_node<intrusive_tag<chunk>> {
        chunk() = default;
        chunk(const chunk &) = delete;
        chunk(chunk &&) = default;
        chunk &operator=(const chunk &) = delete;
        chunk &operator=(chunk &&) = delete;
        ~chunk() = default;
    };

    automatic_free_pool() noexcept { init(&head); }
    ~automatic_free_pool() noexcept {
        for (auto iter = head.begin(); iter != head.end();) {
            const auto now = iter++;
            chunk *const node = &**now;
            free(node);
        }
    }

    automatic_free_pool(const automatic_free_pool &) = delete;
    automatic_free_pool(automatic_free_pool &&) = delete;
    automatic_free_pool &operator=(const automatic_free_pool &) = delete;
    automatic_free_pool &operator=(automatic_free_pool &&) = delete;

    WJR_MALLOC void *allocate(size_t n) noexcept {
        auto *const ptr = static_cast<chunk *>(malloc(n + sizeof(chunk)));
        push_back(&head, ptr);
        return reinterpret_cast<char *>(ptr) + sizeof(chunk);
    }

    void deallocate(void *ptr) noexcept {
        auto *const node =
            reinterpret_cast<chunk *>(static_cast<char *>(ptr) - sizeof(chunk));
        remove_uninit(node);
        free(node);
    }

    static automatic_free_pool &get_instance() noexcept {
        static thread_local automatic_free_pool instance;
        return instance;
    }

    chunk head;
};

class __default_alloc_template__ {
    union obj {
        union obj *free_list_link;
        char client_data[1];
    };

    WJR_CONST static constexpr size_t __round_up(size_t bytes) noexcept {
        return (((bytes) + 2048 - 1) & ~(2048 - 1));
    }

    WJR_CONST static WJR_CONSTEXPR20 unsigned int
    __get_index(unsigned int bytes) noexcept {
        return static_cast<unsigned int>(
            bit_width<uint16_t>(static_cast<uint16_t>((bytes - 1) >> 3)));
    }

    WJR_CONST static constexpr unsigned int __get_size(unsigned int idx) noexcept {
        return static_cast<unsigned int>(1) << (idx + 3);
    }

    static automatic_free_pool &get_chunk() noexcept {
        return automatic_free_pool::get_instance();
    }

    struct object {
        WJR_MALLOC void *__small_allocate_impl(unsigned int idx) noexcept {
            obj *volatile *const my_free_list = free_list + idx;
            obj *const result = *my_free_list;
            if (WJR_LIKELY(result != nullptr)) {
                *my_free_list = result->free_list_link;
                return result;
            }

            return refill(idx);
        }

        WJR_INTRINSIC_INLINE allocation_result<void *>
        __small_allocate_at_least(unsigned int n) noexcept {
            const unsigned int idx = __get_index(n);
            const size_t size = __get_size(idx);
            return {__small_allocate_impl(idx), size};
        }

        WJR_MALLOC void *__small_allocate(unsigned int n) noexcept {
            const unsigned int idx = __get_index(n);
            return __small_allocate_impl(idx);
        }

        WJR_INTRINSIC_INLINE void __small_deallocate(void *p, unsigned int n) noexcept {
            auto *const q = static_cast<obj *>(p);
            obj *volatile *const my_free_list = free_list + __get_index(n);
            q->free_list_link = *my_free_list;
            *my_free_list = q;
        }

        // n must be > 0
        WJR_INTRINSIC_INLINE allocation_result<void *>
        allocate_at_least(size_t n) noexcept {
            if (WJR_LIKELY(n <= 16384)) {
                return __small_allocate_at_least(static_cast<unsigned int>(n));
            }

            return {malloc(n), n};
        }

        // n must be > 0
        WJR_MALLOC WJR_INTRINSIC_INLINE void *allocate(size_t n) noexcept {
            if (WJR_LIKELY(n <= 16384)) {
                return __small_allocate(static_cast<unsigned int>(n));
            }

            return malloc(n);
        }

        // p must not be 0
        WJR_INTRINSIC_INLINE void deallocate(void *p, size_t n) noexcept {
            if (WJR_LIKELY(n <= 16384)) {
                return __small_deallocate(p, static_cast<unsigned int>(n));
            }

            free(p);
        }

        allocation_result<void *> chunk_allocate(size_t n) noexcept {
            if (WJR_LIKELY(n <= 16384)) {
                return __small_allocate_at_least(static_cast<unsigned int>(n));
            }

            return {get_chunk().allocate(n), n};
        }

        // p must not be 0
        WJR_INTRINSIC_INLINE void chunk_deallocate(void *p, size_t n) noexcept {
            if (WJR_LIKELY(n <= 16384)) {
                return __small_deallocate(p, static_cast<unsigned int>(n));
            }

            get_chunk().deallocate(p);
        }

    private:
        // Allocates a chunk for nobjs of size "size".  nobjs may be reduced
        // if it is inconvenient to allocate the requested number.
        WJR_MALLOC char *chunk_alloc(unsigned int idx, unsigned int &nobjs) noexcept;

        // Returns an object of size n, and optionally adds to size n free list.
        WJR_MALLOC void *refill(unsigned int idx) noexcept;

        obj *volatile free_list[12] = {nullptr};
        char *start_free = nullptr;
        char *end_free = nullptr;
        size_t heap_size = 0;
    };

public:
    static object &get_instance() noexcept {
        static thread_local object instance;
        return instance;
    }

    // n must be > 0
    static allocation_result<void *> allocate_at_least(size_t n) noexcept {
        return get_instance().allocate_at_least(n);
    }

    WJR_MALLOC static void *allocate(size_t n) noexcept {
        return get_instance().allocate(n);
    }

    // p must not be 0
    static void deallocate(void *p, size_t n) noexcept {
        get_instance().deallocate(p, n);
    }

    // n must be > 0
    static allocation_result<void *> chunk_allocate_at_least(size_t n) noexcept {
        return get_instance().chunk_allocate(n);
    }

    // p must not be 0
    static void chunk_deallocate(void *p, size_t n) noexcept {
        get_instance().chunk_deallocate(p, n);
    }
};

template <typename Ty>
class memory_pool {
private:
    using allocator_type = __default_alloc_template__;

public:
    using value_type = Ty;
    using size_type = size_t;
    using difference_type = ptrdiff_t;
    using propagate_on_container_move_assignment = std::true_type;
    using is_always_equal = std::true_type;
    using is_trivially_allocator = std::true_type;

    template <typename Other>
    struct rebind {
        using other = memory_pool<Other>;
    };

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(memory_pool);

    template <typename Other>
    constexpr memory_pool(const memory_pool<Other> &) noexcept {}

    WJR_NODISCARD WJR_CONSTEXPR20 allocation_result<Ty *>
    allocate_at_least(size_type n) const noexcept {
        const auto ret = allocator_type::allocate_at_least(n * sizeof(Ty));
        return {static_cast<Ty *>(ret.ptr), ret.count / sizeof(Ty)};
    }

    WJR_NODISCARD WJR_CONSTEXPR20 allocation_result<Ty *>
    chunk_allocate_at_least(size_type n) const noexcept {
        const auto ret = allocator_type::chunk_allocate_at_least(n * sizeof(Ty));
        return {static_cast<Ty *>(ret.ptr), ret.count / sizeof(Ty)};
    }

    WJR_NODISCARD WJR_CONSTEXPR20 WJR_MALLOC Ty *allocate(size_type n) const noexcept {
        return static_cast<Ty *>(allocator_type::allocate(n * sizeof(Ty)));
    }

    WJR_CONSTEXPR20 void deallocate(Ty *ptr, size_type n) const noexcept {
        return allocator_type::deallocate(static_cast<void *>(ptr), sizeof(Ty) * n);
    }

    /**
     * @details Allocate memory, don't need to deallocate it until the thread exits.    \n
     * Automatically deallocate memory when the thread exits.                          \n
     * Used in thread_local memory pool that only needs to allocate memory once and    \n
     * deallocate it when the thread exits.                                            \n
     *
     */
    WJR_NODISCARD WJR_CONSTEXPR20 WJR_MALLOC Ty *
    chunk_allocate(size_type n) const noexcept {
        return chunk_allocate_at_least(n).ptr;
    }

    WJR_CONSTEXPR20 void chunk_deallocate(Ty *ptr, size_type n) const noexcept {
        return allocator_type::chunk_deallocate(static_cast<void *>(ptr), sizeof(Ty) * n);
    }

    constexpr size_t max_size() const noexcept {
        return static_cast<size_t>(-1) / sizeof(Ty);
    }
};

template <typename T, typename U>
constexpr bool operator==(const memory_pool<T> &, const memory_pool<U> &) noexcept {
    return true;
}

template <typename T, typename U>
constexpr bool operator!=(const memory_pool<T> &, const memory_pool<U> &) noexcept {
    return false;
}

} // namespace wjr

#endif // WJR_MEMORY_MEMORY_POOL_HPP__
#ifndef WJR_MEMORY_TEMPORARY_VALUE_ALLOCATOR_HPP__
#define WJR_MEMORY_TEMPORARY_VALUE_ALLOCATOR_HPP__

#ifndef WJR_MEMORY_UNINITIALIZED_HPP__
#define WJR_MEMORY_UNINITIALIZED_HPP__

/**
 * @file uninitialized.hpp
 * @brief The header file for uninitialized memory operations using allocator.
 *
 * @version 0.0.1
 * @date 2024-03-18
 *
 */

#ifndef WJR_CRTP_TRIVIALLY_ALLOCATOR_BASE_HPP__
#define WJR_CRTP_TRIVIALLY_ALLOCATOR_BASE_HPP__

// Already included

namespace wjr {

WJR_REGISTER_HAS_TYPE(is_trivially_allocator,
                      std::declval<typename Alloc::is_trivially_allocator>(), Alloc);
WJR_REGISTER_HAS_TYPE(
    is_trivially_allocator_constructible,
    std::declval<typename Alloc::is_trivially_allocator_constructible>(), Alloc);

WJR_REGISTER_HAS_TYPE(is_trivially_allocator_destructible,
                      std::declval<typename Alloc::is_trivially_allocator_destructible>(),
                      Alloc);

/// @private
template <typename Alloc, typename = void>
struct __is_trivially_allocator_impl : std::false_type {};

/// @private
template <typename Alloc>
struct __is_trivially_allocator_impl<
    Alloc, std::enable_if_t<has_is_trivially_allocator_v<Alloc>>>
    : Alloc::is_trivially_allocator {};

/**
 * @brief Default construct, destruct allocator.
 *
 * @details If `Alloc::is_trivially_allocator` is not defined or
 * `Alloc::is_trivially_allocator` is `std::false_type`, derive from `std::false_type`. \n
 * If is_trivially_allocator_v is true, then `construct_at_using_allocator` and
 * `destroy_at_using_allocator` are same as `construct_at` and `destroy_at`.
 *
 */
template <typename Alloc>
struct is_trivially_allocator : __is_trivially_allocator_impl<Alloc> {};

template <typename T>
struct is_trivially_allocator<std::allocator<T>> : std::true_type {};

template <typename Alloc>
inline constexpr bool is_trivially_allocator_v = is_trivially_allocator<Alloc>::value;

/// @private
template <typename Alloc, typename = void>
struct __is_trivially_allocator_constructible_impl : std::false_type {};

/// @private
template <typename Alloc>
struct __is_trivially_allocator_constructible_impl<
    Alloc, std::enable_if_t<has_is_trivially_allocator_constructible_v<Alloc>>>
    : Alloc::is_trivially_allocator_constructible {};

template <typename Alloc>
struct is_trivially_allocator_constructible
    : std::disjunction<__is_trivially_allocator_constructible_impl<Alloc>,
                       is_trivially_allocator<Alloc>> {};

template <typename Alloc>
inline constexpr bool is_trivially_allocator_constructible_v =
    is_trivially_allocator_constructible<Alloc>::value;

/// @private
template <typename Alloc, typename = void>
struct __is_trivially_allocator_destructible_impl : std::false_type {};

/// @private
template <typename Alloc>
struct __is_trivially_allocator_destructible_impl<
    Alloc, std::enable_if_t<has_is_trivially_allocator_destructible_v<Alloc>>>
    : Alloc::is_trivially_allocator_destructible {};

template <typename Alloc>
struct is_trivially_allocator_destructible
    : std::disjunction<__is_trivially_allocator_destructible_impl<Alloc>,
                       is_trivially_allocator<Alloc>> {};

template <typename Alloc>
inline constexpr bool is_trivially_allocator_destructible_v =
    is_trivially_allocator_destructible<Alloc>::value;

template <typename Alloc>
struct trivially_allocator_traits {
    using is_trivially = is_trivially_allocator<Alloc>;
    using is_trivially_constructible = is_trivially_allocator_constructible<Alloc>;
    using is_trivially_destructible = is_trivially_allocator_destructible<Alloc>;
};

} // namespace wjr

#endif // WJR_CRTP_TRIVIALLY_ALLOCATOR_BASE_HPP__
#ifndef WJR_MEMORY_ALIGNED_STORAGE_HPP__
#define WJR_MEMORY_ALIGNED_STORAGE_HPP__

/**
 * @file union_storage.hpp
 * @author wjr
 * @todo change to use enable_special_members_ctrl_base.
 * @version 0.1
 * @date 2024-07-14
 *
 * @copyright Copyright (c) 2024
 *
 */

#ifndef WJR_MEMORY_UNION_STORAGE_HPP__
#define WJR_MEMORY_UNION_STORAGE_HPP__

// Already included

namespace wjr {

template <typename T, typename U, typename Tag>
using __union2_storage_enabler_selector = enable_special_members_base<
    true, true,
    std::is_trivially_copy_constructible_v<T> &&
        std::is_trivially_copy_constructible_v<U>,
    std::is_trivially_move_constructible_v<T> &&
        std::is_trivially_move_constructible_v<U>,
    std::is_trivially_copy_assignable_v<T> && std::is_trivially_copy_assignable_v<U>,
    std::is_trivially_move_assignable_v<T> && std::is_trivially_move_assignable_v<U>,
    Tag>;

template <typename T, typename U, bool Constructor, bool Destructor>
class __union2_storage_base;

#define WJR_REGISTER_UNION_BASE(CON, DES)                                                \
    template <typename T, typename U>                                                    \
    class __union2_storage_base<T, U, CON, DES>                                          \
        : __union2_storage_enabler_selector<T, U,                                        \
                                            __union2_storage_base<T, U, CON, DES>> {     \
        using Mybase =                                                                   \
            __union2_storage_enabler_selector<T, U,                                      \
                                              __union2_storage_base<T, U, CON, DES>>;    \
                                                                                         \
    public:                                                                              \
        constexpr __union2_storage_base() WJR_PP_BOOL_IF(CON, = default, noexcept {});   \
                                                                                         \
        template <typename... Args>                                                      \
        constexpr __union2_storage_base(                                                 \
            std::in_place_index_t<0>,                                                    \
            Args &&...args) noexcept(std::is_nothrow_constructible_v<T, Args...>)        \
            : first(std::forward<Args>(args)...) {}                                      \
                                                                                         \
        template <typename... Args>                                                      \
        constexpr __union2_storage_base(                                                 \
            std::in_place_index_t<1>,                                                    \
            Args &&...args) noexcept(std::is_nothrow_constructible_v<U, Args...>)        \
            : second(std::forward<Args>(args)...) {}                                     \
                                                                                         \
        ~__union2_storage_base() WJR_PP_BOOL_IF(DES, = default, noexcept {});            \
                                                                                         \
        union {                                                                          \
            T first;                                                                     \
            U second;                                                                    \
        };                                                                               \
    }

WJR_REGISTER_UNION_BASE(0, 0);
WJR_REGISTER_UNION_BASE(0, 1);
WJR_REGISTER_UNION_BASE(1, 0);
WJR_REGISTER_UNION_BASE(1, 1);

#undef WJR_REGISTER_UNION_BASE

template <typename T, typename U>
using __union2_storage_base_selector =
    __union2_storage_base<T, U,
                          std::is_trivially_default_constructible_v<T> &&
                              std::is_trivially_default_constructible_v<U>,
                          std::is_trivially_destructible_v<T> &&
                              std::is_trivially_destructible_v<U>>;

template <typename T, typename U>
class union2_storage : public __union2_storage_base_selector<T, U> {
    using Mybase = __union2_storage_base_selector<T, U>;

public:
    using Mybase::Mybase;
};

} // namespace wjr

#endif // WJR_MEMORY_UNION_STORAGE_HPP__

namespace wjr {

template <typename T>
struct __aligned_storage_t {
    alignas(T) char buf[sizeof(T)];
};

template <typename T>
class aligned_storage : union2_storage<T, __aligned_storage_t<T>> {
    using Mybase = union2_storage<T, __aligned_storage_t<T>>;

public:
    using Mybase::Mybase;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(aligned_storage);

    template <typename... Args, WJR_REQUIRES(std::is_constructible_v<T, Args...>)>
    constexpr aligned_storage(Args &&...args) noexcept(
        std::is_nothrow_constructible_v<T, Args...>)
        : Mybase(std::in_place_index<0>, std::forward<Args>(args)...) {}

    constexpr T &operator*() & noexcept { return Mybase::first; }
    constexpr const T &operator*() const & noexcept { return Mybase::first; }
    constexpr T &&operator*() && noexcept { return static_cast<T &&>(operator*()); }
    constexpr const T &&operator*() const && noexcept {
        return static_cast<const T &&>(operator*());
    }

    constexpr T *get() noexcept { return std::addressof(Mybase::first); }
    constexpr const T *get() const noexcept { return std::addressof(Mybase::first); }

    constexpr T *operator->() noexcept { return get(); }
    constexpr const T *operator->() const noexcept { return get(); }
};

} // namespace wjr

#endif // WJR_MEMORY_ALIGNED_STORAGE_HPP__
// Already included

namespace wjr {

template <typename Iter, typename... Args>
WJR_CONSTEXPR20 void construct_at(Iter iter, Args &&...args) noexcept(
    std::is_nothrow_constructible_v<iterator_value_t<Iter>, Args...>) {
    ::new (static_cast<void *>(wjr::to_address(iter)))
        iterator_value_t<Iter>(std::forward<Args>(args)...);
}

template <typename Iter>
WJR_CONSTEXPR20 void construct_at(Iter iter, dctor_t) noexcept(
    std::is_nothrow_default_constructible_v<iterator_value_t<Iter>>) {
    ::new (static_cast<void *>(wjr::to_address(iter))) iterator_value_t<Iter>;
}

template <typename Iter, typename Alloc, typename... Args>
WJR_CONSTEXPR20 void uninitialized_construct_using_allocator(Iter iter, Alloc &alloc,
                                                             Args &&...args) {
    if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
        (construct_at)(iter, std::forward<Args>(args)...);
    } else {
        std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(iter),
                                                std::forward<Args>(args)...);
    }
}

template <typename Iter, typename Alloc>
WJR_CONSTEXPR20 void uninitialized_construct_using_allocator(Iter iter, Alloc &alloc,
                                                             dctor_t) {
    if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
        (construct_at)(iter, dctor_t{});
    } else {
        std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(iter));
    }
}

template <typename InputIt, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt uninitialized_copy_using_allocator(InputIt first, InputIt last,
                                                            OutputIt d_first,
                                                            Alloc &alloc) {
    if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
        return std::uninitialized_copy(first, last, d_first);
    } else {
        for (; first != last; ++first, ++d_first) {
            std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(d_first),
                                                    *first);
        }
        return d_first;
    }
}

/// @private
template <typename InputIt, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt __uninitialized_copy_restrict_using_allocator_impl_aux(
    add_restrict_t<InputIt> first, add_restrict_t<InputIt> last,
    add_restrict_t<OutputIt> d_first, Alloc &alloc) {
    return uninitialized_copy_using_allocator(first, last, d_first, alloc);
}

/// @private
template <typename InputIt, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt __uninitialized_copy_restrict_using_allocator_impl(
    InputIt first, InputIt last, OutputIt d_first, Alloc &alloc) {
    return __uninitialized_copy_restrict_using_allocator_impl_aux<InputIt, OutputIt,
                                                                  Alloc>(first, last,
                                                                         d_first, alloc);
}

template <typename InputIt, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt uninitialized_copy_restrict_using_allocator(InputIt first,
                                                                     InputIt last,
                                                                     OutputIt d_first,
                                                                     Alloc &alloc) {
    const auto __first = to_contiguous_address(first);
    const auto __last = to_contiguous_address(last);
    if constexpr (is_contiguous_iterator_v<OutputIt>) {
        const auto __d_first = wjr::to_address(d_first);
        const auto __d_last = __uninitialized_copy_restrict_using_allocator_impl(
            __first, __last, __d_first, alloc);
        return std::next(d_first, std::distance(__d_first, __d_last));
    } else {
        return __uninitialized_copy_restrict_using_allocator_impl(__first, __last,
                                                                  d_first, alloc);
    }
}

template <typename InputIt, typename Size, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt uninitialized_copy_n_using_allocator(InputIt first, Size n,
                                                              OutputIt d_first,
                                                              Alloc &alloc) {
    if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
        return std::uninitialized_copy_n(first, n, d_first);
    } else {
        for (; n > 0; ++first, ++d_first, --n) {
            std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(d_first),
                                                    *first);
        }
        return d_first;
    }
}

/// @private
template <typename InputIt, typename Size, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt __uninitialized_copy_n_restrict_using_allocator_impl_aux(
    add_restrict_t<InputIt> first, Size n, add_restrict_t<OutputIt> d_first,
    Alloc &alloc) {
    return uninitialized_copy_n_using_allocator(first, n, d_first, alloc);
}

/// @private
template <typename InputIt, typename Size, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt __uninitialized_copy_n_restrict_using_allocator_impl(
    InputIt first, Size n, OutputIt d_first, Alloc &alloc) {
    return __uninitialized_copy_n_restrict_using_allocator_impl_aux<InputIt, Size,
                                                                    OutputIt, Alloc>(
        first, n, d_first, alloc);
}

template <typename InputIt, typename Size, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt uninitialized_copy_n_restrict_using_allocator(InputIt first,
                                                                       Size n,
                                                                       OutputIt d_first,
                                                                       Alloc &alloc) {
    const auto __first = to_contiguous_address(first);
    if constexpr (is_contiguous_iterator_v<OutputIt>) {
        const auto __d_first = wjr::to_address(d_first);
        const auto __d_last = __uninitialized_copy_n_restrict_using_allocator_impl(
            __first, n, __d_first, alloc);
        return std::next(d_first, std::distance(__d_first, __d_last));
    } else {
        return __uninitialized_copy_n_restrict_using_allocator_impl(__first, n, d_first,
                                                                    alloc);
    }
}

template <typename InputIt, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt uninitialized_move_using_allocator(InputIt first, InputIt last,
                                                            OutputIt d_first,
                                                            Alloc &alloc) {
    return uninitialized_copy_using_allocator(
        std::make_move_iterator(first), std::make_move_iterator(last), d_first, alloc);
}

template <typename InputIt, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt uninitialized_move_restrict_using_allocator(InputIt first,
                                                                     InputIt last,
                                                                     OutputIt d_first,
                                                                     Alloc &alloc) {
    return uninitialized_copy_restrict_using_allocator(
        std::make_move_iterator(first), std::make_move_iterator(last), d_first, alloc);
}

template <typename InputIt, typename Size, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt uninitialized_move_n_using_allocator(InputIt first, Size n,
                                                              OutputIt d_first,
                                                              Alloc &alloc) {
    return uninitialized_copy_n_using_allocator(std::make_move_iterator(first), n,
                                                d_first, alloc);
}

template <typename InputIt, typename Size, typename OutputIt, typename Alloc>
WJR_CONSTEXPR20 OutputIt uninitialized_move_n_restrict_using_allocator(InputIt first,
                                                                       Size n,
                                                                       OutputIt d_first,
                                                                       Alloc &alloc) {
    return uninitialized_copy_n_restrict_using_allocator(std::make_move_iterator(first),
                                                         n, d_first, alloc);
}

template <typename Iter, typename Alloc>
WJR_CONSTEXPR20 void
uninitialized_default_construct_using_allocator(Iter first, Iter last, Alloc &alloc) {
    if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
        std::uninitialized_default_construct(first, last);
    } else {
        using value_type = iterator_value_t<Iter>;
        if constexpr (!std::is_trivially_default_constructible_v<value_type>) {
            for (; first != last; ++first) {
                std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(first));
            }
        }
    }
}

template <typename Iter, typename Size, typename Alloc>
WJR_CONSTEXPR20 void uninitialized_default_construct_n_using_allocator(Iter first, Size n,
                                                                       Alloc &alloc) {
    if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
        std::uninitialized_default_construct_n(first, n);
    } else {
        using value_type = iterator_value_t<Iter>;
        if constexpr (!std::is_trivially_default_constructible_v<value_type>) {
            for (; n > 0; ++first, --n) {
                std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(first),
                                                        value_type());
            }
        }
    }
}

template <typename Iter, typename Alloc>
WJR_CONSTEXPR20 void uninitialized_value_construct_using_allocator(Iter first, Iter last,
                                                                   Alloc &alloc) {
    if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
        std::uninitialized_value_construct(first, last);
    } else {
        for (; first != last; ++first) {
            std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(first));
        }
    }
}

template <typename Iter, typename Size, typename Alloc>
WJR_CONSTEXPR20 void uninitialized_value_construct_n_using_allocator(Iter first, Size n,
                                                                     Alloc &alloc) {
    if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
        std::uninitialized_value_construct_n(first, n);
    } else {
        for (; n > 0; ++first, --n) {
            std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(first));
        }
    }
}

/**
 * @brief Fill the range [first, last) with value using allocator.
 *
 * @tparam T The value type. Use `dctor_t` to default construct the
 * elements. Use `vctor_t` to value construct the elements.
 */
template <typename Iter, typename Alloc, typename T>
WJR_CONSTEXPR20 void uninitialized_fill_using_allocator(Iter first, Iter last,
                                                        Alloc &alloc, const T &value) {
    if constexpr (std::is_same_v<T, dctor_t>) {
        uninitialized_default_construct_using_allocator(first, last, alloc);
    } else if constexpr (std::is_same_v<T, vctor_t>) {
        uninitialized_value_construct_using_allocator(first, last, alloc);
    } else {
        if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
            std::uninitialized_fill(first, last, value);
        } else {
            for (; first != last; ++first) {
                std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(first),
                                                        value);
            }
        }
    }
}

/**
 * @brief Fill the range [first, first + n) with value using allocator.
 *
 * @tparam T The value type. Use `dctor_t` to default construct the
 * elements. Use `vctor_t` to value construct the elements.
 */
template <typename Iter, typename Size, typename Alloc, typename T>
WJR_CONSTEXPR20 void uninitialized_fill_n_using_allocator(Iter first, Size n,
                                                          Alloc &alloc, const T &value) {
    if constexpr (std::is_same_v<T, dctor_t>) {
        uninitialized_default_construct_n_using_allocator(first, n, alloc);
    } else if constexpr (std::is_same_v<T, vctor_t>) {
        uninitialized_value_construct_n_using_allocator(first, n, alloc);
    } else {
        if constexpr (is_trivially_allocator_constructible_v<Alloc>) {
            std::uninitialized_fill_n(first, n, value);
        } else {
            for (; n > 0; ++first, --n) {
                std::allocator_traits<Alloc>::construct(alloc, wjr::to_address(first),
                                                        value);
            }
        }
    }
}

template <typename Iter, typename Alloc>
WJR_CONSTEXPR20 void destroy_at_using_allocator(Iter iter, Alloc &alloc) {
    if constexpr (is_trivially_allocator_destructible_v<Alloc>) {
        std::destroy_at(wjr::to_address(iter));
    } else {
        std::allocator_traits<Alloc>::destroy(alloc, wjr::to_address(iter));
    }
}

template <typename Iter, typename Alloc>
WJR_CONSTEXPR20 void destroy_using_allocator(Iter first, Iter last, Alloc &alloc) {
    if constexpr (is_trivially_allocator_destructible_v<Alloc>) {
        std::destroy(first, last);
    } else {
        for (; first != last; ++first) {
            std::allocator_traits<Alloc>::destroy(alloc, wjr::to_address(first));
        }
    }
}

template <typename Iter, typename Size, typename Alloc>
WJR_CONSTEXPR20 void destroy_n_using_allocator(Iter first, Size n, Alloc &alloc) {
    if constexpr (is_trivially_allocator_v<Alloc>) {
        std::destroy_n(first, n);
    } else {
        for (; n > 0; ++first, --n) {
            std::allocator_traits<Alloc>::destroy(alloc, wjr::to_address(first));
        }
    }
}

#if WJR_DEBUG_LEVEL > 1
#define WJR_HAS_DEBUG_UNINITIALIZED_CHECKER WJR_HAS_DEF
#endif

/**
 * @class uninitialized
 *
 * @details Uninitialized object. Make trivially constructible and destructible of
 * any type.+
 *
 * @details Trivially constructible and destructible uninitialized object. Copy/move
 * constructor and assignment operators are deleted if the type is not trivially
 * copy/move constructible/assignable.
 *
 */
template <typename T>
class uninitialized : aligned_storage<T> {
    using Mybase = aligned_storage<T>;

public:
    using Mybase::Mybase;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(uninitialized);

    template <typename... Args, WJR_REQUIRES(std::is_constructible_v<Mybase, Args...>)>
    constexpr uninitialized(Args &&...args) noexcept(
        std::is_nothrow_constructible_v<Mybase, Args...>)
        : Mybase(std::forward<Args>(args)...) {
        checker_set(true);
    }

    constexpr uninitialized(dctor_t) noexcept : Mybase() {}

    template <typename... Args, WJR_REQUIRES(std::is_constructible_v<T, Args...>)>
    constexpr T &
    emplace(Args &&...args) noexcept(std::is_nothrow_constructible_v<Mybase, Args...>) {
        if constexpr (!std::is_trivially_destructible_v<T>) {
            check(false);
        }

        (construct_at)(get_unsafe(), std::forward<Args>(args)...);
        checker_set(true);
        return get();
    }

    constexpr void reset() noexcept(std::is_nothrow_destructible_v<T>) {
        if constexpr (!std::is_trivially_destructible_v<T>) {
            check(true);
        }

        std::destroy_at(get_unsafe());
        checker_set(false);
    }

    constexpr T &operator*() & noexcept {
        check(true);
        return Mybase::operator*();
    }
    constexpr const T &operator*() const & noexcept {
        check(true);
        return Mybase::operator*();
    }
    constexpr T &&operator*() && noexcept { return static_cast<T &&>(this->operator*()); }
    constexpr const T &&operator*() const && noexcept {
        return static_cast<const T &&>(this->operator*());
    }

    constexpr T *get_unsafe() noexcept { return Mybase::get(); }
    constexpr const T *get_unsafe() const noexcept { return Mybase::get(); }

    constexpr T *get() noexcept {
        check(true);
        return get_unsafe();
    }
    
    constexpr const T *get() const noexcept {
        check(true);
        return get_unsafe();
    }

    constexpr T *operator->() noexcept { return get(); }
    constexpr const T *operator->() const noexcept { return get(); }

private:
#if WJR_HAS_DEBUG(UNINITIALIZED_CHECKER)
    struct __checker {
        constexpr void set(bool value) noexcept { m_initialized = value; }
        constexpr void check(bool value) const noexcept {
            WJR_ASSERT_L0(m_initialized == value, "Expected ",
                          (value ? "initialized" : "uninitialized"),
                          " value when using an uninitialized object.");
        }

        ~__checker() noexcept {
            if constexpr (!std::is_trivially_destructible_v<T>) {
                check(false);
            }
        }

        bool m_initialized = false;
    };

    __checker m_checker;

    constexpr void checker_set(bool value) noexcept { m_checker.set(value); }
    constexpr void check(bool value) const noexcept { m_checker.check(value); }
#else
    constexpr static void checker_set(bool) noexcept {}
    constexpr static void check(bool) noexcept {}
#endif
};

/// @private
template <typename T, bool = true>
class __lazy_initialized_base : public uninitialized<T> {
    using Mybase = uninitialized<T>;

public:
    using Mybase::Mybase;
};

/// @private
template <typename T>
class __lazy_initialized_base<T, false> : public uninitialized<T> {
    using Mybase = uninitialized<T>;

public:
    using Mybase::Mybase;

    ~__lazy_initialized_base() noexcept(noexcept(Mybase::reset())) { Mybase::reset(); }
};

/// @private
template <typename T>
using lazy_initialized_base = __lazy_initialized_base<T,
#if WJR_HAS_DEBUG(UNINITIALIZED_CHECKER)
                                                      false
#else
                                                      std::is_trivially_destructible_v<T>
#endif
                                                      >;

template <typename T>
class lazy_initialized : public lazy_initialized_base<T> {
    using Mybase = lazy_initialized_base<T>;

public:
    using Mybase::Mybase;
};

} // namespace wjr

#endif // WJR_MEMORY_UNINITIALIZED_HPP__

namespace wjr {

template <typename Alloc>
class temporary_value_allocator {
public:
    using value_type = typename std::allocator_traits<Alloc>::value_type;
    using pointer = value_type *;
    using const_pointer = const value_type *;

    template <typename... Args>
    WJR_CONSTEXPR20 temporary_value_allocator(Alloc &_al, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<value_type, Args...>)
        : m_al(_al) {
        uninitialized_construct_using_allocator(get(), m_al, std::forward<Args>(args)...);
    }

    temporary_value_allocator(const temporary_value_allocator &) = delete;
    temporary_value_allocator(temporary_value_allocator &&) = delete;
    temporary_value_allocator &operator=(const temporary_value_allocator &) = delete;
    temporary_value_allocator &operator=(temporary_value_allocator &&) = delete;

    ~temporary_value_allocator() noexcept(noexcept(
        destroy_at_using_allocator(std::declval<pointer>(), std::declval<Alloc &>()))) {
        destroy_at_using_allocator(get(), m_al);
    }

    pointer get() noexcept { return m_storage.get(); }
    const_pointer get() const noexcept { return m_storage.get(); }

private:
    Alloc &m_al;
    aligned_storage<value_type> m_storage;
};

template <typename Alloc, typename... Args>
temporary_value_allocator(Alloc &, Args &&...) -> temporary_value_allocator<Alloc>;

} // namespace wjr

#endif // WJR_MEMORY_TEMPORARY_VALUE_ALLOCATOR_HPP__

namespace wjr {

template <typename T, typename Alloc>
class vector_storage_traits {
    using _Alty = typename std::allocator_traits<Alloc>::template rebind_alloc<T>;
    using _Alty_traits = std::allocator_traits<_Alty>;

public:
    using value_type = T;
    using pointer = typename _Alty_traits::pointer;
    using const_pointer = typename _Alty_traits::const_pointer;
    using size_type = typename _Alty_traits::size_type;
    using difference_type = typename _Alty_traits::difference_type;
    using allocator_type = Alloc;
    using is_trivially_contiguous = std::true_type;
};

template <typename pointer, typename size_type>
class default_vector_size_reference {
public:
    default_vector_size_reference() = delete;
    default_vector_size_reference(const default_vector_size_reference &) = delete;
    default_vector_size_reference(default_vector_size_reference &&) = default;
    default_vector_size_reference &
    operator=(const default_vector_size_reference &) = delete;
    default_vector_size_reference &operator=(default_vector_size_reference &&) = default;
    ~default_vector_size_reference() = default;

    constexpr explicit default_vector_size_reference(pointer ptr, pointer &pos) noexcept
        : m_ptr(ptr), m_pos(pos) {}

    constexpr default_vector_size_reference &operator=(size_type size) noexcept {
        m_pos = m_ptr + size;
        return *this;
    }

    WJR_PURE constexpr operator size_type() const noexcept {
        return static_cast<size_type>(m_pos - m_ptr);
    }

    constexpr default_vector_size_reference &operator++() noexcept {
        ++m_pos;
        return *this;
    }

    constexpr default_vector_size_reference &operator--() noexcept {
        --m_pos;
        return *this;
    }

    constexpr default_vector_size_reference &operator+=(uint32_t size) noexcept {
        m_pos += size;
        return *this;
    }

    constexpr default_vector_size_reference &operator-=(uint32_t size) noexcept {
        m_pos -= size;
        return *this;
    }

private:
    pointer m_ptr;
    pointer &m_pos;
};

/// @private
template <typename pointer, typename size_type>
struct __unref_wrapper_helper<default_vector_size_reference<pointer, size_type>> {
    using type = uint32_t &;
};

/**
 * @brief Default vector storage
 *
 * @details Use one pointer ans two size_type currently.
 *
 */
template <typename T, typename Alloc>
class default_vector_storage {
    using _Alty = typename std::allocator_traits<Alloc>::template rebind_alloc<T>;
    using _Alty_traits = std::allocator_traits<_Alty>;

public:
    using storage_traits_type = vector_storage_traits<T, Alloc>;
    using value_type = typename storage_traits_type::value_type;
    using pointer = typename storage_traits_type::pointer;
    using const_pointer = typename storage_traits_type::const_pointer;
    using size_type = typename storage_traits_type::size_type;
    using difference_type = typename storage_traits_type::difference_type;
    using allocator_type = typename storage_traits_type::allocator_type;
    using is_reallocatable = std::true_type;

private:
    struct Data {
        pointer m_data = nullptr;
        pointer m_end = nullptr;
        pointer m_buffer = nullptr;
    };

    using data_type = Data;
    using size_ref = default_vector_size_reference<pointer, size_type>;

public:
    default_vector_storage() = default;

    default_vector_storage(const default_vector_storage &) = delete;
    default_vector_storage(default_vector_storage &&) = delete;
    default_vector_storage &operator=(const default_vector_storage &) = delete;
    default_vector_storage &operator=(default_vector_storage &&) = delete;

    ~default_vector_storage() = default;

    WJR_CONSTEXPR20 void
    destroy(_Alty &al) noexcept(std::is_nothrow_destructible_v<value_type>) {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(data() == nullptr)) {
            return;
        }

        if (WJR_BUILTIN_CONSTANT_P_TRUE(size() == 0)) {
            return;
        }

        destroy_using_allocator(m_storage.m_data, m_storage.m_end, al);
    }

    WJR_CONSTEXPR20 void destroy_and_deallocate(_Alty &al) noexcept(
        std::is_nothrow_destructible_v<value_type>) {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(data() == nullptr)) {
            return;
        }

        if (WJR_BUILTIN_CONSTANT_P_TRUE(capacity() == 0)) {
            return;
        }

        if (m_storage.m_data != nullptr) {
            WJR_ASSERT_ASSUME_L2(capacity() != 0);

            destroy_using_allocator(m_storage.m_data, m_storage.m_end, al);
            al.deallocate(m_storage.m_data, capacity());
        }
    }

    WJR_CONSTEXPR20 static void uninitialized_construct(
        default_vector_storage &other, size_type size, size_type capacity,
        _Alty &al) noexcept(noexcept(allocate_at_least(al, capacity))) {
        const auto result = allocate_at_least(al, capacity);

        other.m_storage = {
            result.ptr,
            result.ptr + size,
            result.ptr + result.count,
        };
    }

    WJR_CONSTEXPR20 void take_storage(default_vector_storage &other, _Alty &) noexcept {
        auto &other_storage = other.m_storage;
        m_storage = std::move(other_storage);
        other_storage = {};
    }

    WJR_CONSTEXPR20 void swap_storage(default_vector_storage &other, _Alty &) noexcept {
        std::swap(m_storage, other.m_storage);
    }

    WJR_PURE WJR_CONSTEXPR20 size_ref size() noexcept {
        return size_ref(m_storage.m_data, m_storage.m_end);
    }

    WJR_PURE WJR_CONSTEXPR20 size_type size() const noexcept {
        return m_storage.m_end - m_storage.m_data;
    }

    WJR_PURE WJR_CONSTEXPR20 size_type capacity() const noexcept {
        return m_storage.m_buffer - m_storage.m_data;
    }

    WJR_PURE WJR_CONSTEXPR20 pointer data() noexcept { return m_storage.m_data; }
    WJR_PURE WJR_CONSTEXPR20 const_pointer data() const noexcept {
        return m_storage.m_data;
    }

private:
    data_type m_storage;
};

template <typename T, size_t Capacity, typename Alloc>
class static_vector_storage {
    using _Alty = typename std::allocator_traits<Alloc>::template rebind_alloc<T>;
    using _Alty_traits = std::allocator_traits<_Alty>;

public:
    using storage_traits_type = vector_storage_traits<T, Alloc>;
    using value_type = typename storage_traits_type::value_type;
    using pointer = typename storage_traits_type::pointer;
    using const_pointer = typename storage_traits_type::const_pointer;
    using size_type = typename storage_traits_type::size_type;
    using difference_type = typename storage_traits_type::difference_type;
    using allocator_type = typename storage_traits_type::allocator_type;
    using is_reallocatable = std::false_type;

private:
    static constexpr auto max_alignment =
        std::max<size_type>(alignof(T), alignof(size_type));
    static constexpr bool __use_memcpy = is_trivially_allocator_constructible_v<Alloc> &&
                                         std::is_trivially_copyable_v<T> &&
                                         Capacity * sizeof(T) <= 64;

    struct Data {
        size_type m_size = 0;
        alignas(max_alignment) char m_data[Capacity * sizeof(T)];
    };

    using data_type = Data;

public:
    static_vector_storage() = default;

    static_vector_storage(const static_vector_storage &) = delete;
    static_vector_storage(static_vector_storage &&) = delete;
    static_vector_storage &operator=(const static_vector_storage &) = delete;
    static_vector_storage &operator=(static_vector_storage &&) = delete;

    ~static_vector_storage() = default;

    WJR_CONSTEXPR20 void
    destroy(_Alty &al) noexcept(std::is_nothrow_destructible_v<value_type>) {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(size() == 0)) {
            return;
        }

        const size_type __size = size();
        if (WJR_BUILTIN_CONSTANT_P_TRUE(__size == 0)) {
            return;
        }

        destroy_n_using_allocator(data(), size(), al);
    }

    WJR_CONSTEXPR20 void destroy_and_deallocate(_Alty &al) noexcept(
        std::is_nothrow_destructible_v<value_type>) {
        destroy(al);
    }

    WJR_CONSTEXPR20 static void
    uninitialized_construct(static_vector_storage &other, size_type size,
                            WJR_MAYBE_UNUSED size_type capacity, _Alty &) noexcept {
        WJR_ASSERT_ASSUME(capacity <= Capacity,
                          "capacity must be less than or equal to Capacity");
        other.m_storage.m_size = size;
    }

    WJR_CONSTEXPR20 void take_storage(static_vector_storage &other, _Alty &al) {
        auto &other_storage = other.m_storage;
        const auto lhs = data();
        const auto rhs = other.data();

        m_storage.m_size = other_storage.m_size;

        if constexpr (__use_memcpy) {
            if (other.size()) {
                __memcpy(lhs, rhs, Capacity);
            }
        } else {
            wjr::uninitialized_move_n_restrict_using_allocator(rhs, other_storage.m_size,
                                                               lhs, al);
        }

        other_storage.m_size = 0;
    }

    WJR_CONSTEXPR20 void swap_storage(static_vector_storage &other, _Alty &al) {
        auto &other_storage = other.m_storage;
        auto lhs = data();
        auto lsize = size();
        auto rhs = other.data();
        auto rsize = other.size();

        if (lsize && rsize) {
            m_storage.m_size = rsize;
            other_storage.m_size = lsize;

            T tmp[Capacity];
            if constexpr (__use_memcpy) {
                __memcpy(tmp, lhs, Capacity);
                __memcpy(lhs, rhs, Capacity);
                __memcpy(rhs, tmp, Capacity);
            } else {
                if (lsize > rsize) {
                    std::swap(lhs, rhs);
                    std::swap(lsize, rsize);
                }

                wjr::uninitialized_move_n_restrict_using_allocator(lhs, lsize, tmp, al);
                wjr::uninitialized_move_n_restrict_using_allocator(rhs, rsize, lhs, al);
                wjr::uninitialized_move_n_restrict_using_allocator(tmp, lsize, rhs, al);
            }
            return;
        } else if (rsize) {
            if constexpr (__use_memcpy) {
                __memcpy(lhs, rhs, Capacity);
            } else {
                wjr::uninitialized_move_n_restrict_using_allocator(rhs, rsize, lhs, al);
            }
            m_storage.m_size = rsize;
            other_storage.m_size = 0;
            return;
        } else if (lsize) {
            if constexpr (__use_memcpy) {
                __memcpy(rhs, lhs, Capacity);
            } else {
                wjr::uninitialized_move_n_restrict_using_allocator(lhs, lsize, rhs, al);
            }
            other_storage.m_size = lsize;
            m_storage.m_size = 0;
            return;
        } else {
            return;
        }
    }

    WJR_PURE WJR_CONSTEXPR20 size_type &size() noexcept { return m_storage.m_size; }
    WJR_PURE WJR_CONSTEXPR20 size_type size() const noexcept { return m_storage.m_size; }
    WJR_CONST constexpr size_type capacity() const noexcept { return Capacity; }

    WJR_PURE WJR_CONSTEXPR20 pointer data() noexcept {
        return reinterpret_cast<pointer>(m_storage.m_data);
    }
    WJR_PURE WJR_CONSTEXPR20 const_pointer data() const noexcept {
        return reinterpret_cast<const_pointer>(m_storage.m_data);
    }

private:
    static void __memcpy(pointer dst, const_pointer src, size_type count) noexcept {
        std::memcpy(dst, src, count * sizeof(T));
    }

    data_type m_storage;
};

template <typename T, typename Alloc>
class fixed_vector_storage {
    using _Alty = typename std::allocator_traits<Alloc>::template rebind_alloc<T>;
    using _Alty_traits = std::allocator_traits<_Alty>;

public:
    using storage_traits_type = vector_storage_traits<T, Alloc>;
    using value_type = typename storage_traits_type::value_type;
    using pointer = typename storage_traits_type::pointer;
    using const_pointer = typename storage_traits_type::const_pointer;
    using size_type = typename storage_traits_type::size_type;
    using difference_type = typename storage_traits_type::difference_type;
    using allocator_type = typename storage_traits_type::allocator_type;
    using is_reallocatable = std::false_type;

private:
    struct Data {
        pointer m_data = nullptr;
        pointer m_end = nullptr;
        pointer m_buffer = nullptr;
    };

    using data_type = Data;
    using size_ref = default_vector_size_reference<pointer, size_type>;

public:
    fixed_vector_storage() = default;

    fixed_vector_storage(const fixed_vector_storage &) = delete;
    fixed_vector_storage(fixed_vector_storage &&) = delete;
    fixed_vector_storage &operator=(const fixed_vector_storage &) = delete;
    fixed_vector_storage &operator=(fixed_vector_storage &&) = delete;

    ~fixed_vector_storage() = default;

private:
    WJR_PURE WJR_INTRINSIC_INLINE bool __is_null_data() const {
        return WJR_BUILTIN_CONSTANT_P_TRUE(data() == nullptr);
    }

    WJR_PURE WJR_INTRINSIC_INLINE bool __is_zero_size() const {
        return WJR_BUILTIN_CONSTANT_P_TRUE(size() == 0);
    }

    WJR_PURE WJR_INTRINSIC_INLINE bool __is_zero_capacity() const {
        return WJR_BUILTIN_CONSTANT_P_TRUE(capacity() == 0);
    }

public:
    WJR_CONSTEXPR20 void
    destroy(_Alty &al) noexcept(std::is_nothrow_destructible_v<value_type>) {
        if (__is_null_data() || __is_zero_size()) {
            return;
        }

        destroy_using_allocator(m_storage.m_data, m_storage.m_end, al);
    }

    WJR_CONSTEXPR20 void destroy_and_deallocate(_Alty &al) noexcept(
        std::is_nothrow_destructible_v<value_type>) {
        if (__is_null_data() || __is_zero_capacity()) {
            return;
        }

        if (m_storage.m_data != nullptr) {
            WJR_ASSERT_ASSUME_L2(capacity() != 0);

            destroy_using_allocator(m_storage.m_data, m_storage.m_end, al);
            al.deallocate(m_storage.m_data, capacity());
        }
    }

    WJR_CONSTEXPR20 static void uninitialized_construct(
        fixed_vector_storage &other, size_type size, size_type capacity,
        _Alty &al) noexcept(noexcept(allocate_at_least(al, capacity))) {
        const auto result = allocate_at_least(al, capacity);

        other.m_storage = {
            result.ptr,
            result.ptr + size,
            result.ptr + result.count,
        };
    }

    WJR_CONSTEXPR20 void take_storage(fixed_vector_storage &other, _Alty &) noexcept {
        auto &other_storage = other.m_storage;
        m_storage = std::move(other_storage);
        other_storage = {};
    }

    WJR_CONSTEXPR20 void swap_storage(fixed_vector_storage &other, _Alty &) noexcept {
        std::swap(m_storage, other.m_storage);
    }

    WJR_PURE WJR_CONSTEXPR20 size_ref size() noexcept {
        return size_ref(m_storage.m_data, m_storage.m_end);
    }

    WJR_PURE WJR_CONSTEXPR20 size_type size() const noexcept {
        return m_storage.m_end - m_storage.m_data;
    }

    WJR_PURE WJR_CONSTEXPR20 size_type capacity() const noexcept {
        return m_storage.m_buffer - m_storage.m_data;
    }

    WJR_PURE WJR_CONSTEXPR20 pointer data() noexcept { return m_storage.m_data; }
    WJR_PURE WJR_CONSTEXPR20 const_pointer data() const noexcept {
        return m_storage.m_data;
    }

private:
    data_type m_storage;
};

template <typename T, size_t Capacity, typename Alloc, typename STraits>
class __sso_vector_storage_impl {
    using _Alty = typename std::allocator_traits<Alloc>::template rebind_alloc<T>;
    using _Alty_traits = std::allocator_traits<_Alty>;

public:
    using storage_traits_type = STraits;
    using value_type = typename storage_traits_type::value_type;
    using pointer = typename storage_traits_type::pointer;
    using const_pointer = typename storage_traits_type::const_pointer;
    using size_type = typename storage_traits_type::size_type;
    using difference_type = typename storage_traits_type::difference_type;
    using allocator_type = typename storage_traits_type::allocator_type;
    using is_reallocatable = std::true_type;

private:
    static constexpr auto max_alignment = std::max<size_type>(
        alignof(T), std::max<size_type>(alignof(pointer), alignof(size_type)));

    struct __Data_test {
        pointer m_data;
        size_type m_size;
        union {
            size_type m_capacity;
            alignas(max_alignment) T m_storage[Capacity];
        };
    };

    static constexpr auto __sizeof_data = sizeof(__Data_test);
    static constexpr auto __offsetof_storage =
        __align_up(__align_up(sizeof(pointer), alignof(pointer)) +
                       __align_up(sizeof(size_type), alignof(size_type)),
                   max_alignment);

    static constexpr auto __max_capacity =
        (__sizeof_data - __offsetof_storage) / sizeof(T);
    static constexpr bool __use_memcpy = is_trivially_allocator_constructible_v<Alloc> &&
                                         std::is_trivially_copyable_v<T> &&
                                         __max_capacity * sizeof(T) <= 64;

    struct Data {
        Data() : m_capacity() {}
        Data(const Data &) = delete;
        Data &operator=(const Data &) = delete;
        ~Data() {}

        pointer m_data = m_storage;
        size_type m_size = 0;
        union {
            size_type m_capacity;
            alignas(max_alignment) T m_storage[__max_capacity];
        };
    };

    using data_type = Data;

public:
    __sso_vector_storage_impl() = default;

    __sso_vector_storage_impl(const __sso_vector_storage_impl &) = delete;
    __sso_vector_storage_impl(__sso_vector_storage_impl &&) = delete;
    __sso_vector_storage_impl &operator=(const __sso_vector_storage_impl &) = delete;
    __sso_vector_storage_impl &operator=(__sso_vector_storage_impl &&) = delete;

    ~__sso_vector_storage_impl() = default;

    WJR_CONSTEXPR20 void
    destroy(_Alty &al) noexcept(std::is_nothrow_destructible_v<value_type>) {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(size() == 0)) {
            return;
        }

        destroy_n_using_allocator(data(), size(), al);
    }

    WJR_CONSTEXPR20 void destroy_and_deallocate(_Alty &al) noexcept(
        std::is_nothrow_destructible_v<value_type>) {

        destroy(al);
        if (!__is_sso()) {
            WJR_ASSERT_ASSUME_L2(m_storage.m_capacity != 0);
            al.deallocate(data(), m_storage.m_capacity);
            m_storage.m_data = m_storage.m_storage;
        }
    }

    WJR_CONSTEXPR20 static void uninitialized_construct(__sso_vector_storage_impl &other,
                                                        size_type size,
                                                        size_type capacity, _Alty &al) {
        auto &storage = other.m_storage;
        if (capacity <= __max_capacity) {
            storage.m_size = size;
        } else {
            const auto result = allocate_at_least(al, capacity);

            storage.m_data = result.ptr;
            storage.m_size = size;
            storage.m_capacity = result.count;
        }
    }

    WJR_CONSTEXPR20 void take_storage(__sso_vector_storage_impl &other, _Alty &al) {
        auto &other_storage = other.m_storage;

        WJR_ASSERT_ASSUME_L2(__is_sso());

        if (other.__is_sso()) {
            m_storage.m_size = other_storage.m_size;

            if constexpr (__use_memcpy) {
                if (other.size()) {
                    __memcpy(m_storage.m_storage, other_storage.m_storage,
                             __max_capacity);
                }
            } else {
                wjr::uninitialized_move_n_restrict_using_allocator(
                    other_storage.m_storage, other.size(), m_storage.m_storage, al);
            }
        } else {
            m_storage.m_data = other_storage.m_data;
            m_storage.m_size = other_storage.m_size;
            m_storage.m_capacity = other_storage.m_capacity;

            other_storage.m_data = other_storage.m_storage;
        }

        other_storage.m_size = 0;
        WJR_ASSUME(other.__is_sso());
    }

    WJR_CONSTEXPR20 void swap_storage(__sso_vector_storage_impl &other, _Alty &al) {
        auto &storage = m_storage;
        auto &other_storage = other.m_storage;

        if (__is_sso()) {
            if (other.__is_sso()) {
                auto lhs = storage.m_storage;
                auto lsize = size();
                auto rhs = other_storage.m_storage;
                auto rsize = other.size();

                if (lsize && rsize) {
                    T tmp[__max_capacity];
                    if constexpr (__use_memcpy) {
                        __memcpy(tmp, lhs, __max_capacity);
                        __memcpy(lhs, rhs, __max_capacity);
                        __memcpy(rhs, tmp, __max_capacity);
                    } else {
                        if (lsize > rsize) {
                            std::swap(lhs, rhs);
                            std::swap(lsize, rsize);
                        }

                        wjr::uninitialized_move_n_restrict_using_allocator(lhs, lsize,
                                                                           tmp, al);
                        wjr::uninitialized_move_n_restrict_using_allocator(rhs, rsize,
                                                                           lhs, al);
                        wjr::uninitialized_move_n_restrict_using_allocator(tmp, lsize,
                                                                           rhs, al);
                    }
                } else if (rsize) {
                    if constexpr (__use_memcpy) {
                        __memcpy(lhs, rhs, __max_capacity);
                    } else {
                        wjr::uninitialized_move_n_restrict_using_allocator(rhs, rsize,
                                                                           lhs, al);
                    }
                    storage.m_size = rsize;
                    other_storage.m_size = 0;
                    return;
                } else if (lsize) {
                    if constexpr (__use_memcpy) {
                        __memcpy(rhs, lhs, __max_capacity);
                    } else {
                        wjr::uninitialized_move_n_restrict_using_allocator(lhs, lsize,
                                                                           rhs, al);
                    }
                    other_storage.m_size = lsize;
                    storage.m_size = 0;
                    return;
                } else {
                    return;
                }
            } else {
                const size_type __tmp_capacity = other_storage.m_capacity;
                if constexpr (__use_memcpy) {
                    if (size()) {
                        __memcpy(other_storage.m_storage, storage.m_storage,
                                 __max_capacity);
                    }
                } else {
                    wjr::uninitialized_move_n_restrict_using_allocator(
                        storage.m_storage, size(), other_storage.m_storage, al);
                }

                storage.m_data = other_storage.m_data;
                other_storage.m_data = other_storage.m_storage;
                storage.m_capacity = __tmp_capacity;
            }
        } else {
            const size_type __tmp_capacity = storage.m_capacity;
            if (other.__is_sso()) {
                if constexpr (__use_memcpy) {
                    if (other.size()) {
                        __memcpy(storage.m_storage, other_storage.m_storage,
                                 __max_capacity);
                    }
                } else {
                    wjr::uninitialized_move_n_restrict_using_allocator(
                        other_storage.m_storage, other.size(), storage.m_storage, al);
                }

                other_storage.m_data = storage.m_data;
                storage.m_data = storage.m_storage;
            } else {
                const auto __tmp_data = storage.m_data;
                storage.m_data = other_storage.m_data;
                other_storage.m_data = __tmp_data;
                storage.m_capacity = other_storage.m_capacity;
            }
            other_storage.m_capacity = __tmp_capacity;
        }

        const size_type __tmp_size = size();
        storage.m_size = other.size();
        other_storage.m_size = __tmp_size;
    }

    WJR_PURE WJR_CONSTEXPR20 size_type &size() noexcept { return m_storage.m_size; }
    WJR_PURE WJR_CONSTEXPR20 size_type size() const noexcept { return m_storage.m_size; }
    WJR_PURE WJR_CONSTEXPR20 size_type capacity() const noexcept {
        const size_type ret = __is_sso() ? __max_capacity : m_storage.m_capacity;
        WJR_ASSERT_ASSUME_L2(ret >= __max_capacity);
        return ret;
    }

    WJR_PURE WJR_CONSTEXPR20 pointer data() noexcept { return m_storage.m_data; }
    WJR_PURE WJR_CONSTEXPR20 const_pointer data() const noexcept {
        return m_storage.m_data;
    }

private:
    static void __memcpy(pointer dst, const_pointer src, size_type count) noexcept {
        std::memcpy(dst, src, count * sizeof(T));
    }

    WJR_PURE bool __is_sso() const noexcept {
        return m_storage.m_data == m_storage.m_storage;
    }

    data_type m_storage;
};

template <typename T, size_t Capacity, typename Alloc>
using sso_vector_storage =
    __sso_vector_storage_impl<T, Capacity, Alloc, vector_storage_traits<T, Alloc>>;

WJR_REGISTER_HAS_TYPE(vector_storage_shrink_to_fit,
                      std::declval<Storage>().shrink_to_fit(), Storage);

WJR_REGISTER_HAS_TYPE(vector_storage_empty, std::declval<Storage>().empty(), Storage);

WJR_REGISTER_HAS_TYPE(vector_storage_uninitialized_construct,
                      std::declval<Storage>().uninitialized_construct(
                          std::declval<Size>(), std::declval<Size>(),
                          std::declval<Alloc &>()),
                      Storage, Size, Alloc);

template <typename Storage>
struct basic_vector_traits {
    using value_type = typename Storage::value_type;
    using difference_type = typename Storage::difference_type;
    using pointer = typename Storage::pointer;
    using const_pointer = typename Storage::const_pointer;
    using reference = value_type &;
    using const_reference = const value_type &;
};

/**
 * @brief Customized vector by storage.
 *
 * @details Type of pointer is same as iterator.
 *
 */
template <typename Storage>
class basic_vector {
public:
    using value_type = typename Storage::value_type;
    using allocator_type = typename Storage::allocator_type;
    using storage_type = Storage;

private:
    using _Alty =
        typename std::allocator_traits<allocator_type>::template rebind_alloc<value_type>;
    using _Alty_traits = std::allocator_traits<_Alty>;

    using storage_fn_type = container_fn<_Alty>;
    using __get_size_t = decltype(std::declval<storage_type>().size());
    using IteratorTraits = basic_vector_traits<storage_type>;

    friend class container_fn<_Alty>;

public:
    static_assert(std::is_same_v<typename _Alty_traits::value_type, value_type>,
                  "allocator_type::value_type must be the same as value_type");

    using size_type = typename storage_type::size_type;
    using difference_type = typename storage_type::difference_type;
    using reference = value_type &;
    using const_reference = const value_type &;
    using pointer = typename Storage::pointer;
    using const_pointer = typename Storage::const_pointer;
    using iterator = contiguous_iterator_adapter<basic_vector, IteratorTraits>;
    using const_iterator =
        contiguous_const_iterator_adapter<basic_vector, IteratorTraits>;
    using reverse_iterator = std::reverse_iterator<iterator>;
    using const_reverse_iterator = std::reverse_iterator<const_iterator>;

    using storage_traits_type = typename storage_type::storage_traits_type;
    using is_trivially_contiguous = typename storage_traits_type::is_trivially_contiguous;
    using is_reallocatable = typename storage_type::is_reallocatable;

private:
    using STraits = storage_traits_type;

    static_assert(is_contiguous_iterator_v<iterator>, "");
    static_assert(is_contiguous_iterator_v<const_iterator>, "");

    static constexpr bool __storage_noexcept_destroy =
        noexcept(std::declval<storage_type>().destroy(std::declval<_Alty &>()));
    static constexpr bool __storage_noexcept_destroy_and_deallocate = noexcept(
        std::declval<storage_type>().destroy_and_deallocate(std::declval<_Alty &>()));
    static constexpr bool __storage_noexcept_take_storage =
        noexcept(std::declval<storage_type>().take_storage(std::declval<storage_type &>(),
                                                           std::declval<_Alty &>()));
    static constexpr bool __storage_noexcept_swap_storage =
        noexcept(std::declval<storage_type>().swap_storage(std::declval<storage_type &>(),
                                                           std::declval<_Alty &>()));

public:
    basic_vector() = default;

    WJR_CONSTEXPR20 explicit basic_vector(const allocator_type &al) noexcept(
        std::is_nothrow_constructible_v<_Alty, const allocator_type &>)
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {}

    WJR_CONSTEXPR20 explicit basic_vector(const size_type n,
                                          const allocator_type &al = allocator_type())
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {
        __construct_n(n, vctor);
    }

    WJR_CONSTEXPR20 basic_vector(size_type n, const value_type &val,
                                 const allocator_type &al = allocator_type())
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {
        __construct_n(n, val);
    }

private:
    template <typename _Alloc>
    WJR_CONSTEXPR20 basic_vector(const basic_vector &other, _Alloc &&al, in_place_empty_t)
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {
        const auto size = other.size();
        if (size != 0) {
            uninitialized_construct(size, other.capacity());
            wjr::uninitialized_copy_n_restrict_using_allocator(other.data(), size, data(),
                                                               __get_allocator());
        }
    }

    template <typename _Alloc>
    WJR_CONSTEXPR20
    basic_vector(basic_vector &&other, _Alloc &&al, in_place_empty_t) noexcept(
        std::is_nothrow_constructible_v<storage_type, _Alloc &&>
            &&__storage_noexcept_take_storage)
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {
        __take_storage(std::move(other));
    }

public:
    WJR_CONSTEXPR20 basic_vector(const basic_vector &other)
        : basic_vector(other,
                       _Alty_traits::select_on_container_copy_construction(
                           other.__get_allocator()),
                       in_place_empty) {}

    WJR_CONSTEXPR20 basic_vector(const basic_vector &other, const allocator_type &al)
        : basic_vector(other, al, in_place_empty) {}

    WJR_CONSTEXPR20 basic_vector(basic_vector &&other) noexcept(noexcept(basic_vector(
        std::move(other), std::move(other.__get_allocator()), in_place_empty)))
        : basic_vector(std::move(other), std::move(other.__get_allocator()),
                       in_place_empty) {}

    WJR_CONSTEXPR20 basic_vector(basic_vector &&other, const allocator_type &al) noexcept(
        noexcept(basic_vector(std::move(other), al, in_place_empty)))
        : basic_vector(std::move(other), al, in_place_empty) {}

    template <typename Iter, WJR_REQUIRES(is_iterator_v<Iter>)>
    WJR_CONSTEXPR20 basic_vector(Iter first, Iter last,
                                 const allocator_type &al = allocator_type())
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {
        __range_construct(to_contiguous_address(first), to_contiguous_address(last),
                          iterator_category_t<Iter>());
    }

    WJR_CONSTEXPR20 basic_vector(std::initializer_list<value_type> il,
                                 const allocator_type &al = allocator_type())
        : basic_vector(il.begin(), il.end(), al) {}

    WJR_CONSTEXPR20 ~basic_vector() noexcept(__storage_noexcept_destroy_and_deallocate) {
        __destroy_and_deallocate();
    }

    WJR_CONSTEXPR20 basic_vector &operator=(const basic_vector &other) noexcept(
        noexcept(storage_fn_type::copy_assign(*this, other))) {
        if (WJR_LIKELY(this != std::addressof(other))) {
            storage_fn_type::copy_assign(*this, other);
        }

        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &operator=(basic_vector &&other) noexcept(
        noexcept(storage_fn_type::move_assign(*this, std::move(other)))) {
        WJR_ASSERT(this != std::addressof(other));
        storage_fn_type::move_assign(*this, std::move(other));
        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &operator=(std::initializer_list<value_type> il) {
        return assign(il);
    }

    WJR_CONSTEXPR20 basic_vector &assign(size_type n, const value_type &val) {
        __fill_assign(n, val);
        return *this;
    }

    template <typename Iter, WJR_REQUIRES(is_iterator_v<Iter>)>
    WJR_CONSTEXPR20 basic_vector &assign(Iter first, Iter last) {
        __range_assign(to_contiguous_address(first), to_contiguous_address(last),
                       iterator_category_t<Iter>());
        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &assign(std::initializer_list<value_type> il) {
        return assign(il.begin(), il.end());
    }

    WJR_PURE WJR_CONSTEXPR20 pointer begin_unsafe() noexcept { return data(); }
    WJR_PURE WJR_CONSTEXPR20 const_pointer begin_unsafe() const noexcept {
        return data();
    }
    WJR_PURE WJR_CONSTEXPR20 const_pointer cbegin_unsafe() const noexcept {
        return data();
    }

    WJR_PURE WJR_CONSTEXPR20 pointer end_unsafe() noexcept { return data() + size(); }
    WJR_PURE WJR_CONSTEXPR20 const_pointer end_unsafe() const noexcept {
        return data() + size();
    }
    WJR_PURE WJR_CONSTEXPR20 const_pointer cend_unsafe() const noexcept {
        return end_unsafe();
    }

    WJR_PURE WJR_CONSTEXPR20 pointer buf_end_unsafe() noexcept {
        return data() + capacity();
    }
    WJR_PURE WJR_CONSTEXPR20 const_pointer buf_end_unsafe() const noexcept {
        return data() + capacity();
    }
    WJR_PURE WJR_CONSTEXPR20 const_pointer cbuf_end_unsafe() const noexcept {
        return buf_end_unsafe();
    }

private:
    WJR_PURE WJR_CONSTEXPR20 iterator __make_iterator(const_pointer ptr) const noexcept {
        return iterator(const_cast<pointer>(ptr), this);
    }

    WJR_PURE WJR_CONSTEXPR20 pointer __get_pointer(iterator ptr) const noexcept {
        ptr.check_same_container(this);
        return wjr::to_address(ptr);
    }

    WJR_PURE WJR_CONSTEXPR20 pointer __get_pointer(const_iterator ptr) const noexcept {
        ptr.check_same_container(this);
        return const_cast<pointer>(wjr::to_address(ptr));
    }

public:
    WJR_PURE WJR_CONSTEXPR20 iterator begin() noexcept {
        return __make_iterator(begin_unsafe());
    }

    WJR_PURE WJR_CONSTEXPR20 const_iterator begin() const noexcept {
        return __make_iterator(begin_unsafe());
    }

    WJR_PURE WJR_CONSTEXPR20 const_iterator cbegin() const noexcept { return begin(); }

    WJR_PURE WJR_CONSTEXPR20 iterator end() noexcept {
        return __make_iterator(end_unsafe());
    }

    WJR_PURE WJR_CONSTEXPR20 const_iterator end() const noexcept {
        return __make_iterator(end_unsafe());
    }

    WJR_PURE WJR_CONSTEXPR20 const_iterator cend() const noexcept { return end(); }

    WJR_PURE WJR_CONSTEXPR20 reverse_iterator rbegin() noexcept {
        return reverse_iterator(end());
    }

    WJR_PURE WJR_CONSTEXPR20 const_reverse_iterator crbegin() const noexcept {
        return rbegin();
    }

    WJR_PURE WJR_CONSTEXPR20 const_reverse_iterator rbegin() const noexcept {
        return const_reverse_iterator(end());
    }

    WJR_PURE WJR_CONSTEXPR20 reverse_iterator rend() noexcept {
        return reverse_iterator(begin());
    }

    WJR_PURE WJR_CONSTEXPR20 const_reverse_iterator rend() const noexcept {
        return const_reverse_iterator(begin());
    }

    WJR_PURE WJR_CONSTEXPR20 const_reverse_iterator crend() const noexcept {
        return rend();
    }

    WJR_PURE WJR_CONSTEXPR20 size_type size() const noexcept {
        return get_storage().size();
    }

    WJR_CONSTEXPR20 void resize(const size_type new_size) { __resize(new_size, vctor); }

    WJR_CONSTEXPR20 void resize(const size_type new_size, const value_type &val) {
        __resize(new_size, val);
    }

    /**
     * @todo designed shrink_to_fit for storage.
     */
    WJR_CONSTEXPR20 void shrink_to_fit() {
        if constexpr (has_vector_storage_shrink_to_fit_v<storage_type>) {
            get_storage().shrink_to_fit();
        } else if constexpr (is_reallocatable::value) {
            const size_type __size = size();
            if (__size == 0) {
                __destroy_and_deallocate();
                storage_type new_storage;
                __take_storage(new_storage);
            } else if (__size < capacity()) {
                auto &al = __get_allocator();

                storage_type new_storage;
                uninitialized_construct(new_storage, __size, __size);

                wjr::uninitialized_move_n_restrict_using_allocator(
                    data(), __size, new_storage.data(), al);
                __destroy_and_deallocate();
                __take_storage(new_storage);
            }
        }
    }

    WJR_PURE WJR_CONSTEXPR20 size_type capacity() const noexcept {
        return get_storage().capacity();
    }

    WJR_PURE WJR_CONSTEXPR20 bool empty() const noexcept {
        if constexpr (has_vector_storage_empty_v<storage_type>) {
            return get_storage().empty();
        } else {
            return size() == 0;
        }
    }

    WJR_CONST WJR_CONSTEXPR20 static size_type
    get_growth_capacity(size_type old_capacity, size_type new_size) noexcept {
        constexpr size_type __small_growth = sizeof(value_type) <= 16   ? 2
                                             : sizeof(value_type) <= 64 ? 1
                                                                        : 0;

        return std::max<size_type>(old_capacity + (old_capacity / 2) + __small_growth,
                                   new_size);
    }

private:
    WJR_CONSTEXPR20 void __reserve_impl(size_type n) {
        if constexpr (is_reallocatable::value) {
            const size_type old_capacity = capacity();
            if (WJR_UNLIKELY(old_capacity < n)) {
                auto &al = __get_allocator();
                const size_type old_size = size();
                const size_type new_capacity = get_growth_capacity(old_capacity, n);

                storage_type new_storage;
                uninitialized_construct(new_storage, old_size, new_capacity);

                wjr::uninitialized_move_n_restrict_using_allocator(
                    data(), old_size, new_storage.data(), al);
                __destroy_and_deallocate();
                __take_storage(new_storage);
            }
        }
    }

    WJR_CONSTEXPR20 void __empty_reserve_impl(size_type n) {
        if constexpr (is_reallocatable::value) {
            const size_type old_capacity = capacity();
            if (WJR_UNLIKELY(old_capacity < n)) {
                const size_type new_capacity = get_growth_capacity(old_capacity, n);

                storage_type new_storage;
                uninitialized_construct(new_storage, 0, new_capacity);

                __destroy_and_deallocate();
                __take_storage(new_storage);
            }
        }
    }

public:
    WJR_CONSTEXPR20 void reserve(size_type n) {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(size() == 0)) {
            __empty_reserve_impl(n);
            return;
        }

        __reserve_impl(n);
    }

    WJR_CONSTEXPR20 reference operator[](size_type pos) noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(pos < size(), "basic_vector::operator[]: out of range");
#endif
        return data()[pos];
    }

    WJR_CONSTEXPR20 const_reference operator[](size_type pos) const noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(pos < size(), "basic_vector::operator[]: out of range");
#endif
        return data()[pos];
    }

    WJR_CONSTEXPR20 reference at(size_type pos) {
        if (WJR_UNLIKELY(pos >= size())) {
            WJR_THROW(std::out_of_range("basic_vector::at"));
        }

        return data()[pos];
    }

    WJR_CONSTEXPR20 const_reference at(size_type pos) const {
        if (WJR_UNLIKELY(pos >= size())) {
            WJR_THROW(std::out_of_range("basic_vector::at"));
        }

        return data()[pos];
    }

    WJR_CONSTEXPR20 reference front() noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(size() > 0, "basic_vector::front: empty");
#endif
        return *data();
    }

    WJR_CONSTEXPR20 const_reference front() const noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(size() > 0, "basic_vector::front: empty");
#endif
        return *data();
    }

    WJR_CONSTEXPR20 reference back() noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(size() > 0, "basic_vector::back: empty");
#endif
        return *(end_unsafe() - 1);
    }

    WJR_CONSTEXPR20 const_reference back() const noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(size() > 0, "basic_vector::back: empty");
#endif
        return *(end_unsafe() - 1);
    }

    WJR_PURE WJR_CONSTEXPR20 pointer data() noexcept { return get_storage().data(); }

    WJR_PURE WJR_CONSTEXPR20 const_pointer data() const noexcept {
        return get_storage().data();
    }

    WJR_PURE WJR_CONSTEXPR20 const_pointer cdata() const noexcept { return data(); }

    template <typename... Args>
    WJR_CONSTEXPR20 reference emplace_back(Args &&...args) {
        const pointer __end = end_unsafe();
        const pointer __buf_end = buf_end_unsafe();

        if (WJR_LIKELY(__end != __buf_end)) {
            wjr::uninitialized_construct_using_allocator(__end, __get_allocator(),
                                                         std::forward<Args>(args)...);
            ++__get_size();
        } else {
            __realloc_insert_at_end(std::forward<Args>(args)...);
        }

        return back();
    }

    WJR_CONSTEXPR20 void push_back(const value_type &val) { emplace_back(val); }
    WJR_CONSTEXPR20 void push_back(value_type &&val) { emplace_back(std::move(val)); }

    WJR_CONSTEXPR20 void pop_back() noexcept {
        const size_type __size = --__get_size();
        destroy_at_using_allocator(data() + __size, __get_allocator());
    }

    template <typename... Args>
    WJR_CONSTEXPR20 iterator emplace(const_iterator pos, Args &&...args) {
        return __emplace_aux(__get_pointer(pos), std::forward<Args>(args)...);
    }

    WJR_CONSTEXPR20 iterator insert(const_iterator pos, const value_type &val) {
        return emplace(pos, val);
    }

    WJR_CONSTEXPR20 iterator insert(const_iterator pos, value_type &&val) {
        return emplace(pos, std::move(val));
    }

    WJR_CONSTEXPR20 iterator insert(const_iterator pos,
                                    std::initializer_list<value_type> il) {
        return insert(pos, il.begin(), il.end());
    }

    WJR_CONSTEXPR20 iterator insert(const_iterator pos, size_type n,
                                    const value_type &val) {
        const auto old_pos = static_cast<size_type>(pos - cbegin());
        __fill_insert(data() + old_pos, n, val);
        return begin() + old_pos;
    }

    template <typename Iter, WJR_REQUIRES(is_iterator_v<Iter>)>
    WJR_CONSTEXPR20 iterator insert(const_iterator pos, Iter first, Iter last) {
        const auto old_pos = static_cast<size_type>(pos - cbegin());
        __range_insert(data() + old_pos, to_contiguous_address(first),
                       to_contiguous_address(last), iterator_category_t<Iter>());
        return begin() + old_pos;
    }

    WJR_CONSTEXPR20 iterator erase(const_iterator pos) {
        return __erase(__get_pointer(pos));
    }

    WJR_CONSTEXPR20 iterator erase(const_iterator first, const_iterator last) {
        return __erase(__get_pointer(first), __get_pointer(last));
    }

    WJR_CONSTEXPR20 void swap(basic_vector &other) noexcept {
        storage_fn_type::swap(*this, other);
    }

    WJR_CONSTEXPR20 void clear() {
        __erase_at_end(data());
        WJR_ASSUME(size() == 0);
    }

    WJR_PURE WJR_CONSTEXPR20 allocator_type &get_allocator() noexcept {
        return __get_allocator();
    }
    WJR_PURE WJR_CONSTEXPR20 const allocator_type &get_allocator() const noexcept {
        return __get_allocator();
    }

    // extension

    WJR_CONSTEXPR20 basic_vector(size_type n, dctor_t,
                                 const allocator_type &al = allocator_type())
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {
        __construct_n(n, dctor);
    }

    WJR_CONSTEXPR20 basic_vector(size_type n, in_place_reserve_t,
                                 const allocator_type &al = allocator_type())
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {
        if (n != 0) {
            uninitialized_construct(0, n);
        }
    }

    WJR_CONSTEXPR20 basic_vector(storage_type &&other,
                                 const allocator_type &al = allocator_type())
        : m_pair(std::piecewise_construct, wjr::forward_as_tuple(al),
                 wjr::forward_as_tuple()) {
        take_storage(other);
    }

    WJR_CONSTEXPR20 basic_vector &operator=(storage_type &&other) {
        if (std::addressof(get_storage()) == std::addressof(other)) {
            return *this;
        }

        take_storage(other);
        return *this;
    }

private:
    WJR_CONSTEXPR20 void __clear_if_reserved_impl(size_type n) {
        if constexpr (is_reallocatable::value) {
            const size_type old_capacity = capacity();
            if (WJR_UNLIKELY(old_capacity < n)) {
                const size_type new_capacity = get_growth_capacity(old_capacity, n);

                storage_type new_storage;
                uninitialized_construct(new_storage, 0, new_capacity);

                __destroy_and_deallocate();
                __take_storage(new_storage);

                WJR_ASSUME(size() == 0);
            }
        }
    }

public:
    /**
     * @brief clear() if capacity() < new_capacity.
     *
     * @details Useful when old data unused. If reserved, this function won't move any old
     * data to new pointer.
     */
    WJR_CONSTEXPR20 void clear_if_reserved(size_type n) { __clear_if_reserved_impl(n); }

    WJR_CONSTEXPR20 void resize(const size_type new_size, dctor_t) {
        __resize(new_size, dctor);
    }

    WJR_CONSTEXPR20 void push_back(dctor_t) { emplace_back(dctor); }

    WJR_CONSTEXPR20 basic_vector &append(const value_type &val) {
        emplace_back(val);
        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &append(value_type &&val) {
        emplace_back(std::move(val));
        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &append(dctor_t) {
        emplace_back(dctor);
        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &append(const size_type n, const value_type &val) {
        __append(n, val);
        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &append(const size_type n, dctor_t) {
        __append(n, dctor);
        return *this;
    }

    template <typename Iter, WJR_REQUIRES(is_iterator_v<Iter>)>
    WJR_CONSTEXPR20 basic_vector &append(Iter first, Iter last) {
        __range_append(to_contiguous_address(first), to_contiguous_address(last),
                       iterator_category_t<Iter>());
        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &append(std::initializer_list<value_type> il) {
        return append(il.begin(), il.end());
    }

    /**
     * @brief Pop n elements from the end
     *
     */
    WJR_CONSTEXPR20 basic_vector &chop(const size_type n) {
        __erase_at_end(end_unsafe() - n);
        return *this;
    }

    /**
     * @brief Truncate the size to n
     *
     */
    WJR_CONSTEXPR20 basic_vector &truncate(const size_type n) { return chop(size() - n); }

    template <typename Iter, WJR_REQUIRES(is_iterator_v<Iter>)>
    WJR_CONSTEXPR20 basic_vector &replace(const_iterator from, const_iterator to,
                                          Iter first, Iter last) {
        __range_replace(__get_pointer(from), __get_pointer(to),
                        to_contiguous_address(first), to_contiguous_address(last),
                        iterator_category_t<Iter>());
        return *this;
    }

    WJR_CONSTEXPR20 basic_vector &replace(const_iterator from, const_iterator to,
                                          const size_type n, const value_type &val) {
        __fill_replace(__get_pointer(from), __get_pointer(to), n, val);
        return *this;
    }

    WJR_PURE WJR_CONSTEXPR20 storage_type &get_storage() noexcept {
        return m_pair.second();
    }

    WJR_PURE WJR_CONSTEXPR20 const storage_type &get_storage() const noexcept {
        return m_pair.second();
    }

    WJR_CONSTEXPR20 void take_storage(storage_type &other) noexcept {
        get_storage().take_storage(other, __get_allocator());
    }

    WJR_CONSTEXPR20 void uninitialized_construct(storage_type &other, size_type siz,
                                                 size_type cap) noexcept {
        WJR_ASSERT_ASSUME(cap != 0);
        get_storage().uninitialized_construct(other, siz, cap, __get_allocator());
    }

    WJR_CONSTEXPR20 void uninitialized_construct(size_type siz, size_type cap) noexcept {
        WJR_ASSERT_ASSUME(cap != 0);
        if constexpr (has_vector_storage_uninitialized_construct_v<storage_type,
                                                                   size_type, _Alty>) {
            get_storage().uninitialized_construct(siz, cap, __get_allocator());
        } else {
            uninitialized_construct(get_storage(), siz, cap);
        }
    }

private:
    // member function for container_fn (START)

    WJR_PURE WJR_CONSTEXPR20 _Alty &__get_allocator() noexcept { return m_pair.first(); }

    WJR_PURE WJR_CONSTEXPR20 const _Alty &__get_allocator() const noexcept {
        return m_pair.first();
    }

    WJR_CONSTEXPR20 void __destroy() noexcept(__storage_noexcept_destroy) {
        get_storage().destroy(__get_allocator());
    }

    WJR_CONSTEXPR20 void
    __destroy_and_deallocate() noexcept(__storage_noexcept_destroy_and_deallocate) {
        get_storage().destroy_and_deallocate(__get_allocator());
    }

    WJR_CONSTEXPR20 void __copy_element(const basic_vector &other) {
        assign(other.begin_unsafe(), other.end_unsafe());
    }

    WJR_CONSTEXPR20 void __take_storage(basic_vector &&other) noexcept(
        noexcept(__take_storage(other.get_storage()))) {
        __take_storage(other.get_storage());
    }

    WJR_CONSTEXPR20 void __move_element(basic_vector &&other) {
        assign(std::make_move_iterator(other.begin_unsafe()),
               std::make_move_iterator(other.end_unsafe()));
    }

    WJR_CONSTEXPR20 void
    __swap_storage(basic_vector &other) noexcept(__storage_noexcept_swap_storage) {
        get_storage().swap_storage(other.get_storage(), __get_allocator());
    }

    // member function for container_fn (END)

    WJR_PURE WJR_CONSTEXPR20 __get_size_t __get_size() noexcept {
        return get_storage().size();
    }

    WJR_CONSTEXPR20 void
    __take_storage(storage_type &other) noexcept(__storage_noexcept_take_storage) {
        take_storage(other);
    }

    WJR_NORETURN WJR_CONSTEXPR20 void
    __unreallocatable_unreachable(WJR_MAYBE_UNUSED size_type new_capacity) const {
        WJR_ASSERT(
            new_capacity <= capacity(),
            "new_capacity must be less than or equal to capacity if the storage is not reallocatable.\nnew_capacity = ",
            new_capacity, ", capacity = ", capacity());
        WJR_UNREACHABLE();
    }

    template <typename... Args,
              WJR_REQUIRES(sizeof...(Args) == 1 || sizeof...(Args) == 2)>
    WJR_CONSTEXPR20 void __construct_n(const size_type n, Args &&...args) {
        if (n != 0) {
            auto &al = __get_allocator();
            uninitialized_construct(get_storage(), n, n);
            if constexpr (sizeof...(Args) == 1) {
                wjr::uninitialized_fill_n_using_allocator(data(), n, al,
                                                          std::forward<Args>(args)...);
            } else if constexpr (sizeof...(Args) == 2) {
                wjr::uninitialized_copy_restrict_using_allocator(
                    std::forward<Args>(args)..., data(), al);
            }
        }
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_construct(Iter first, Iter last,
                                           std::input_iterator_tag) {
        for (; first != last; ++first) {
            emplace_back(*first);
        }
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_construct(Iter first, Iter last,
                                           std::forward_iterator_tag) {
        const auto n = static_cast<size_type>(std::distance(first, last));
        __construct_n(n, first, last);
    }

    WJR_CONSTEXPR20 void __erase_at_end(pointer pos) noexcept {
        const pointer __begin = data();
        const pointer __end = end_unsafe();
        WJR_ASSERT_L2(pos >= __begin && pos <= __end,
                      "pos must be in the range of [begin(), end()]");
        const auto new_size = static_cast<size_type>(pos - __begin);
        destroy_using_allocator(__begin + new_size, __end, __get_allocator());
        __get_size() = new_size;
    }

    WJR_CONSTEXPR20 iterator __erase(pointer pos) noexcept {
        const pointer __end = end_unsafe();
        if (pos + 1 != __end) {
            std::move(pos + 1, __end, pos);
        }

        destroy_at_using_allocator(__end - 1, __get_allocator());
        --__get_size();
        return __make_iterator(pos);
    }

    WJR_CONSTEXPR20 iterator __erase(pointer first, pointer last) noexcept {
        const pointer __end = end_unsafe();
        if (WJR_LIKELY(first != last)) {
            if (last != __end) {
                std::move(last, __end, first);
            }

            __erase_at_end(__end - (last - first));
        }

        return __make_iterator(first);
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_insert(pointer pos, Iter first, Iter last,
                                        std::input_iterator_tag) {
        if (pos == end_unsafe()) {
            __range_append(first, last, std::input_iterator_tag());
        } else if (first != last) {
            basic_vector tmp(first, last, __get_allocator());
            __range_insert(pos, tmp.begin_unsafe(), tmp.end_unsafe(),
                           std::forward_iterator_tag());
        }
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_insert(pointer pos, Iter first, Iter last,
                                        std::forward_iterator_tag) {
        if (WJR_UNLIKELY(first == last)) {
            return;
        }

        auto &al = __get_allocator();
        const pointer __begin = data();
        const pointer __end = end_unsafe();
        const pointer __buf_end = buf_end_unsafe();

        const auto n = static_cast<size_type>(std::distance(first, last));
        const auto __rest = static_cast<size_type>(__buf_end - __end);

        if (WJR_LIKELY(__rest >= n)) {
            const auto __elements_after = static_cast<size_type>(__end - pos);
            if (__elements_after > n) {
                wjr::uninitialized_move_n_restrict_using_allocator(__end - n, n, __end,
                                                                   al);
                std::move_backward(pos, __end - n, __end);
                wjr::copy_restrict(first, last, pos);
            } else {
                const auto mid = std::next(first, __elements_after);

                wjr::uninitialized_copy_restrict_using_allocator(mid, last, __end, al);
                wjr::uninitialized_move_restrict_using_allocator(pos, __end, pos + n, al);
                wjr::copy_restrict(first, mid, pos);
            }

            __get_size() += n;
        } else {
            if constexpr (is_reallocatable::value) {
                const auto old_size = static_cast<size_type>(__end - __begin);
                const auto old_pos = static_cast<size_type>(pos - __begin);
                const size_type new_capacity =
                    get_growth_capacity(capacity(), old_size + n);

                storage_type new_storage;
                uninitialized_construct(new_storage, old_size + n, new_capacity);

                const pointer __new_begin = new_storage.data();

                wjr::uninitialized_copy_restrict_using_allocator(
                    first, last, __new_begin + old_pos, al);
                wjr::uninitialized_move_restrict_using_allocator(__begin, pos,
                                                                 __new_begin, al);
                wjr::uninitialized_move_restrict_using_allocator(
                    pos, __end, __new_begin + old_pos + n, al);

                __destroy_and_deallocate();
                __take_storage(new_storage);
            } else {
                __unreallocatable_unreachable(size() + n);
            }
        }
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_append(Iter first, Iter last, std::input_iterator_tag) {
        for (; first != last; ++first) {
            emplace_back(*first);
        }
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_append(Iter first, Iter last,
                                        std::forward_iterator_tag) {
        if (WJR_UNLIKELY(first == last)) {
            return;
        }

        auto &al = __get_allocator();
        const pointer __begin = data();
        const pointer __end = end_unsafe();
        const pointer __buf_end = buf_end_unsafe();

        const auto n = static_cast<size_type>(std::distance(first, last));
        const auto __rest = static_cast<size_type>(__buf_end - __end);

        if (WJR_LIKELY(__rest >= n)) {
            wjr::uninitialized_copy_n_restrict_using_allocator(first, n, __end, al);
            __get_size() += n;
        } else {
            if constexpr (is_reallocatable::value) {
                const auto old_size = static_cast<size_type>(__end - __begin);
                const size_type new_capacity =
                    get_growth_capacity(capacity(), old_size + n);

                storage_type new_storage;
                uninitialized_construct(new_storage, old_size + n, new_capacity);

                const pointer __new_begin = new_storage.data();

                wjr::uninitialized_copy_restrict_using_allocator(
                    first, last, __new_begin + old_size, al);
                wjr::uninitialized_move_restrict_using_allocator(__begin, __end,
                                                                 __new_begin, al);

                __destroy_and_deallocate();
                __take_storage(new_storage);
            } else {
                __unreallocatable_unreachable(size() + n);
            }
        }
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_assign(Iter first, Iter last, std::input_iterator_tag) {
        pointer cur = data();
        const pointer __end = end_unsafe();

        for (; first != last && cur != __end; ++first, ++cur) {
            *cur = *first;
        }

        if (first == last) {
            __erase_at_end(cur);
        } else {
            __range_append(first, last, std::input_iterator_tag());
        }
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_assign(Iter first, Iter last,
                                        std::forward_iterator_tag) {
        auto n = static_cast<size_type>(std::distance(first, last));
        auto &al = __get_allocator();
        const pointer __begin = data();
        const pointer __end = end_unsafe();

        if (n <= size()) {
            wjr::copy_restrict(first, last, __begin);
            __erase_at_end(__begin + n);
        } else if (WJR_LIKELY(n <= capacity())) {
            auto mid = first;
            std::advance(mid, size());
            wjr::copy_restrict(first, mid, data());
            wjr::uninitialized_copy_restrict_using_allocator(mid, last, __end, al);
            __get_size() = n;
        } else {
            if constexpr (is_reallocatable::value) {
                size_type new_capacity = get_growth_capacity(capacity(), n);

                storage_type new_storage;
                uninitialized_construct(new_storage, n, new_capacity);

                const pointer __new_begin = new_storage.data();
                wjr::uninitialized_copy_n_restrict_using_allocator(first, n, __new_begin,
                                                                   al);

                __destroy_and_deallocate();
                __take_storage(new_storage);
            } else {
                __unreallocatable_unreachable(n);
            }
        }
    }

    WJR_CONSTEXPR20 void __fill_assign(size_type n, const value_type &val) {
        auto &al = __get_allocator();

        if (WJR_UNLIKELY(n > capacity())) {
            if constexpr (is_reallocatable::value) {
                __destroy_and_deallocate();

                storage_type new_storage;
                uninitialized_construct(new_storage, n, n);

                wjr::uninitialized_fill_n_using_allocator(new_storage.data(), n, al, val);
                __take_storage(new_storage);
                return;
            } else {
                __unreallocatable_unreachable(n);
            }
        }

        if (n > size()) {
            std::fill(begin_unsafe(), end_unsafe(), val);
            wjr::uninitialized_fill_n_using_allocator(end_unsafe(), n - size(), al, val);
            __get_size() = n;
        } else {
            __erase_at_end(std::fill_n(begin_unsafe(), n, val));
        }
    }

    template <typename... Args>
    WJR_CONSTEXPR20 void __realloc_insert(pointer pos, Args &&...args) {
        if constexpr (is_reallocatable::value) {
            auto &al = __get_allocator();
            const pointer __begin = data();
            const pointer __end = end_unsafe();

            const auto old_pos_size = static_cast<size_type>(pos - __begin);
            const auto old_size = static_cast<size_type>(__end - __begin);
            const size_type new_size = old_size + 1;
            const size_type new_capacity = get_growth_capacity(old_size, new_size);

            storage_type new_storage;
            uninitialized_construct(new_storage, new_size, new_capacity);

            const pointer __new_begin = new_storage.data();
            const pointer new_pos = __new_begin + old_pos_size;

            wjr::uninitialized_construct_using_allocator(new_pos, al,
                                                         std::forward<Args>(args)...);

            wjr::uninitialized_move_n_restrict_using_allocator(__begin, old_pos_size,
                                                               __new_begin, al);
            wjr::uninitialized_move_restrict_using_allocator(pos, __end, new_pos + 1, al);

            __destroy_and_deallocate();
            __take_storage(new_storage);
        } else {
            __unreallocatable_unreachable(size() + 1);
        }
    }

    template <typename... Args>
    WJR_CONSTEXPR20 void __realloc_insert_at_end(Args &&...args) {
        if constexpr (is_reallocatable::value) {
            auto &al = __get_allocator();
            const pointer __begin = data();
            const pointer __end = end_unsafe();

            const auto old_size = static_cast<size_type>(__end - __begin);
            const auto new_size = old_size + 1;
            const size_type new_capacity = get_growth_capacity(old_size, new_size);

            storage_type new_storage;
            uninitialized_construct(new_storage, new_size, new_capacity);

            const pointer __new_begin = new_storage.data();

            const pointer new_pos = __new_begin + old_size;
            wjr::uninitialized_construct_using_allocator(new_pos, al,
                                                         std::forward<Args>(args)...);

            wjr::uninitialized_move_restrict_using_allocator(__begin, __end, __new_begin,
                                                             al);

            __destroy_and_deallocate();
            __take_storage(new_storage);
        } else {
            __unreallocatable_unreachable(size() + 1);
        }
    }

    WJR_CONSTEXPR20 void __fill_insert(pointer pos, size_type n, const value_type &val) {
        if (WJR_UNLIKELY(n == 0)) {
            return;
        }

        auto &al = __get_allocator();
        const pointer __begin = data();
        const pointer __end = end_unsafe();
        const pointer __buf_end = buf_end_unsafe();

        const auto __rest = static_cast<size_type>(__buf_end - __end);

        if (WJR_LIKELY(__rest >= n)) {
            const temporary_value_allocator tmp(al, val);
            const auto &real_val = *tmp.get();

            const auto __elements_after = static_cast<size_type>(__end - pos);
            if (__elements_after > n) {
                wjr::uninitialized_move_n_restrict_using_allocator(__end - n, n, __end,
                                                                   al);
                std::move_backward(pos, __end - n, __end);
                std::fill_n(pos, n, real_val);
            } else {
                wjr::uninitialized_fill_n_using_allocator(__end, n - __elements_after, al,
                                                          real_val);
                wjr::uninitialized_move_restrict_using_allocator(pos, __end, pos + n, al);
                std::fill(pos, __end, real_val);
            }

            __get_size() += n;
        } else {
            const auto old_size = static_cast<size_type>(__end - __begin);
            if constexpr (is_reallocatable::value) {
                const auto new_capacity = get_growth_capacity(capacity(), old_size + n);

                storage_type new_storage;
                uninitialized_construct(new_storage, old_size + n, new_capacity);

                const pointer __new_begin = new_storage.data();

                const auto old_pos = static_cast<size_type>(pos - __begin);

                wjr::uninitialized_fill_n_using_allocator(__new_begin + old_pos, n, al,
                                                          val);
                wjr::uninitialized_move_restrict_using_allocator(__begin, pos,
                                                                 __new_begin, al);
                wjr::uninitialized_move_restrict_using_allocator(
                    pos, __end, __new_begin + old_pos + n, al);

                __destroy_and_deallocate();
                __take_storage(new_storage);
            } else {
                __unreallocatable_unreachable(old_size + n);
            }
        }
    }

    template <typename Ty>
    WJR_CONSTEXPR20 void __resize(const size_type new_size, const Ty &val) {
        const auto old_size = size();

        if constexpr (is_reallocatable::value) {
            if (new_size > old_size) {
                __append(new_size - old_size, val);
            } else if (new_size < old_size) {
                __erase_at_end(data() + new_size);
            }
        } else {
            auto &al = __get_allocator();

            const pointer __begin = data();
            const pointer __end = data() + old_size;

            if (WJR_UNLIKELY(new_size > capacity())) {
                __unreallocatable_unreachable(new_size);
            }

            if (new_size > old_size) {
                wjr::uninitialized_fill_n_using_allocator(__end, new_size - old_size, al,
                                                          val);
            } else if (new_size < old_size) {
                destroy_using_allocator(__begin + new_size, __end, al);
            }

            __get_size() = new_size;
        }
    }

    template <typename Ty>
    WJR_CONSTEXPR20 void __append(size_type n, const Ty &val) {
        auto &al = __get_allocator();

        const auto old_size = size();
        const auto old_capacity = capacity();

        const pointer __begin = data();
        const pointer __end = __begin + old_size;

        const auto __rest = old_capacity - old_size;
        const auto new_size = old_size + n;

        if (WJR_LIKELY(__rest >= n)) {
            wjr::uninitialized_fill_n_using_allocator(__end, n, al, val);
            __get_size() = new_size;
        } else {
            if constexpr (is_reallocatable::value) {
                auto new_capacity = get_growth_capacity(old_capacity, new_size);

                storage_type new_storage;
                uninitialized_construct(new_storage, new_size, new_capacity);

                const pointer __new_begin = new_storage.data();

                wjr::uninitialized_fill_n_using_allocator(__new_begin + old_size, n, al,
                                                          val);
                wjr::uninitialized_move_restrict_using_allocator(__begin, __end,
                                                                 __new_begin, al);

                __destroy_and_deallocate();
                __take_storage(new_storage);
            } else {
                __unreallocatable_unreachable(new_size);
            }
        }
    }

    template <typename Args>
    WJR_CONSTEXPR20 void __insert_aux(pointer pos, Args &&args) {
        auto &al = __get_allocator();
        const pointer __end = end_unsafe();

        wjr::uninitialized_construct_using_allocator(__end, al, std::move(*(__end - 1)));

        std::move_backward(pos, __end - 1, __end);
        *pos = std::forward<Args>(args);

        ++__get_size();
    }

    template <typename... Args>
    WJR_CONSTEXPR20 iterator __emplace_aux(pointer pos, Args &&...args) {
        auto &al = __get_allocator();
        const pointer __end = end_unsafe();
        const pointer __buf_end = buf_end_unsafe();

        if (WJR_LIKELY(__end != __buf_end)) {
            if (pos == __end) {
                wjr::uninitialized_construct_using_allocator(__end, al,
                                                             std::forward<Args>(args)...);
                ++__get_size();
            } else {
                temporary_value_allocator tmp(al, std::forward<Args>(args)...);
                __insert_aux(pos, std::move(*tmp.get()));
            }

            return __make_iterator(pos);
        }

        const size_type offset = static_cast<size_type>(pos - data());
        __realloc_insert(pos, std::forward<Args>(args)...);
        return begin() + offset;
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_replace(pointer old_first, pointer old_last,
                                         Iter new_begin, Iter new_last,
                                         std::input_iterator_tag) {
        for (; old_first != old_last && new_begin != new_last; ++old_first, ++new_begin) {
            *old_first = *new_begin;
        }

        if (new_begin == new_last) {
            __erase_at_end(old_first, old_last);
        } else {
            __range_insert(old_last, new_begin, new_last, std::input_iterator_tag());
        }
    }

    template <typename Iter>
    WJR_CONSTEXPR20 void __range_replace(pointer old_first, pointer old_last,
                                         Iter new_begin, Iter new_last,
                                         std::forward_iterator_tag) {
        const auto n = static_cast<size_type>(old_last - old_first);
        const auto m = static_cast<size_type>(std::distance(new_begin, new_last));

        if (m <= n) {
            erase(std::copy_n(new_begin, m, old_first), old_last);
        } else {
            const auto __delta = m - n;

            auto &al = __get_allocator();
            const auto __begin = data();
            const auto __end = end_unsafe();
            const auto __buf_end = buf_end_unsafe();

            const auto __rest = static_cast<size_type>(__buf_end - __end);

            if (WJR_LIKLELY(__rest >= __delta)) {
                const auto __elements_after = static_cast<size_type>(__end - old_first);
                if (__elements_after > m) {
                    wjr::uninitialized_move_using_allocator(__end - __delta, __end, __end,
                                                            al);
                    std::move_backward(old_last, __end - __delta, __end);
                    std::copy(new_begin, new_last, old_first);
                } else {
                    auto mid = new_begin;
                    std::advance(mid, __elements_after);
                    wjr::uninitialized_copy_using_allocator(mid, new_last, __end, al);
                    wjr::uninitialized_move_using_allocator(old_last, __end,
                                                            old_first + m, al);
                    std::copy(new_begin, mid, old_first);
                }
                __get_size() += __delta;
            } else {
                if constexpr (is_reallocatable::value) {
                    const auto old_size = static_cast<size_type>(__end - __begin);
                    const auto old_pos = static_cast<size_type>(old_first - __begin);
                    const auto new_capacity =
                        get_growth_capacity(capacity(), old_size + __delta);

                    storage_type new_storage;
                    uninitialized_construct(new_storage, old_size + __delta,
                                            new_capacity);

                    const pointer __new_begin = new_storage.data();

                    wjr::uninitialized_copy_restrict_using_allocator(
                        new_begin, new_last, __new_begin + old_pos, al);
                    wjr::uninitialized_move_restrict_using_allocator(__begin, old_first,
                                                                     __new_begin, al);
                    wjr::uninitialized_move_restrict_using_allocator(
                        old_last, __end, __new_begin + old_pos + m, al);

                    __destroy_and_deallocate();
                    __take_storage(new_storage);
                } else {
                    __unreallocatable_unreachable(size() + __delta);
                }
            }
        }
    }

    WJR_CONSTEXPR20 void __fill_replace(pointer old_first, pointer old_last, size_type m,
                                        const value_type &val) {
        const auto n = static_cast<size_type>(old_last - old_first);

        if (m <= n) {
            __erase(std::fill_n(old_first, m, val), old_last);
        } else {
            const auto __delta = m - n;

            auto &al = __get_allocator();
            const auto __begin = data();
            const auto __end = end_unsafe();
            const auto __buf_end = buf_end_unsafe();

            const auto __rest = static_cast<size_type>(__buf_end - __end);

            if (WJR_LIKELY(__rest >= __delta)) {
                const temporary_value_allocator tmp(al, val);
                const auto &real_value = *tmp.get();

                const auto __elements_after = static_cast<size_type>(__end - old_first);
                if (__elements_after > m) {
                    wjr::uninitialized_move_using_allocator(__end - __delta, __end, __end,
                                                            al);
                    std::move_backward(old_last, __end - __delta, __end);
                    std::fill_n(old_first, m, real_value);
                } else {
                    wjr::uninitialized_fill_n_using_allocator(__end, m - __elements_after,
                                                              al, real_value);
                    wjr::uninitialized_move_using_allocator(old_last, __end,
                                                            old_first + m, al);
                    std::fill(old_first, __end, real_value);
                }
                __get_size() += __delta;
            } else {
                if constexpr (is_reallocatable::value) {
                    const auto old_size = static_cast<size_type>(__end - __begin);
                    const auto old_pos = static_cast<size_type>(old_first - __begin);
                    const auto new_capacity =
                        get_growth_capacity(capacity(), old_size + __delta);

                    storage_type new_storage;
                    uninitialized_construct(new_storage, old_size + __delta,
                                            new_capacity);

                    const pointer __ptr = new_storage.data();

                    wjr::uninitialized_fill_n_using_allocator(__ptr + old_pos, m, al,
                                                              val);
                    wjr::uninitialized_move_restrict_using_allocator(__begin, old_first,
                                                                     __ptr, al);
                    wjr::uninitialized_move_restrict_using_allocator(
                        old_last, __end, __ptr + old_pos + m, al);

                    __destroy_and_deallocate();
                    __take_storage(new_storage);
                } else {
                    __unreallocatable_unreachable(size() + __delta);
                }
            }
        }
    }

private:
    compressed_pair<_Alty, storage_type> m_pair;
};

template <typename T, typename Alloc = memory_pool<T>>
using vector = basic_vector<default_vector_storage<T, Alloc>>;

/**
 * @brief A vector with elements stored on the stack.
 *
 */
template <typename T, size_t Capacity, typename Alloc = memory_pool<T>>
using static_vector = basic_vector<static_vector_storage<T, Capacity, Alloc>>;

/**
 * @brief A vector with fixed capacity by construction.
 *
 * @details Only allocate memory on construction and deallocation on destruction.
 * After construction, it cannot be expanded and can only be modified through move
 * assignment. For example, vector that using stack allocator.
 */
template <typename T, typename Alloc = memory_pool<T>>
using fixed_vector = basic_vector<fixed_vector_storage<T, Alloc>>;

template <typename T, size_t Capacity, typename Alloc = memory_pool<T>>
using sso_vector = basic_vector<sso_vector_storage<T, Capacity, Alloc>>;

template <typename Iter, typename T = iterator_value_t<Iter>,
          typename Alloc = memory_pool<T>, WJR_REQUIRES(is_iterator_v<Iter>)>
basic_vector(Iter, Iter, Alloc = Alloc())
    -> basic_vector<default_vector_storage<T, Alloc>>;

template <typename Storage>
void swap(basic_vector<Storage> &lhs, basic_vector<Storage> &rhs) noexcept {
    lhs.swap(rhs);
}

template <typename Storage>
bool operator==(const basic_vector<Storage> &lhs, const basic_vector<Storage> &rhs) {
    return std::equal(lhs.begin_unsafe(), lhs.end_unsafe(), rhs.begin_unsafe(),
                      rhs.end_unsafe());
}

template <typename Storage>
bool operator!=(const basic_vector<Storage> &lhs, const basic_vector<Storage> &rhs) {
    return !(lhs == rhs);
}

template <typename Storage>
bool operator<(const basic_vector<Storage> &lhs, const basic_vector<Storage> &rhs) {
    return std::lexicographical_compare(lhs.begin_unsafe(), lhs.end_unsafe(),
                                        rhs.begin_unsafe(), rhs.end_unsafe());
}

template <typename Storage>
bool operator>(const basic_vector<Storage> &lhs, const basic_vector<Storage> &rhs) {
    return rhs < lhs;
}

template <typename Storage>
bool operator<=(const basic_vector<Storage> &lhs, const basic_vector<Storage> &rhs) {
    return !(rhs < lhs);
}

template <typename Storage>
bool operator>=(const basic_vector<Storage> &lhs, const basic_vector<Storage> &rhs) {
    return !(lhs < rhs);
}

} // namespace wjr

namespace std {

template <typename Storage>
constexpr void swap(wjr::basic_vector<Storage> &lhs,
                    wjr::basic_vector<Storage> &rhs) noexcept(noexcept(lhs.swap(rhs))) {
    lhs.swap(rhs);
}

} // namespace std

#endif // WJR_CONTAINER_GENERIC_CONTAINER_VECTOR_HPP__

#endif // WJR_VECTOR_HPP__

namespace wjr {

template <typename Container>
struct container_traits : __container_traits_base<Container> {};

template <typename T, size_t N>
struct container_traits<std::array<T, N>> : __container_traits_base<std::array<T, N>> {
    constexpr static bool is_contiguous_v = true;
    constexpr static bool is_trivially_contiguous_v = true;
};

template <typename T, typename Alloc>
struct container_traits<std::vector<T, Alloc>>
    : __container_traits_base<std::vector<T, Alloc>> {
    constexpr static bool is_contiguous_v = true;
    constexpr static bool is_trivially_contiguous_v = true;
};

template <typename CharT, typename Traits, typename Alloc>
struct container_traits<std::basic_string<CharT, Traits, Alloc>>
    : __container_traits_base<std::basic_string<CharT, Traits, Alloc>> {
    constexpr static bool is_contiguous_v = true;
    constexpr static bool is_trivially_contiguous_v =
        std::is_same_v<Traits, std::char_traits<CharT>>;
};

template <typename Storage>
struct container_traits<basic_vector<Storage>>
    : __container_traits_base<basic_vector<Storage>> {
    constexpr static bool is_contiguous_v = true;
    constexpr static bool is_trivially_contiguous_v =
        basic_vector<Storage>::is_trivially_contiguous::value;
};

} // namespace wjr

#endif // WJR_CONTAINER_GENERIC_TYPE_TRAITS_HPP__
/**
 * @file expected.hpp
 * @author wjr
 * @details
 * @version 0.1
 * @date 2024-07-13
 *
 * @copyright Copyright (c) 2024
 *
 */

#ifndef WJR_EXPECTED_HPP__
#define WJR_EXPECTED_HPP__

#include <exception>

// Already included
// Already included
// Already included

namespace wjr {

struct unexpect_t {};
inline constexpr unexpect_t unexpect = {};

template <typename E, typename Tag>
using unexpected_base = enable_special_members_base<
    std::is_trivially_default_constructible_v<E>, std::is_destructible_v<E>,
    std::is_copy_constructible_v<E>, std::is_move_constructible_v<E>,
    std::is_copy_assignable_v<E>, std::is_move_assignable_v<E>, Tag>;

template <typename E>
class unexpected : unexpected_base<E, unexpected<E>> {
    using Mybase = unexpected_base<E, unexpected<E>>;

public:
    using Mybase::Mybase;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(unexpected);

    template <typename Err = E,
              WJR_REQUIRES(!std::is_same_v<remove_cvref_t<Err>, unexpected> &&
                           !std::is_same_v<remove_cvref_t<Err>, std::in_place_t> &&
                           std::is_constructible_v<E, Err &&>)>
    constexpr explicit unexpected(Err &&e) noexcept(
        std::is_nothrow_constructible_v<E, Err &&>)
        : Mybase(enable_default_constructor), m_err(std::forward<Err>(e)) {}

    template <typename... Args, WJR_REQUIRES(std::is_constructible_v<E, Args...>)>
    constexpr explicit unexpected(std::in_place_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<E, Args...>)
        : Mybase(enable_default_constructor), m_err(std::forward<Args>(args)...) {}

    template <
        typename U, typename... Args,
        WJR_REQUIRES(std::is_constructible_v<E, std::initializer_list<U> &, Args...>)>
    constexpr explicit unexpected(
        std::in_place_t, std::initializer_list<U> il,
        Args &&...args) noexcept(std::is_constructible_v<E, std::initializer_list<U> &,
                                                         Args...>)
        : Mybase(enable_default_constructor), m_err(il, std::forward<Args>(args)...) {}

    constexpr E &error() & noexcept { return m_err; }
    constexpr const E &error() const & noexcept { return m_err; }
    constexpr E &&error() && noexcept { return std::move(m_err); }
    constexpr const E &&error() const && noexcept { return std::move(m_err); }

    constexpr void swap(unexpected &other) noexcept(std::is_nothrow_swappable_v<E>) {
        std::swap(m_err, other.m_err);
    }

    template <typename E2>
    friend constexpr bool operator==(unexpected &x, unexpected<E2> &y) {
        return x.error() == y.error();
    }

    template <typename E2>
    friend constexpr bool operator!=(unexpected &x, unexpected<E2> &y) {
        return x.error() != y.error();
    }

private:
    E m_err;
};

template <typename Err>
unexpected(Err) -> unexpected<Err>;

template <typename E>
class bad_expected_access;

template <>
class bad_expected_access<void> : public std::exception {
public:
    WJR_NODISCARD virtual const char *what() const noexcept override {
        return "Bad expected access";
    }
};

template <typename E>
class bad_expected_access : public bad_expected_access<void> {
public:
    explicit bad_expected_access(E e) : m_val(std::move(e)) {}

    const E &error() const & { return m_val; }
    E &error() & { return m_val; }
    const E &&error() const && { return std::move(m_val); }
    E &&error() && { return std::move(m_val); }

private:
    E m_val;
};

template <typename E, E init>
class compressed_unexpected {
    static_assert(std::is_trivial_v<E>, "Only support trivial type currently.");
    static_assert(sizeof(E) <= 8, "Don't need to compress.");

public:
    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(compressed_unexpected);

    constexpr compressed_unexpected(E err) noexcept : m_err(err) {
        WJR_ASSERT(err != init);
    }

    constexpr operator E() const noexcept { return m_err; }

private:
    E m_err;
};

template <typename E>
struct __expected_error_type {
    using type = E;
};

template <typename E, E init>
struct __expected_error_type<compressed_unexpected<E, init>> {
    using type = E;
};

template <typename E>
using __expected_error_type_t = typename __expected_error_type<E>::type;

template <typename T, typename E>
class expected;

template <typename NewType, typename OldType, typename... Args>
WJR_CONSTEXPR20 void reinit_expected(NewType &new_val, OldType &old_val, Args &&...args) {
    if constexpr (std::is_nothrow_constructible_v<NewType, Args...>) {
        std::destroy_at(std::addressof(old_val));
        construct_at(std::addressof(new_val), std::forward<Args>(args)...);
    } else if constexpr (std::is_nothrow_move_constructible_v<NewType>) {
        NewType temp(std::forward<Args>(args)...);
        std::destroy_at(std::addressof(old_val));
        construct_at(std::addressof(new_val), std::move(temp));
    } else {
        OldType temp(std::move(old_val));
        std::destroy_at(std::addressof(old_val));
        WJR_TRY { construct_at(std::addressof(new_val), std::forward<Args>(args)...); }
        WJR_CATCH(...) {
            construct_at(std::addressof(old_val), std::move(temp));
            WJR_XTHROW;
        }
    }
}

namespace expected_detail {

template <typename T, typename U>
struct is_void_or : U {};

template <typename U>
struct is_void_or<void, U> : std::true_type {};

template <typename T, typename U>
inline constexpr bool is_void_or_v = is_void_or<T, U>::value;

template <typename T, typename E,
          bool Destructor = is_void_or_v<T, std::is_trivially_destructible<T>>
              &&std::is_trivially_destructible_v<__expected_error_type_t<E>>>
struct expected_storage_base {
    constexpr expected_storage_base() noexcept(std::is_nothrow_default_constructible_v<T>)
        : m_has_val(true), m_val() {}

    template <typename... Args>
    constexpr expected_storage_base(std::in_place_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<T, Args...>)
        : m_has_val(true), m_val(std::forward<Args>(args)...) {}

    template <typename... Args>
    constexpr expected_storage_base(unexpect_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<E, Args...>)
        : m_has_val(false), m_err(std::forward<Args>(args)...) {}

    expected_storage_base(const expected_storage_base &) = default;
    expected_storage_base(expected_storage_base &&) = default;
    expected_storage_base &operator=(const expected_storage_base &) = default;
    expected_storage_base &operator=(expected_storage_base &&) = default;

    constexpr expected_storage_base(enable_default_constructor_t) noexcept {}

    ~expected_storage_base() = default;

    WJR_PURE constexpr bool has_value() const noexcept { return m_has_val; }
    constexpr void set_valid() noexcept { m_has_val = true; }
    constexpr void set_invalid() noexcept { m_has_val = false; }

    bool m_has_val;
    union {
        T m_val;
        E m_err;
    };
};

template <typename T, typename E>
struct expected_storage_base<T, E, false> {
    constexpr expected_storage_base() noexcept(std::is_nothrow_default_constructible_v<T>)
        : m_has_val(true), m_val() {}

    template <typename... Args>
    constexpr expected_storage_base(std::in_place_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<T, Args...>)
        : m_has_val(true), m_val(std::forward<Args>(args)...) {}

    template <typename... Args>
    constexpr expected_storage_base(unexpect_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<E, Args...>)
        : m_has_val(false), m_err(std::forward<Args>(args)...) {}

    expected_storage_base(const expected_storage_base &) = default;
    expected_storage_base(expected_storage_base &&) = default;
    expected_storage_base &operator=(const expected_storage_base &) = default;
    expected_storage_base &operator=(expected_storage_base &&) = default;

    constexpr expected_storage_base(enable_default_constructor_t) noexcept {}

    ~expected_storage_base() noexcept(
        std::is_nothrow_destructible_v<T> &&std::is_nothrow_destructible_v<E>) {
        if (this->m_has_val) {
            std::destroy_at(std::addressof(this->m_val));
        } else {
            std::destroy_at(std::addressof(this->m_err));
        }
    }

    WJR_PURE constexpr bool has_value() const noexcept { return m_has_val; }
    constexpr void set_valid() noexcept { m_has_val = true; }
    constexpr void set_invalid() noexcept { m_has_val = false; }

    bool m_has_val;
    union {
        T m_val;
        E m_err;
    };
};

template <typename E>
struct expected_storage_base<void, E, true> {
    constexpr expected_storage_base() noexcept : m_has_val(true) {}

    constexpr expected_storage_base(std::in_place_t) noexcept : m_has_val(true) {}

    template <typename... Args>
    constexpr expected_storage_base(unexpect_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<E, Args...>)
        : m_has_val(false), m_err(std::forward<Args>(args)...) {}

    expected_storage_base(const expected_storage_base &) = default;
    expected_storage_base(expected_storage_base &&) = default;
    expected_storage_base &operator=(const expected_storage_base &) = default;
    expected_storage_base &operator=(expected_storage_base &&) = default;

    constexpr expected_storage_base(enable_default_constructor_t) noexcept {}

    ~expected_storage_base() = default;

    WJR_PURE constexpr bool has_value() const noexcept { return m_has_val; }
    constexpr void set_valid() noexcept { m_has_val = true; }
    constexpr void set_invalid() noexcept { m_has_val = false; }

    bool m_has_val;
    union {
        E m_err;
    };
};

template <typename E>
struct expected_storage_base<void, E, false> {
    constexpr expected_storage_base() noexcept : m_has_val(true) {}

    constexpr expected_storage_base(std::in_place_t) noexcept : m_has_val(true) {}

    template <typename... Args>
    constexpr expected_storage_base(unexpect_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<E, Args...>)
        : m_has_val(false), m_err(std::forward<Args>(args)...) {}

    expected_storage_base(const expected_storage_base &) = default;
    expected_storage_base(expected_storage_base &&) = default;
    expected_storage_base &operator=(const expected_storage_base &) = default;
    expected_storage_base &operator=(expected_storage_base &&) = default;

    constexpr expected_storage_base(enable_default_constructor_t) noexcept {}

    ~expected_storage_base() noexcept(std::is_nothrow_destructible_v<E>) {
        if (!this->m_has_val) {
            std::destroy_at(std::addressof(this->m_err));
        }
    }

    WJR_PURE constexpr bool has_value() const noexcept { return m_has_val; }
    constexpr void set_valid() noexcept { m_has_val = true; }
    constexpr void set_invalid() noexcept { m_has_val = false; }

    bool m_has_val;
    union {
        E m_err;
    };
};

template <typename T, typename E, E init>
struct expected_storage_base<T, compressed_unexpected<E, init>, true> {
    constexpr expected_storage_base() noexcept(std::is_nothrow_default_constructible_v<T>)
        : m_val(), m_err(init) {}

    template <typename... Args>
    constexpr expected_storage_base(std::in_place_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<T, Args...>)
        : m_val(std::forward<Args>(args)...), m_err(init) {}

    template <typename... Args>
    constexpr expected_storage_base(unexpect_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<E, Args...>)
        : m_err(std::forward<Args>(args)...) {}

    expected_storage_base(const expected_storage_base &) = default;
    expected_storage_base(expected_storage_base &&) = default;
    expected_storage_base &operator=(const expected_storage_base &) = default;
    expected_storage_base &operator=(expected_storage_base &&) = default;

    constexpr expected_storage_base(enable_default_constructor_t) noexcept {}

    ~expected_storage_base() = default;

    WJR_PURE constexpr bool has_value() const noexcept { return m_err == init; }
    constexpr void set_valid() noexcept { m_err = init; }
    constexpr void set_invalid() noexcept {}

    union {
        T m_val;
    };

    E m_err;
};

template <typename T, typename E, E init>
struct expected_storage_base<T, compressed_unexpected<E, init>, false> {
    constexpr expected_storage_base() noexcept(std::is_nothrow_default_constructible_v<T>)
        : m_val(), m_err(init) {}

    template <typename... Args>
    constexpr expected_storage_base(std::in_place_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<T, Args...>)
        : m_val(std::forward<Args>(args)...), m_err(init) {}

    template <typename... Args>
    constexpr expected_storage_base(unexpect_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<E, Args...>)
        : m_err(std::forward<Args>(args)...) {}

    expected_storage_base(const expected_storage_base &) = default;
    expected_storage_base(expected_storage_base &&) = default;
    expected_storage_base &operator=(const expected_storage_base &) = default;
    expected_storage_base &operator=(expected_storage_base &&) = default;

    constexpr expected_storage_base(enable_default_constructor_t) noexcept {}

    ~expected_storage_base() noexcept(
        std::is_nothrow_destructible_v<T> &&std::is_nothrow_destructible_v<E>) {
        if (this->has_value()) {
            std::destroy_at(std::addressof(this->m_val));
        } else {
            std::destroy_at(std::addressof(this->m_err));
        }
    }

    WJR_PURE constexpr bool has_value() const noexcept { return m_err == init; }
    constexpr void set_valid() noexcept { m_err = init; }
    constexpr void set_invalid() noexcept {}

    union {
        T m_val;
    };

    E m_err;
};

template <typename E, E init>
struct expected_storage_base<void, compressed_unexpected<E, init>, true> {
    constexpr expected_storage_base() noexcept : m_err(init) {}

    constexpr expected_storage_base(std::in_place_t) noexcept : m_err(init) {}

    template <typename... Args>
    constexpr expected_storage_base(unexpect_t, Args &&...args) noexcept(
        std::is_nothrow_constructible_v<E, Args...>)
        : m_err(std::forward<Args>(args)...) {}

    expected_storage_base(const expected_storage_base &) = default;
    expected_storage_base(expected_storage_base &&) = default;
    expected_storage_base &operator=(const expected_storage_base &) = default;
    expected_storage_base &operator=(expected_storage_base &&) = default;

    constexpr expected_storage_base(enable_default_constructor_t) noexcept {}

    ~expected_storage_base() = default;

    WJR_PURE constexpr bool has_value() const noexcept { return m_err == init; }
    constexpr void set_valid() noexcept { m_err = init; }
    constexpr void set_invalid() noexcept {}

    E m_err;
};

template <typename T, typename E>
struct expected_operations_base : expected_storage_base<T, E> {
    using Mybase = expected_storage_base<T, E>;
    using Mybase::Mybase;

    using error_type = __expected_error_type_t<E>;

    template <typename... Args>
    constexpr void construct_value(Args &&...args) noexcept(
        std::is_nothrow_constructible_v<T, Args...>) {
        this->set_valid();
        construct_at(std::addressof(this->m_val), std::forward<Args>(args)...);
    }

    template <typename... Args>
    constexpr void construct_error(Args &&...args) noexcept(
        std::is_nothrow_constructible_v<error_type, Args...>) {
        this->set_invalid();
        construct_at(std::addressof(this->m_err), std::forward<Args>(args)...);
    }

    WJR_CONSTEXPR20 void __copy_construct(const expected_operations_base &other) {
        if (other.has_value()) {
            construct_value(other.m_val);
        } else {
            construct_error(other.m_err);
        }
    }

    WJR_CONSTEXPR20 void __move_construct(expected_operations_base &&other) noexcept(
        std::is_nothrow_move_constructible_v<T>
            &&std::is_nothrow_move_constructible_v<error_type>) {
        if (other.has_value()) {
            construct_value(std::move(other.m_val));
        } else {
            construct_error(std::move(other.m_err));
        }
    }

    WJR_CONSTEXPR20 void __copy_assign(const expected_operations_base &other) {
        if (this->has_value()) {
            if (WJR_LIKELY(other.has_value())) {
                this->m_val = other.m_val;
            } else {
                reinit_expected(this->m_err, this->m_val, other.m_err);
                this->set_invalid();
            }
        } else {
            if (WJR_LIKELY(!other.has_value())) {
                this->m_err = other.m_err;
            } else {
                reinit_expected(this->m_val, this->m_err, other.m_val);
                this->set_valid();
            }
        }
    }

    WJR_CONSTEXPR20 void __move_assign(expected_operations_base &&other) noexcept(
        std::is_nothrow_move_assignable_v<T> &&std::is_nothrow_move_assignable_v<E>) {
        if (this->has_value()) {
            if (WJR_LIKELY(other.has_value())) {
                this->m_val = std::move(other.m_val);
            } else {
                reinit_expected(this->m_err, this->m_val, std::move(other.m_err));
                this->set_invalid();
            }
        } else {
            if (WJR_LIKELY(!other.has_value())) {
                this->m_err = std::move(other.m_err);
            } else {
                reinit_expected(this->m_val, this->m_err, std::move(other.m_val));
                this->set_valid();
            }
        }
    }
};

template <typename E>
struct expected_operations_base<void, E> : expected_storage_base<void, E> {
    using Mybase = expected_storage_base<void, E>;
    using Mybase::Mybase;

    using error_type = __expected_error_type_t<E>;

    template <typename... Args>
    constexpr void construct_error(Args &&...args) noexcept(
        std::is_nothrow_constructible_v<error_type, Args...>) {
        this->set_invalid();
        construct_at(std::addressof(this->m_err), std::forward<Args>(args)...);
    }

    WJR_CONSTEXPR20 void __copy_construct(const expected_operations_base &other) {
        if (!other.has_value()) {
            construct_error(other.m_err);
        }
    }

    WJR_CONSTEXPR20 void __move_construct(expected_operations_base &&other) noexcept(
        std::is_nothrow_move_constructible_v<error_type>) {
        if (!other.has_value()) {
            construct_error(std::move(other.m_err));
        }
    }

    WJR_CONSTEXPR20 void __copy_assign(const expected_operations_base &other) {
        if (this->has_value()) {
            if (!other.has_value()) {
                construct_at(std::addressof(this->m_err), other.m_err);
                this->set_invalid();
            }
        } else {
            if (WJR_LIKELY(!other.has_value())) {
                this->m_err = other.m_err;
            } else {
                std::destroy_at(std::addressof(this->m_err));
                this->set_valid();
            }
        }
    }

    WJR_CONSTEXPR20 void __move_assign(expected_operations_base &&other) noexcept(
        std::is_nothrow_move_assignable_v<error_type>) {
        if (this->has_value()) {
            if (!other.has_value()) {
                construct_at(std::addressof(this->m_err), std::move(other.m_err));
                this->set_invalid();
            }
        } else {
            if (WJR_LIKELY(!other.has_value())) {
                this->m_err = std::move(other.m_err);
            } else {
                std::destroy_at(std::addressof(this->m_err));
                this->set_valid();
            }
        }
    }
};

template <typename T, typename E>
struct __expected_storage_impl {
    using error_type = __expected_error_type_t<E>;

    using type = control_special_members_base<
        expected_operations_base<T, E>,
        std::is_trivially_copy_constructible_v<T> &&
            std::is_trivially_copy_constructible_v<error_type>,
        std::is_trivially_move_constructible_v<T> &&
            std::is_trivially_move_constructible_v<error_type>,
        std::is_trivially_copy_assignable_v<T> &&
            std::is_trivially_copy_constructible_v<T> &&
            std::is_trivially_destructible_v<T> &&
            std::is_trivially_copy_assignable_v<error_type> &&
            std::is_trivially_copy_constructible_v<error_type> &&
            std::is_trivially_destructible_v<error_type>,
        std::is_trivially_move_assignable_v<T> &&
            std::is_trivially_move_constructible_v<T> &&
            std::is_trivially_destructible_v<T> &&
            std::is_trivially_move_assignable_v<error_type> &&
            std::is_trivially_move_constructible_v<error_type> &&
            std::is_trivially_destructible_v<error_type>>;
};

template <typename E>
struct __expected_storage_impl<void, E> {
    using error_type = __expected_error_type_t<E>;

    using type = control_special_members_base<
        expected_operations_base<void, E>,
        std::is_trivially_copy_constructible_v<error_type>,
        std::is_trivially_move_constructible_v<error_type>,
        std::is_trivially_copy_assignable_v<error_type> &&
            std::is_trivially_copy_constructible_v<error_type> &&
            std::is_trivially_destructible_v<error_type>,
        std::is_trivially_move_assignable_v<error_type> &&
            std::is_trivially_move_constructible_v<error_type> &&
            std::is_trivially_destructible_v<error_type>>;
};

template <typename T, typename E>
using expected_storage = typename __expected_storage_impl<T, E>::type;

template <typename T, typename E>
struct __enable_expeted_storage_impl {
    using type = enable_special_members_base<
        std::is_default_constructible_v<T>, true,
        std::is_copy_constructible_v<T> && std::is_copy_constructible_v<E>,
        std::is_move_constructible_v<T> && std::is_move_constructible_v<E>,
        std::is_copy_assignable_v<T> && std::is_copy_constructible_v<T> &&
            std::is_copy_assignable_v<E> && std::is_copy_constructible_v<E> &&
            (std::is_nothrow_move_constructible_v<T> ||
             std::is_nothrow_move_constructible_v<E>),
        std::is_move_assignable_v<T> && std::is_move_constructible_v<T> &&
            std::is_move_assignable_v<E> && std::is_move_constructible_v<E> &&
            (std::is_nothrow_move_constructible_v<T> ||
             std::is_nothrow_move_constructible_v<E>)>;
};

template <typename E>
struct __enable_expeted_storage_impl<void, E> {
    using type = enable_special_members_base<
        true, true, std::is_copy_constructible_v<E>, std::is_move_constructible_v<E>,
        std::is_copy_assignable_v<E> && std::is_copy_constructible_v<E>,
        std::is_move_assignable_v<E> && std::is_move_constructible_v<E>>;
};

template <typename T, typename E>
using enable_expected_storage = typename __enable_expeted_storage_impl<T, E>::type;

template <typename T, typename E, typename U, typename G>
struct expected_construct_with
    : std::conjunction<
          std::disjunction<std::is_same<std::remove_cv_t<T>, bool>,
                           std::negation<std::disjunction<
                               std::is_constructible<T, expected<U, G> &>,
                               std::is_constructible<T, expected<U, G>>,
                               std::is_constructible<T, const expected<U, G> &>,
                               std::is_constructible<T, const expected<U, G>>,
                               std::is_convertible<expected<U, G> &, T>,
                               std::is_convertible<expected<U, G>, T>,
                               std::is_convertible<const expected<U, G> &, T>,
                               std::is_convertible<const expected<U, G>, T>>>>,
          std::negation<std::disjunction<
              std::is_constructible<unexpected<E>, expected<U, G> &>,
              std::is_constructible<unexpected<E>, expected<U, G>>,
              std::is_constructible<unexpected<E>, const expected<U, G> &>,
              std::is_constructible<unexpected<E>, const expected<U, G>>>>> {};

template <typename E, typename G>
struct expected_construct_with<void, E, void, G>
    : std::negation<std::disjunction<
          std::is_constructible<unexpected<E>, expected<void, G> &>,
          std::is_constructible<unexpected<E>, expected<void, G>>,
          std::is_constructible<unexpected<E>, const expected<void, G> &>,
          std::is_constructible<unexpected<E>, const expected<void, G>>>> {};

template <typename T, typename E, typename U, typename G>
inline constexpr bool expected_construct_with_v =
    expected_construct_with<T, E, U, G>::value;

template <typename T>
struct is_not_unexpected : std::true_type {};

template <typename E>
struct is_not_unexpected<unexpected<E>> : std::false_type {};

template <typename T>
struct is_not_expected : std::true_type {};

template <typename T, typename E>
struct is_not_expected<expected<T, E>> : std::false_type {};

template <typename T, typename E, typename U>
struct expected_construct_with_arg
    : std::conjunction<std::negation<std::is_same<remove_cvref_t<U>, std::in_place_t>>,
                       std::negation<std::is_same<remove_cvref_t<U>, expected<T, E>>>,
                       std::is_constructible<T, U>, is_not_unexpected<remove_cvref_t<U>>,
                       std::disjunction<std::is_same<remove_cvref_t<U>, bool>,
                                        is_not_expected<remove_cvref_t<U>>>> {};

template <typename T, typename E, typename U>
inline constexpr bool expected_construct_with_arg_v =
    expected_construct_with_arg<T, E, U>::value;

} // namespace expected_detail

template <typename Func, typename... Args>
using __expected_result = std::remove_cv_t<std::invoke_result_t<Func, Args...>>;

template <typename T, typename E>
class WJR_EMPTY_BASES expected
    : expected_detail::expected_storage<T, E>,
      expected_detail::enable_expected_storage<T, __expected_error_type_t<E>> {
    using Mybase = expected_detail::expected_storage<T, E>;

public:
    using value_type = T;
    using error_type = typename Mybase::error_type;
    using unexpected_type = unexpected<error_type>;

    using Mybase::Mybase;

    expected() = default;
    expected(const expected &) = default;
    expected(expected &&) = default;
    expected &operator=(const expected &) = default;
    expected &operator=(expected &&) = default;
    ~expected() = default;

    template <typename... Args, WJR_REQUIRES(std::is_constructible_v<T, Args...>)>
    constexpr explicit expected(std::in_place_t, Args &&...args)
        : Mybase(std::in_place, std::forward<Args>(args)...) {}

    template <
        typename U, typename... Args,
        WJR_REQUIRES(std::is_constructible_v<T, std::initializer_list<U> &, Args...>)>
    constexpr explicit expected(std::in_place_t, std::initializer_list<U> il,
                                Args &&...args)
        : Mybase(std::in_place, il, std::forward<Args>(args)...) {}

    template <typename... Args,
              WJR_REQUIRES(std::is_constructible_v<error_type, Args...>)>
    constexpr explicit expected(unexpect_t, Args &&...args)
        : Mybase(unexpect, std::forward<Args>(args)...) {}

    template <typename U, typename... Args,
              WJR_REQUIRES(std::is_constructible_v<error_type, std::initializer_list<U> &,
                                                   Args...>)>
    constexpr explicit expected(unexpect_t, std::initializer_list<U> il, Args &&...args)
        : Mybase(unexpect, il, std::forward<Args>(args)...) {}

#if defined(__cpp_conditional_explicit)
    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &>)>
    constexpr explicit(!std::is_convertible_v<const G &, error_type>)
        expected(const unexpected<G> &e)
        : Mybase(unexpect, std::forward<const G &>(e.error())) {}

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, G>)>
    constexpr explicit(!std::is_convertible_v<G, error_type>) expected(unexpected<G> &&e)
        : Mybase(unexpect, std::forward<G>(e.error())) {}
#else
    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &> &&
                                           std::is_convertible_v<const G &, error_type>)>
    constexpr expected(const unexpected<G> &e)
        : Mybase(unexpect, std::forward<const G &>(e.error())) {}

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &> &&
                                       !std::is_convertible_v<const G &, error_type>)>
    constexpr explicit expected(const unexpected<G> &e)
        : Mybase(unexpect, std::forward<const G &>(e.error())) {}

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, G>
                                           &&std::is_convertible_v<G, error_type>)>
    constexpr expected(unexpected<G> &&e)
        : Mybase(unexpect, std::forward<G>(e.error())) {}
    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, G> &&
                                       !std::is_convertible_v<G, error_type>)>
    constexpr explicit expected(unexpected<G> &&e)
        : Mybase(unexpect, std::forward<G>(e.error())) {}
#endif

#if defined(__cpp_conditional_explicit)
    template <typename U, typename G,
              WJR_REQUIRES(
                  std::is_constructible_v<T, const U &> &&std::is_constructible_v<
                      error_type, const G &>
                      &&expected_detail::expected_construct_with_v<T, error_type, U, G>)>
    constexpr explicit(!(std::is_convertible_v<const U &, T> &&
                         std::is_convertible_v<const G &, error_type>))
        expected(const expected<U, G> &other)
        : Mybase(enable_default_constructor) {
        if (other.has_value()) {
            this->construct_value(std::forward<const U &>(other.m_val));
        } else {
            this->construct_error(std::forward<const G &>(other.m_err));
        }
    }

    template <typename U, typename G,
              WJR_REQUIRES(
                  std::is_constructible_v<T, U> &&std::is_constructible_v<error_type, G>
                      &&expected_detail::expected_construct_with_v<T, error_type, U, G>)>
    constexpr explicit(!(std::is_convertible_v<U, T> &&
                         std::is_convertible_v<G, error_type>))
        expected(expected<U, G> &&other)
        : Mybase(enable_default_constructor) {
        if (other.has_value()) {
            this->construct_value(std::forward<U>(other.m_val));
        } else {
            this->construct_error(std::forward<G>(other.m_err));
        }
    }
#else
    template <typename U, typename G,
              WJR_REQUIRES(
                  std::is_constructible_v<T, const U &> &&std::is_constructible_v<
                      error_type, const G &>
                      &&expected_detail::expected_construct_with_v<T, error_type, U, G> &&
                  (std::is_convertible_v<const U &, T> &&
                   std::is_convertible_v<const G &, error_type>))>
    constexpr expected(const expected<U, G> &other) : Mybase(enable_default_constructor) {
        if (other.has_value()) {
            this->construct_value(std::forward<const U &>(other.m_val));
        } else {
            this->construct_error(std::forward<const G &>(other.m_err));
        }
    }

    template <typename U, typename G,
              WJR_REQUIRES(
                  std::is_constructible_v<T, const U &> &&std::is_constructible_v<
                      error_type, const G &>
                      &&expected_detail::expected_construct_with_v<T, error_type, U, G> &&
                  !(std::is_convertible_v<const U &, T> &&
                    std::is_convertible_v<const G &, error_type>))>
    constexpr explicit expected(const expected<U, G> &other)
        : Mybase(enable_default_constructor) {
        if (other.has_value()) {
            this->construct_value(std::forward<const U &>(other.m_val));
        } else {
            this->construct_error(std::forward<const G &>(other.m_err));
        }
    }

    template <typename U, typename G,
              WJR_REQUIRES(
                  std::is_constructible_v<T, U> &&std::is_constructible_v<error_type, G>
                      &&expected_detail::expected_construct_with_v<T, error_type, U, G> &&
                  (std::is_convertible_v<U, T> && std::is_convertible_v<G, error_type>))>
    constexpr expected(expected<U, G> &&other) : Mybase(enable_default_constructor) {
        if (other.has_value()) {
            this->construct_value(std::forward<U>(other.m_val));
        } else {
            this->construct_error(std::forward<G>(other.m_err));
        }
    }

    template <typename U, typename G,
              WJR_REQUIRES(
                  std::is_constructible_v<T, U> &&std::is_constructible_v<error_type, G>
                      &&expected_detail::expected_construct_with_v<T, error_type, U, G> &&
                  !(std::is_convertible_v<U, T> && std::is_convertible_v<G, error_type>))>
    constexpr explicit expected(expected<U, G> &&other)
        : Mybase(enable_default_constructor) {
        if (other.has_value()) {
            this->construct_value(std::forward<U>(other.m_val));
        } else {
            this->construct_error(std::forward<G>(other.m_err));
        }
    }
#endif

#if defined(__cpp_conditional_explicit)
    template <typename U = T, WJR_REQUIRES(expected_detail::expected_construct_with_arg_v<
                                           T, error_type, U>)>
    constexpr explicit(!std::is_convertible_v<U, T>) expected(U &&v)
        : Mybase(std::in_place, std::forward<U>(v)) {}
#else
    template <typename U = T,
              WJR_REQUIRES(expected_detail::expected_construct_with_arg_v<
                           T, error_type, U> &&std::is_convertible_v<U, T>)>
    constexpr expected(U &&v) : Mybase(std::in_place, std::forward<U>(v)) {}

    template <typename U = T, WJR_REQUIRES(expected_detail::expected_construct_with_arg_v<
                                               T, error_type, U> &&
                                           !std::is_convertible_v<U, T>)>
    constexpr explicit expected(U &&v) : Mybase(std::in_place, std::forward<U>(v)) {}
#endif

    template <typename G,
              WJR_REQUIRES(std::is_constructible_v<error_type, const G &>
                               &&std::is_assignable_v<error_type &, const G &> &&
                           (std::is_nothrow_constructible_v<error_type, const G &> ||
                            std::is_nothrow_move_constructible_v<T> ||
                            std::is_nothrow_move_constructible_v<error_type>))>
    WJR_CONSTEXPR20 expected &operator=(const unexpected<G> &e) {
        if (has_value()) {
            reinit_expected(this->m_err, this->m_val, std::forward<const G &>(e.error()));
            this->set_invalid();
        } else {
            this->m_err = std::forward<const G &>(e.error());
        }

        return *this;
    }

    template <typename G,
              WJR_REQUIRES(std::is_constructible_v<error_type, G>
                               &&std::is_assignable_v<error_type &, G> &&
                           (std::is_nothrow_constructible_v<error_type, G> ||
                            std::is_nothrow_move_constructible_v<T> ||
                            std::is_nothrow_move_constructible_v<error_type>))>
    WJR_CONSTEXPR20 expected &operator=(unexpected<G> &&e) {
        if (has_value()) {
            reinit_expected(this->m_err, this->m_val, std::forward<G>(e.error()));
            this->set_invalid();
        } else {
            this->m_err = std::forward<G>(e.error());
        }

        return *this;
    }

    template <typename U,
              WJR_REQUIRES(!std::is_same_v<remove_cvref_t<U>, expected> &&
                           expected_detail::is_not_unexpected<remove_cvref_t<U>>::value &&
                           std::is_constructible_v<T, U> &&
                           std::is_assignable_v<T &, U> &&
                           (std::is_nothrow_constructible_v<T, U> ||
                            std::is_nothrow_move_constructible_v<T> ||
                            std::is_nothrow_move_constructible_v<error_type>))>
    WJR_CONSTEXPR20 expected &operator=(U &&v) {
        if (has_value()) {
            this->m_val = std::forward<U>(v);
        } else {
            reinit_expected(this->m_val, this->m_err, std::forward<U>(v));
            this->set_valid();
        }

        return *this;
    }

    using Mybase::has_value;
    WJR_PURE constexpr explicit operator bool() const noexcept { return has_value(); }

    constexpr T *operator->() noexcept { return std::addressof(this->m_val); }
    constexpr const T *operator->() const noexcept { return std::addressof(this->m_val); }

    constexpr T &operator*() & noexcept {
        WJR_ASSERT(has_value());
        return this->m_val;
    }
    constexpr const T &operator*() const & noexcept {
        WJR_ASSERT(has_value());
        return this->m_val;
    }
    constexpr T &&operator*() && noexcept {
        WJR_ASSERT(has_value());
        return std::move(this->m_val);
    }
    constexpr const T &&operator*() const && noexcept {
        WJR_ASSERT(has_value());
        return std::move(this->m_val);
    }

    constexpr T &value() & {
        if (WJR_UNLIKELY(!has_value())) {
            WJR_THROW(
                bad_expected_access<std::decay_t<error_type>>(std::as_const(error())));
        }

        return this->m_val;
    }

    constexpr const T &value() const & {
        if (WJR_UNLIKELY(!has_value())) {
            WJR_THROW(
                bad_expected_access<std::decay_t<error_type>>(std::as_const(error())));
        }

        return this->m_val;
    }

    constexpr T &&value() && {
        if (WJR_UNLIKELY(!has_value())) {
            WJR_THROW(bad_expected_access<std::decay_t<error_type>>(std::move(error())));
        }

        return std::move(this->m_val);
    }

    constexpr const T &&value() const && {
        if (WJR_UNLIKELY(!has_value())) {
            WJR_THROW(bad_expected_access<std::decay_t<error_type>>(std::move(error())));
        }

        return std::move(this->m_val);
    }

    constexpr error_type &error() & noexcept {
        WJR_ASSERT(!has_value());
        return this->m_err;
    }
    constexpr const error_type &error() const & noexcept {
        WJR_ASSERT(!has_value());
        return this->m_err;
    }
    constexpr error_type &&error() && noexcept {
        WJR_ASSERT(!has_value());
        return std::move(this->m_err);
    }
    constexpr const error_type &&error() const && noexcept {
        WJR_ASSERT(!has_value());
        return std::move(this->m_err);
    }

    template <typename U>
    constexpr T value_or(U &&default_value) const & {
        return has_value() ? **this : static_cast<T>(std::forward<U>(default_value));
    }

    template <typename U>
    constexpr T value_or(U &&default_value) && {
        return has_value() ? std::move(**this)
                           : static_cast<T>(std::forward<U>(default_value));
    }

    template <typename G = error_type>
    constexpr error_type error_or(G &&default_value) const & {
        return has_value() ? std::forward<G>(default_value) : error();
    }

    template <typename G = error_type>
    constexpr error_type error_or(G &&default_value) && {
        return has_value() ? std::forward<G>(default_value) : std::move(error());
    }

    template <typename Func, typename U = __expected_result<Func, T &>>
    constexpr U and_then(Func &&func) & {
        if (has_value()) {
            return std::invoke(std::forward<Func>(func), this->m_val);
        }

        return U(unexpect, error());
    }

    template <typename Func, typename U = __expected_result<Func, const T &>>
    constexpr U and_then(Func &&func) const & {
        if (has_value()) {
            return std::invoke(std::forward<Func>(func), this->m_val);
        }

        return U(unexpect, error());
    }

    template <typename Func, typename U = __expected_result<Func, T &&>>
    constexpr U and_then(Func &&func) && {
        if (has_value()) {
            return std::invoke(std::forward<Func>(func), std::move(this->m_val));
        }

        return U(unexpect, std::move(error()));
    }

    template <typename Func, typename U = __expected_result<Func, const T &&>>
    constexpr U and_then(Func &&func) const && {
        if (has_value()) {
            return std::invoke(std::forward<Func>(func), std::move(this->m_val));
        }

        return U(unexpect, std::move(error()));
    }

    template <typename Func, typename U = __expected_result<Func, E &>>
    constexpr U or_else(Func &&func) & {
        if (!has_value()) {
            return std::invoke(std::forward<Func>(func), error());
        }

        return U(std::in_place, this->m_val);
    }

    template <typename Func, typename U = __expected_result<Func, const E &>>
    constexpr U or_else(Func &&func) const & {
        if (!has_value()) {
            return std::invoke(std::forward<Func>(func), error());
        }

        return U(std::in_place, this->m_val);
    }

    template <typename Func, typename U = __expected_result<Func, E &&>>
    constexpr U or_else(Func &&func) && {
        if (!has_value()) {
            return std::invoke(std::forward<Func>(func), std::move(error()));
        }

        return U(std::in_place, std::move(this->m_val));
    }

    template <typename Func, typename U = __expected_result<Func, const E &&>>
    constexpr U or_else(Func &&func) const && {
        if (!has_value()) {
            return std::invoke(std::forward<Func>(func), std::move(error()));
        }

        return U(std::in_place, std::move(this->m_val));
    }

    template <typename Func, typename U = __expected_result<Func, T &>>
    constexpr expected<U, E> transform(Func &&func) & {
        if (has_value()) {
            if constexpr (!std::is_void_v<U>) {
                return std::invoke(std::forward<Func>(func), this->m_val);
            } else {
                std::invoke(std::forward<Func>(func), this->m_val);
                return {};
            }
        }

        return expected<U, E>(unexpect, error());
    }

    template <typename Func, typename U = __expected_result<Func, const T &>>
    constexpr expected<U, E> transform(Func &&func) const & {
        if (has_value()) {
            if constexpr (!std::is_void_v<U>) {
                return std::invoke(std::forward<Func>(func), this->m_val);
            } else {
                std::invoke(std::forward<Func>(func), this->m_val);
                return {};
            }
        }

        return expected<U, E>(unexpect, error());
    }

    template <typename Func, typename U = __expected_result<Func, T &&>>
    constexpr expected<U, E> transform(Func &&func) && {
        if (has_value()) {
            if constexpr (!std::is_void_v<U>) {
                return std::invoke(std::forward<Func>(func), std::move(this->m_val));
            } else {
                std::invoke(std::forward<Func>(func), std::move(this->m_val));
                return {};
            }
        }

        return expected<U, E>(unexpect, std::move(error()));
    }

    template <typename Func, typename U = __expected_result<Func, const T &&>>
    constexpr expected<U, E> transform(Func &&func) const && {
        if (has_value()) {
            if constexpr (!std::is_void_v<U>) {
                return std::invoke(std::forward<Func>(func), std::move(this->m_val));
            } else {
                std::invoke(std::forward<Func>(func), std::move(this->m_val));
                return {};
            }
        }

        return expected<U, E>(unexpect, std::move(error()));
    }

    template <typename Func, typename G = __expected_result<Func, error_type &>>
    constexpr expected<T, G> transform_error(Func &&func) & {
        if (!has_value()) {
            return expected<T, G>(unexpect,
                                  std::invoke(std::forward<Func>(func), error()));
        }

        return expected<T, G>(std::in_place, this->m_val);
    }

    template <typename Func, typename G = __expected_result<Func, const error_type &>>
    constexpr expected<T, G> transform_error(Func &&func) const & {
        if (!has_value()) {
            return expected<T, G>(unexpect,
                                  std::invoke(std::forward<Func>(func), error()));
        }

        return expected<T, G>(std::in_place, this->m_val);
    }

    template <typename Func, typename G = __expected_result<Func, error_type &&>>
    constexpr expected<T, G> transform_error(Func &&func) && {
        if (!has_value()) {
            return expected<T, G>(
                unexpect, std::invoke(std::forward<Func>(func), std::move(error())));
        }

        return expected<T, G>(std::in_place, std::move(this->m_val));
    }

    template <typename Func, typename G = __expected_result<Func, const error_type &&>>
    constexpr expected<T, G> transform_error(Func &&func) const && {
        if (!has_value()) {
            return expected<T, G>(
                unexpect, std::invoke(std::forward<Func>(func), std::move(error())));
        }

        return expected<T, G>(std::in_place, std::move(this->m_val));
    }

    template <typename... Args, WJR_REQUIRES(std::is_constructible_v<T, Args...>)>
    constexpr T &emplace(Args &&...args) noexcept {
        if (has_value()) {
            std::destroy_at(std::addressof(this->m_val));
        } else {
            std::destroy_at(std::addressof(this->m_err));
            this->set_valid();
        }

        construct_at(std::addressof(this->m_val), std::forward<Args>(args)...);
        return this->m_val;
    }

    template <
        typename U, typename... Args,
        WJR_REQUIRES(std::is_constructible_v<T, std::initializer_list<U> &, Args...>)>
    constexpr T &emplace(std::initializer_list<U> il, Args &&...args) noexcept {
        if (has_value()) {
            std::destroy_at(std::addressof(this->m_val));
        } else {
            std::destroy_at(std::addressof(this->m_err));
            this->set_valid();
        }

        construct_at(std::addressof(this->m_val), il, std::forward<Args>(args)...);
        return this->m_val;
    }

private:
    WJR_CONSTEXPR20 void __swap_impl(expected &other) noexcept(
        std::is_nothrow_move_constructible_v<T> &&std::is_nothrow_swappable_v<T>
            &&std::is_nothrow_move_constructible_v<error_type>
                &&std::is_nothrow_swappable_v<error_type>) {
        if constexpr (std::is_nothrow_move_constructible_v<error_type>) {
            error_type temp(std::move(other.m_err));
            std::destroy_at(std::addressof(other.m_err));
            WJR_TRY {
                construct_at(std::addressof(other.m_val), std::move(this->m_val));
                std::destroy_at(std::addressof(this->m_val));
                construct_at(std::addressof(this->m_err), std::move(temp));
            }
            WJR_CATCH(...) {
                construct_at(std::addressof(other.m_err), std::move(temp));
                WJR_XTHROW;
            }
        } else {
            T temp(std::move(this->m_val));
            std::destroy_at(std::addressof(this->m_val));
            WJR_TRY {
                construct_at(std::addressof(this->m_err), std::move(other.m_err));
                std::destroy_at(std::addressof(other.m_err));
                construct_at(std::addressof(other.m_val), std::move(temp));
            }
            WJR_CATCH(...) {
                construct_at(std::addressof(this->m_val), std::move(temp));
                WJR_XTHROW;
            }
        }
    }

public:
    template <typename _T = T,
              WJR_REQUIRES(std::is_swappable_v<_T> &&std::is_swappable_v<error_type>
                               &&std::is_move_constructible_v<_T>
                                   &&std::is_move_constructible_v<error_type> &&
                           (std::is_nothrow_move_constructible_v<_T> ||
                            std::is_nothrow_move_constructible_v<error_type>))>
    WJR_CONSTEXPR20 void swap(expected &other) noexcept(
        std::is_nothrow_move_constructible_v<T> &&std::is_nothrow_swappable_v<T>
            &&std::is_nothrow_move_constructible_v<error_type>
                &&std::is_nothrow_swappable_v<error_type>) {
        using std::swap;
        if (has_value()) {
            if (other.has_value()) {
                std::swap(this->m_val, other.m_val);
            } else {
                __swap_impl(other);
            }
        } else {
            if (!other.has_value()) {
                std::swap(this->m_err, other.m_err);
            } else {
                other.__swap_impl(*this);
            }
        }
    }

    template <typename T2, typename E2>
    friend constexpr bool operator==(const expected &lhs, const expected<T2, E2> &rhs) {
        if (WJR_UNLIKELY(lhs.has_value() != rhs.has_value())) {
            return false;
        }

        if (lhs.has_value()) {
            return *lhs == *rhs;
        }

        return lhs.error() == rhs.error();
    }

    template <typename E2>
    friend constexpr bool operator==(const expected &lhs, const unexpected<E2> &rhs) {
        return !lhs.has_value() && lhs.error() == rhs.error();
    }

    template <typename E2>
    friend constexpr bool operator==(const unexpected<E2> &lhs, const expected &rhs) {
        return rhs == lhs;
    }

    template <
        typename U,
        WJR_REQUIRES(expected_detail::is_not_expected<remove_cvref_t<U>>::value
                         &&expected_detail::is_not_unexpected<remove_cvref_t<U>>::value)>
    friend constexpr bool operator==(const expected &lhs, const U &rhs) {
        return lhs.has_value() && *lhs == rhs;
    }

    template <
        typename U,
        WJR_REQUIRES(expected_detail::is_not_expected<remove_cvref_t<U>>::value
                         &&expected_detail::is_not_unexpected<remove_cvref_t<U>>::value)>
    friend constexpr bool operator==(const U &lhs, const expected &rhs) {
        return rhs == lhs;
    }
};

template <typename E>
class WJR_EMPTY_BASES expected<void, E>
    : expected_detail::expected_storage<void, E>,
      expected_detail::enable_expected_storage<void, __expected_error_type_t<E>> {
    using Mybase = expected_detail::expected_storage<void, E>;

public:
    using value_type = void;
    using error_type = typename Mybase::error_type;
    using unexpected_type = unexpected<error_type>;

    using Mybase::Mybase;

    expected() = default;
    expected(const expected &) = default;
    expected(expected &&) = default;
    expected &operator=(const expected &) = default;
    expected &operator=(expected &&) = default;
    ~expected() = default;

    constexpr explicit expected(std::in_place_t) : Mybase(std::in_place) {}

    template <typename... Args,
              WJR_REQUIRES(std::is_constructible_v<error_type, Args...>)>
    constexpr explicit expected(unexpect_t, Args &&...args)
        : Mybase(unexpect, std::forward<Args>(args)...) {}

    template <typename U, typename... Args,
              WJR_REQUIRES(std::is_constructible_v<error_type, std::initializer_list<U> &,
                                                   Args...>)>
    constexpr explicit expected(unexpect_t, std::initializer_list<U> il, Args &&...args)
        : Mybase(unexpect, il, std::forward<Args>(args)...) {}

#if defined(__cpp_conditional_explicit)
    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &>)>
    constexpr explicit(!std::is_convertible_v<const G &, error_type>)
        expected(const unexpected<G> &e)
        : Mybase(unexpect, std::forward<const G &>(e.error())) {}

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, G>)>
    constexpr explicit(!std::is_convertible_v<G, error_type>) expected(unexpected<G> &&e)
        : Mybase(unexpect, std::forward<G>(e.error())) {}
#else
    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &> &&
                                           std::is_convertible_v<const G &, error_type>)>
    constexpr expected(const unexpected<G> &e)
        : Mybase(unexpect, std::forward<const G &>(e.error())) {}

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &> &&
                                       !std::is_convertible_v<const G &, error_type>)>
    constexpr explicit expected(const unexpected<G> &e)
        : Mybase(unexpect, std::forward<const G &>(e.error())) {}

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, G>
                                           &&std::is_convertible_v<G, error_type>)>
    constexpr expected(unexpected<G> &&e)
        : Mybase(unexpect, std::forward<G>(e.error())) {}
    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, G> &&
                                       !std::is_convertible_v<G, error_type>)>
    constexpr explicit expected(unexpected<G> &&e)
        : Mybase(unexpect, std::forward<G>(e.error())) {}
#endif

#if defined(__cpp_conditional_explicit)
    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &>
                                           &&expected_detail::expected_construct_with_v<
                                               void, error_type, void, G>)>
    constexpr explicit(!std::is_convertible_v<const G &, error_type>)
        expected(const expected<void, G> &other)
        : Mybase(enable_default_constructor) {
        if (!other.has_value()) {
            this->construct_error(std::forward<const G &>(other.m_err));
        }
    }

    template <typename G,
              WJR_REQUIRES(std::is_constructible_v<error_type, G> &&expected_detail::
                               expected_construct_with_v<void, error_type, void, G>)>
    constexpr explicit(!std::is_convertible_v<G, error_type>)
        expected(expected<void, G> &&other)
        : Mybase(enable_default_constructor) {
        if (!other.has_value()) {
            this->construct_error(std::forward<G>(other.m_err));
        }
    }
#else
    template <typename G,
              WJR_REQUIRES(std::is_constructible_v<error_type, const G &>
                               &&expected_detail::expected_construct_with_v<
                                   void, error_type, void, G>
                                   &&std::is_convertible_v<const G &, error_type>)>
    constexpr expected(const expected<void, G> &other)
        : Mybase(enable_default_constructor) {
        if (!other.has_value()) {
            this->construct_error(std::forward<const G &>(other.m_err));
        }
    }

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &>
                                           &&expected_detail::expected_construct_with_v<
                                               void, error_type, void, G> &&
                                       !std::is_convertible_v<const G &, error_type>)>
    constexpr explicit expected(const expected<void, G> &other)
        : Mybase(enable_default_constructor) {
        if (!other.has_value()) {
            this->construct_error(std::forward<const G &>(other.m_err));
        }
    }

    template <typename G,
              WJR_REQUIRES(std::is_constructible_v<error_type, G> &&expected_detail::
                               expected_construct_with_v<void, error_type, void, G>
                                   &&std::is_convertible_v<G, error_type>)>
    constexpr expected(expected<void, G> &&other) : Mybase(enable_default_constructor) {
        if (!other.has_value()) {
            this->construct_error(std::forward<G>(other.m_err));
        }
    }

    template <typename G,
              WJR_REQUIRES(std::is_constructible_v<error_type, G> &&expected_detail::
                               expected_construct_with_v<void, error_type, void, G> &&
                           !std::is_convertible_v<G, error_type>)>
    constexpr explicit expected(expected<void, G> &&other)
        : Mybase(enable_default_constructor) {
        if (!other.has_value()) {
            this->construct_error(std::forward<G>(other.m_err));
        }
    }
#endif

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, const G &> &&
                                           std::is_assignable_v<error_type &, const G &>)>
    WJR_CONSTEXPR20 expected &operator=(const unexpected<G> &e) {
        if (has_value()) {
            construct_at(std::addressof(this->m_err), std::forward<const G &>(e.error()));
            this->set_invalid();
        } else {
            this->m_err = std::forward<const G &>(e.error());
        }

        return *this;
    }

    template <typename G, WJR_REQUIRES(std::is_constructible_v<error_type, G>
                                           &&std::is_assignable_v<error_type &, G>)>
    WJR_CONSTEXPR20 expected &operator=(unexpected<G> &&e) {
        if (has_value()) {
            construct_at(std::addressof(this->m_err), std::forward<G>(e.error()));
            this->set_invalid();
        } else {
            this->m_err = std::forward<G>(e.error());
        }

        return *this;
    }

    using Mybase::has_value;
    WJR_PURE constexpr explicit operator bool() const noexcept { return has_value(); }

    constexpr void operator*() const noexcept { WJR_ASSERT(has_value()); }

    constexpr void value() const & {
        if (WJR_UNLIKELY(!has_value())) {
            WJR_THROW(
                bad_expected_access<std::decay_t<error_type>>(std::as_const(error())));
        }
    }

    constexpr void value() && {
        if (WJR_UNLIKELY(!has_value())) {
            WJR_THROW(bad_expected_access<std::decay_t<error_type>>(std::move(error())));
        }
    }

    constexpr error_type &error() & noexcept {
        WJR_ASSERT(!has_value());
        return this->m_err;
    }
    constexpr const error_type &error() const & noexcept {
        WJR_ASSERT(!has_value());
        return this->m_err;
    }
    constexpr error_type &&error() && noexcept {
        WJR_ASSERT(!has_value());
        return std::move(this->m_err);
    }
    constexpr const error_type &&error() const && noexcept {
        WJR_ASSERT(!has_value());
        return std::move(this->m_err);
    }

    template <typename G = error_type>
    constexpr error_type error_or(G &&default_value) const & {
        return has_value() ? std::forward<G>(default_value) : error();
    }

    template <typename G = error_type>
    constexpr error_type error_or(G &&default_value) && {
        return has_value() ? std::forward<G>(default_value) : std::move(error());
    }

    template <typename Func, typename U = __expected_result<Func>>
    constexpr U and_then(Func &&func) & {
        if (has_value()) {
            return std::invoke(std::forward<Func>(func));
        }

        return U(unexpect, error());
    }

    template <typename Func, typename U = __expected_result<Func>>
    constexpr U and_then(Func &&func) const & {
        if (has_value()) {
            return std::invoke(std::forward<Func>(func));
        }

        return U(unexpect, error());
    }

    template <typename Func, typename U = __expected_result<Func>>
    constexpr U and_then(Func &&func) && {
        if (has_value()) {
            return std::invoke(std::forward<Func>(func));
        }

        return U(unexpect, std::move(error()));
    }

    template <typename Func, typename U = __expected_result<Func>>
    constexpr U and_then(Func &&func) const && {
        if (has_value()) {
            return std::invoke(std::forward<Func>(func));
        }

        return U(unexpect, std::move(error()));
    }

    template <typename Func, typename U = __expected_result<Func, E &>>
    constexpr U or_else(Func &&func) & {
        if (!has_value()) {
            return std::invoke(std::forward<Func>(func), error());
        }

        return U();
    }

    template <typename Func, typename U = __expected_result<Func, const E &>>
    constexpr U or_else(Func &&func) const & {
        if (!has_value()) {
            return std::invoke(std::forward<Func>(func), error());
        }

        return U();
    }

    template <typename Func, typename U = __expected_result<Func, E &&>>
    constexpr U or_else(Func &&func) && {
        if (!has_value()) {
            return std::invoke(std::forward<Func>(func), std::move(error()));
        }

        return U();
    }

    template <typename Func, typename U = __expected_result<Func, const E &&>>
    constexpr U or_else(Func &&func) const && {
        if (!has_value()) {
            return std::invoke(std::forward<Func>(func), std::move(error()));
        }

        return U();
    }

    template <typename Func, typename U = __expected_result<Func>>
    constexpr expected<U, E> transform(Func &&func) & {
        if (has_value()) {
            if constexpr (!std::is_void_v<U>) {
                return std::invoke(std::forward<Func>(func));
            } else {
                std::invoke(std::forward<Func>(func));
                return {};
            }
        }

        return expected<U, E>(unexpect, error());
    }

    template <typename Func, typename U = __expected_result<Func>>
    constexpr expected<U, E> transform(Func &&func) const & {
        if (has_value()) {
            if constexpr (!std::is_void_v<U>) {
                return std::invoke(std::forward<Func>(func));
            } else {
                std::invoke(std::forward<Func>(func));
                return {};
            }
        }

        return expected<U, E>(unexpect, error());
    }

    template <typename Func, typename U = __expected_result<Func>>
    constexpr expected<U, E> transform(Func &&func) && {
        if (has_value()) {
            if constexpr (!std::is_void_v<U>) {
                return std::invoke(std::forward<Func>(func));
            } else {
                std::invoke(std::forward<Func>(func));
                return {};
            }
        }

        return expected<U, E>(unexpect, std::move(error()));
    }

    template <typename Func, typename U = __expected_result<Func>>
    constexpr expected<U, E> transform(Func &&func) const && {
        if (has_value()) {
            if constexpr (!std::is_void_v<U>) {
                return std::invoke(std::forward<Func>(func));
            } else {
                std::invoke(std::forward<Func>(func));
                return {};
            }
        }

        return expected<U, E>(unexpect, std::move(error()));
    }

    template <typename Func, typename G = __expected_result<Func, error_type &>>
    constexpr expected<void, G> transform_error(Func &&func) & {
        if (!has_value()) {
            return expected<void, G>(unexpect,
                                     std::invoke(std::forward<Func>(func), error()));
        }

        return expected<void, G>(std::in_place);
    }

    template <typename Func, typename G = __expected_result<Func, const error_type &>>
    constexpr expected<void, G> transform_error(Func &&func) const & {
        if (!has_value()) {
            return expected<void, G>(unexpect,
                                     std::invoke(std::forward<Func>(func), error()));
        }

        return expected<void, G>(std::in_place);
    }

    template <typename Func, typename G = __expected_result<Func, error_type &&>>
    constexpr expected<void, G> transform_error(Func &&func) && {
        if (!has_value()) {
            return expected<void, G>(
                unexpect, std::invoke(std::forward<Func>(func), std::move(error())));
        }

        return expected<void, G>(std::in_place);
    }

    template <typename Func, typename G = __expected_result<Func, const error_type &&>>
    constexpr expected<void, G> transform_error(Func &&func) const && {
        if (!has_value()) {
            return expected<void, G>(
                unexpect, std::invoke(std::forward<Func>(func), std::move(error())));
        }

        return expected<void, G>(std::in_place);
    }

    constexpr void emplace() noexcept {
        if (!has_value()) {
            std::destroy_at(std::addressof(this->m_err));
            this->set_valid();
        }
    }

private:
    WJR_CONSTEXPR20 void
    __swap_impl(expected &other) noexcept(std::is_nothrow_move_constructible_v<error_type>
                                              &&std::is_nothrow_swappable_v<error_type>) {
        if constexpr (std::is_nothrow_move_constructible_v<error_type>) {
            construct_at(std::addressof(this->m_err), std::move(other.m_err));
            std::destroy_at(std::addressof(other.m_err));
        } else {
            WJR_TRY {
                construct_at(std::addressof(this->m_err), std::move(other.m_err));
                std::destroy_at(std::addressof(other.m_err));
            }
            WJR_CATCH(...) { WJR_XTHROW; }
        }
    }

public:
    template <typename _E = error_type,
              WJR_REQUIRES(std::is_swappable_v<_E> &&std::is_move_constructible_v<_E>)>
    WJR_CONSTEXPR20 void
    swap(expected &other) noexcept(std::is_nothrow_move_constructible_v<error_type>
                                       &&std::is_nothrow_swappable_v<error_type>) {
        using std::swap;
        if (has_value()) {
            if (!other.has_value()) {
                __swap_impl(other);
            }
        } else {
            if (!other.has_value()) {
                std::swap(this->m_err, other.m_err);
            } else {
                other.__swap_impl(*this);
            }
        }
    }

    template <typename T2, typename E2>
    friend constexpr bool operator==(const expected &lhs, const expected<T2, E2> &rhs) {
        if (WJR_UNLIKELY(lhs.has_value() != rhs.has_value())) {
            return false;
        }

        if (lhs.has_value()) {
            return true;
        }

        return lhs.error() == rhs.error();
    }

    template <typename E2>
    friend constexpr bool operator==(const expected &lhs, const unexpected<E2> &rhs) {
        return !lhs.has_value() && lhs.error() == rhs.error();
    }

    template <typename E2>
    friend constexpr bool operator==(const unexpected<E2> &lhs, const expected &rhs) {
        return rhs == lhs;
    }
};

template <typename T, typename E, E init>
using compressed_expected = expected<T, compressed_unexpected<E, init>>;

#define WJR_EXPECTED_TRY(...)                                                            \
    do {                                                                                 \
        if (auto exp = (__VA_ARGS__); WJR_UNLIKELY(!exp)) {                              \
            return ::wjr::unexpected(std::move(exp).error());                            \
        }                                                                                \
    } while (0)

#define WJR_EXPECTED_INIT(NAME, ...)                                                     \
    auto NAME = (__VA_ARGS__);                                                           \
    if (WJR_UNLIKELY(!NAME)) {                                                           \
        return ::wjr::unexpected(std::move(NAME).error());                               \
    }

#define WJR_EXPECTED_SET(VAR, ...)                                                       \
    do {                                                                                 \
        if (auto exp = (__VA_ARGS__); WJR_UNLIKELY(!exp)) {                              \
            return ::wjr::unexpected(std::move(exp).error());                            \
        } else {                                                                         \
            VAR = *std::move(exp);                                                       \
        }                                                                                \
    } while (0)

} // namespace wjr

namespace std {

template <typename E>
constexpr void swap(wjr::unexpected<E> &lhs,
                    wjr::unexpected<E> &rhs) noexcept(noexcept(lhs.swap(rhs))) {
    lhs.swap(rhs);
}

template <typename T, typename E>
constexpr void swap(wjr::expected<T, E> &lhs,
                    wjr::expected<T, E> &rhs) noexcept(noexcept(lhs.swap(rhs))) {
    lhs.swap(rhs);
}

} // namespace std

#endif // WJR_EXPECTED_HPP__
#ifndef WJR_FORMAT_CHARCONV_IMPL_HPP__
#define WJR_FORMAT_CHARCONV_IMPL_HPP__

#include <array>

// Already included

namespace wjr {

enum class convert_option : uint8_t {
    none = 0x00,
    no_leading_zeros = 0x01,
};

template <convert_option option>
using convert_option_t = integral_constant<convert_option, option>;

class char_converter_t {
    static constexpr std::array<uint8_t, 36> to_table = {
        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b',
        'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',
        'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'};

    static constexpr std::array<uint8_t, 256> from_table = {
        127, 127, 127, 127, 127, 127, 127, 127, 127, 64,  64,  64,  64,  64,  127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        64,  127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        0,   1,   2,   3,   4,   5,   6,   7,   8,   9,   127, 127, 127, 127, 127, 127,
        127, 10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,
        25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  127, 127, 127, 127, 127,
        127, 10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,
        25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,
        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127};

public:
    template <uint64_t Base = 0>
    WJR_CONST static constexpr uint8_t to(uint8_t x) noexcept {
        if constexpr (Base == 0) {
            WJR_ASSERT_L3(x < 36);
        } else {
            WJR_ASSERT_L3(x < Base);
        }

        if constexpr (Base == 0 || Base > 10) {

            if (WJR_BUILTIN_CONSTANT_P_TRUE(x < 10)) {
                return x + '0';
            }

            return to_table[x];
        } else {
            return x + '0';
        }
    }

    template <uint64_t Base = 0>
    WJR_CONST static constexpr uint8_t from(uint8_t x) noexcept {
        if constexpr (Base == 0 || Base > 10) {
            return from_table[x];
        } else {
            return x - '0';
        }
    }
};

inline constexpr char_converter_t char_converter;

class origin_converter_t {
public:
    template <uint64_t Base = 0>
    WJR_CONST static constexpr uint64_t to(uint64_t x) noexcept {
        return x;
    }

    template <uint64_t Base = 0>
    WJR_CONST static constexpr uint64_t from(uint64_t x) noexcept {
        return x;
    }
};

inline constexpr origin_converter_t origin_converter;

enum class chars_format : uint8_t {
    scientific = 0x01,
    fixed = 0x02,
    hex = 0x04,
    general = fixed | scientific,
    // only used in integeral_constant
    __json_format = 0x08,
    json = general | __json_format,
};

template <typename Iter>
struct to_chars_result {
    Iter ptr;
    std::errc ec;

    friend bool operator==(const to_chars_result &lhs,
                           const to_chars_result &rhs) noexcept {
        return lhs.ptr == rhs.ptr && lhs.ec == rhs.ec;
    }

    constexpr explicit operator bool() const noexcept { return ec == std::errc{}; }
};

template <typename Iter = const char *>
struct from_chars_result {
    Iter ptr;
    std::errc ec;

    friend bool operator==(const from_chars_result &lhs,
                           const from_chars_result &rhs) noexcept {
        return lhs.ptr == rhs.ptr && lhs.ec == rhs.ec;
    }

    constexpr explicit operator bool() const noexcept { return ec == std::errc{}; }
};

WJR_PURE WJR_INTRINSIC_INLINE bool
is_made_of_eight_digits_fast(const char *src) noexcept {
    const auto val = read_memory<uint64_t>(src);
    return ((val & 0xF0F0F0F0F0F0F0F0) & (val + 0x0606060606060606)) ==
           0x3030303030303030;
}

WJR_PURE WJR_INTRINSIC_INLINE uint32_t
parse_eight_digits_unrolled(const char *src) noexcept;

} // namespace wjr

#endif // WJR_FORMAT_CHARCONV_IMPL_HPP__
// Already included
#ifndef WJR_MATH_MUL_HPP__
#define WJR_MATH_MUL_HPP__

/**
 * @todo optimize temporary memory usage of mul_s, mul_n, sqr
 *
 */

#ifndef WJR_MATH_ADD_HPP__
#define WJR_MATH_ADD_HPP__

// Already included
#ifndef WJR_MATH_ADD_IMPL_HPP__
#define WJR_MATH_ADD_IMPL_HPP__

// Already included

namespace wjr {

template <typename T, typename U,
          WJR_REQUIRES(is_nonbool_unsigned_integral_v<T> &&is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 T addc(T a, T b, type_identity_t<U> c_in,
                                               U &c_out) noexcept;

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 T addc_cc(T a, T b, uint8_t c_in,
                                                  uint8_t &c_out) noexcept;

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 bool
add_overflow(type_identity_t<T> a, type_identity_t<T> b, T &ret) noexcept;

template <typename U = uint64_t, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 U addc_1(uint64_t *dst, const uint64_t *src0,
                                                 size_t n, uint64_t src1,
                                                 U c_in = 0) noexcept;

template <typename U = uint64_t, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 U addc_n(uint64_t *dst, const uint64_t *src0,
                                                 const uint64_t *src1, size_t n,
                                                 U c_in = 0) noexcept;

template <typename U = uint64_t, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 U addc_s(uint64_t *dst, const uint64_t *src0,
                                                 size_t n, const uint64_t *src1, size_t m,
                                                 U c_in = 0) noexcept;

/// @note m can be zero
template <typename U = uint64_t, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 U addc_sz(uint64_t *dst, const uint64_t *src0,
                                                  size_t n, const uint64_t *src1,
                                                  size_t m, U c_in = 0) noexcept;

WJR_INTRINSIC_CONSTEXPR20 void __add_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                         uint64_t hi0, uint64_t lo1,
                                         uint64_t hi1) noexcept;

WJR_INTRINSIC_CONSTEXPR20 uint64_t __addc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                              uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                              uint64_t c_in) noexcept;

WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 uint8_t __addc_cc_128(uint64_t &al, uint64_t &ah,
                                                              uint64_t lo0, uint64_t hi0,
                                                              uint64_t lo1, uint64_t hi1,
                                                              uint8_t c_in) noexcept;

} // namespace wjr

#endif // WJR_MATH_ADD_IMPL_HPP__
#ifndef WJR_MATH_REPLACE_HPP__
#define WJR_MATH_REPLACE_HPP__

#ifndef WJR_MATH_FIND_HPP__
#define WJR_MATH_FIND_HPP__

// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_FIND_HPP__
#define WJR_X86_MATH_FIND_HPP__

#ifndef WJR_X86_MATH_LARGE_FIND_IMPL_HPP__
#define WJR_X86_MATH_LARGE_FIND_IMPL_HPP__

// Already included
// Already included
// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

namespace wjr {

#if WJR_HAS_SIMD(SSE4_1)
#define WJR_HAS_BUILTIN_FIND_N WJR_HAS_DEF
#define WJR_HAS_BUILTIN_REVERSE_FIND_N WJR_HAS_DEF
#define WJR_HAS_BUILTIN_FIND_NOT_N WJR_HAS_DEF
#define WJR_HAS_BUILTIN_REVERSE_FIND_NOT_N WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(FIND_NOT_N)

template <typename T>
WJR_PURE size_t large_builtin_find_not_n(const T *src0, const T *src1,
                                         size_t n) noexcept {
#define WJR_REGISTER_FIND_NOT_N_2(index)                                                 \
    do {                                                                                 \
        const auto x = sse::loadu(src0 + (index));                                       \
        const auto y = sse::loadu(src1 + (index));                                       \
        const auto r = sse::cmpeq_epi64(x, y);                                           \
                                                                                         \
        const sse::mask_type mask = ~sse::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            return (index) + (mask == 0xFF00);                                           \
        }                                                                                \
    } while (0)

#if WJR_HAS_SIMD(AVX2)
#define WJR_REGISTER_FIND_NOT_N_4(index)                                                 \
    do {                                                                                 \
        const auto x = avx::loadu(src0 + (index));                                       \
        const auto y = avx::loadu(src1 + (index));                                       \
        const auto r = avx::cmpeq_epi64(x, y);                                           \
                                                                                         \
        const avx::mask_type mask = ~avx::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            return (index) + ctz(mask) / 8;                                              \
        }                                                                                \
    } while (0)
#else
#define WJR_REGISTER_FIND_NOT_N_4(index)                                                 \
    WJR_REGISTER_FIND_NOT_N_2(index);                                                    \
    WJR_REGISTER_FIND_NOT_N_2((index) + 2)
#endif

#define WJR_REGISTER_FIND_NOT_N_ADVNCE(index)                                            \
    src0 += index;                                                                       \
    src1 += index

#define WJR_REGISTER_FIND_NOT_N_RET(index) index

    WJR_REGISTER_X86_NORMAL_SIMD_FUNCTION(
        n, WJR_REGISTER_FIND_NOT_N_2, WJR_REGISTER_FIND_NOT_N_4, WJR_HAS_SIMD(AVX2),
        WJR_REGISTER_FIND_NOT_N_ADVNCE, const auto __src0 = src0,
        WJR_REGISTER_FIND_NOT_N_RET);

#if !WJR_HAS_SIMD(AVX2)
    do {
        const auto r0 = sse::cmpeq_epi64(sse::loadu(src0), sse::loadu(src1));
        const auto r1 = sse::cmpeq_epi64(sse::loadu(src0 + 2), sse::loadu(src1 + 2));
        const auto r2 = sse::cmpeq_epi64(sse::loadu(src0 + 4), sse::loadu(src1 + 4));
        const auto r3 = sse::cmpeq_epi64(sse::loadu(src0 + 6), sse::loadu(src1 + 6));

        const auto z = sse::And(sse::And(r0, r1), sse::And(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_ones(z))) {
            sse::mask_type mask = ~sse::movemask_epi8(r0);
            if (mask != 0) {
                return (src0 - __src0) + ctz(mask) / 8;
            }

            mask = ~sse::movemask_epi8(r1);
            if (mask != 0) {
                return (src0 - __src0) + 2 + ctz(mask) / 8;
            }

            mask = ~sse::movemask_epi8(r2);
            if (mask != 0) {
                return (src0 - __src0) + 4 + ctz(mask) / 8;
            }

            mask = ~sse::movemask_epi8(r3);
            return (src0 - __src0) + 6 + ctz(mask) / 8;
        }

        src0 += 8;
        src1 += 8;
        n -= 8;
    } while (WJR_LIKELY(n != 0));
#else
    do {
        const auto r0 = avx::cmpeq_epi64(avx::loadu(src0), avx::loadu(src1));
        const auto r1 = avx::cmpeq_epi64(avx::loadu(src0 + 4), avx::loadu(src1 + 4));
        const auto r2 = avx::cmpeq_epi64(avx::loadu(src0 + 8), avx::loadu(src1 + 8));
        const auto r3 = avx::cmpeq_epi64(avx::loadu(src0 + 12), avx::loadu(src1 + 12));

        const auto z = avx::And(avx::And(r0, r1), avx::And(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_ones(z))) {
            avx::mask_type mask = ~avx::movemask_epi8(r0);
            if (mask != 0) {
                return (src0 - __src0) + ctz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r1);
            if (mask != 0) {
                return (src0 - __src0) + 4 + ctz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r2);
            if (mask != 0) {
                return (src0 - __src0) + 8 + ctz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r3);
            return (src0 - __src0) + 12 + ctz(mask) / 8;
        }

        src0 += 16;
        src1 += 16;
        n -= 16;
    } while (WJR_LIKELY(n != 0));
#endif

    return src0 - __src0;

#undef WJR_REGISTER_FIND_NOT_N_RET
#undef WJR_REGISTER_FIND_NOT_N_ADVNCE
#undef WJR_REGISTER_FIND_NOT_N_4
#undef WJR_REGISTER_FIND_NOT_N_2
}

extern template WJR_PURE size_t large_builtin_find_not_n<uint64_t>(const uint64_t *src0,
                                                                   const uint64_t *src1,
                                                                   size_t n) noexcept;

template <typename T>
WJR_PURE size_t large_builtin_find_not_n(const T *src, T val, size_t n) noexcept {
#define WJR_REGISTER_FIND_NOT_N_2(index)                                                 \
    do {                                                                                 \
        const auto r = sse::cmpeq_epi64(sse::loadu(src + (index)), y2);                  \
                                                                                         \
        const sse::mask_type mask = ~sse::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            return (index) + (mask == 0xFF00);                                           \
        }                                                                                \
    } while (0)

#if WJR_HAS_SIMD(AVX2)
#define WJR_REGISTER_FIND_NOT_N_4(index)                                                 \
    do {                                                                                 \
        const auto r = avx::cmpeq_epi64(avx::loadu(src + (index)), y4);                  \
                                                                                         \
        const avx::mask_type mask = ~avx::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            return (index) + ctz(mask) / 8;                                              \
        }                                                                                \
    } while (0)
#else
#define WJR_REGISTER_FIND_NOT_N_4(index)                                                 \
    WJR_REGISTER_FIND_NOT_N_2(index);                                                    \
    WJR_REGISTER_FIND_NOT_N_2((index) + 2)
#endif

#define WJR_REGISTER_FIND_NOT_N_ADVANCE(index) src += index

#define WJR_REGISTER_FIND_NOT_N_RET(index) index

    const auto y2 = sse::set1(val, T());
#if WJR_HAS_SIMD(AVX2)
    const auto y4 = broadcast<__m128i_t, __m256i_t>(y2);
#endif

    WJR_REGISTER_X86_NORMAL_SIMD_FUNCTION(
        n, WJR_REGISTER_FIND_NOT_N_2, WJR_REGISTER_FIND_NOT_N_4, WJR_HAS_SIMD(AVX2),
        WJR_REGISTER_FIND_NOT_N_ADVANCE, const auto __src = src,
        WJR_REGISTER_FIND_NOT_N_RET);

#if !WJR_HAS_SIMD(AVX2)
    do {
        const auto r0 = sse::cmpeq_epi64(sse::loadu(src), y2);
        const auto r1 = sse::cmpeq_epi64(sse::loadu(src + 2), y2);
        const auto r2 = sse::cmpeq_epi64(sse::loadu(src + 4), y2);
        const auto r3 = sse::cmpeq_epi64(sse::loadu(src + 6), y2);

        const auto z = sse::And(sse::And(r0, r1), sse::And(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_ones(z))) {
            sse::mask_type mask = ~sse::movemask_epi8(r0);
            if (mask != 0) {
                return (src - __src) + ctz(mask) / 8;
            }

            mask = ~sse::movemask_epi8(r1);
            if (mask != 0) {
                return (src - __src) + 2 + ctz(mask) / 8;
            }

            mask = ~sse::movemask_epi8(r2);
            if (mask != 0) {
                return (src - __src) + 4 + ctz(mask) / 8;
            }

            mask = ~sse::movemask_epi8(r3);
            return (src - __src) + 6 + ctz(mask) / 8;
        }

        src += 8;
        n -= 8;
    } while (WJR_LIKELY(n != 0));
#else
    do {
        const auto r0 = avx::cmpeq_epi64(avx::loadu(src), y4);
        const auto r1 = avx::cmpeq_epi64(avx::loadu(src + 4), y4);
        const auto r2 = avx::cmpeq_epi64(avx::loadu(src + 8), y4);
        const auto r3 = avx::cmpeq_epi64(avx::loadu(src + 12), y4);

        const auto z = avx::And(avx::And(r0, r1), avx::And(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_ones(z))) {
            avx::mask_type mask = ~avx::movemask_epi8(r0);
            if (mask != 0) {
                return (src - __src) + ctz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r1);
            if (mask != 0) {
                return (src - __src) + 4 + ctz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r2);
            if (mask != 0) {
                return (src - __src) + 8 + ctz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r3);
            return (src - __src) + 12 + ctz(mask) / 8;
        }

        src += 16;
        n -= 16;
    } while (WJR_LIKELY(n != 0));
#endif

    return src - __src;

#undef WJR_REGISTER_FIND_NOT_N_RET
#undef WJR_REGISTER_FIND_NOT_N_ADVANCE
#undef WJR_REGISTER_FIND_NOT_N_4
#undef WJR_REGISTER_FIND_NOT_N_2
}

extern template WJR_PURE size_t large_builtin_find_not_n<uint64_t>(const uint64_t *src,
                                                                   uint64_t val,
                                                                   size_t n) noexcept;

#endif // WJR_HAS_BUILTIN(FIND_NOT_N)

#if WJR_HAS_BUILTIN(REVERSE_FIND_NOT_N)

template <typename T>
WJR_PURE size_t large_builtin_reverse_find_not_n(const T *src0, const T *src1,
                                                 size_t n) noexcept {
#define WJR_REGISTER_REVERSE_FIND_NOT_N_2(index)                                         \
    do {                                                                                 \
        const auto x = sse::loadu(src0 + (index));                                       \
        const auto y = sse::loadu(src1 + (index));                                       \
        const auto r = sse::cmpeq_epi64(x, y);                                           \
                                                                                         \
        const sse::mask_type mask = ~sse::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            return (index) + 2 - (mask == 0x00FF);                                       \
        }                                                                                \
    } while (0)

#if WJR_HAS_SIMD(AVX2)
#define WJR_REGISTER_REVERSE_FIND_NOT_N_4(index)                                         \
    do {                                                                                 \
        const auto x = avx::loadu(src0 + (index));                                       \
        const auto y = avx::loadu(src1 + (index));                                       \
        const auto r = avx::cmpeq_epi64(x, y);                                           \
                                                                                         \
        const avx::mask_type mask = ~avx::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            return (index) + 4 - clz(mask) / 8;                                          \
        }                                                                                \
    } while (0)
#else
#define WJR_REGISTER_REVERSE_FIND_NOT_N_4(index)                                         \
    WJR_REGISTER_REVERSE_FIND_NOT_N_2((index) + 2);                                      \
    WJR_REGISTER_REVERSE_FIND_NOT_N_2(index);
#endif

#define WJR_REGISTER_REVERSE_FIND_NOT_N_ADVANCE(index)                                   \
    src0 += index;                                                                       \
    src1 += index

#define WJR_REGISTER_REVERSE_FIND_NOT_N_RET(index) 0

    WJR_REGISTER_X86_NORMAL_REVERSE_SIMD_FUNCTION(
        n, WJR_REGISTER_REVERSE_FIND_NOT_N_2, WJR_REGISTER_REVERSE_FIND_NOT_N_4,
        WJR_HAS_SIMD(AVX2), WJR_REGISTER_REVERSE_FIND_NOT_N_ADVANCE, ,
        WJR_REGISTER_REVERSE_FIND_NOT_N_RET);

#if !WJR_HAS_SIMD(AVX2)
    do {
        const auto r0 = sse::cmpeq_epi64(sse::loadu(src0 - 8), sse::loadu(src1 - 8));
        const auto r1 = sse::cmpeq_epi64(sse::loadu(src0 - 6), sse::loadu(src1 - 6));
        const auto r2 = sse::cmpeq_epi64(sse::loadu(src0 - 4), sse::loadu(src1 - 4));
        const auto r3 = sse::cmpeq_epi64(sse::loadu(src0 - 2), sse::loadu(src1 - 2));

        const auto z = sse::And(sse::And(r0, r1), sse::And(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_ones(z))) {
            sse::mask_type mask = ~sse::movemask_epi8(r3);
            if (mask != 0) {
                return n - (mask == 0x00FF);
            }

            mask = ~sse::movemask_epi8(r2);
            if (mask != 0) {
                return n - 2 - (mask == 0x00FF);
            }

            mask = ~sse::movemask_epi8(r1);
            if (mask != 0) {
                return n - 4 - (mask == 0x00FF);
            }

            mask = ~sse::movemask_epi8(r0);
            return n - 6 - (mask == 0x00FF);
        }

        src0 -= 8;
        src1 -= 8;
        n -= 8;
    } while (WJR_LIKELY(n != 0));
#else
    do {
        const auto r0 = avx::cmpeq_epi64(avx::loadu(src0 - 16), avx::loadu(src1 - 16));
        const auto r1 = avx::cmpeq_epi64(avx::loadu(src0 - 12), avx::loadu(src1 - 12));
        const auto r2 = avx::cmpeq_epi64(avx::loadu(src0 - 8), avx::loadu(src1 - 8));
        const auto r3 = avx::cmpeq_epi64(avx::loadu(src0 - 4), avx::loadu(src1 - 4));

        const auto z = avx::And(avx::And(r0, r1), avx::And(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_ones(z))) {
            avx::mask_type mask = ~avx::movemask_epi8(r3);
            if (mask != 0) {
                return n - clz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r2);
            if (mask != 0) {
                return n - 4 - clz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r1);
            if (mask != 0) {
                return n - 8 - clz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r0);
            return n - 12 - clz(mask) / 8;
        }

        src0 -= 16;
        src1 -= 16;
        n -= 16;
    } while (WJR_LIKELY(n != 0));
#endif

    return 0;

#undef WJR_REGISTER_REVERSE_FIND_NOT_N_RET
#undef WJR_REGISTER_REVERSE_FIND_NOT_N_ADVANCE
#undef WJR_REGISTER_REVERSE_FIND_NOT_N_4
#undef WJR_REGISTER_REVERSE_FIND_NOT_N_2
}

extern template WJR_PURE size_t large_builtin_reverse_find_not_n<uint64_t>(
    const uint64_t *src0, const uint64_t *src1, size_t n) noexcept;

template <typename T>
WJR_PURE size_t large_builtin_reverse_find_not_n(const T *src, T val, size_t n) noexcept {
#define WJR_REGISTER_REVERSE_FIND_NOT_N_2(index)                                         \
    do {                                                                                 \
        const auto x = sse::loadu(src + (index));                                        \
        const auto r = sse::cmpeq_epi64(x, y2);                                          \
                                                                                         \
        const sse::mask_type mask = ~sse::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            return (index) + 2 - (mask == 0x00FF);                                       \
        }                                                                                \
    } while (0)

#if WJR_HAS_SIMD(AVX2)
#define WJR_REGISTER_REVERSE_FIND_NOT_N_4(index)                                         \
    do {                                                                                 \
        const auto x = avx::loadu(src + (index));                                        \
        const auto r = avx::cmpeq_epi64(x, y4);                                          \
                                                                                         \
        const avx::mask_type mask = ~avx::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            return (index) + 4 - clz(mask) / 8;                                          \
        }                                                                                \
    } while (0)
#else
#define WJR_REGISTER_REVERSE_FIND_NOT_N_4(index)                                         \
    WJR_REGISTER_REVERSE_FIND_NOT_N_2((index) + 2);                                      \
    WJR_REGISTER_REVERSE_FIND_NOT_N_2(index)
#endif

#define WJR_REGISTER_REVERSE_FIND_NOT_N_ADVANCE(index) src += index

#define WJR_REGISTER_REVERSE_FIND_NOT_N_RET(index) 0

    const auto y2 = sse::set1(val, T());
#if WJR_HAS_SIMD(AVX2)
    const auto y4 = broadcast<__m128i_t, __m256i_t>(y2);
#endif

    WJR_REGISTER_X86_NORMAL_REVERSE_SIMD_FUNCTION(
        n, WJR_REGISTER_REVERSE_FIND_NOT_N_2, WJR_REGISTER_REVERSE_FIND_NOT_N_4,
        WJR_HAS_SIMD(AVX2), WJR_REGISTER_REVERSE_FIND_NOT_N_ADVANCE, ,
        WJR_REGISTER_REVERSE_FIND_NOT_N_RET);

#if !WJR_HAS_SIMD(AVX2)
    do {
        const auto r0 = sse::cmpeq_epi64(sse::loadu(src - 8), y2);
        const auto r1 = sse::cmpeq_epi64(sse::loadu(src - 6), y2);
        const auto r2 = sse::cmpeq_epi64(sse::loadu(src - 4), y2);
        const auto r3 = sse::cmpeq_epi64(sse::loadu(src - 2), y2);

        const auto z = sse::And(sse::And(r0, r1), sse::And(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_ones(z))) {
            sse::mask_type mask = ~sse::movemask_epi8(r3);
            if (mask != 0) {
                return n - (mask == 0x00FF);
            }

            mask = ~sse::movemask_epi8(r2);
            if (mask != 0) {
                return n - 2 - (mask == 0x00FF);
            }

            mask = ~sse::movemask_epi8(r1);
            if (mask != 0) {
                return n - 4 - (mask == 0x00FF);
            }

            mask = ~sse::movemask_epi8(r0);
            return n - 6 - (mask == 0x00FF);
        }

        src -= 8;
        n -= 8;
    } while (WJR_LIKELY(n != 0));
#else
    do {
        const auto r0 = avx::cmpeq_epi64(avx::loadu(src - 16), y4);
        const auto r1 = avx::cmpeq_epi64(avx::loadu(src - 12), y4);
        const auto r2 = avx::cmpeq_epi64(avx::loadu(src - 8), y4);
        const auto r3 = avx::cmpeq_epi64(avx::loadu(src - 4), y4);

        const auto z = avx::And(avx::And(r0, r1), avx::And(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_ones(z))) {
            avx::mask_type mask = ~avx::movemask_epi8(r3);
            if (mask != 0) {
                return n - clz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r2);
            if (mask != 0) {
                return n - 4 - clz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r1);
            if (mask != 0) {
                return n - 8 - clz(mask) / 8;
            }

            mask = ~avx::movemask_epi8(r0);
            return n - 12 - clz(mask) / 8;
        }

        src -= 16;
        n -= 16;
    } while (WJR_LIKELY(n != 0));
#endif

    return 0;

#undef WJR_REGISTER_REVERSE_FIND_NOT_N_RET
#undef WJR_REGISTER_REVERSE_FIND_NOT_N_ADVANCE
#undef WJR_REGISTER_REVERSE_FIND_NOT_N_4
#undef WJR_REGISTER_REVERSE_FIND_NOT_N_2
}

extern template WJR_PURE size_t large_builtin_reverse_find_not_n<uint64_t>(
    const uint64_t *src, uint64_t val, size_t n) noexcept;

#endif // WJR_HAS_BUILTIN(REVERSE_FIND_NOT_N)

} // namespace wjr

#endif // WJR_X86_MATH_LARGE_FIND_IMPL_HPP__

namespace wjr {

#if WJR_HAS_BUILTIN(FIND_N)

template <typename T>
WJR_PURE size_t large_builtin_find_n(const T *src0, const T *src1, size_t n) noexcept {
#define WJR_REGISTER_FIND_N_AVX(index)                                                   \
    do {                                                                                 \
        auto x = avx::loadu(src0 + (index));                                             \
        auto y = avx::loadu(src1 + (index));                                             \
        auto r = avx::cmpeq_epi64(x, y);                                                 \
                                                                                         \
        avx::mask_type mask = avx::movemask_epi8(r);                                     \
        if (WJR_LIKELY(mask != 0)) {                                                     \
            return (index) + ctz(mask) / 8;                                              \
        }                                                                                \
    } while (0)

    size_t rem = n & 7;

    if (rem > 4) {
#if !WJR_HAS_SIMD(AVX2)
        auto x0 = sse::loadu(src0 + (rem - 4));
        auto x1 = sse::loadu(src0 + (rem - 2));
        auto y1 = sse::loadu(src1 + (rem - 2));
        auto y0 = sse::loadu(src1 + (rem - 4));

        auto r0 = sse::cmpeq_epi64(x0, y0);
        auto r1 = sse::cmpeq_epi64(x1, y1);

        if (WJR_LIKELY(!sse::test_all_zeros(sse::Or(r0, r1)))) {
            sse::mask_type mask = sse::movemask_epi8(r0);
            if (mask != 0) {
                return (rem - 4) + (mask == 0xFF00);
            }

            mask = sse::movemask_epi8(r1);
            return (rem - 2) + (mask == 0xFF00);
        }
#else
        WJR_REGISTER_FIND_N_AVX(rem - 4);
#endif
    }

    if (WJR_UNLIKELY(rem == n)) {
        return n;
    }

#if !WJR_HAS_SIMD(AVX2)
    do {
        auto x0 = sse::loadu(src0 + rem);
        auto x1 = sse::loadu(src0 + rem + 2);
        auto x2 = sse::loadu(src0 + rem + 4);
        auto x3 = sse::loadu(src0 + rem + 6);
        auto y0 = sse::loadu(src1 + rem);
        auto y1 = sse::loadu(src1 + rem + 2);
        auto y2 = sse::loadu(src1 + rem + 4);
        auto y3 = sse::loadu(src1 + rem + 6);

        auto r0 = sse::cmpeq_epi64(x0, y0);
        auto r1 = sse::cmpeq_epi64(x1, y1);
        auto r2 = sse::cmpeq_epi64(x2, y2);
        auto r3 = sse::cmpeq_epi64(x3, y3);

        auto z = sse::Or(sse::Or(r0, r1), sse::Or(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_zeros(z))) {
            sse::mask_type mask = sse::movemask_epi8(r0);
            if (mask != 0) {
                return rem + (mask == 0xFF00);
            }

            mask = sse::movemask_epi8(r1);
            if (mask != 0) {
                return rem + 2 + (mask == 0xFF00);
            }

            mask = sse::movemask_epi8(r2);
            if (mask != 0) {
                return rem + 4 + (mask == 0xFF00);
            }

            mask = sse::movemask_epi8(r3);
            return rem + 6 + (mask == 0xFF00);
        }

        rem += 8;
    } while (WJR_LIKELY(rem != n));
#else
    if ((n - rem) & 8) {
        WJR_REGISTER_FIND_N_AVX(rem);
        WJR_REGISTER_FIND_N_AVX(rem + 4);

        rem += 8;

        if (WJR_UNLIKELY(rem == n)) {
            return n;
        }
    }

    do {
        auto x0 = avx::loadu(src0 + rem);
        auto x2 = avx::loadu(src0 + rem + 8);
        auto x3 = avx::loadu(src0 + rem + 12);
        auto x1 = avx::loadu(src0 + rem + 4);
        auto y0 = avx::loadu(src1 + rem);
        auto y1 = avx::loadu(src1 + rem + 4);
        auto y2 = avx::loadu(src1 + rem + 8);
        auto y3 = avx::loadu(src1 + rem + 12);

        auto r0 = avx::cmpeq_epi64(x0, y0);
        auto r1 = avx::cmpeq_epi64(x1, y1);
        auto r2 = avx::cmpeq_epi64(x2, y2);
        auto r3 = avx::cmpeq_epi64(x3, y3);

        auto z = avx::Or(avx::Or(r0, r1), avx::Or(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_zeros(z))) {
            avx::mask_type mask = avx::movemask_epi8(r0);
            if (mask != 0) {
                return rem + ctz(mask) / 8;
            }

            mask = avx::movemask_epi8(r1);
            if (mask != 0) {
                return rem + 4 + ctz(mask) / 8;
            }

            mask = avx::movemask_epi8(r2);
            if (mask != 0) {
                return rem + 8 + ctz(mask) / 8;
            }

            mask = avx::movemask_epi8(r3);
            return rem + 12 + ctz(mask) / 8;
        }

        rem += 16;
    } while (WJR_LIKELY(rem != n));
#endif

    return n;

#undef WJR_REGISTER_FIND_N_AVX
}

template <typename T>
WJR_INTRINSIC_INLINE size_t builtin_find_n(const T *src0, const T *src1,
                                           size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0 || src0[0] == src1[0])) {
        return 0;
    }

    if (n == 1 || WJR_UNLIKELY(src0[1] == src1[1])) {
        return 1;
    }

    if (n == 2 || WJR_UNLIKELY(src0[2] == src1[2])) {
        return 2;
    }

    if (n == 3 || WJR_UNLIKELY(src0[3] == src1[3])) {
        return 3;
    }

    if (n == 4) {
        return 4;
    }

    size_t ret = large_builtin_find_n(src0, src1, n);
    WJR_ASSUME(ret >= 4);
    return ret;
}

template <typename T>
WJR_PURE size_t large_builtin_find_n(const T *src, T val, size_t n) noexcept {
#define WJR_REGISTER_FIND_N_AVX(index)                                                   \
    do {                                                                                 \
        auto x = avx::loadu(src + (index));                                              \
        auto r = avx::cmpeq_epi64(x, y);                                                 \
                                                                                         \
        auto mask = avx::movemask_epi8(r);                                               \
        if (WJR_LIKELY(mask != 0)) {                                                     \
            return (index) + ctz(mask) / 8;                                              \
        }                                                                                \
    } while (0)

#if !WJR_HAS_SIMD(AVX2)
    auto y = sse::set1(val, T());
#else
    auto y = avx::set1(val, T());
#endif

    size_t rem = n & 7;

    if (rem > 4) {
#if !WJR_HAS_SIMD(AVX2)
        auto x0 = sse::loadu(src + (rem - 4));
        auto x1 = sse::loadu(src + (rem - 2));

        auto r0 = sse::cmpeq_epi64(x0, y);
        auto r1 = sse::cmpeq_epi64(x1, y);

        if (WJR_LIKELY(!sse::test_all_zeros(sse::Or(r0, r1)))) {
            sse::mask_type mask = sse::movemask_epi8(r0);
            if (mask != 0) {
                return rem - 4 + (mask == 0xFF00);
            }

            mask = sse::movemask_epi8(r1);
            return rem - 2 + (mask == 0xFF00);
        }
#else
        WJR_REGISTER_FIND_N_AVX(rem - 4);
#endif
    }

    if (WJR_UNLIKELY(rem == n)) {
        return n;
    }

#if !WJR_HAS_SIMD(AVX2)
    do {
        auto x0 = sse::loadu(src + rem);
        auto x1 = sse::loadu(src + rem + 2);
        auto x2 = sse::loadu(src + rem + 4);
        auto x3 = sse::loadu(src + rem + 6);

        auto r0 = sse::cmpeq_epi64(x0, y);
        auto r1 = sse::cmpeq_epi64(x1, y);
        auto r2 = sse::cmpeq_epi64(x2, y);
        auto r3 = sse::cmpeq_epi64(x3, y);

        auto z = sse::Or(sse::Or(r0, r1), sse::Or(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_zeros(z))) {
            sse::mask_type mask = sse::movemask_epi8(r0);
            if (mask != 0) {
                return rem + (mask == 0xFF00);
            }

            mask = sse::movemask_epi8(r1);
            if (mask != 0) {
                return rem + 2 + (mask == 0xFF00);
            }

            mask = sse::movemask_epi8(r2);
            if (mask != 0) {
                return rem + 4 + (mask == 0xFF00);
            }

            mask = sse::movemask_epi8(r3);
            return rem + 6 + (mask == 0xFF00);
        }

        rem += 8;
    } while (WJR_LIKELY(rem != n));
#else
    if ((n - rem) & 8) {
        WJR_REGISTER_FIND_N_AVX(rem);
        WJR_REGISTER_FIND_N_AVX(rem + 4);

        rem += 8;

        if (WJR_UNLIKELY(rem == n)) {
            return n;
        }
    }

    do {
        auto x0 = avx::loadu(src + rem);
        auto x1 = avx::loadu(src + rem + 4);
        auto x2 = avx::loadu(src + rem + 8);
        auto x3 = avx::loadu(src + rem + 12);

        auto r0 = avx::cmpeq_epi64(x0, y);
        auto r1 = avx::cmpeq_epi64(x1, y);
        auto r2 = avx::cmpeq_epi64(x2, y);
        auto r3 = avx::cmpeq_epi64(x3, y);

        auto z = avx::Or(avx::Or(r0, r1), avx::Or(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_zeros(z))) {
            avx::mask_type mask = avx::movemask_epi8(r0);
            if (mask != 0) {
                return rem + ctz(mask) / 8;
            }

            mask = avx::movemask_epi8(r1);
            if (mask != 0) {
                return rem + 4 + ctz(mask) / 8;
            }

            mask = avx::movemask_epi8(r2);
            if (mask != 0) {
                return rem + 8 + ctz(mask) / 8;
            }

            mask = avx::movemask_epi8(r3);
            return rem + 12 + ctz(mask) / 8;
        }

        rem += 16;
    } while (WJR_LIKELY(rem != n));
#endif

    return n;

#undef WJR_REGISTER_FIND_N_AVX
}

template <typename T>
WJR_INTRINSIC_INLINE size_t builtin_find_n(const T *src, T val, size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0 || src[0] == val)) {
        return 0;
    }

    if (n == 1 || WJR_UNLIKELY(src[1] == val)) {
        return 1;
    }

    if (n == 2 || WJR_UNLIKELY(src[2] == val)) {
        return 2;
    }

    if (n == 3 || WJR_UNLIKELY(src[3] == val)) {
        return 3;
    }

    if (n == 4) {
        return 4;
    }

    size_t ret = large_builtin_find_n(src, val, n);
    WJR_ASSUME(ret >= 4);
    return ret;
}

#endif // WJR_HAS_BUILTIN(FIND_N)

#if WJR_HAS_BUILTIN(FIND_NOT_N)

template <typename T>
WJR_INTRINSIC_INLINE size_t builtin_find_not_n(const T *src0, const T *src1,
                                               size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0) || WJR_LIKELY(src0[0] != src1[0])) {
        return 0;
    }

    if (WJR_UNLIKELY(n == 1) || WJR_LIKELY(src0[1] != src1[1])) {
        return 1;
    }

    if (WJR_UNLIKELY(n == 2)) {
        return 2;
    }

    const size_t ret = large_builtin_find_not_n(src0, src1, n);
    WJR_ASSUME(ret >= 2 && ret <= n);
    return ret;
}

template <typename T>
WJR_INTRINSIC_INLINE size_t builtin_find_not_n(const T *src, T val, size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0) || WJR_LIKELY(src[0] != val)) {
        return 0;
    }

    if (WJR_UNLIKELY(n == 1) || WJR_LIKELY(src[1] != val)) {
        return 1;
    }

    if (WJR_UNLIKELY(n == 2)) {
        return 2;
    }

    const size_t ret = large_builtin_find_not_n(src, val, n);
    WJR_ASSUME(ret >= 2 && ret <= n);
    return ret;
}

#endif // WJR_HAS_BUILTIN(FIND_NOT_N)

#if WJR_HAS_BUILTIN(REVERSE_FIND_N)

template <typename T>
WJR_PURE size_t large_builtin_reverse_find_n(const T *src0, const T *src1,
                                             size_t n) noexcept {
#define WJR_REGISTER_REVERSE_FIND_N_AVX(index)                                           \
    do {                                                                                 \
        auto x = avx::loadu(src0 - 4 + (index));                                         \
        auto y = avx::loadu(src1 - 4 + (index));                                         \
        auto r = avx::cmpeq_epi64(x, y);                                                 \
                                                                                         \
        avx::mask_type mask = avx::movemask_epi8(r);                                     \
        if (WJR_LIKELY(mask != 0)) {                                                     \
            return (index)-clz(mask) / 8;                                                \
        }                                                                                \
    } while (0)

    const size_t rem = n & 7;
    n -= rem;

    if (rem > 4) {
#if !WJR_HAS_SIMD(AVX2)
        auto x0 = sse::loadu(src0 + n + 2);
        auto x1 = sse::loadu(src0 + n);
        auto y0 = sse::loadu(src1 + n + 2);
        auto y1 = sse::loadu(src1 + n);

        auto r0 = sse::cmpeq_epi64(x0, y0);
        auto r1 = sse::cmpeq_epi64(x1, y1);

        if (WJR_LIKELY(!sse::test_all_zeros(sse::Or(r0, r1)))) {
            sse::mask_type mask = sse::movemask_epi8(r0);
            if (mask != 0) {
                return n + 4 - (mask == 0x00FF);
            }

            mask = sse::movemask_epi8(r1);
            return n + 2 - (mask == 0x00FF);
        }
#else
        WJR_REGISTER_REVERSE_FIND_N_AVX(n + 4);
#endif
    }

    if (WJR_UNLIKELY(n == 0)) {
        return 0;
    }

#if !WJR_HAS_SIMD(AVX2)
    do {
        auto x0 = sse::loadu(src0 + n - 8);
        auto x1 = sse::loadu(src0 + n - 6);
        auto x2 = sse::loadu(src0 + n - 4);
        auto x3 = sse::loadu(src0 + n - 2);
        auto y0 = sse::loadu(src1 + n - 8);
        auto y1 = sse::loadu(src1 + n - 6);
        auto y2 = sse::loadu(src1 + n - 4);
        auto y3 = sse::loadu(src1 + n - 2);

        auto r0 = sse::cmpeq_epi64(x0, y0);
        auto r1 = sse::cmpeq_epi64(x1, y1);
        auto r2 = sse::cmpeq_epi64(x2, y2);
        auto r3 = sse::cmpeq_epi64(x3, y3);

        auto z = sse::Or(sse::Or(r0, r1), sse::Or(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_zeros(z))) {
            sse::mask_type mask = sse::movemask_epi8(r3);
            if (mask != 0) {
                return n - (mask == 0x00FF);
            }

            mask = sse::movemask_epi8(r2);
            if (mask != 0) {
                return n - 2 - (mask == 0x00FF);
            }

            mask = sse::movemask_epi8(r1);
            if (mask != 0) {
                return n - 4 - (mask == 0x00FF);
            }

            mask = sse::movemask_epi8(r0);
            return n - 6 - (mask == 0x00FF);
        }

        n -= 8;
    } while (WJR_LIKELY(n != 0));
#else
    if ((n & 8) != 0) {
        WJR_REGISTER_REVERSE_FIND_N_AVX(n);
        WJR_REGISTER_REVERSE_FIND_N_AVX(n - 4);

        n -= 8;

        if (WJR_UNLIKELY(n == 0)) {
            return 0;
        }
    }

    do {
        auto x0 = avx::loadu(src0 + n - 16);
        auto x1 = avx::loadu(src0 + n - 12);
        auto x2 = avx::loadu(src0 + n - 8);
        auto x3 = avx::loadu(src0 + n - 4);
        auto y0 = avx::loadu(src1 + n - 16);
        auto y1 = avx::loadu(src1 + n - 12);
        auto y2 = avx::loadu(src1 + n - 8);
        auto y3 = avx::loadu(src1 + n - 4);

        auto r0 = avx::cmpeq_epi64(x0, y0);
        auto r1 = avx::cmpeq_epi64(x1, y1);
        auto r2 = avx::cmpeq_epi64(x2, y2);
        auto r3 = avx::cmpeq_epi64(x3, y3);

        auto z = avx::Or(avx::Or(r0, r1), avx::Or(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_zeros(z))) {
            avx::mask_type mask = avx::movemask_epi8(r3);
            if (mask != 0) {
                return n - clz(mask) / 8;
            }

            mask = avx::movemask_epi8(r2);
            if (mask != 0) {
                return n - 4 - clz(mask) / 8;
            }

            mask = avx::movemask_epi8(r1);
            if (mask != 0) {
                return n - 8 - clz(mask) / 8;
            }

            mask = avx::movemask_epi8(r0);
            return n - 12 - clz(mask) / 8;
        }

        n -= 16;
    } while (WJR_LIKELY(n != 0));
#endif

    return 0;

#undef WJR_REGISTER_REVERSE_FIND_N_AVX
}

template <typename T>
WJR_INTRINSIC_INLINE size_t builtin_reverse_find_n(const T *src0, const T *src1,
                                                   size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0 || src0[n - 1] == src1[n - 1])) {
        return n;
    }

    if (n == 1 || WJR_UNLIKELY(src0[n - 2] == src1[n - 2])) {
        return n - 1;
    }

    if (n == 2 || WJR_UNLIKELY(src0[n - 3] == src1[n - 3])) {
        return n - 2;
    }

    if (n == 3 || WJR_UNLIKELY(src0[n - 4] == src1[n - 4])) {
        return n - 3;
    }

    if (n == 4) {
        return n - 4;
    }

    size_t ret = large_builtin_reverse_find_n(src0, src1, n);
    WJR_ASSUME(n > 4);
    WJR_ASSUME(ret <= n - 4);
    return ret;
}

template <typename T>
WJR_PURE size_t large_builtin_reverse_find_n(const T *src, T val, size_t n) noexcept {
#define WJR_REGISTER_REVERSE_FIND_N_AVX(index)                                           \
    do {                                                                                 \
        auto x = avx::loadu(src - 4 + (index));                                          \
        auto r = avx::cmpeq_epi64(x, y);                                                 \
                                                                                         \
        avx::mask_type mask = avx::movemask_epi8(r);                                     \
        if (WJR_LIKELY(mask != 0)) {                                                     \
            return (index)-clz(mask) / 8;                                                \
        }                                                                                \
    } while (0)

#if !WJR_HAS_SIMD(AVX2)
    auto y = sse::set1(val, T());
#else
    auto y = avx::set1(val, T());
#endif

    const size_t rem = n & 7;
    n -= rem;

    if (rem > 4) {
#if !WJR_HAS_SIMD(AVX2)
        auto x0 = sse::loadu(src + n + 2);
        auto x1 = sse::loadu(src + n);

        auto r0 = sse::cmpeq_epi64(x0, y);
        auto r1 = sse::cmpeq_epi64(x1, y);

        if (WJR_LIKELY(!sse::test_all_zeros(sse::Or(r0, r1)))) {
            sse::mask_type mask = sse::movemask_epi8(r0);
            if (mask != 0) {
                return n + 4 - (mask == 0x00FF);
            }

            mask = sse::movemask_epi8(r1);
            return n + 2 - (mask == 0x00FF);
        }
#else
        WJR_REGISTER_REVERSE_FIND_N_AVX(n + 4);
#endif
    }

    if (WJR_UNLIKELY(n == 0)) {
        return 0;
    }

#if !WJR_HAS_SIMD(AVX2)
    do {
        auto x0 = sse::loadu(src + n - 8);
        auto x1 = sse::loadu(src + n - 6);
        auto x2 = sse::loadu(src + n - 4);
        auto x3 = sse::loadu(src + n - 2);

        auto r0 = sse::cmpeq_epi64(x0, y);
        auto r1 = sse::cmpeq_epi64(x1, y);
        auto r2 = sse::cmpeq_epi64(x2, y);
        auto r3 = sse::cmpeq_epi64(x3, y);

        auto z = sse::Or(sse::Or(r0, r1), sse::Or(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_zeros(z))) {
            sse::mask_type mask = sse::movemask_epi8(r3);
            if (mask != 0) {
                return n - (mask == 0x00FF);
            }

            mask = sse::movemask_epi8(r2);
            if (mask != 0) {
                return n - 2 - (mask == 0x00FF);
            }

            mask = sse::movemask_epi8(r1);
            if (mask != 0) {
                return n - 4 - (mask == 0x00FF);
            }

            mask = sse::movemask_epi8(r0);
            return n - 6 - (mask == 0x00FF);
        }

        n -= 8;
    } while (WJR_LIKELY(n != 0));
#else
    if ((n & 8) != 0) {
        WJR_REGISTER_REVERSE_FIND_N_AVX(n);
        WJR_REGISTER_REVERSE_FIND_N_AVX(n - 4);

        n -= 8;

        if (WJR_UNLIKELY(n == 0)) {
            return 0;
        }
    }

    do {
        auto x0 = avx::loadu(src + n - 16);
        auto x1 = avx::loadu(src + n - 12);
        auto x2 = avx::loadu(src + n - 8);
        auto x3 = avx::loadu(src + n - 4);

        auto r0 = avx::cmpeq_epi64(x0, y);
        auto r1 = avx::cmpeq_epi64(x1, y);
        auto r2 = avx::cmpeq_epi64(x2, y);
        auto r3 = avx::cmpeq_epi64(x3, y);

        auto z = avx::Or(avx::Or(r0, r1), avx::Or(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_zeros(z))) {
            avx::mask_type mask = avx::movemask_epi8(r3);
            if (mask != 0) {
                return n - clz(mask) / 8;
            }

            mask = avx::movemask_epi8(r2);
            if (mask != 0) {
                return n - 4 - clz(mask) / 8;
            }

            mask = avx::movemask_epi8(r1);
            if (mask != 0) {
                return n - 8 - clz(mask) / 8;
            }

            mask = avx::movemask_epi8(r0);
            return n - 12 - clz(mask) / 8;
        }

        n -= 16;
    } while (WJR_LIKELY(n != 0));
#endif

    return 0;

#undef WJR_REGISTER_REVERSE_FIND_N_AVX
}

template <typename T>
WJR_INTRINSIC_INLINE size_t builtin_reverse_find_n(const T *src, T val,
                                                   size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0 || src[n - 1] == val)) {
        return n;
    }

    if (n == 1 || WJR_UNLIKELY(src[n - 2] == val)) {
        return n - 1;
    }

    if (n == 2 || WJR_UNLIKELY(src[n - 3] == val)) {
        return n - 2;
    }

    if (n == 3 || WJR_UNLIKELY(src[n - 4] == val)) {
        return n - 3;
    }

    if (n == 4) {
        return n - 4;
    }

    size_t ret = large_builtin_reverse_find_n(src, val, n);
    WJR_ASSUME(n > 4);
    WJR_ASSUME(ret <= n - 4);
    return ret;
}

#endif // WJR_HAS_BUILTIN(REVERSE_FIND_N)

#if WJR_HAS_BUILTIN(REVERSE_FIND_NOT_N)

template <typename T>
WJR_INTRINSIC_INLINE size_t builtin_reverse_find_not_n(const T *src0, const T *src1,
                                                       size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0) || WJR_LIKELY(src0[n - 1] != src1[n - 1])) {
        return n;
    }

    if (WJR_UNLIKELY(n == 1) || WJR_LIKELY(src0[n - 2] != src1[n - 2])) {
        return n - 1;
    }

    if (WJR_UNLIKELY(n == 2)) {
        return n - 2;
    }

    const size_t ret = large_builtin_reverse_find_not_n(src0, src1, n);
    WJR_ASSUME(ret >= 0 && ret <= n - 2);
    return ret;
}

template <typename T>
WJR_INTRINSIC_INLINE size_t builtin_reverse_find_not_n(const T *src, T val,
                                                       size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0) || WJR_LIKELY(src[n - 1] != val)) {
        return n;
    }

    if (WJR_UNLIKELY(n == 1) || WJR_LIKELY(src[n - 2] != val)) {
        return n - 1;
    }

    if (WJR_UNLIKELY(n == 2)) {
        return n - 2;
    }

    const size_t ret = large_builtin_reverse_find_not_n(src, val, n);
    WJR_ASSUME(n > 4);
    WJR_ASSUME(ret <= n - 4);
    return ret;
}

#endif // WJR_HAS_BUILTIN(REVERSE_FIND_NOT_N)

} // namespace wjr

#endif // WJR_X86_MATH_FIND_HPP__
#endif

namespace wjr {

template <typename T>
WJR_INTRINSIC_CONSTEXPR size_t fallback_find_n(const T *src0, const T *src1,
                                               size_t n) noexcept {
    size_t idx = 0;

    WJR_UNROLL(4)
    for (; idx < n; ++idx) {
        if (src0[idx] == src1[idx]) {
            break;
        }
    }

    return idx;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t find_n_impl(const T *src0, const T *src1,
                                                      size_t n) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(src0 == src1)) {
        return 0;
    }

#if WJR_HAS_BUILTIN(FIND_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_find_n(src0, src1, n);
        }

        return builtin_find_n(src0, src1, n);
    } else {
        return fallback_find_n(src0, src1, n);
    }
#else
    return fallback_find_n(src0, src1, n);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t find_n(const T *src0, const T *src1,
                                                 size_t n) noexcept {
    using uT = std::make_unsigned_t<T>;
    return find_n_impl<uT>(reinterpret_cast<const uT *>(src0),
                           reinterpret_cast<const uT *>(src1), n);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR size_t fallback_find_n(const T *src, T val, size_t n) noexcept {
    size_t idx = 0;

    WJR_UNROLL(4)
    for (; idx < n; ++idx) {
        if (src[idx] == val) {
            break;
        }
    }

    return idx;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t find_n_impl(const T *src,
                                                      type_identity_t<T> val,
                                                      size_t n) noexcept {
#if WJR_HAS_BUILTIN(FIND_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_find_n(src, val, n);
        }

        return builtin_find_n(src, val, n);
    } else {
        return fallback_find_n(src, val, n);
    }
#else
    return fallback_find_n(src, val, n);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t find_n(const T *src, type_identity_t<T> val,
                                                 size_t n) noexcept {
    using uT = std::make_unsigned_t<T>;
    return find_n_impl<uT>(reinterpret_cast<const uT *>(src), val, n);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR size_t fallback_find_not_n(const T *src0, const T *src1,
                                                   size_t n) noexcept {
    size_t idx = 0;

    WJR_UNROLL(4)
    for (; idx < n; ++idx) {
        if (src0[idx] != src1[idx]) {
            break;
        }
    }

    return idx;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t find_not_n_impl(const T *src0, const T *src1,
                                                          size_t n) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(src0 == src1)) {
        return n;
    }

#if WJR_HAS_BUILTIN(FIND_NOT_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_find_not_n(src0, src1, n);
        }

        return builtin_find_not_n(src0, src1, n);
    } else {
        return fallback_find_not_n(src0, src1, n);
    }
#else
    return fallback_find_not_n(src0, src1, n);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t find_not_n(const T *src0, const T *src1,
                                                     size_t n) noexcept {
    using uT = std::make_unsigned_t<T>;
    return find_not_n_impl<uT>(reinterpret_cast<const uT *>(src0),
                               reinterpret_cast<const uT *>(src1), n);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR size_t fallback_find_not_n(const T *src, T val,
                                                   size_t n) noexcept {
    size_t idx = 0;

    WJR_UNROLL(4)
    for (; idx < n; ++idx) {
        if (src[idx] != val) {
            break;
        }
    }

    return idx;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t find_not_n_impl(const T *src,
                                                          type_identity_t<T> val,
                                                          size_t n) noexcept {
#if WJR_HAS_BUILTIN(FIND_NOT_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_find_not_n(src, val, n);
        }

        return builtin_find_not_n(src, val, n);
    } else {
        return fallback_find_not_n(src, val, n);
    }
#else
    return fallback_find_not_n(src, val, n);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t find_not_n(const T *src, type_identity_t<T> val,
                                                     size_t n) noexcept {
    using uT = std::make_unsigned_t<T>;
    return find_not_n_impl<uT>(reinterpret_cast<const uT *>(src), val, n);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR size_t fallback_reverse_find_n(const T *src0, const T *src1,
                                                       size_t n) noexcept {
    size_t idx = 0;
    src0 += n;
    src1 += n;

    WJR_UNROLL(4)
    for (; idx < n; ++idx) {
        if (src0[-1 - idx] == src1[-1 - idx]) {
            break;
        }
    }

    return n - idx;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t reverse_find_n_impl(const T *src0,
                                                              const T *src1,
                                                              size_t n) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(src0 == src1)) {
        return n;
    }

#if WJR_HAS_BUILTIN(REVERSE_FIND_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_reverse_find_n(src0, src1, n);
        }

        return builtin_reverse_find_n(src0, src1, n);
    } else {
        return fallback_reverse_find_n(src0, src1, n);
    }
#else
    return fallback_reverse_find_n(src0, src1, n);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t reverse_find_n(const T *src0, const T *src1,
                                                         size_t n) noexcept {
    using uT = std::make_unsigned_t<T>;
    return reverse_find_n_impl<uT>(reinterpret_cast<const uT *>(src0),
                                   reinterpret_cast<const uT *>(src1), n);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR size_t fallback_reverse_find_n(const T *src, T val,
                                                       size_t n) noexcept {
    size_t idx = 0;
    src += n;

    WJR_UNROLL(4)
    for (; idx < n; ++idx) {
        if (src[-1 - idx] == val) {
            break;
        }
    }

    return n - idx;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t reverse_find_n_impl(const T *src,
                                                              type_identity_t<T> val,
                                                              size_t n) noexcept {
#if WJR_HAS_BUILTIN(REVERSE_FIND_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_reverse_find_n(src, val, n);
        }

        return builtin_reverse_find_n(src, val, n);
    } else {
        return fallback_reverse_find_n(src, val, n);
    }
#else
    return fallback_reverse_find_n(src, val, n);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t reverse_find_n(const T *src,
                                                         type_identity_t<T> val,
                                                         size_t n) noexcept {
    using uT = std::make_unsigned_t<T>;
    return reverse_find_n_impl<uT>(reinterpret_cast<const uT *>(src), val, n);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR size_t fallback_reverse_find_not_n(const T *src0, const T *src1,
                                                           size_t n) noexcept {
    size_t idx = 0;
    src0 += n;
    src1 += n;

    WJR_UNROLL(4)
    for (; idx < n; ++idx) {
        if (src0[-1 - idx] != src1[-1 - idx]) {
            break;
        }
    }

    return n - idx;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t reverse_find_not_n_impl(const T *src0,
                                                                  const T *src1,
                                                                  size_t n) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(src0 == src1)) {
        return 0;
    }

#if WJR_HAS_BUILTIN(REVERSE_FIND_NOT_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_reverse_find_not_n(src0, src1, n);
        }

        return builtin_reverse_find_not_n(src0, src1, n);
    } else {
        return fallback_reverse_find_not_n(src0, src1, n);
    }
#else
    return fallback_reverse_find_not_n(src0, src1, n);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t reverse_find_not_n(const T *src0, const T *src1,
                                                             size_t n) noexcept {
    using uT = std::make_unsigned_t<T>;
    return reverse_find_not_n_impl<uT>(reinterpret_cast<const uT *>(src0),
                                       reinterpret_cast<const uT *>(src1), n);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR size_t fallback_reverse_find_not_n(const T *src, T val,
                                                           size_t n) noexcept {
    size_t idx = 0;
    src += n;

    WJR_UNROLL(4)
    for (; idx < n; ++idx) {
        if (src[-1 - idx] != val) {
            break;
        }
    }

    return n - idx;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t reverse_find_not_n_impl(const T *src,
                                                                  type_identity_t<T> val,
                                                                  size_t n) noexcept {
#if WJR_HAS_BUILTIN(REVERSE_FIND_NOT_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_reverse_find_not_n(src, val, n);
        }

        return builtin_reverse_find_not_n(src, val, n);
    } else {
        return fallback_reverse_find_not_n(src, val, n);
    }
#else
    return fallback_reverse_find_not_n(src, val, n);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 size_t reverse_find_not_n(const T *src,
                                                             type_identity_t<T> val,
                                                             size_t n) noexcept {
    using uT = std::make_unsigned_t<T>;
    return reverse_find_not_n_impl<uT>(reinterpret_cast<const uT *>(src), val, n);
}

} // namespace wjr

#endif // WJR_MATH_FIND_HPP__
#ifndef WJR_MATH_SET_HPP__
#define WJR_MATH_SET_HPP__

#include <cstring>

// Already included
// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_SET_HPP__
#define WJR_X86_MATH_SET_HPP__

#include <cstring>

// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

namespace wjr {

#if WJR_HAS_SIMD(SSE2)
#define WJR_HAS_BUILTIN_SET_N WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(SET_N)

template <typename T>
void large_builtin_set_n(T *dst, T val, size_t n) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    constexpr auto is_avx = WJR_HAS_SIMD(AVX2);

    using simd = std::conditional_t<is_avx, avx, sse>;
    using simd_int = typename simd::int_type;
    constexpr auto simd_width = simd::width();
    constexpr auto type_width = simd_width / nd;
    constexpr auto u8_width = simd_width / 8;
    constexpr auto mask = u8_width * 4;

    WJR_ASSUME(n > type_width * 4);

    auto y = simd::set1(val, T());

    simd::storeu(dst, y);
    simd::storeu(dst + n - type_width, y);
    simd::storeu(dst + type_width, y);
    simd::storeu(dst + n - type_width * 2, y);
    simd::storeu(dst + type_width * 2, y);
    simd::storeu(dst + n - type_width * 3, y);
    simd::storeu(dst + type_width * 3, y);
    simd::storeu(dst + n - type_width * 4, y);

    uintptr_t ps = reinterpret_cast<uintptr_t>(dst);
    uintptr_t pe = reinterpret_cast<uintptr_t>(dst + n);

    ps += mask;
    ps &= -mask;
    pe &= -mask;

    if (WJR_UNLIKELY(ps == pe)) {
        return;
    }

    const uintptr_t mo = reinterpret_cast<uintptr_t>(dst) % sizeof(T);

    if (WJR_UNLIKELY(mo != 0)) {
        T stk[2] = {val, val};
        std::memcpy(&val, reinterpret_cast<uint8_t *>(stk) + mo, sizeof(T));
        y = simd::set1(val, T());
    }

    do {
        simd::store((simd_int *)(ps), y);
        simd::store((simd_int *)(ps + u8_width * 1), y);
        simd::store((simd_int *)(ps + u8_width * 2), y);
        simd::store((simd_int *)(ps + u8_width * 3), y);

        ps += u8_width * 4;
    } while (WJR_LIKELY(ps != pe));
    return;
}

template <typename T>
WJR_INTRINSIC_INLINE void builtin_set_n(T *dst, T val, size_t n) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    constexpr auto is_avx = WJR_HAS_SIMD(AVX2);

    using simd = std::conditional_t<is_avx, avx, sse>;
    constexpr auto simd_width = simd::width();
    constexpr auto type_width = simd_width / nd;

    constexpr auto sse_width = sse::width();
    constexpr auto sse_loop = sse_width / nd;

    if (WJR_UNLIKELY(n == 0)) {
        return;
    }

    if (WJR_BUILTIN_CONSTANT_P(n) && n <= 4) {
        for (size_t i = 0; i < n; ++i) {
            dst[i] = val;
        }

        return;
    }

    if (WJR_UNLIKELY(n > type_width * 2)) {
        if (WJR_UNLIKELY(n > type_width * 4)) {
            return large_builtin_set_n(dst, val, n);
        }

        auto y = simd::set1(val, T());

        simd::storeu(dst, y);
        simd::storeu(dst + type_width, y);
        simd::storeu(dst + n - type_width, y);
        simd::storeu(dst + n - type_width * 2, y);
        return;
    }

    const auto x = broadcast<T, uint64_t>(val);
    const auto y = broadcast<uint64_t, __m128i_t>(x);

    if (WJR_UNLIKELY(n <= sse_loop * 2)) {
        if (WJR_UNLIKELY(n >= sse_loop)) {
            sse::storeu(dst, y);
            sse::storeu(dst + n - sse_loop, y);
            return;
        }

        if constexpr (sse_loop == 2) {
            std::memcpy(dst, &x, 8);
            return;
        } else {
            if (WJR_UNLIKELY(n >= sse_loop / 2)) {
                std::memcpy(dst, &x, 8);
                std::memcpy(dst + n - sse_loop / 2, &x, 8);
                return;
            }
        }

        if constexpr (sse_loop >= 4) {
            if constexpr (sse_loop == 4) {
                std::memcpy(dst, &x, 4);
                return;
            } else {
                if (WJR_UNLIKELY(n >= sse_loop / 4)) {
                    std::memcpy(dst, &x, 4);
                    std::memcpy(dst + n - sse_loop / 4, &x, 4);
                    return;
                }
            }
        }

        if constexpr (sse_loop >= 8) {
            if constexpr (sse_loop == 8) {
                std::memcpy(dst, &x, 2);
                return;
            } else {
                if (WJR_UNLIKELY(n >= sse_loop / 8)) {
                    std::memcpy(dst, &x, 2);
                    std::memcpy(dst + n - sse_loop / 8, &x, 2);
                    return;
                }
            }
        }

        if constexpr (sse_loop >= 16) {
            if constexpr (sse_loop == 16) {
                std::memcpy(dst, &x, 1);
                return;
            } else {
                if (WJR_UNLIKELY(n >= sse_loop / 16)) {
                    std::memcpy(dst, &x, 16);
                    std::memcpy(dst + n - sse_loop / 16, &x, 16);
                    return;
                }
            }
        }

        return;
    }

#if WJR_HAS_SIMD(AVX2)
    if constexpr (is_avx) {
        auto z = broadcast<__m128i_t, __m256i_t>(y);
        avx::storeu(dst, z);
        avx::storeu(dst + n - type_width, z);
        return;
    }
#endif

    WJR_UNREACHABLE();
}

#endif

} // namespace wjr

#endif // WJR_X86_MATH_SET_HPP__
#endif

namespace wjr {

template <typename T>
WJR_INTRINSIC_CONSTEXPR void fallback_set_n(T *dst, T val, size_t n) noexcept {
    for (size_t i = 0; i < n; ++i) {
        dst[i] = val;
    }
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 void set_n(T *dst, type_identity_t<T> val, size_t n) noexcept {
#if WJR_HAS_BUILTIN(SET_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_set_n(dst, val, n);
        }

        if (WJR_BUILTIN_CONSTANT_P(val) &&
            broadcast<uint8_t, T>(static_cast<uint8_t>(val)) == val) {
            if (WJR_UNLIKELY(n >= 2048 / sizeof(T))) {
                std::memset(dst, static_cast<uint8_t>(val), n * sizeof(T));
                return;
            }
        }

        return builtin_set_n(dst, val, n);
    } else {
        return fallback_set_n(dst, val, n);
    }
#else
    return fallback_set_n(dst, val, n);
#endif
}

} // namespace wjr

#endif // WJR_MATH_SET_HPP__

namespace wjr {

// find the first position(ret) that is not equal to number "from"
// and replace [0, ret) to number "to"
// For example, inc replaces a continuous segment of -1 with 0. And dec replaces a
// continuous segment of 0 with -1
template <typename T>
WJR_INTRINSIC_CONSTEXPR20 size_t replace_find_not(T *dst, const T *src, size_t n,
                                                  type_identity_t<T> from,
                                                  type_identity_t<T> to) noexcept {

    const size_t ret = find_not_n(src, from, n);
    if (WJR_UNLIKELY(ret != 0) && WJR_LIKELY(dst != src || from != to)) {
        set_n(dst, to, ret);
    }

    return ret;
}

// find the last position(ret-1) that is not equal to number "from"
// and replace [ret, n) to number "to"
template <typename T>
WJR_INTRINSIC_CONSTEXPR20 size_t
reverse_replace_find_not(T *dst, const T *src, size_t n, type_identity_t<T> from,
                         type_identity_t<T> to) noexcept {
    const size_t ret = reverse_find_not_n(src, from, n);
    if (WJR_UNLIKELY(ret != n) && WJR_LIKELY(dst != src || from != to)) {
        set_n(dst + ret, to, n - ret);
    }

    return ret;
}

} // namespace wjr

#endif // WJR_MATH_REPLACE_HPP__

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_ADD_HPP__
#define WJR_X86_MATH_ADD_HPP__

// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_ADDC WJR_HAS_DEF
#define WJR_HAS_BUILTIN_ASM_ADDC_N WJR_HAS_DEF
#define WJR_HAS_BUILTIN___ASM_ADD_128 WJR_HAS_DEF
#define WJR_HAS_BUILTIN___ASM_ADDC_128 WJR_HAS_DEF

#if WJR_HAS_FEATURE(INLINE_ASM_CCCOND)
#define WJR_HAS_BUILTIN_ASM_ADDC_CC WJR_HAS_DEF
#define WJR_HAS_BUILTIN___ASM_ADDC_CC_128 WJR_HAS_DEF
#endif
#else

#if defined(WJR_MSVC)
#define WJR_HAS_BUILTIN_ASM_ADDC WJR_HAS_DEF_VAR(2)
#endif

#if defined(WJR_ENABLE_ASSEMBLY)
#define WJR_HAS_BUILTIN_ASM_ADDC_N WJR_HAS_DEF_VAR(3)
#endif

#endif

#if WJR_HAS_BUILTIN(ASM_ADDC) == 2
// Already included
#endif

namespace wjr {

#if WJR_HAS_BUILTIN(ASM_ADDC)

/**
 * @brief Use inline assembly to add two 64-bit integers with carry-in and return the
 * carry-out.
 *
 * @details The carry-in and carry-out flags are both 0 or 1. \n
 * The carry-out flag is set to 1 if the result overflows. \n
 * Optimization: \n
 * 1. Use constraint "i" if a or b is a constant and is in i32 range. \n
 * 2. If c_in is a constant and c_in == 1, use "stc" to set the carry flag.
 *
 * @tparam U The type of the carry.
 * @param[in] c_in The carry-in flag.
 * @param[out] c_out The carry-out flag.
 * @return a + b + c_in
 */
template <typename U>
WJR_INTRINSIC_INLINE uint64_t asm_addc(uint64_t a, uint64_t b, U c_in,
                                       U &c_out) noexcept {
#if WJR_HAS_BUILTIN(ASM_ADDC) == 1
    if (WJR_BUILTIN_CONSTANT_P_TRUE(c_in == 1)) {
        if (WJR_BUILTIN_CONSTANT_P(b) && in_range<int32_t>(b)) {
            asm("stc\n\t"
                "adc{q %2, %0| %0, %2}\n\t"
                "setb %b1"
                : "=r"(a), "+r"(c_in)
                : "ri"(b), "0"(a)
                : "cc");
        } else {
            asm("stc\n\t"
                "adc{q %2, %0| %0, %2}\n\t"
                "setb %b1"
                : "=r"(a), "+r"(c_in)
                : "r"(b), "0"(a)
                : "cc");
        }
        c_out = c_in;
        return a;
    }

    if (WJR_BUILTIN_CONSTANT_P(a)) {
        if (in_range<int32_t>(a)) {
            asm("add{b $255, %b1| %b1, 255}\n\t"
                "adc{q %2, %0| %0, %2}\n\t"
                "setb %b1"
                : "=r"(b), "+&r"(c_in)
                : "ri"(a), "0"(b)
                : "cc");
        } else {
            asm("add{b $255, %b1| %b1, 255}\n\t"
                "adc{q %2, %0| %0, %2}\n\t"
                "setb %b1"
                : "=r"(b), "+&r"(c_in)
                : "r"(a), "0"(b)
                : "cc");
        }
        c_out = c_in;
        return b;
    }

    if (WJR_BUILTIN_CONSTANT_P(b) && in_range<int32_t>(b)) {
        asm("add{b $255, %b1| %b1, 255}\n\t"
            "adc{q %2, %0| %0, %2}\n\t"
            "setb %b1"
            : "=r"(a), "+&r"(c_in)
            : "ri"(b), "0"(a)
            : "cc");
    } else {
        asm("add{b $255, %b1| %b1, 255}\n\t"
            "adc{q %2, %0| %0, %2}\n\t"
            "setb %b1"
            : "=r"(a), "+&r"(c_in)
            : "r"(b), "0"(a)
            : "cc");
    }
    c_out = c_in;
    return a;
#else
    uint64_t ret;
    c_out = fast_cast<U>(_addcarry_u64(fast_cast<unsigned char>(c_in), a, b, &ret));
    return ret;
#endif
}

#endif

#if WJR_HAS_BUILTIN(ASM_ADDC_CC)

/**
 * @brief Use inline assembly to add two 64-bit integers with carry-in and return the
 * carry-out.
 *
 * @details Similar to asm_addc, but the carry-out flag is set by using constraint
 * "=@cccond" instead of "setb". \n
 *
 * @param[in] c_in
 * @param[out] c_out
 */
WJR_INTRINSIC_INLINE uint64_t asm_addc_cc(uint64_t a, uint64_t b, uint8_t c_in,
                                          uint8_t &c_out) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(c_in == 1)) {
        if (WJR_BUILTIN_CONSTANT_P(b) && in_range<int32_t>(b)) {
            asm("stc\n\t"
                "adc{q %2, %0| %0, %2}\n\t" WJR_ASM_CCSET(c)
                : "=r"(a), WJR_ASM_CCOUT(c)(c_out)
                : "ri"(b), "0"(a)
                : "cc");
        } else {
            asm("stc\n\t"
                "adc{q %2, %0| %0, %2}\n\t" WJR_ASM_CCSET(c)
                : "=r"(a), WJR_ASM_CCOUT(c)(c_out)
                : "r"(b), "0"(a)
                : "cc");
        }
        return a;
    }

    if (WJR_BUILTIN_CONSTANT_P(a)) {
        if (in_range<int32_t>(a)) {
            asm("add{b $255, %b1| %b1, 255}\n\t"
                "adc{q %3, %0| %0, %3}\n\t" WJR_ASM_CCSET(c)
                : "=r"(b), "+&r"(c_in), WJR_ASM_CCOUT(c)(c_out)
                : "ri"(a), "0"(b)
                : "cc");
        } else {
            asm("add{b $255, %b1| %b1, 255}\n\t"
                "adc{q %3, %0| %0, %3}\n\t" WJR_ASM_CCSET(c)
                : "=r"(b), "+&r"(c_in), WJR_ASM_CCOUT(c)(c_out)
                : "r"(a), "0"(b)
                : "cc");
        }
        return b;
    }

    if (WJR_BUILTIN_CONSTANT_P(b) && in_range<int32_t>(b)) {
        asm("add{b $255, %b1| %b1, 255}\n\t"
            "adc{q %3, %0| %0, %3}\n\t" WJR_ASM_CCSET(c)
            : "=r"(a), "+&r"(c_in), WJR_ASM_CCOUT(c)(c_out)
            : "ri"(b), "0"(a)
            : "cc");
    } else {
        asm("add{b $255, %b1| %b1, 255}\n\t"
            "adc{q %3, %0| %0, %3}\n\t" WJR_ASM_CCSET(c)
            : "=r"(a), "+&r"(c_in), WJR_ASM_CCOUT(c)(c_out)
            : "r"(b), "0"(a)
            : "cc");
    }
    return a;
}

#endif

#if WJR_HAS_BUILTIN(ASM_ADDC_N)
#define WJR_ADDSUB_I 1
// WJR_ADDSUB_I :
// 0 : SUB
// 1 : ADD

// Already included

#ifndef WJR_ADDSUB_I
#error "abort"
#endif

#if WJR_ADDSUB_I == 1
#define WJR_addcsubc addc
#define WJR_adcsbb adc
#define __WJR_TEST_ASSEMBLY ASM_ADDC_N
#else
#define WJR_addcsubc subc
#define WJR_adcsbb sbb
#define __WJR_TEST_ASSEMBLY ASM_SUBC_N
#endif

#if WJR_HAS_BUILTIN(__WJR_TEST_ASSEMBLY) == 1

inline uint64_t WJR_PP_CONCAT(__wjr_asm_, WJR_PP_CONCAT(WJR_addcsubc, _n_impl))(
    uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n,
    uint64_t c_in) noexcept {
    size_t rcx = n / 8;
    uint64_t r8 = c_in, r9, r10 = n & 7, r11;

    asm volatile(
        "add{b $255, %b[r8]| %b[r8], 255}\n\t"
        "lea{q| %[r9], [rip +} .Llookup%={(%%rip), %[r9]|]}\n\t"
        "movs{lq (%[r9], %[r10], 4), %[r10]|xd %[r10], DWORD PTR [%[r9] + %[r10] * 4]}\n\t"
        "lea{q (%[r9], %[r10], 1), %[r10]| %[r10], [%[r9] + %[r10]]}\n\t"
        "jmp{q *%[r10]| %[r10]}\n\t"
        
        ".align 8\n\t"
        ".Llookup%=:\n\t"
        ".long .Ll0%=-.Llookup%=\n\t"
        ".long .Ll1%=-.Llookup%=\n\t"
        ".long .Ll2%=-.Llookup%=\n\t"
        ".long .Ll3%=-.Llookup%=\n\t"
        ".long .Ll4%=-.Llookup%=\n\t"
        ".long .Ll5%=-.Llookup%=\n\t"
        ".long .Ll6%=-.Llookup%=\n\t"
        ".long .Ll7%=-.Llookup%=\n\t"
        ".align 16\n\t"
        
        ".Ll0%=:\n\t"
        "mov{q (%[src0]), %[r9]| %[r9], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r11]| %[r11], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r9]| %[r9], [%[src1]]}\n\t"
        "jmp .Lb0%=\n\t"

        ".Ld1%=:\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r10]| %[r10], [%[src1]]}\n\t"
        "mov{q %[r10], (%[dst])| [%[dst]], %[r10]}\n\t"
        "jmp .Ldone%=\n\t"

        ".Ll1%=:\n\t"
        "mov{q (%[src0]), %[r10]| %[r10], [%[src0]]}\n\t"
        "jrcxz .Ld1%=\n\t"
        "mov{q 8(%[src0]), %[r9]| %[r9], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r10]| %[r10], [%[src1]]}\n\t"
        "lea{q 8(%[src0]), %[src0]| %[src0], [%[src0] + 8]}\n\t"
        "lea{q 8(%[src1]), %[src1]| %[src1], [%[src1] + 8]}\n\t"
        "lea{q 8(%[dst]), %[dst]| %[dst], [%[dst] + 8]}\n\t"
        "jmp .Lb1%=\n\t"

        ".Ll3%=:\n\t"
        "mov{q (%[src0]), %[r11]| %[r11], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r8]| %[r8], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r11]| %[r11], [%[src1]]}\n\t"
        "lea{q -40(%[src0]), %[src0]| %[src0], [%[src0] - 40]}\n\t"
        "lea{q -40(%[src1]), %[src1]| %[src1], [%[src1] - 40]}\n\t"
        "lea{q -40(%[dst]), %[dst]| %[dst], [%[dst] - 40]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb3%=\n\t"

        ".Ll4%=:\n\t"
        "mov{q (%[src0]), %[r9]| %[r9], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r11]| %[r11], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r9]| %[r9], [%[src1]]}\n\t"
        "lea{q -32(%[src0]), %[src0]| %[src0], [%[src0] - 32]}\n\t"
        "lea{q -32(%[src1]), %[src1]| %[src1], [%[src1] - 32]}\n\t"
        "lea{q -32(%[dst]), %[dst]| %[dst], [%[dst] - 32]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb4%=\n\t"

        ".Ll5%=:\n\t"
        "mov{q (%[src0]), %[r10]| %[r10], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r9]| %[r9], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r10]| %[r10], [%[src1]]}\n\t"
        "lea{q -24(%[src0]), %[src0]| %[src0], [%[src0] - 24]}\n\t"
        "lea{q -24(%[src1]), %[src1]| %[src1], [%[src1] - 24]}\n\t"
        "lea{q -24(%[dst]), %[dst]| %[dst], [%[dst] - 24]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb5%=\n\t"

        ".Ll6%=:\n\t"
        "mov{q (%[src0]), %[r8]| %[r8], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r10]| %[r10], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r8]| %[r8], [%[src1]]}\n\t"
        "lea{q -16(%[src0]), %[src0]| %[src0], [%[src0] - 16]}\n\t"
        "lea{q -16(%[src1]), %[src1]| %[src1], [%[src1] - 16]}\n\t"
        "lea{q -16(%[dst]), %[dst]| %[dst], [%[dst] - 16]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb6%=\n\t"

        ".Ll7%=:\n\t"
        "mov{q (%[src0]), %[r11]| %[r11], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r8]| %[r8], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r11]| %[r11], [%[src1]]}\n\t"
        "lea{q -8(%[src0]), %[src0]| %[src0], [%[src0] - 8]}\n\t"
        "lea{q -8(%[src1]), %[src1]| %[src1], [%[src1] - 8]}\n\t"
        "lea{q -8(%[dst]), %[dst]| %[dst], [%[dst] - 8]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb7%=\n\t"

        ".Ld2%=:\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 8(%[src1]), %[r10]| %[r10], [%[src1] + 8]}\n\t"
        "mov{q %[r8], (%[dst])| [%[dst]], %[r8]}\n\t"
        "mov{q %[r10], 8(%[dst])| [%[dst] + 8], %[r10]}\n\t"
        "jmp .Ldone%=\n\t"

        ".Ll2%=:\n\t"
        "mov{q (%[src0]), %[r8]| %[r8], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r10]| %[r10], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r8]| %[r8], [%[src1]]}\n\t"
        "jrcxz .Ld2%=\n\t"
        "lea{q 16(%[src0]), %[src0]| %[src0], [%[src0] + 16]}\n\t"
        "lea{q 16(%[src1]), %[src1]| %[src1], [%[src1] + 16]}\n\t"
        "lea{q 16(%[dst]), %[dst]| %[dst], [%[dst] + 16]}\n\t"

        ".align 32\n\t"
        ".Lloop%=:\n\t"

        ".Lb2%=:\n\t"
        "mov{q (%[src0]), %[r9]| %[r9], [%[src0]]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q -8(%[src1]), %[r10]| %[r10], [%[src1] - 8]}\n\t"
        "mov{q %[r8], -16(%[dst])| [%[dst] - 16], %[r8]}\n\t"

        ".Lb1%=:\n\t"
        "mov{q 8(%[src0]), %[r11]| %[r11], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r9]| %[r9], [%[src1]]}\n\t"
        "mov{q %[r10], -8(%[dst])| [%[dst] - 8], %[r10]}\n\t"

        ".Lb0%=:\n\t"
        "mov{q 16(%[src0]), %[r8]| %[r8], [%[src0] + 16]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 8(%[src1]), %[r11]| %[r11], [%[src1] + 8]}\n\t"
        "mov{q %[r9], (%[dst])| [%[dst]], %[r9]}\n\t"

        ".Lb7%=:\n\t"
        "mov{q 24(%[src0]), %[r10]| %[r10], [%[src0] + 24]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 16(%[src1]), %[r8]| %[r8], [%[src1] + 16]}\n\t"
        "mov{q %[r11], 8(%[dst])| [%[dst] + 8], %[r11]}\n\t"

        ".Lb6%=:\n\t"
        "mov{q 32(%[src0]), %[r9]| %[r9], [%[src0] + 32]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 24(%[src1]), %[r10]| %[r10], [%[src1] + 24]}\n\t"
        "mov{q %[r8], 16(%[dst])| [%[dst] + 16], %[r8]}\n\t"

        ".Lb5%=:\n\t"
        "mov{q 40(%[src0]), %[r11]| %[r11], [%[src0] + 40]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 32(%[src1]), %[r9]| %[r9], [%[src1] + 32]}\n\t"
        "mov{q %[r10], 24(%[dst])| [%[dst] + 24], %[r10]}\n\t"

        ".Lb4%=:\n\t"
        "mov{q 48(%[src0]), %[r8]| %[r8], [%[src0] + 48]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 40(%[src1]), %[r11]| %[r11], [%[src1] + 40]}\n\t"
        "mov{q %[r9], 32(%[dst])| [%[dst] + 32], %[r9]}\n\t"

        ".Lb3%=:\n\t"
        "mov{q 56(%[src0]), %[r10]| %[r10], [%[src0] + 56]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 48(%[src1]), %[r8]| %[r8], [%[src1] + 48]}\n\t"
        "mov{q %[r11], 40(%[dst])| [%[dst] + 40], %[r11]}\n\t"

        // TODO : optimize pipeline
        "lea{q 64(%[src0]), %[src0]| %[src0], [%[src0] + 64]}\n\t"
        "lea{q 64(%[src1]), %[src1]| %[src1], [%[src1] + 64]}\n\t"
        "lea{q 64(%[dst]), %[dst]| %[dst], [%[dst] + 64]}\n\t"
        "dec %[rcx]\n\t"
        
        "jne .Lloop%=\n\t"

        WJR_PP_STR(WJR_adcsbb) "{q -8(%[src1]), %[r10]| %[r10], [%[src1] - 8]}\n\t"
        "mov{q %[r8], -16(%[dst])| [%[dst] - 16], %[r8]}\n\t"
        "mov{q %[r10], -8(%[dst])| [%[dst] - 8], %[r10]}\n\t"

        ".Ldone%=:\n\t"
        "mov{l %k[rcx], %k[r9]| %k[r9], %k[rcx]}\n\t"
        "adc{l %k[rcx], %k[r9]| %k[r9], %k[rcx]}"

        : [dst] "+r"(dst), [src0] "+r"(src0), [src1] "+r"(src1), [rcx] "+c"(rcx), 
          [r8] "+r"(r8), [r9] "=&r"(r9), [r10] "+r"(r10), [r11] "=&r"(r11)
        :
        : "cc", "memory");

    WJR_ASSERT_ASSUME(rcx == 0);
    WJR_ASSERT_ASSUME(r9 <= 1);

    return r9;
}

#else
extern "C" WJR_MS_ABI uint64_t WJR_PP_CONCAT(
    __wjr_asm_, WJR_PP_CONCAT(WJR_addcsubc, _n_impl))(uint64_t *dst, const uint64_t *src0,
                                                      const uint64_t *src1, size_t n,
                                                      uint64_t c_in) noexcept;
#endif

WJR_INTRINSIC_INLINE uint64_t WJR_PP_CONCAT(asm_, WJR_PP_CONCAT(WJR_addcsubc, _n))(
    uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n,
    uint64_t c_in) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(n)) {
        if (n == 1) {
            dst[0] = WJR_PP_CONCAT(asm_, WJR_addcsubc)(src0[0], src1[0], c_in, c_in);
            return c_in;
        }
    }

    return WJR_PP_CONCAT(__wjr_asm_, WJR_PP_CONCAT(WJR_addcsubc, _n_impl))(dst, src0,
                                                                           src1, n, c_in);
}

#undef __WJR_TEST_ASSEMBLY
#undef WJR_adcsbb
#undef WJR_addcsubc

#undef WJR_ADDSUB_I
#endif

#if WJR_HAS_BUILTIN(__ASM_ADD_128)

/**
 * @brief Use inline assembly to add two 64-bit integers and return the result.
 *
 */
WJR_INTRINSIC_INLINE void __asm_add_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                        uint64_t hi0, uint64_t lo1,
                                        uint64_t hi1) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(hi0) && hi0 <= UINT32_MAX) {
        asm("add{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "adc{q %[hi0], %[hi1]| %[hi1], %[hi0]}"
            : [lo0] "+&r"(lo0), [hi1] "+r"(hi1)
            : [lo1] "r"(lo1), [hi0] "i"(hi0)
            : "cc");
        al = lo0;
        ah = hi1;
        return;
    } else if (WJR_BUILTIN_CONSTANT_P(hi1) && hi1 <= UINT32_MAX) {
        asm("add{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "adc{q %[hi1], %[hi0]| %[hi0], %[hi1]}"
            : [lo0] "+&r"(lo0), [hi0] "+r"(hi0)
            : [lo1] "r"(lo1), [hi1] "i"(hi1)
            : "cc");
        al = lo0;
        ah = hi0;
        return;
    }

    asm("add{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "adc{q %[hi1], %[hi0]| %[hi0], %[hi1]}"
        : [lo0] "+&r"(lo0), [hi0] "+r"(hi0)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    al = lo0;
    ah = hi0;
    return;
}

#endif

#if WJR_HAS_BUILTIN(__ASM_ADDC_128) || WJR_HAS_BUILTIN(__ASM_ADDC_CC_128)

/**
 * @brief Use inline assembly to add two 64-bit integers and return the
 * carry-out.
 *
 * @details Optimzation for __asm_addc_cc_128 and __asm_addc_128 when the carry-in is 0.
 *
 */
WJR_INTRINSIC_INLINE uint8_t __asm_addc_cc_zero_128(uint64_t &al, uint64_t &ah,
                                                    uint64_t lo0, uint64_t hi0,
                                                    uint64_t lo1, uint64_t hi1) noexcept {
    uint8_t c_out;
    if (WJR_BUILTIN_CONSTANT_P(hi0) && hi0 <= UINT32_MAX) {
        asm("add{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "adc{q %[hi0], %[hi1]| %[hi1], %[hi0]}\n\t" WJR_ASM_CCSET(c)
            : [lo0] "+&r"(lo0), [hi1] "+r"(hi1), WJR_ASM_CCOUT(c)(c_out)
            : [lo1] "r"(lo1), [hi0] "i"(hi0)
            : "cc");
        al = lo0;
        ah = hi1;
        return c_out;
    } else if (WJR_BUILTIN_CONSTANT_P(hi1) && hi1 <= UINT32_MAX) {
        asm("add{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "adc{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(c)
            : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), WJR_ASM_CCOUT(c)(c_out)
            : [lo1] "r"(lo1), [hi1] "i"(hi1)
            : "cc");
        al = lo0;
        ah = hi0;
        return c_out;
    }

    asm("add{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "adc{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(c)
        : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), WJR_ASM_CCOUT(c)(c_out)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    al = lo0;
    ah = hi0;
    return c_out;
}

#endif

#if WJR_HAS_BUILTIN(__ASM_ADDC_128)

/**
 * @brief Use inline assembly to add two 64-bit integers with carry-in and return the
 * carry-out.
 *
 */
WJR_INTRINSIC_INLINE uint64_t __asm_addc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                             uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                             uint64_t c_in) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(c_in == 0)) {
        return __asm_addc_cc_zero_128(al, ah, lo0, hi0, lo1, hi1);
    }

    if (WJR_BUILTIN_CONSTANT_P(hi0) && hi0 <= UINT32_MAX) {
        asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
            "adc{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "adc{q %[hi0], %[hi1]| %[hi1], %[hi0]}\n\t"
            "setb %b[c_in]"
            : [lo0] "+&r"(lo0), [hi1] "+r"(hi1), [c_in] "+&r"(c_in)
            : [lo1] "r"(lo1), [hi0] "i"(hi0)
            : "cc");
        al = lo0;
        ah = hi1;
        return c_in;
    } else if (WJR_BUILTIN_CONSTANT_P(hi1) && hi1 <= UINT32_MAX) {
        asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
            "adc{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "adc{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t"
            "setb %b[c_in]"
            : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), [c_in] "+&r"(c_in)
            : [lo1] "r"(lo1), [hi1] "i"(hi1)
            : "cc");
        al = lo0;
        ah = hi0;
        return c_in;
    }

    asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
        "adc{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "adc{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t"
        "setb %b[c_in]"
        : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), [c_in] "+&r"(c_in)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    al = lo0;
    ah = hi0;
    return c_in;
}

#endif

#if WJR_HAS_BUILTIN(__ASM_ADDC_CC_128)

/**
 * @brief Use inline assembly to add two 64-bit integers with carry-in and return the
 * carry-out.
 *
 * @details Similar to __asm_addc_128, but the carry-out flag is set by using constraint
 * "=@cccond" instead of "setb".
 *
 */
WJR_INTRINSIC_INLINE uint8_t __asm_addc_cc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                               uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                               uint8_t c_in) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(c_in == 0)) {
        return __asm_addc_cc_zero_128(al, ah, lo0, hi0, lo1, hi1);
    }

    uint8_t c_out;
    if (WJR_BUILTIN_CONSTANT_P(hi0) && hi0 <= UINT32_MAX) {
        asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
            "adc{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "adc{q %[hi0], %[hi1]| %[hi1], %[hi0]}\n\t" WJR_ASM_CCSET(c)
            : [lo0] "+&r"(lo0), [hi1] "+r"(hi1), [c_in] "+&r"(c_in),
              WJR_ASM_CCOUT(c)(c_out)
            : [lo1] "r"(lo1), [hi0] "i"(hi0)
            : "cc");
        al = lo0;
        ah = hi1;
        return c_out;
    } else if (WJR_BUILTIN_CONSTANT_P(hi1) && hi1 <= UINT32_MAX) {
        asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
            "adc{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "adc{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(c)
            : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), [c_in] "+&r"(c_in),
              WJR_ASM_CCOUT(c)(c_out)
            : [lo1] "r"(lo1), [hi1] "i"(hi1)
            : "cc");
        al = lo0;
        ah = hi0;
        return c_out;
    }

    asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
        "adc{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "adc{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(c)
        : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), [c_in] "+&r"(c_in), WJR_ASM_CCOUT(c)(c_out)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    al = lo0;
    ah = hi0;
    return c_out;
}

#endif

} // namespace wjr

#endif // WJR_X86_MATH_ADD_HPP__
#endif

namespace wjr {

template <typename T, typename U>
WJR_INTRINSIC_CONSTEXPR T fallback_addc(T a, T b, U c_in, U &c_out) noexcept {
    T ret = a;
    ret += b;
    U c = ret < b;
    ret += c_in;
    c |= ret < c_in;
    c_out = c;
    return ret;
}

#if WJR_HAS_BUILTIN(__builtin_addc)
#define WJR_HAS_BUILTIN_ADDC WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(ADDC)

template <typename T, typename U>
WJR_INTRINSIC_INLINE T builtin_addc(T a, T b, U c_in, U &c_out) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;

#define WJR_REGISTER_BUILTIN_ADDC(suffix, type)                                          \
    if constexpr (nd <= std::numeric_limits<type>::digits) {                             \
        type __c_out;                                                                    \
        const T ret = __builtin_addc##suffix(a, b, static_cast<type>(c_in), &__c_out);   \
        c_out = static_cast<U>(__c_out);                                                 \
        return ret;                                                                      \
    } else

    WJR_REGISTER_BUILTIN_ADDC(b, unsigned char)
    WJR_REGISTER_BUILTIN_ADDC(s, unsigned short)
    WJR_REGISTER_BUILTIN_ADDC(, unsigned int)
    WJR_REGISTER_BUILTIN_ADDC(l, unsigned long)
    WJR_REGISTER_BUILTIN_ADDC(ll, unsigned long long) {
        static_assert(nd <= 64, "not supported yet");
    }

#undef WJR_REGISTER_BUILTIN_ADDC
}

#endif // WJR_HAS_BUILTIN(ADDC)

/**
 * @brief Add two numbers with carry-in, and return the result and carry-out
 *
 * @note The carry-in and carry-out are limited to 0 and 1
 * @tparam U Type of the carry-in and carry-out. It must be an unsigned integral type.
 * the default type is the same as `T`
 * @param[in] c_in The carry-in flag.
 * @param[out] c_out The carry-out flag.
 *
 * @return a + b + c_in
 */
template <typename T, typename U,
          WJR_REQUIRES_I(is_nonbool_unsigned_integral_v<T> &&is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 T addc(T a, T b, type_identity_t<U> c_in, U &c_out) noexcept {
    WJR_ASSERT_ASSUME_L2(c_in <= 1);

#if !WJR_HAS_BUILTIN(ADDC) && !WJR_HAS_BUILTIN(ASM_ADDC)
    return fallback_addc(a, b, c_in, c_out);
#else
    constexpr auto is_constant_or_zero = [](auto x) -> int {
        return WJR_BUILTIN_CONSTANT_P(x == 0) && x == 0 ? 2
               : WJR_BUILTIN_CONSTANT_P(x)              ? 1
                                                        : 0;
    };

    // The compiler should be able to optimize the judgment condition of if when enabling
    // optimization. If it doesn't work, then there should be a issue
    if (is_constant_evaluated() ||
        // constant value is zero or constant value number greater or equal than 2
        (is_constant_or_zero(a) + is_constant_or_zero(b) + is_constant_or_zero(c_in) >=
         2)) {
        return fallback_addc(a, b, c_in, c_out);
    }

    if constexpr (sizeof(T) == 8) {
        return WJR_PP_BOOL_IF_NE(WJR_HAS_BUILTIN(ASM_ADDC), asm_addc,
                                 WJR_PP_BOOL_IF(WJR_HAS_BUILTIN(ADDC), builtin_addc,
                                                fallback_addc))(a, b, c_in, c_out);
    } else {
        return WJR_PP_BOOL_IF(WJR_HAS_BUILTIN(ADDC), builtin_addc,
                              fallback_addc)(a, b, c_in, c_out);
    }
#endif
}

/**
 * @brief Performs addition with carry-in and carry-out, optimized for subsequent
 * branching based on carry-out.
 *
 * @details This function, `addc_cc`, adds two numbers with a carry-in, and returns the
 * result and a carry-out. The carry-out (`c_out`) is optimized for subsequent code that
 * branches based on its value. For example, it can be used with jump instructions like
 * `je` or `jne`. This is in contrast to the `addc` function, which may use instructions
 * like `setc` or `test` for branching.
 *
 * @note The carry-in and carry-out are limited to 0 and 1
 * @tparam U Type of the carry-in and carry-out. It must be an unsigned integral type.
 * @param[in] c_in The carry-in flag.
 * @param[out] c_out The carry-out flag.
 */
template <typename T, WJR_REQUIRES_I(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 T addc_cc(T a, T b, uint8_t c_in, uint8_t &c_out) noexcept {
    WJR_ASSERT_ASSUME_L2(c_in <= 1);

#if WJR_HAS_BUILTIN(ASM_ADDC_CC)
    constexpr auto is_constant_or_zero = [](auto x) -> int {
        return WJR_BUILTIN_CONSTANT_P(x == 0) && x == 0 ? 2
               : WJR_BUILTIN_CONSTANT_P(x)              ? 1
                                                        : 0;
    };

    // The compiler should be able to optimize the judgment condition of if when enabling
    // optimization. If it doesn't work, then there should be a issue
    if (is_constant_evaluated() ||
        // constant value is zero or constant value number greater or equal than 2
        (is_constant_or_zero(a) + is_constant_or_zero(b) + is_constant_or_zero(c_in) >=
         2)) {
        return fallback_addc(a, b, c_in, c_out);
    }

    if constexpr (sizeof(T) == 8) {
        return asm_addc_cc(a, b, c_in, c_out);
    } else {
        return addc(a, b, c_in, c_out);
    }
#else
    return addc(a, b, c_in, c_out);
#endif
}

#if WJR_HAS_BUILTIN(__builtin_add_overflow)
#define WJR_HAS_BUILTIN_ADD_OVERFLOW WJR_HAS_DEF
#endif

template <typename T>
WJR_INTRINSIC_CONSTEXPR20 bool fallback_add_overflow(T a, T b, T &ret) noexcept {
    ret = a + b;
    return ret < a;
}

template <typename T, WJR_REQUIRES_I(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 bool add_overflow(type_identity_t<T> a, type_identity_t<T> b,
                                            T &ret) noexcept {
#if WJR_HAS_BUILTIN(ADD_OVERFLOW)
    if (is_constant_evaluated() ||
        (WJR_BUILTIN_CONSTANT_P(a) && WJR_BUILTIN_CONSTANT_P(b))) {
        return fallback_add_overflow(a, b, ret);
    }

    return __builtin_add_overflow(a, b, &ret);
#else
    return fallback_add_overflow(a, b, ret);
#endif
}

template <typename U>
WJR_INTRINSIC_CONSTEXPR20 U __addc_1_impl(uint64_t *dst, const uint64_t *src0, size_t n,
                                          uint64_t src1, U c_in) noexcept {
    uint8_t overflow = 0;
    dst[0] = addc_cc(src0[0], src1, static_cast<uint8_t>(c_in), overflow);

    if (overflow) {
        const size_t idx = 1 + replace_find_not(dst + 1, src0 + 1, n - 1, UINT64_MAX, 0);

        if (WJR_UNLIKELY(idx == n)) {
            return static_cast<U>(1);
        }

        dst[idx] = src0[idx] + 1;

        dst += idx;
        src0 += idx;
        n -= idx;
    }

    if (src0 != dst) {
        std::copy(src0 + 1, src0 + n, dst + 1);
    }

    return static_cast<U>(0);
}

/**
 * @brief Add biginteger(src0) and number with carry-in, and return the result(dst) and
 * carry-out.
 *
 * @tparam U Type of the carry-in and carry-out. It must be an unsigned integral type.
 * @param[out] dst The result of the addition.
 * @param[in] src0 The biginteger to be added.
 * @param[in] n The number of elements in the biginteger.
 * @param[in] src1 The number to be added.
 * @param[in] c_in The carry-in flag.
 * @return The carry-out flag.
 */
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 U addc_1(uint64_t *dst, const uint64_t *src0, size_t n,
                                   uint64_t src1, U c_in) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src0, n));
    WJR_ASSERT_ASSUME(c_in <= 1);

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == 1)) {
        uint8_t overflow = 0;
        dst[0] = addc_cc(src0[0], src1, static_cast<uint8_t>(c_in), overflow);
        return static_cast<U>(overflow);
    }

    return __addc_1_impl(dst, src0, n, src1, c_in);
}

template <typename U>
WJR_INTRINSIC_CONSTEXPR U fallback_addc_n(uint64_t *dst, const uint64_t *src0,
                                          const uint64_t *src1, size_t n,
                                          U c_in) noexcept {
    size_t m = n / 4;

    for (size_t i = 0; i < m; ++i) {
        dst[0] = addc(src0[0], src1[0], c_in, c_in);
        dst[1] = addc(src0[1], src1[1], c_in, c_in);
        dst[2] = addc(src0[2], src1[2], c_in, c_in);
        dst[3] = addc(src0[3], src1[3], c_in, c_in);

        dst += 4;
        src0 += 4;
        src1 += 4;
    }

    n &= 3;
    if (WJR_UNLIKELY(n == 0)) {
        return c_in;
    }

    dst += n;
    src0 += n;
    src1 += n;

    switch (n) {
    case 3: {
        dst[-3] = addc(src0[-3], src1[-3], c_in, c_in);
        WJR_FALLTHROUGH;
    }
    case 2: {
        dst[-2] = addc(src0[-2], src1[-2], c_in, c_in);
        WJR_FALLTHROUGH;
    }
    case 1: {
        dst[-1] = addc(src0[-1], src1[-1], c_in, c_in);
        WJR_FALLTHROUGH;
    }
    default: {
        break;
    }
    }

    return c_in;
}

/**
 * @brief Add biginteger(src0) and biginteger(src1) with carry-in, and return the result
 * (dst) and carry-out.
 *
 * @tparam U Type of the carry-in and carry-out. It must be an unsigned integral type.
 * @param[out] dst The result of the addition.
 * @param[in] src0 The biginteger to be added.
 * @param[in] src1 The biginteger to be added.
 * @param[in] n The number of elements in the biginteger.
 * @param[in] c_in The carry-in flag.
 * @return The carry-out flag.
 */
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 U addc_n(uint64_t *dst, const uint64_t *src0,
                                   const uint64_t *src1, size_t n, U c_in) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src0, n));
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src1, n));

#if WJR_HAS_BUILTIN(ASM_ADDC_N)
    if (is_constant_evaluated()) {
        return fallback_addc_n(dst, src0, src1, n, c_in);
    }

    return asm_addc_n(dst, src0, src1, n, c_in);
#else
    return fallback_addc_n(dst, src0, src1, n, c_in);
#endif
}

/*
require :
1. m >= 1
2. n >= m
3. WJR_IS_SAME_OR_INCR_P(dst, n, src0, n)
4. WJR_IS_SAME_OR_INCR_P(dst, m, src1, m)
*/
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 U addc_s(uint64_t *dst, const uint64_t *src0, size_t n,
                                   const uint64_t *src1, size_t m, U c_in) noexcept {
    WJR_ASSERT_ASSUME(m >= 1);
    WJR_ASSERT_ASSUME(n >= m);

    c_in = addc_n(dst, src0, src1, m, c_in);

    if (n != m) {
        c_in = addc_1(dst + m, src0 + m, n - m, 0, c_in);
    }

    return c_in;
}

/*
require :
1. n >= 0
2. n >= m
3. WJR_IS_SAME_OR_INCR_P(dst, n, src0, n)
4. WJR_IS_SAME_OR_INCR_P(dst, m, src1, m)
*/
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 U addc_sz(uint64_t *dst, const uint64_t *src0, size_t n,
                                    const uint64_t *src1, size_t m, U c_in) noexcept {
    WJR_ASSERT_ASSUME(n >= m);

    if (WJR_LIKELY(m != 0)) {
        c_in = addc_n(dst, src0, src1, m, c_in);
    }

    if (n != m) {
        c_in = addc_1(dst + m, src0 + m, n - m, 0, c_in);
    }

    return c_in;
}

WJR_INTRINSIC_CONSTEXPR void __fallback_add_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                                uint64_t hi0, uint64_t lo1,
                                                uint64_t hi1) noexcept {
    const uint64_t __al = lo0 + lo1;
    ah = hi0 + hi1 + (__al < lo0);
    al = __al;
}

#if WJR_HAS_FEATURE(FAST_INT128_ADDSUB)
#define WJR_HAS_BUILTIN___BUILTIN_ADD_128 WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(__BUILTIN_ADD_128)

WJR_INTRINSIC_INLINE void __builtin_add_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                            uint64_t hi0, uint64_t lo1,
                                            uint64_t hi1) noexcept {
    const auto x0 = static_cast<__uint128_t>(hi0) << 64 | lo0;
    const auto x1 = static_cast<__uint128_t>(hi1) << 64 | lo1;
    x0 += x1;

    al = x0;
    ah = x0 >> 64;
}

#endif

/// @brief <ah, al> = <hi0, lo0> + <hi1, lo1>
WJR_INTRINSIC_CONSTEXPR20 void __add_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                         uint64_t hi0, uint64_t lo1,
                                         uint64_t hi1) noexcept {
#if WJR_HAS_BUILTIN(__BUILTIN_ADD_128) || WJR_HAS_BUILTIN(__ASM_ADD_128)
    if (is_constant_evaluated() || WJR_BUILTIN_CONSTANT_P_TRUE(lo0 == 0) ||
        WJR_BUILTIN_CONSTANT_P_TRUE(lo1 == 0) || WJR_BUILTIN_CONSTANT_P(lo0 + lo1)) {
        return __fallback_add_128(al, ah, lo0, hi0, lo1, hi1);
    }

    return WJR_PP_BOOL_IF(WJR_HAS_BUILTIN(__BUILTIN_ADD_128), __builtin_add_128,
                          __asm_add_128)(al, ah, lo0, hi0, lo1, hi1);
#else
    return __fallback_add_128(al, ah, lo0, hi0, lo1, hi1);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t __fallback_addc_128(uint64_t &al, uint64_t &ah,
                                                       uint64_t lo0, uint64_t hi0,
                                                       uint64_t lo1, uint64_t hi1,
                                                       uint64_t c_in) noexcept {
    al = addc(lo0, lo1, c_in, c_in);
    ah = addc(hi0, hi1, c_in, c_in);
    return c_in;
}

/**
 * @return carry-out
 */
WJR_INTRINSIC_CONSTEXPR20 uint64_t __addc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                              uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                              uint64_t c_in) noexcept {
#if WJR_HAS_BUILTIN(__ASM_ADDC_128)
    if (is_constant_evaluated()) {
        return __fallback_addc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
    }

    return __asm_addc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
#else
    return __fallback_addc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 uint8_t __addc_cc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                                uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                                uint8_t c_in) noexcept {
#if WJR_HAS_BUILTIN(__ASM_ADDC_CC_128)
    if (is_constant_evaluated()) {
        return __fallback_addc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
    }

    return __asm_addc_cc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
#else
    return fast_cast<uint8_t>(__addc_128(al, ah, lo0, hi0, lo1, hi1, c_in));
#endif
}

} // namespace wjr

#endif // WJR_MATH_ADD_HPP__
#ifndef WJR_MATH_BIGNUM_CONFIG_HPP__
#define WJR_MATH_BIGNUM_CONFIG_HPP__

#ifndef WJR_GENERIC_MATH_BIGNUM_CONFIG_HPP__
#define WJR_GENERIC_MATH_BIGNUM_CONFIG_HPP__

#ifndef WJR_TOOM22_MUL_THRESHOLD
#define WJR_TOOM22_MUL_THRESHOLD 22
#endif

#ifndef WJR_TOOM33_MUL_THRESHOLD
#define WJR_TOOM33_MUL_THRESHOLD 84
#endif

#ifndef WJR_TOOM44_MUL_THRESHOLD
#define WJR_TOOM44_MUL_THRESHOLD 208
#endif

#ifndef WJR_TOOM55_MUL_THRESHOLD
#define WJR_TOOM55_MUL_THRESHOLD 800
#endif

#ifndef WJR_TOOM32_TO_TOOM43_MUL_THRESHOLD
#define WJR_TOOM32_TO_TOOM43_MUL_THRESHOLD 73
#endif

#ifndef WJR_TOOM32_TO_TOOM53_MUL_THRESHOLD
#define WJR_TOOM32_TO_TOOM53_MUL_THRESHOLD 153
#endif

#ifndef WJR_TOOM42_TO_TOOM53_MUL_THRESHOLD
#define WJR_TOOM42_TO_TOOM53_MUL_THRESHOLD 137
#endif

#ifndef WJR_TOOM42_TO_TOOM63_MUL_THRESHOLD
#define WJR_TOOM42_TO_TOOM63_MUL_THRESHOLD 153
#endif

#ifndef WJR_TOOM2_SQR_THRESHOLD
#define WJR_TOOM2_SQR_THRESHOLD 34
#endif

#ifndef WJR_TOOM3_SQR_THRESHOLD
#define WJR_TOOM3_SQR_THRESHOLD 124
#endif

#ifndef WJR_TOOM4_SQR_THRESHOLD
#define WJR_TOOM4_SQR_THRESHOLD 288
#endif

#ifndef WJR_TOOM5_SQR_THRESHOLD
#define WJR_TOOM5_SQR_THRESHOLD 980
#endif

#ifndef WJR_DC_DIV_QR_THRESHOLD
#define WJR_DC_DIV_QR_THRESHOLD (WJR_TOOM22_MUL_THRESHOLD * 2)
#endif // WJR_DC_DIV_QR_THRESHOLD

#ifndef WJR_DC_BIGNUM_TO_CHARS_THRESHOLD
#define WJR_DC_BIGNUM_TO_CHARS_THRESHOLD 20
#endif

#ifndef WJR_DC_BIGNUM_TO_CHARS_PRECOMPUTE_THRESHOLD
#define WJR_DC_BIGNUM_TO_CHARS_PRECOMPUTE_THRESHOLD 20
#endif

#ifndef WJR_DC_BIGNUM_FROM_CHARS_THRESHOLD
#define WJR_DC_BIGNUM_FROM_CHARS_THRESHOLD 1670
#endif

#ifndef WJR_DC_BIGNUM_FROM_CHARS_PRECOMPUTE_THRESHOLD
#define WJR_DC_BIGNUM_FROM_CHARS_PRECOMPUTE_THRESHOLD 3105
#endif

#endif // WJR_GENERIC_MATH_BIGNUM_CONFIG_HPP__

#endif // WJR_MATH_BIGNUM_CONFIG_HPP__
// Already included
#ifndef WJR_MATH_SHIFT_HPP__
#define WJR_MATH_SHIFT_HPP__

// Already included
// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_SHIFT_HPP__
#define WJR_X86_MATH_SHIFT_HPP__

// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

namespace wjr {

template <typename T>
WJR_INTRINSIC_CONSTEXPR20 T shld(T hi, T lo, unsigned int c) noexcept;

template <typename T>
WJR_INTRINSIC_CONSTEXPR20 T shrd(T lo, T hi, unsigned int c) noexcept;

#if WJR_HAS_SIMD(SSE2)
#define WJR_HAS_BUILTIN_LSHIFT_N WJR_HAS_DEF
#define WJR_HAS_BUILTIN_RSHIFT_N WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(LSHIFT_N) || WJR_HAS_BUILTIN(RSHIFT_N)

/// @private
template <bool is_constant>
WJR_INTRINSIC_INLINE auto __mm_get_shift(unsigned int c) noexcept {
    if constexpr (is_constant) {
        return c;
    } else {
        return simd_cast<unsigned int, __m128i_t>(c);
    }
}

/// @private
WJR_INTRINSIC_INLINE __m128i __mm_sll_epi64(__m128i x, unsigned int c) noexcept {
    return sse::slli_epi64(x, c);
}

/// @private
WJR_INTRINSIC_INLINE __m128i __mm_sll_epi64(__m128i x, __m128i c) noexcept {
    return sse::sll_epi64(x, c);
}

/// @private
WJR_INTRINSIC_INLINE __m128i __mm_srl_epi64(__m128i x, unsigned int c) noexcept {
    return sse::srli_epi64(x, c);
}

/// @private
WJR_INTRINSIC_INLINE __m128i __mm_srl_epi64(__m128i x, __m128i c) noexcept {
    return sse::srl_epi64(x, c);
}

#endif

#if WJR_HAS_BUILTIN(LSHIFT_N)

#define WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED(index)                                      \
    do {                                                                                 \
        __m128i x1 = sse::loadu(src - 3 - (index));                                      \
        x0 = simd_cast<__m128_t, __m128i_t>(sse::template shuffle_ps<78>(                \
            simd_cast<__m128i_t, __m128_t>(x1), simd_cast<__m128i_t, __m128_t>(x0)));    \
                                                                                         \
        __m128i r0 = __mm_sll_epi64(x0, y);                                              \
        __m128i r1 = __mm_srl_epi64(x1, z);                                              \
                                                                                         \
        __m128i r = sse::Or(r0, r1);                                                     \
                                                                                         \
        sse::storeu(dst - 2 - (index), r);                                               \
                                                                                         \
        x0 = x1;                                                                         \
    } while (0)

template <bool is_constant, typename T>
void large_builtin_lshift_n_impl(T *dst, const T *src, size_t n,
                                 unsigned int c) noexcept {
    const auto y = __mm_get_shift<is_constant>(c);
    const auto z = __mm_get_shift<is_constant>(64 - c);

    if (n & 1) {
        dst[-1] = shld(src[-1], src[-2], c);
        --src;
        --dst;
    }

    __m128i x0 = sse::set1_epi64(src[-1]);

    if (n & 2) {
        WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED(0);

        src -= 2;
        dst -= 2;
    }

    if (n & 4) {
        WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED(0);
        WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED(2);

        src -= 4;
        dst -= 4;
    }

    size_t idx = n / 8;

    if (WJR_UNLIKELY(idx == 0)) {
        return;
    }

    do {
        WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED(0);
        WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED(2);
        WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED(4);
        WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED(6);

        src -= 8;
        dst -= 8;
        --idx;
    } while (WJR_LIKELY(idx != 0));
}

extern template void
large_builtin_lshift_n_impl<false, uint64_t>(uint64_t *dst, const uint64_t *src, size_t n,
                                             unsigned int c) noexcept;

extern template void large_builtin_lshift_n_impl<true, uint64_t>(uint64_t *dst,
                                                                 const uint64_t *src,
                                                                 size_t n,
                                                                 unsigned int c) noexcept;

template <typename T>
WJR_INTRINSIC_INLINE void builtin_lshift_n_impl(T *dst, const T *src, size_t n,
                                                unsigned int c) noexcept {
    if (n < 4) {
        switch (n) {
        case 3: {
            dst[2] = shld(src[2], src[1], c);
            WJR_FALLTHROUGH;
        }
        case 2: {
            dst[1] = shld(src[1], src[0], c);
            WJR_FALLTHROUGH;
        }
        case 1: {
            dst[0] = shld(src[0], src[-1], c);
            WJR_FALLTHROUGH;
        }
        case 0: {
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }

        return;
    }

    src += n;
    dst += n;

    if (WJR_BUILTIN_CONSTANT_P(c)) {
        return large_builtin_lshift_n_impl<true>(dst, src, n, c);
    }

    return large_builtin_lshift_n_impl<false>(dst, src, n, c);
}

#undef WJR_REGISTER_LSHIFT_N_IMPL_UNALIGNED

template <typename T>
WJR_INTRINSIC_INLINE T builtin_lshift_n(T *dst, const T *src, size_t n, unsigned int c,
                                        T lo) noexcept {
    const T ret = src[n - 1] >> (64 - c);
    builtin_lshift_n_impl(dst + 1, src + 1, n - 1, c);
    dst[0] = shld(src[0], lo, c);
    return ret;
}

#endif

#if WJR_HAS_BUILTIN(RSHIFT_N)

#define WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED(index)                                      \
    do {                                                                                 \
        __m128i x1 = sse::loadu(src + 1 + (index));                                      \
        x0 = simd_cast<__m128_t, __m128i_t>(sse::template shuffle_ps<78>(                \
            simd_cast<__m128i_t, __m128_t>(x0), simd_cast<__m128i_t, __m128_t>(x1)));    \
                                                                                         \
        __m128i r0 = __mm_srl_epi64(x0, y);                                              \
        __m128i r1 = __mm_sll_epi64(x1, z);                                              \
                                                                                         \
        __m128i r = sse::Or(r0, r1);                                                     \
                                                                                         \
        sse::storeu(dst + (index), r);                                                   \
                                                                                         \
        x0 = x1;                                                                         \
    } while (0)

template <bool is_constant, typename T>
void large_builtin_rshift_n_impl(T *dst, const T *src, size_t n,
                                 unsigned int c) noexcept {
    const auto y = __mm_get_shift<is_constant>(c);
    const auto z = __mm_get_shift<is_constant>(64 - c);

    if (n & 1) {
        dst[0] = shrd(src[0], src[1], c);
        ++src;
        ++dst;
    }

    __m128i x0 = sse::set1_epi64(src[0]);

    if (n & 2) {
        WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED(0);

        src += 2;
        dst += 2;
    }

    if (n & 4) {
        WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED(0);
        WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED(2);

        src += 4;
        dst += 4;
    }

    size_t idx = n / 8;

    if (WJR_UNLIKELY(idx == 0)) {
        return;
    }

    do {
        WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED(0);
        WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED(2);
        WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED(4);
        WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED(6);

        dst += 8;
        src += 8;
        --idx;
    } while (WJR_LIKELY(idx != 0));
}

extern template void
large_builtin_rshift_n_impl<false, uint64_t>(uint64_t *dst, const uint64_t *src, size_t n,
                                             unsigned int c) noexcept;

extern template void large_builtin_rshift_n_impl<true, uint64_t>(uint64_t *dst,
                                                                 const uint64_t *src,
                                                                 size_t n,
                                                                 unsigned int c) noexcept;

template <typename T>
WJR_INTRINSIC_INLINE void builtin_rshift_n_impl(T *dst, const T *src, size_t n,
                                                unsigned int c) noexcept {
    if (n < 4) {
        dst += n - 3;
        src += n - 3;

        switch (n) {
        case 3: {
            dst[0] = shrd(src[0], src[1], c);
            WJR_FALLTHROUGH;
        }
        case 2: {
            dst[1] = shrd(src[1], src[2], c);
            WJR_FALLTHROUGH;
        }
        case 1: {
            dst[2] = shrd(src[2], src[3], c);
            WJR_FALLTHROUGH;
        }
        case 0: {
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }

        return;
    }

    if (WJR_BUILTIN_CONSTANT_P(c)) {
        return large_builtin_rshift_n_impl<true>(dst, src, n, c);
    }

    return large_builtin_rshift_n_impl<false>(dst, src, n, c);
}

#undef WJR_REGISTER_RSHIFT_N_IMPL_UNALIGNED

template <typename T>
WJR_INTRINSIC_INLINE T builtin_rshift_n(T *dst, const T *src, size_t n, unsigned int c,
                                        T hi) noexcept {
    const T ret = src[0] << (64 - c);
    builtin_rshift_n_impl(dst, src, n - 1, c);
    dst[n - 1] = shrd(src[n - 1], hi, c);
    return ret;
}

#endif

} // namespace wjr

#endif // WJR_X86_MATH_SHIFT_HPP__
#endif

namespace wjr {

template <typename T>
WJR_INTRINSIC_CONSTEXPR T fallback_shld(T hi, T lo, unsigned int c) noexcept {
    constexpr auto digits = std::numeric_limits<T>::digits;
    return hi << c | lo >> (digits - c);
}

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 T shld(T hi, T lo, unsigned int c) noexcept {
    return fallback_shld(hi, lo, c);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR T fallback_shrd(T lo, T hi, unsigned int c) noexcept {
    constexpr auto digits = std::numeric_limits<T>::digits;
    return lo >> c | hi << (digits - c);
}

template <typename T>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 T shrd(T lo, T hi, unsigned int c) noexcept {
    return fallback_shrd(lo, hi, c);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR T fallback_lshift_n(T *dst, const T *src, size_t n,
                                            unsigned int c, T lo) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    T ret = src[n - 1] >> (nd - c);
    for (size_t i = 0; i < n - 1; ++i) {
        dst[n - i - 1] = fallback_shld(src[n - i - 1], src[n - i - 2], c);
    }
    dst[0] = fallback_shld(src[0], lo, c);
    return ret;
}

/*
require :
1. n >= 1
2. WJR_IS_SAME_OR_DECR_P(dst, n, src, n)
*/
template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 T lshift_n(T *dst, const T *src, size_t n,
                                                   unsigned int c,
                                                   type_identity_t<T> lo = 0) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_DECR_P(dst, n, src, n));
    WJR_ASSERT_L2(c < std::numeric_limits<T>::digits);

    if (WJR_UNLIKELY(c == 0)) {
        if (WJR_LIKELY(dst != src)) {
            std::copy_backward(src, src + n, dst + n);
        }

        return 0;
    }

#if WJR_HAS_BUILTIN(LSHIFT_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_lshift_n(dst, src, n, c, lo);
        }

        return builtin_lshift_n(dst, src, n, c, lo);
    } else {
        return fallback_lshift_n(dst, src, n, c, lo);
    }
#else
    return fallback_lshift_n(dst, src, n, c, lo);
#endif
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR T fallback_rshift_n(T *dst, const T *src, size_t n,
                                            unsigned int c, T hi) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    T ret = src[0] << (nd - c);
    for (size_t i = 0; i < n - 1; ++i) {
        dst[i] = fallback_shrd(src[i], src[i + 1], c);
    }
    dst[n - 1] = fallback_shrd(src[n - 1], hi, c);
    return ret;
}

/*
require :
1. n >= 1
2. WJR_IS_SAME_OR_INCR_P(dst, n, src, n)
*/
template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 T rshift_n(T *dst, const T *src, size_t n, unsigned int c,
                                     type_identity_t<T> hi = 0) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src, n));
    WJR_ASSERT_L2(c < std::numeric_limits<T>::digits);

    if (WJR_UNLIKELY(c == 0)) {
        if (WJR_LIKELY(dst != src)) {
            std::copy(src, src + n, dst);
        }

        return 0;
    }

#if WJR_HAS_BUILTIN(RSHIFT_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_rshift_n(dst, src, n, c, hi);
        }

        return builtin_rshift_n(dst, src, n, c, hi);
    } else {
        return fallback_rshift_n(dst, src, n, c, hi);
    }
#else
    return fallback_rshift_n(dst, src, n, c, hi);
#endif
}

} // namespace wjr

#endif // WJR_MATH_SHIFT_HPP__
#ifndef WJR_MATH_SUB_HPP__
#define WJR_MATH_SUB_HPP__

// Already included
// Already included
// Already included
#ifndef WJR_MATH_SUB_IMPL_HPP__
#define WJR_MATH_SUB_IMPL_HPP__

// Already included

namespace wjr {

template <typename T, typename U,
          WJR_REQUIRES(is_nonbool_unsigned_integral_v<T> &&is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 T subc(T a, T b, type_identity_t<U> c_in,
                                               U &c_out) noexcept;

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 T subc_cc(T a, T b, uint8_t c_in,
                                                  uint8_t &c_out) noexcept;

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 bool
sub_overflow(type_identity_t<T> a, type_identity_t<T> b, T &ret) noexcept;

template <typename U = uint64_t, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 U subc_1(uint64_t *dst, const uint64_t *src0,
                                                 size_t n, uint64_t src1,
                                                 U c_in = 0) noexcept;

template <typename U = uint64_t, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 U subc_n(uint64_t *dst, const uint64_t *src0,
                                                 const uint64_t *src1, size_t n,
                                                 U c_in = 0) noexcept;

template <typename U = uint64_t, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 U subc_s(uint64_t *dst, const uint64_t *src0,
                                                 size_t n, const uint64_t *src1, size_t m,
                                                 U c_in = 0) noexcept;

template <typename U = uint64_t, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 U subc_sz(uint64_t *dst, const uint64_t *src0,
                                                  size_t n, const uint64_t *src1,
                                                  size_t m, U c_in = 0) noexcept;

WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_n(uint64_t *dst,
                                                           const uint64_t *src0,
                                                           const uint64_t *src1,
                                                           size_t n) noexcept;

WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_n_pos(uint64_t *dst,
                                                               const uint64_t *src0,
                                                               const uint64_t *src1,
                                                               size_t n) noexcept;

WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_s1(uint64_t *dst,
                                                            const uint64_t *src0,
                                                            size_t n,
                                                            const uint64_t *src1,
                                                            size_t m) noexcept;

WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_s(uint64_t *dst,
                                                           const uint64_t *src0, size_t n,
                                                           const uint64_t *src1,
                                                           size_t m) noexcept;

WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_s_pos(uint64_t *dst,
                                                               const uint64_t *src0,
                                                               size_t n,
                                                               const uint64_t *src1,
                                                               size_t m) noexcept;

template <typename U, WJR_REQUIRES(is_unsigned_integral_v<U>)>
WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 ssize_t
abs_subc_n(uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n, U &c_out,
           type_identity_t<U> cf0, type_identity_t<U> cf1) noexcept;

// preview :

WJR_INTRINSIC_CONSTEXPR20 void __sub_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                         uint64_t hi0, uint64_t lo1,
                                         uint64_t hi1) noexcept;

WJR_INTRINSIC_CONSTEXPR20 uint64_t __subc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                              uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                              uint64_t c_in) noexcept;

WJR_INTRINSIC_CONSTEXPR20 uint8_t __subc_cc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                                uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                                uint8_t c_in) noexcept;

} // namespace wjr

#endif // WJR_MATH_SUB_IMPL_HPP__

#if defined(WJR_X86)
#ifndef WJR_X86_SUB_HPP__
#define WJR_X86_SUB_HPP__

// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_SUBC WJR_HAS_DEF
#define WJR_HAS_BUILTIN_ASM_SUBC_N WJR_HAS_DEF
#define WJR_HAS_BUILTIN___ASM_SUB_128 WJR_HAS_DEF
#define WJR_HAS_BUILTIN___ASM_SUBC_128 WJR_HAS_DEF

#if WJR_HAS_FEATURE(INLINE_ASM_CCCOND)
#define WJR_HAS_BUILTIN_ASM_SUBC_CC WJR_HAS_DEF
#define WJR_HAS_BUILTIN___ASM_SUBC_CC_128 WJR_HAS_DEF
#endif
#else

#if defined(WJR_MSVC)
#define WJR_HAS_BUILTIN_ASM_SUBC WJR_HAS_DEF_VAR(2)
#endif

#if defined(WJR_ENABLE_ASSEMBLY)
#define WJR_HAS_BUILTIN_ASM_SUBC_N WJR_HAS_DEF_VAR(3)
#endif

#endif

#if WJR_HAS_BUILTIN(ASM_SUBC) == 2
// Already included
#endif

namespace wjr {

#if WJR_HAS_BUILTIN(ASM_SUBC)

template <typename U>
WJR_INTRINSIC_INLINE uint64_t asm_subc(uint64_t a, uint64_t b, U c_in,
                                       U &c_out) noexcept {
#if WJR_HAS_BUILTIN(ASM_SUBC) == 1
    if (WJR_BUILTIN_CONSTANT_P_TRUE(c_in == 1)) {
        if (WJR_BUILTIN_CONSTANT_P(b) && in_range<int32_t>(b)) {
            asm("stc\n\t"
                "sbb{q %2, %0| %0, %2}\n\t"
                "setb %b1"
                : "=r"(a), "+r"(c_in)
                : "ri"(b), "0"(a)
                : "cc");
        } else {
            asm("stc\n\t"
                "sbb{q %2, %0| %0, %2}\n\t"
                "setb %b1"
                : "=r"(a), "+r"(c_in)
                : "r"(b), "0"(a)
                : "cc");
        }
        c_out = c_in;
        return a;
    }

    if (WJR_BUILTIN_CONSTANT_P(b) && in_range<int32_t>(b)) {
        asm("add{b $255, %b1| %b1, 255}\n\t"
            "sbb{q %2, %0| %0, %2}\n\t"
            "setb %b1"
            : "=r"(a), "+&r"(c_in)
            : "ri"(b), "0"(a)
            : "cc");
    } else {
        asm("add{b $255, %b1| %b1, 255}\n\t"
            "sbb{q %2, %0| %0, %2}\n\t"
            "setb %b1"
            : "=r"(a), "+&r"(c_in)
            : "r"(b), "0"(a)
            : "cc");
    }
    c_out = c_in;
    return a;
#else
    uint64_t ret;
    c_out = fast_cast<U>(_subborrow_u64(fast_cast<unsigned char>(c_in), a, b, &ret));
    return ret;
#endif
}

#endif

#if WJR_HAS_BUILTIN(ASM_SUBC_CC)

WJR_INTRINSIC_INLINE uint64_t asm_subc_cc(uint64_t a, uint64_t b, uint8_t c_in,
                                          uint8_t &c_out) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(c_in == 1)) {
        if (WJR_BUILTIN_CONSTANT_P(b) && in_range<int32_t>(b)) {
            asm("stc\n\t"
                "sbb{q %2, %0| %0, %2}\n\t" WJR_ASM_CCSET(c)
                : "=r"(a), WJR_ASM_CCOUT(c)(c_out)
                : "ri"(b), "0"(a)
                : "cc");
        } else {
            asm("stc\n\t"
                "sbb{q %2, %0| %0, %2}\n\t" WJR_ASM_CCSET(c)
                : "=r"(a), WJR_ASM_CCOUT(c)(c_out)
                : "r"(b), "0"(a)
                : "cc");
        }
        return a;
    }

    if (WJR_BUILTIN_CONSTANT_P(b) && in_range<int32_t>(b)) {
        asm("add{b $255, %b1| %b1, 255}\n\t"
            "sbb{q %3, %0| %0, %3}\n\t" WJR_ASM_CCSET(c)
            : "=r"(a), "+&r"(c_in), WJR_ASM_CCOUT(c)(c_out)
            : "ri"(b), "0"(a)
            : "cc");
    } else {
        asm("add{b $255, %b1| %b1, 255}\n\t"
            "sbb{q %3, %0| %0, %3}\n\t" WJR_ASM_CCSET(c)
            : "=r"(a), "+&r"(c_in), WJR_ASM_CCOUT(c)(c_out)
            : "r"(b), "0"(a)
            : "cc");
    }
    return a;
}

#endif

#if WJR_HAS_BUILTIN(ASM_SUBC_N)
#define WJR_ADDSUB_I 0
// WJR_ADDSUB_I :
// 0 : SUB
// 1 : ADD

// Already included

#ifndef WJR_ADDSUB_I
#error "abort"
#endif

#if WJR_ADDSUB_I == 1
#define WJR_addcsubc addc
#define WJR_adcsbb adc
#define __WJR_TEST_ASSEMBLY ASM_ADDC_N
#else
#define WJR_addcsubc subc
#define WJR_adcsbb sbb
#define __WJR_TEST_ASSEMBLY ASM_SUBC_N
#endif

#if WJR_HAS_BUILTIN(__WJR_TEST_ASSEMBLY) == 1

inline uint64_t WJR_PP_CONCAT(__wjr_asm_, WJR_PP_CONCAT(WJR_addcsubc, _n_impl))(
    uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n,
    uint64_t c_in) noexcept {
    size_t rcx = n / 8;
    uint64_t r8 = c_in, r9, r10 = n & 7, r11;

    asm volatile(
        "add{b $255, %b[r8]| %b[r8], 255}\n\t"
        "lea{q| %[r9], [rip +} .Llookup%={(%%rip), %[r9]|]}\n\t"
        "movs{lq (%[r9], %[r10], 4), %[r10]|xd %[r10], DWORD PTR [%[r9] + %[r10] * 4]}\n\t"
        "lea{q (%[r9], %[r10], 1), %[r10]| %[r10], [%[r9] + %[r10]]}\n\t"
        "jmp{q *%[r10]| %[r10]}\n\t"
        
        ".align 8\n\t"
        ".Llookup%=:\n\t"
        ".long .Ll0%=-.Llookup%=\n\t"
        ".long .Ll1%=-.Llookup%=\n\t"
        ".long .Ll2%=-.Llookup%=\n\t"
        ".long .Ll3%=-.Llookup%=\n\t"
        ".long .Ll4%=-.Llookup%=\n\t"
        ".long .Ll5%=-.Llookup%=\n\t"
        ".long .Ll6%=-.Llookup%=\n\t"
        ".long .Ll7%=-.Llookup%=\n\t"
        ".align 16\n\t"
        
        ".Ll0%=:\n\t"
        "mov{q (%[src0]), %[r9]| %[r9], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r11]| %[r11], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r9]| %[r9], [%[src1]]}\n\t"
        "jmp .Lb0%=\n\t"

        ".Ld1%=:\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r10]| %[r10], [%[src1]]}\n\t"
        "mov{q %[r10], (%[dst])| [%[dst]], %[r10]}\n\t"
        "jmp .Ldone%=\n\t"

        ".Ll1%=:\n\t"
        "mov{q (%[src0]), %[r10]| %[r10], [%[src0]]}\n\t"
        "jrcxz .Ld1%=\n\t"
        "mov{q 8(%[src0]), %[r9]| %[r9], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r10]| %[r10], [%[src1]]}\n\t"
        "lea{q 8(%[src0]), %[src0]| %[src0], [%[src0] + 8]}\n\t"
        "lea{q 8(%[src1]), %[src1]| %[src1], [%[src1] + 8]}\n\t"
        "lea{q 8(%[dst]), %[dst]| %[dst], [%[dst] + 8]}\n\t"
        "jmp .Lb1%=\n\t"

        ".Ll3%=:\n\t"
        "mov{q (%[src0]), %[r11]| %[r11], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r8]| %[r8], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r11]| %[r11], [%[src1]]}\n\t"
        "lea{q -40(%[src0]), %[src0]| %[src0], [%[src0] - 40]}\n\t"
        "lea{q -40(%[src1]), %[src1]| %[src1], [%[src1] - 40]}\n\t"
        "lea{q -40(%[dst]), %[dst]| %[dst], [%[dst] - 40]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb3%=\n\t"

        ".Ll4%=:\n\t"
        "mov{q (%[src0]), %[r9]| %[r9], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r11]| %[r11], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r9]| %[r9], [%[src1]]}\n\t"
        "lea{q -32(%[src0]), %[src0]| %[src0], [%[src0] - 32]}\n\t"
        "lea{q -32(%[src1]), %[src1]| %[src1], [%[src1] - 32]}\n\t"
        "lea{q -32(%[dst]), %[dst]| %[dst], [%[dst] - 32]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb4%=\n\t"

        ".Ll5%=:\n\t"
        "mov{q (%[src0]), %[r10]| %[r10], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r9]| %[r9], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r10]| %[r10], [%[src1]]}\n\t"
        "lea{q -24(%[src0]), %[src0]| %[src0], [%[src0] - 24]}\n\t"
        "lea{q -24(%[src1]), %[src1]| %[src1], [%[src1] - 24]}\n\t"
        "lea{q -24(%[dst]), %[dst]| %[dst], [%[dst] - 24]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb5%=\n\t"

        ".Ll6%=:\n\t"
        "mov{q (%[src0]), %[r8]| %[r8], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r10]| %[r10], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r8]| %[r8], [%[src1]]}\n\t"
        "lea{q -16(%[src0]), %[src0]| %[src0], [%[src0] - 16]}\n\t"
        "lea{q -16(%[src1]), %[src1]| %[src1], [%[src1] - 16]}\n\t"
        "lea{q -16(%[dst]), %[dst]| %[dst], [%[dst] - 16]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb6%=\n\t"

        ".Ll7%=:\n\t"
        "mov{q (%[src0]), %[r11]| %[r11], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r8]| %[r8], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r11]| %[r11], [%[src1]]}\n\t"
        "lea{q -8(%[src0]), %[src0]| %[src0], [%[src0] - 8]}\n\t"
        "lea{q -8(%[src1]), %[src1]| %[src1], [%[src1] - 8]}\n\t"
        "lea{q -8(%[dst]), %[dst]| %[dst], [%[dst] - 8]}\n\t"
        "inc %[rcx]\n\t"
        "jmp .Lb7%=\n\t"

        ".Ld2%=:\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 8(%[src1]), %[r10]| %[r10], [%[src1] + 8]}\n\t"
        "mov{q %[r8], (%[dst])| [%[dst]], %[r8]}\n\t"
        "mov{q %[r10], 8(%[dst])| [%[dst] + 8], %[r10]}\n\t"
        "jmp .Ldone%=\n\t"

        ".Ll2%=:\n\t"
        "mov{q (%[src0]), %[r8]| %[r8], [%[src0]]}\n\t"
        "mov{q 8(%[src0]), %[r10]| %[r10], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r8]| %[r8], [%[src1]]}\n\t"
        "jrcxz .Ld2%=\n\t"
        "lea{q 16(%[src0]), %[src0]| %[src0], [%[src0] + 16]}\n\t"
        "lea{q 16(%[src1]), %[src1]| %[src1], [%[src1] + 16]}\n\t"
        "lea{q 16(%[dst]), %[dst]| %[dst], [%[dst] + 16]}\n\t"

        ".align 32\n\t"
        ".Lloop%=:\n\t"

        ".Lb2%=:\n\t"
        "mov{q (%[src0]), %[r9]| %[r9], [%[src0]]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q -8(%[src1]), %[r10]| %[r10], [%[src1] - 8]}\n\t"
        "mov{q %[r8], -16(%[dst])| [%[dst] - 16], %[r8]}\n\t"

        ".Lb1%=:\n\t"
        "mov{q 8(%[src0]), %[r11]| %[r11], [%[src0] + 8]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q (%[src1]), %[r9]| %[r9], [%[src1]]}\n\t"
        "mov{q %[r10], -8(%[dst])| [%[dst] - 8], %[r10]}\n\t"

        ".Lb0%=:\n\t"
        "mov{q 16(%[src0]), %[r8]| %[r8], [%[src0] + 16]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 8(%[src1]), %[r11]| %[r11], [%[src1] + 8]}\n\t"
        "mov{q %[r9], (%[dst])| [%[dst]], %[r9]}\n\t"

        ".Lb7%=:\n\t"
        "mov{q 24(%[src0]), %[r10]| %[r10], [%[src0] + 24]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 16(%[src1]), %[r8]| %[r8], [%[src1] + 16]}\n\t"
        "mov{q %[r11], 8(%[dst])| [%[dst] + 8], %[r11]}\n\t"

        ".Lb6%=:\n\t"
        "mov{q 32(%[src0]), %[r9]| %[r9], [%[src0] + 32]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 24(%[src1]), %[r10]| %[r10], [%[src1] + 24]}\n\t"
        "mov{q %[r8], 16(%[dst])| [%[dst] + 16], %[r8]}\n\t"

        ".Lb5%=:\n\t"
        "mov{q 40(%[src0]), %[r11]| %[r11], [%[src0] + 40]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 32(%[src1]), %[r9]| %[r9], [%[src1] + 32]}\n\t"
        "mov{q %[r10], 24(%[dst])| [%[dst] + 24], %[r10]}\n\t"

        ".Lb4%=:\n\t"
        "mov{q 48(%[src0]), %[r8]| %[r8], [%[src0] + 48]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 40(%[src1]), %[r11]| %[r11], [%[src1] + 40]}\n\t"
        "mov{q %[r9], 32(%[dst])| [%[dst] + 32], %[r9]}\n\t"

        ".Lb3%=:\n\t"
        "mov{q 56(%[src0]), %[r10]| %[r10], [%[src0] + 56]}\n\t"
        WJR_PP_STR(WJR_adcsbb) "{q 48(%[src1]), %[r8]| %[r8], [%[src1] + 48]}\n\t"
        "mov{q %[r11], 40(%[dst])| [%[dst] + 40], %[r11]}\n\t"

        // TODO : optimize pipeline
        "lea{q 64(%[src0]), %[src0]| %[src0], [%[src0] + 64]}\n\t"
        "lea{q 64(%[src1]), %[src1]| %[src1], [%[src1] + 64]}\n\t"
        "lea{q 64(%[dst]), %[dst]| %[dst], [%[dst] + 64]}\n\t"
        "dec %[rcx]\n\t"
        
        "jne .Lloop%=\n\t"

        WJR_PP_STR(WJR_adcsbb) "{q -8(%[src1]), %[r10]| %[r10], [%[src1] - 8]}\n\t"
        "mov{q %[r8], -16(%[dst])| [%[dst] - 16], %[r8]}\n\t"
        "mov{q %[r10], -8(%[dst])| [%[dst] - 8], %[r10]}\n\t"

        ".Ldone%=:\n\t"
        "mov{l %k[rcx], %k[r9]| %k[r9], %k[rcx]}\n\t"
        "adc{l %k[rcx], %k[r9]| %k[r9], %k[rcx]}"

        : [dst] "+r"(dst), [src0] "+r"(src0), [src1] "+r"(src1), [rcx] "+c"(rcx), 
          [r8] "+r"(r8), [r9] "=&r"(r9), [r10] "+r"(r10), [r11] "=&r"(r11)
        :
        : "cc", "memory");

    WJR_ASSERT_ASSUME(rcx == 0);
    WJR_ASSERT_ASSUME(r9 <= 1);

    return r9;
}

#else
extern "C" WJR_MS_ABI uint64_t WJR_PP_CONCAT(
    __wjr_asm_, WJR_PP_CONCAT(WJR_addcsubc, _n_impl))(uint64_t *dst, const uint64_t *src0,
                                                      const uint64_t *src1, size_t n,
                                                      uint64_t c_in) noexcept;
#endif

WJR_INTRINSIC_INLINE uint64_t WJR_PP_CONCAT(asm_, WJR_PP_CONCAT(WJR_addcsubc, _n))(
    uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n,
    uint64_t c_in) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(n)) {
        if (n == 1) {
            dst[0] = WJR_PP_CONCAT(asm_, WJR_addcsubc)(src0[0], src1[0], c_in, c_in);
            return c_in;
        }
    }

    return WJR_PP_CONCAT(__wjr_asm_, WJR_PP_CONCAT(WJR_addcsubc, _n_impl))(dst, src0,
                                                                           src1, n, c_in);
}

#undef __WJR_TEST_ASSEMBLY
#undef WJR_adcsbb
#undef WJR_addcsubc

#undef WJR_ADDSUB_I
#endif

#if WJR_HAS_BUILTIN(__ASM_SUB_128)

WJR_INTRINSIC_INLINE void __asm_sub_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                        uint64_t hi0, uint64_t lo1,
                                        uint64_t hi1) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(hi1) && hi1 <= UINT32_MAX) {
        asm("sub{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}"
            : [lo0] "+&r"(lo0), [hi0] "+r"(hi0)
            : [lo1] "r"(lo1), [hi1] "i"(hi1)
            : "cc");
        al = lo0;
        ah = hi0;
        return;
    }
    asm("sub{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}"
        : [lo0] "+&r"(lo0), [hi0] "+r"(hi0)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    al = lo0;
    ah = hi0;
}

#endif

#if WJR_HAS_BUILTIN(__ASM_SUBC_128) || WJR_HAS_BUILTIN(__ASM_SUBC_CC_128)

WJR_INTRINSIC_INLINE uint8_t __asm_subc_cc_zero_128(uint64_t &al, uint64_t &ah,
                                                    uint64_t lo0, uint64_t hi0,
                                                    uint64_t lo1, uint64_t hi1) noexcept {
    uint8_t c_out;
    if (WJR_BUILTIN_CONSTANT_P(hi1) && hi1 <= UINT32_MAX) {
        asm("sub{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(c)
            : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), WJR_ASM_CCOUT(c)(c_out)
            : [lo1] "r"(lo1), [hi1] "i"(hi1)
            : "cc");
        al = lo0;
        ah = hi0;
        return c_out;
    }

    asm("sub{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(c)
        : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), WJR_ASM_CCOUT(c)(c_out)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    al = lo0;
    ah = hi0;
    return c_out;
}

#endif

#if WJR_HAS_BUILTIN(__ASM_SUBC_128)

WJR_INTRINSIC_INLINE uint64_t __asm_subc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                             uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                             uint64_t c_in) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(c_in == 0)) {
        return __asm_subc_cc_zero_128(al, ah, lo0, hi0, lo1, hi1);
    }

    if (WJR_BUILTIN_CONSTANT_P(hi1) && hi1 <= UINT32_MAX) {
        asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
            "sbb{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t"
            "setb %b[c_in]"
            : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), [c_in] "+&r"(c_in)
            : [lo1] "r"(lo1), [hi1] "i"(hi1)
            : "cc");
        al = lo0;
        ah = hi0;
        return c_in;
    }

    asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
        "sbb{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t"
        "setb %b[c_in]"
        : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), [c_in] "+&r"(c_in)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    al = lo0;
    ah = hi0;
    return c_in;
}

#endif

#if WJR_HAS_BUILTIN(__ASM_SUBC_CC_128)

WJR_INTRINSIC_INLINE uint8_t __asm_subc_cc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                               uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                               uint8_t c_in) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(c_in == 0)) {
        return __asm_subc_cc_zero_128(al, ah, lo0, hi0, lo1, hi1);
    }

    uint8_t c_out;
    if (WJR_BUILTIN_CONSTANT_P(hi1) && hi1 <= UINT32_MAX) {
        asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
            "sbb{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
            "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(c)
            : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), [c_in] "+&r"(c_in),
              WJR_ASM_CCOUT(c)(c_out)
            : [lo1] "r"(lo1), [hi1] "i"(hi1)
            : "cc");
        al = lo0;
        ah = hi0;
        return c_out;
    }

    asm("add{b $0xff, %b[c_in]| %b[c_in], 0xff}\n\t"
        "sbb{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(c)
        : [lo0] "+&r"(lo0), [hi0] "+r"(hi0), [c_in] "+&r"(c_in), WJR_ASM_CCOUT(c)(c_out)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    al = lo0;
    ah = hi0;
    return c_out;
}

#endif

} // namespace wjr

#endif // WJR_X86_SUB_HPP__
#endif

namespace wjr {

template <typename T, typename U>
WJR_INTRINSIC_CONSTEXPR T fallback_subc(T a, T b, U c_in, U &c_out) noexcept {
    T ret = a - b;
    U c = ret > a;
    a = ret;
    ret -= c_in;
    c |= ret > a;
    c_out = c;
    return ret;
}

#if WJR_HAS_BUILTIN(__builtin_subc)
#define WJR_HAS_BUILTIN_SUBC WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(SUBC)

template <typename T, typename U>
WJR_INTRINSIC_INLINE T builtin_subc(T a, T b, U c_in, U &c_out) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;

#define WJR_REGISTER_BUILTIN_SUBC(suffix, type)                                          \
    if constexpr (nd <= std::numeric_limits<type>::digits) {                             \
        type __c_out;                                                                    \
        T ret = __builtin_subc##suffix(a, b, static_cast<type>(c_in), &__c_out);         \
        c_out = static_cast<U>(__c_out);                                                 \
        return ret;                                                                      \
    } else

    WJR_REGISTER_BUILTIN_SUBC(b, unsigned char)
    WJR_REGISTER_BUILTIN_SUBC(s, unsigned short)
    WJR_REGISTER_BUILTIN_SUBC(, unsigned int)
    WJR_REGISTER_BUILTIN_SUBC(l, unsigned long)
    WJR_REGISTER_BUILTIN_SUBC(ll, unsigned long long) {
        static_assert(nd <= 64, "not supported yet");
    }

#undef WJR_REGISTER_BUILTIN_SUBC
}

#endif // WJR_HAS_BUILTIN(SUBC)

template <typename T, typename U,
          WJR_REQUIRES_I(is_nonbool_unsigned_integral_v<T> &&is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 T subc(T a, T b, type_identity_t<U> c_in, U &c_out) noexcept {
    WJR_ASSERT_ASSUME_L2(c_in <= 1);

#if !WJR_HAS_BUILTIN(SUBC) && !WJR_HAS_BUILTIN(ASM_SUBC)
    return fallback_subc(a, b, c_in, c_out);
#else
    constexpr auto is_constant_or_zero = [](auto x) -> int {
        return WJR_BUILTIN_CONSTANT_P(x == 0) && x == 0 ? 2
               : WJR_BUILTIN_CONSTANT_P(x)              ? 1
                                                        : 0;
    };

    // The compiler should be able to optimize the judgment condition of if when enabling
    // optimization. If it doesn't work, then there should be a issue
    if (is_constant_evaluated() ||
        // constant value is zero or constant value number greater or equal than 2
        (is_constant_or_zero(a) + is_constant_or_zero(b) + is_constant_or_zero(c_in) >=
         2)) {
        return fallback_subc(a, b, c_in, c_out);
    }

    if constexpr (sizeof(T) == 8) {
        return WJR_PP_BOOL_IF_NE(WJR_HAS_BUILTIN(ASM_SUBC), asm_subc,
                                 WJR_PP_BOOL_IF(WJR_HAS_BUILTIN(SUBC), builtin_subc,
                                                fallback_subc))(a, b, c_in, c_out);
    } else {
        return WJR_PP_BOOL_IF(WJR_HAS_BUILTIN(SUBC), builtin_subc,
                              fallback_subc)(a, b, c_in, c_out);
    }
#endif
}

/*
 Used for subc and then jump according to cc flag. Therefore, the types of c_in and
 c_out are limited to uint8_t, while the default c_in and c_out types of normal subc are
 the same as T, so that the high register is not cleared. Currently, GCC/Clang @=cccond
 cannot know that the high register is not cleared, so the performance is worse than the
 normal version when cc flag is not needed immediately.
*/
template <typename T, WJR_REQUIRES_I(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 T subc_cc(T a, T b, uint8_t c_in, uint8_t &c_out) noexcept {
    WJR_ASSERT_ASSUME_L2(c_in <= 1);

#if WJR_HAS_BUILTIN(ASM_SUBC_CC)
    constexpr auto is_constant_or_zero = [](auto x) -> int {
        return WJR_BUILTIN_CONSTANT_P(x == 0) && x == 0 ? 2
               : WJR_BUILTIN_CONSTANT_P(x)              ? 1
                                                        : 0;
    };

    // The compiler should be able to optimize the judgment condition of if when enabling
    // optimization. If it doesn't work, then there should be a issue
    if (is_constant_evaluated() ||
        // constant value is zero or constant value number greater or equal than 2
        (is_constant_or_zero(a) + is_constant_or_zero(b) + is_constant_or_zero(c_in) >=
         2)) {
        return fallback_subc(a, b, c_in, c_out);
    }

    if constexpr (sizeof(T) == 8) {
        return asm_subc_cc(a, b, c_in, c_out);
    } else {
        return subc(a, b, c_in, c_out);
    }
#else
    return subc(a, b, c_in, c_out);
#endif
}

#if WJR_HAS_BUILTIN(__builtin_sub_overflow)
#define WJR_HAS_BUILTIN_SUB_OVERFLOW WJR_HAS_DEF
#endif

template <typename T>
WJR_INTRINSIC_CONSTEXPR20 bool fallback_sub_overflow(T a, T b, T &ret) noexcept {
    ret = a - b;
    return ret > a;
}

template <typename T, WJR_REQUIRES_I(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 bool sub_overflow(type_identity_t<T> a, type_identity_t<T> b,
                                            T &ret) noexcept {
#if WJR_HAS_BUILTIN(SUB_OVERFLOW)
    if (is_constant_evaluated() ||
        (WJR_BUILTIN_CONSTANT_P(a) && WJR_BUILTIN_CONSTANT_P(b))) {
        return fallback_sub_overflow(a, b, ret);
    }

    return __builtin_sub_overflow(a, b, &ret);
#else
    return fallback_sub_overflow(a, b, ret);
#endif
}

template <typename U>
WJR_INTRINSIC_CONSTEXPR20 U __subc_1_impl(uint64_t *dst, const uint64_t *src0, size_t n,
                                          uint64_t src1, U c_in) noexcept {
    uint8_t overflow = 0;
    dst[0] = subc_cc(src0[0], src1, static_cast<uint8_t>(c_in), overflow);

    if (overflow) {
        size_t idx = 1 + replace_find_not(dst + 1, src0 + 1, n - 1, 0, UINT64_MAX);

        if (WJR_UNLIKELY(idx == n)) {
            return static_cast<U>(1);
        }

        dst[idx] = src0[idx] - 1;

        dst += idx;
        src0 += idx;
        n -= idx;
    }

    if (src0 != dst) {
        std::copy(src0 + 1, src0 + n, dst + 1);
    }

    return static_cast<U>(0);
}

/*
require :
1. n >= 1
2. WJR_IS_SAME_OR_INCR_P(dst, n, src0, n)
*/
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 U subc_1(uint64_t *dst, const uint64_t *src0, size_t n,
                                   uint64_t src1, U c_in) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src0, n));

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == 1)) {
        uint8_t overflow = 0;
        dst[0] = subc_cc(src0[0], src1, static_cast<uint8_t>(c_in), overflow);
        return static_cast<U>(overflow);
    }

    return __subc_1_impl(dst, src0, n, src1, c_in);
}

template <typename U>
WJR_INTRINSIC_CONSTEXPR U fallback_subc_n(uint64_t *dst, const uint64_t *src0,
                                          const uint64_t *src1, size_t n,
                                          U c_in) noexcept {
    size_t m = n / 4;

    for (size_t i = 0; i < m; ++i) {
        dst[0] = subc(src0[0], src1[0], c_in, c_in);
        dst[1] = subc(src0[1], src1[1], c_in, c_in);
        dst[2] = subc(src0[2], src1[2], c_in, c_in);
        dst[3] = subc(src0[3], src1[3], c_in, c_in);

        dst += 4;
        src0 += 4;
        src1 += 4;
    }

    n &= 3;
    if (WJR_UNLIKELY(n == 0)) {
        return c_in;
    }

    dst += n;
    src0 += n;
    src1 += n;

    switch (n) {
    case 3: {
        dst[-3] = subc(src0[-3], src1[-3], c_in, c_in);
        WJR_FALLTHROUGH;
    }
    case 2: {
        dst[-2] = subc(src0[-2], src1[-2], c_in, c_in);
        WJR_FALLTHROUGH;
    }
    case 1: {
        dst[-1] = subc(src0[-1], src1[-1], c_in, c_in);
        WJR_FALLTHROUGH;
    }
    default: {
        break;
    }
    }

    return c_in;
}

/*
require :
1. n >= 1
2. WJR_IS_SAME_OR_INCR_P(dst, n, src0, n)
3. WJR_IS_SAME_OR_INCR_P(dst, n, src1, n)
*/
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 U subc_n(uint64_t *dst, const uint64_t *src0,
                                   const uint64_t *src1, size_t n, U c_in) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src0, n));
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src1, n));

#if WJR_HAS_BUILTIN(ASM_SUBC_N)
    if (is_constant_evaluated()) {
        return fallback_subc_n(dst, src0, src1, n, c_in);
    }

    return asm_subc_n(dst, src0, src1, n, c_in);
#else
    return fallback_subc_n(dst, src0, src1, n, c_in);
#endif
}

/*
require :
1. m >= 1
2. n >= m
3. WJR_IS_SAME_OR_INCR_P(dst, n, src0, n)
4. WJR_IS_SAME_OR_INCR_P(dst, m, src1, m)
*/
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 U subc_s(uint64_t *dst, const uint64_t *src0, size_t n,
                                   const uint64_t *src1, size_t m, U c_in) noexcept {
    WJR_ASSERT_ASSUME(m >= 1);
    WJR_ASSERT_ASSUME(n >= m);

    c_in = subc_n(dst, src0, src1, m, c_in);

    if (n != m) {
        c_in = subc_1(dst + m, src0 + m, n - m, 0, c_in);
    }

    return c_in;
}

/*
require :
1. n >= 0
2. n >= m
3. WJR_IS_SAME_OR_INCR_P(dst, n, src0, n)
4. WJR_IS_SAME_OR_INCR_P(dst, m, src1, m)
*/
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 U subc_sz(uint64_t *dst, const uint64_t *src0, size_t n,
                                    const uint64_t *src1, size_t m, U c_in) noexcept {
    WJR_ASSERT_ASSUME(n >= m);

    if (WJR_LIKELY(m != 0)) {
        c_in = subc_n(dst, src0, src1, m, c_in);
    }

    if (n != m) {
        c_in = subc_1(dst + m, src0 + m, n - m, 0, c_in);
    }

    return c_in;
}

WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_n(uint64_t *dst, const uint64_t *src0,
                                             const uint64_t *src1, size_t n) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_SEPARATE_P(dst, n, src0, n));
    WJR_ASSERT_L2(WJR_IS_SAME_OR_SEPARATE_P(dst, n, src1, n));

    size_t idx = reverse_find_not_n(src0, src1, n);

    if (WJR_UNLIKELY(idx != n)) {
        set_n(dst + idx, 0, n - idx);

        if (WJR_UNLIKELY(idx == 0)) {
            return 0;
        }
    }

    WJR_ASSUME(idx >= 1);

    uint64_t hi = 0;
    WJR_ASSUME(src0[idx - 1] != src1[idx - 1]);
    const bool overflow = sub_overflow(src0[idx - 1], src1[idx - 1], hi);

    if (overflow) {
        std::swap(src0, src1);
        hi = -hi;
    }

    do {
        if (WJR_UNLIKELY(idx == 1)) {
            dst[0] = hi;
            break;
        }

        hi -= subc_n(dst, src0, src1, idx - 1);
        dst[idx - 1] = hi;
    } while (0);

    return overflow ? -1 : 1;
}

WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_n_pos(uint64_t *dst, const uint64_t *src0,
                                                 const uint64_t *src1,
                                                 size_t n) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_SEPARATE_P(dst, n, src0, n));
    WJR_ASSERT_L2(WJR_IS_SAME_OR_SEPARATE_P(dst, n, src1, n));

    size_t idx = reverse_find_not_n(src0, src1, n);

    if (WJR_UNLIKELY(idx != n)) {
        set_n(dst + idx, 0, n - idx);

        if (WJR_UNLIKELY(idx == 0)) {
            return 0;
        }
    }

    WJR_ASSUME(idx >= 1);

    uint64_t hi = 0;
    WJR_ASSUME(src0[idx - 1] != src1[idx - 1]);
    const bool overflow = sub_overflow(src0[idx - 1], src1[idx - 1], hi);

    if (overflow) {
        std::swap(src0, src1);
        hi = -hi;
    }

    ssize_t ret = __fasts_from_unsigned(idx);
    WJR_ASSUME(ret >= 1);

    do {
        if (WJR_UNLIKELY(idx == 1)) {
            dst[0] = hi;
            break;
        }

        WJR_ASSUME(ret >= 2);

        hi -= subc_n(dst, src0, src1, idx - 1);

        if (WJR_LIKELY(hi != 0)) {
            dst[idx - 1] = hi;
        } else {
            --ret;
        }
    } while (0);

    WJR_ASSUME(ret > 0);
    return overflow ? -ret : ret;
}

WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_s1(uint64_t *dst, const uint64_t *src0,
                                              size_t n, const uint64_t *src1,
                                              size_t m) noexcept {
    WJR_ASSERT_ASSUME(m >= 1);
    WJR_ASSERT_ASSUME(n >= m);

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == m)) {
        return abs_subc_n(dst, src0, src1, m);
    }

    WJR_ASSERT(n - m <= 1);

    do {
        if (n == m) {
            break;
        }

        if (WJR_UNLIKELY(src0[m] == 0)) {
            dst[m] = 0;
            break;
        }

        uint64_t hi = src0[m];
        hi -= subc_n(dst, src0, src1, m);
        dst[m] = hi;
        return 1;
    } while (0);

    return abs_subc_n(dst, src0, src1, m);
}

WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_s(uint64_t *dst, const uint64_t *src0,
                                             size_t n, const uint64_t *src1,
                                             size_t m) noexcept {
    WJR_ASSERT_ASSUME(m >= 1);
    WJR_ASSERT_ASSUME(n >= m);

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == m)) {
        return abs_subc_n(dst, src0, src1, m);
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n - m <= 1)) {
        return abs_subc_s1(dst, src0, n, src1, m);
    }

    size_t idx = reverse_replace_find_not(dst + m, src0 + m, n - m, 0, 0);

    if (WJR_UNLIKELY(idx == 0)) {
        return abs_subc_n(dst, src0, src1, m);
    }

    (void)subc_s(dst, src0, m + idx, src1, m);
    return 1;
}

WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_s_pos(uint64_t *dst, const uint64_t *src0,
                                                 size_t n, const uint64_t *src1,
                                                 size_t m) noexcept {
    WJR_ASSERT_ASSUME(m >= 1);
    WJR_ASSERT_ASSUME(n >= m);

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == m)) {
        return abs_subc_n_pos(dst, src0, src1, m);
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n - m <= 1)) {
        do {
            if (n == m) {
                break;
            }

            if (WJR_UNLIKELY(src0[m] == 0)) {
                dst[m] = 0;
                break;
            }

            uint64_t hi = src0[m];
            hi -= subc_n(dst, src0, src1, m);
            ssize_t ret = __fasts_from_unsigned(m + 1);

            if (WJR_LIKELY(hi != 0)) {
                dst[m] = hi;
            } else {
                --ret;
            }

            WJR_ASSUME(ret > 0);
            return ret;
        } while (0);

        return abs_subc_n_pos(dst, src0, src1, m);
    }

    size_t idx = reverse_replace_find_not(dst + m, src0 + m, n - m, 0, 0);

    if (WJR_UNLIKELY(idx == 0)) {
        return abs_subc_n_pos(dst, src0, src1, m);
    }

    (void)subc_s(dst, src0, m + idx, src1, m);
    ssize_t ret = __fasts_from_unsigned(m + idx);
    WJR_ASSUME(ret >= 2);
    ret -= dst[m + idx - 1] == 0;
    WJR_ASSUME(ret >= 1);
    return ret;
}

// just like abs_subc_n.
template <typename U, WJR_REQUIRES_I(is_unsigned_integral_v<U>)>
WJR_INTRINSIC_CONSTEXPR20 ssize_t abs_subc_n(uint64_t *dst, const uint64_t *src0,
                                             const uint64_t *src1, size_t n, U &c_out,
                                             type_identity_t<U> cf0,
                                             type_identity_t<U> cf1) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    if (cf0 != cf1) {
        ssize_t ret = __fasts_from_unsigned(n);
        U cf = 0;
        if (cf0 < cf1) {
            std::swap(src0, src1);
            ret = __fasts_negate(ret);
            cf = cf1 - cf0;
        } else {
            cf = cf0 - cf1;
        }

        c_out = cf - subc_n(dst, src0, src1, n);
        return ret;
    } else {
        c_out = 0;
        return abs_subc_n(dst, src0, src1, n);
    }
}

WJR_INTRINSIC_CONSTEXPR void __fallback_sub_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                                uint64_t hi0, uint64_t lo1,
                                                uint64_t hi1) noexcept {
    uint64_t __al = lo0 - lo1;
    ah = hi0 - hi1 - (__al > lo0);
    al = __al;
}

#if WJR_HAS_FEATURE(FAST_INT128_ADDSUB)
#define WJR_HAS_BUILTIN___BUILTIN_SUB_128 WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(__BUILTIN_SUBC_128)

WJR_INTRINSIC_INLINE void __builtin_sub_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                            uint64_t hi0, uint64_t lo1,
                                            uint64_t hi1) noexcept {
    const auto x0 = static_cast<__uint128_t>(hi0) << 64 | lo0;
    const auto x1 = static_cast<__uint128_t>(hi1) << 64 | lo1;
    x0 -= x1;

    al = x0;
    ah = x0 >> 64;
}

#endif

// <ah, al> = <hi0, lo0> - <hi1, lo1>
WJR_INTRINSIC_CONSTEXPR20 void __sub_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                         uint64_t hi0, uint64_t lo1,
                                         uint64_t hi1) noexcept {
#if WJR_HAS_BUILTIN(__BUILTIN_SUB_128) || WJR_HAS_BUILTIN(__ASM_SUB_128)
    if (is_constant_evaluated() || WJR_BUILTIN_CONSTANT_P_TRUE(lo0 == 0) ||
        WJR_BUILTIN_CONSTANT_P_TRUE(lo1 == 0) || WJR_BUILTIN_CONSTANT_P(lo0 + hi0)) {
        return __fallback_sub_128(al, ah, lo0, hi0, lo1, hi1);
    }

    return WJR_PP_BOOL_IF(WJR_HAS_BUILTIN(__BUILTIN_SUB_128), __builtin_sub_128,
                          __asm_sub_128)(al, ah, lo0, hi0, lo1, hi1);
#else
    return __fallback_sub_128(al, ah, lo0, hi0, lo1, hi1);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t __fallback_subc_128(uint64_t &al, uint64_t &ah,
                                                       uint64_t lo0, uint64_t hi0,
                                                       uint64_t lo1, uint64_t hi1,
                                                       uint64_t c_in) noexcept {
    al = subc(lo0, lo1, c_in, c_in);
    ah = subc(hi0, hi1, c_in, c_in);
    return c_in;
}

// return c_out
WJR_INTRINSIC_CONSTEXPR20 uint64_t __subc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                              uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                              uint64_t c_in) noexcept {
#if WJR_HAS_BUILTIN(__ASM_SUBC_128)
    if (is_constant_evaluated()) {
        return __fallback_subc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
    }

    return __asm_subc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
#else
    return __fallback_subc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 uint8_t __subc_cc_128(uint64_t &al, uint64_t &ah, uint64_t lo0,
                                                uint64_t hi0, uint64_t lo1, uint64_t hi1,
                                                uint8_t c_in) noexcept {
#if WJR_HAS_BUILTIN(__ASM_SUBC_CC_128)
    if (is_constant_evaluated()) {
        return __fallback_subc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
    }

    return __asm_subc_cc_128(al, ah, lo0, hi0, lo1, hi1, c_in);
#else
    return fast_cast<uint8_t>(__subc_128(al, ah, lo0, hi0, lo1, hi1, c_in));
#endif
}

} // namespace wjr

#endif // WJR_MATH_SUB_HPP__
#ifndef WJR_MEMORY_SAFE_POINTER_HPP__
#define WJR_MEMORY_SAFE_POINTER_HPP__

#ifndef WJR_SPAN_HPP__
#define WJR_SPAN_HPP__

#include <stdexcept>

// Already included
// Already included

namespace wjr {

/**
 * @brief A type representing a static-sized span.
 *
 * @tparam Extent The number of elements in the span.
 */
template <typename T, size_t Extent>
struct __span_static_storage {

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(__span_static_storage);

    __span_static_storage(T *p, WJR_MAYBE_UNUSED size_t s) noexcept : ptr(p) {
        WJR_ASSERT_L2(s == size);
    }

    T *ptr = nullptr;
    static constexpr size_t size = Extent;
};

/**
 * @brief A type representing a dynamic-sized span.
 */
template <typename T>
struct __span_dynamic_storage {

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(__span_dynamic_storage);

    __span_dynamic_storage(T *p, size_t s) noexcept : ptr(p), size(s) {}

    T *ptr = nullptr;
    size_t size = 0;
};

template <typename Iter, typename Elem>
struct __is_span_iterator
    : std::conjunction<is_contiguous_iterator<Iter>,
                       std::is_convertible<iterator_contiguous_pointer_t<Iter>, Elem *>> {
};

template <typename T, size_t Extent = dynamic_extent>
class span;

namespace span_detail {

WJR_REGISTER_HAS_TYPE(data,
                      std::data(std::declval<std::add_lvalue_reference_t<Container>>()),
                      Container);
WJR_REGISTER_HAS_TYPE(size,
                      std::size(std::declval<std::add_lvalue_reference_t<Container>>()),
                      Container);

/// @private
template <typename T>
struct __is_std_array : std::false_type {};

/// @private
template <typename T, size_t N>
struct __is_std_array<std::array<T, N>> : std::true_type {};

/// @private
template <typename T>
inline constexpr bool __is_std_array_v = __is_std_array<T>::value;

template <typename T>
struct __is_span : std::false_type {};

template <typename T, size_t Extent>
struct __is_span<span<T, Extent>> : std::true_type {};

template <typename T>
inline constexpr bool __is_span_v = __is_span<T>::value;

/// @private
template <typename Container, typename = void>
struct __is_container_like : std::false_type {};

/// @private
template <typename Container>
struct __is_container_like<
    Container, std::enable_if_t<has_data_v<Container> && has_size_v<Container>>>
    : std::conjunction<
          std::negation<std::is_array<remove_cvref_t<Container>>>,
          std::negation<__is_std_array<remove_cvref_t<Container>>>,
          std::negation<__is_span<remove_cvref_t<Container>>>,
          std::is_pointer<decltype(std::data(std::declval<Container &>()))>> {};

/// @private
template <typename Container>
inline constexpr bool __is_container_like_v = __is_container_like<Container>::value;

template <typename Container, typename Elem, typename = void>
struct __is_span_like : std::false_type {};

template <typename Container, typename Elem>
struct __is_span_like<Container, Elem,
                      std::enable_if_t<has_data_v<Container> && has_size_v<Container>>>
    : std::conjunction<
          __is_container_like<Container>,
          std::is_convertible<decltype(std::data(std::declval<Container &>())), Elem *>> {
};

template <typename Container, typename Elem>
inline constexpr bool __is_span_like_v = __is_span_like<Container, Elem>::value;

/// @private
template <typename T>
struct basic_span_traits {
    using value_type = std::remove_cv_t<T>;
    using difference_type = ptrdiff_t;
    using pointer = T *;
    using const_pointer = const T *;
    using reference = T &;
    using const_reference = const T &;
};

} // namespace span_detail

/**
 * @class span
 *
 * @brief A view over a contiguous sequence of objectsd.
 *
 * @tparam Extent if Extent is `dynamic_extent`, the span is a runtime-sized view.
 * Otherwise, the span is a compile-time-sized view.
 */
template <typename T, size_t Extent>
class span {
    static constexpr bool __is_dynamic = Extent == dynamic_extent;
    using __storage = std::conditional_t<__is_dynamic, __span_dynamic_storage<T>,
                                         __span_static_storage<T, Extent>>;

    using IteratorTraits = span_detail::basic_span_traits<T>;

public:
    using element_type = T;
    using value_type = std::remove_cv_t<T>;
    using size_type = size_t;
    using difference_type = ptrdiff_t;
    using pointer = T *;
    using const_pointer = const T *;
    using reference = T &;
    using const_reference = const T &;
    using iterator = contiguous_iterator_adapter<span, IteratorTraits>;
    using const_iterator = contiguous_const_iterator_adapter<span, IteratorTraits>;
    using reverse_iterator = std::reverse_iterator<iterator>;
    using const_reverse_iterator = std::reverse_iterator<const_iterator>;

    template <size_t Ex = Extent, WJR_REQUIRES(Ex == dynamic_extent || Ex == 0)>
    constexpr span() noexcept : storage() {}

#if defined(__cpp_conditional_explicit)
    template <typename It, WJR_REQUIRES(__is_span_iterator<It, element_type>::value)>
    constexpr explicit(!__is_dynamic) span(It first, size_type count) noexcept
        : storage(wjr::to_address(first), count) {}
#else
    template <typename It,
              WJR_REQUIRES(__is_span_iterator<It, element_type>::value &&__is_dynamic)>
    constexpr span(It first, size_type count) noexcept
        : storage(wjr::to_address(first), count) {}

    template <typename It,
              WJR_REQUIRES(__is_span_iterator<It, element_type>::value && !__is_dynamic)>
    constexpr explicit span(It first, size_type count) noexcept
        : storage(wjr::to_address(first), count) {}
#endif

#if defined(__cpp_conditional_explicit)
    template <typename It, WJR_REQUIRES(__is_span_iterator<It, element_type>::value)>
    constexpr explicit(!__is_dynamic) span(It first, It last) noexcept
        : storage(wjr::to_address(first), static_cast<size_type>(last - first)) {}
#else
    template <typename It,
              WJR_REQUIRES(__is_span_iterator<It, element_type>::value &&__is_dynamic)>
    constexpr span(It first, It last) noexcept
        : storage(wjr::to_address(first), static_cast<size_type>(last - first)) {}

    template <typename It,
              WJR_REQUIRES(__is_span_iterator<It, element_type>::value && !__is_dynamic)>
    constexpr explicit span(It first, It last) noexcept
        : storage(wjr::to_address(first), static_cast<size_type>(last - first)) {}
#endif

    template <size_t N, WJR_REQUIRES((__is_dynamic || N == Extent))>
    constexpr span(type_identity_t<element_type> (&arr)[N]) noexcept
        : storage(std::data(arr), N) {}

    template <typename U, size_t N,
              WJR_REQUIRES((__is_dynamic || N == Extent) &&
                           std::is_convertible_v<U *, T *>)>
    constexpr span(std::array<U, N> &arr) noexcept
        : storage(std::data(arr), std::size(arr)) {}

    template <typename U, size_t N,
              WJR_REQUIRES((__is_dynamic || N == Extent) &&
                           std::is_convertible_v<const U *, T *>)>
    constexpr span(const std::array<U, N> &arr) noexcept
        : storage(std::data(arr), std::size(arr)) {}

#if defined(__cpp_conditional_explicit)
    template <typename U, size_t N,
              WJR_REQUIRES((__is_dynamic || N == dynamic_extent || N == Extent) &&
                           std::is_convertible_v<U *, T *>)>
    constexpr explicit(!__is_dynamic) span(const span<U, N> &source) noexcept
        : storage(source.data(), source.size()) {}
#else
    template <typename U, size_t N,
              WJR_REQUIRES((__is_dynamic || N == dynamic_extent || N == Extent) &&
                           std::is_convertible_v<U *, T *> && __is_dynamic)>
    constexpr span(const span<U, N> &source) noexcept
        : storage(source.data(), source.size()) {}

    template <typename U, size_t N,
              WJR_REQUIRES((__is_dynamic || N == dynamic_extent || N == Extent) &&
                           std::is_convertible_v<U *, T *> && !__is_dynamic)>
    constexpr explicit span(const span<U, N> &source) noexcept
        : storage(source.data(), source.size()) {}
#endif

    span(const span &) = default;
    span(span &&) = default;
    span &operator=(const span &) = default;
    span &operator=(span &&) = default;
    ~span() = default;

    WJR_PURE WJR_CONSTEXPR20 pointer begin_unsafe() noexcept { return data(); }
    WJR_PURE WJR_CONSTEXPR20 const_pointer begin_unsafe() const noexcept {
        return data();
    }
    WJR_PURE WJR_CONSTEXPR20 const_pointer cbegin_unsafe() const noexcept {
        return data();
    }

    WJR_PURE WJR_CONSTEXPR20 pointer end_unsafe() noexcept { return data() + size(); }
    WJR_PURE WJR_CONSTEXPR20 const_pointer end_unsafe() const noexcept {
        return data() + size();
    }
    WJR_PURE WJR_CONSTEXPR20 const_pointer cend_unsafe() const noexcept {
        return end_unsafe();
    }

private:
    WJR_PURE WJR_CONSTEXPR20 iterator __make_iterator(const_pointer ptr) const noexcept {
        return iterator(const_cast<pointer>(ptr), this);
    }

    WJR_PURE WJR_CONSTEXPR20 pointer __get_pointer(iterator ptr) const noexcept {
        ptr.check_same_container(this);
        return wjr::to_address(ptr);
    }

    WJR_PURE WJR_CONSTEXPR20 pointer __get_pointer(const_iterator ptr) const noexcept {
        ptr.check_same_container(this);
        return const_cast<pointer>(wjr::to_address(ptr));
    }

public:
    constexpr iterator begin() noexcept { return __make_iterator(begin_unsafe()); }
    constexpr const_iterator begin() const noexcept {
        return __make_iterator(begin_unsafe());
    }
    constexpr const_iterator cbegin() const noexcept {
        return __make_iterator(begin_unsafe());
    }

    constexpr iterator end() noexcept { return __make_iterator(end_unsafe()); }
    constexpr const_iterator end() const noexcept {
        return __make_iterator(end_unsafe());
    }
    constexpr const_iterator cend() const noexcept {
        return __make_iterator(end_unsafe());
    }

    constexpr reverse_iterator rbegin() noexcept {
        return std::make_reverse_iterator(end());
    }
    constexpr reverse_iterator rbegin() const noexcept {
        return std::make_reverse_iterator(end());
    }
    constexpr const_reverse_iterator crbegin() const noexcept {
        return std::make_reverse_iterator(cend());
    }

    constexpr reverse_iterator rend() noexcept {
        return std::make_reverse_iterator(begin());
    }
    constexpr reverse_iterator rend() const noexcept {
        return std::make_reverse_iterator(begin());
    }
    constexpr const_reverse_iterator crend() const noexcept {
        return std::make_reverse_iterator(cbegin());
    }

    constexpr reference front() const noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(size() > 0, "basic_vector::front: empty");
#endif
        return *data();
    }
    constexpr reference back() const noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(size() > 0, "basic_vector::front: empty");
#endif
        return *(end_unsafe() - 1);
    }

    constexpr reference at(size_type pos) const noexcept {
        if (WJR_UNLIKELY(pos >= size())) {
            WJR_THROW(std::out_of_range("span at out of range"));
        }

        return data()[pos];
    }

    constexpr reference operator[](size_type pos) const noexcept {
#if WJR_HAS_DEBUG(CONTIGUOUS_ITERATOR_CHECKER)
        WJR_ASSERT_L0(pos < size(), "basic_vector::operator[]: out of range");
#endif
        return data()[pos];
    }

    WJR_PURE constexpr pointer data() const noexcept { return storage.ptr; }
    
    WJR_PURE constexpr size_type size() const noexcept { return storage.size; }

    WJR_PURE constexpr size_type size_bytes() const noexcept {
        return size() * sizeof(element_type);
    }

    WJR_PURE constexpr bool empty() const noexcept { return size() == 0; }

    template <size_t Count>
    constexpr span<element_type, Count> first() const noexcept {
        static_assert(Count <= Extent, "");

        return {begin(), Count};
    }

    constexpr span<element_type, dynamic_extent> first(size_type Count) const noexcept {
        WJR_ASSERT_L2(Count <= size());

        return {begin(), Count};
    }

    template <size_t Count>
    constexpr span<element_type, Count> last() const noexcept {
        static_assert(Count <= Extent, "");

        return {end() - Count, Count};
    }

    constexpr span<element_type, dynamic_extent> last(size_type Count) const noexcept {
        WJR_ASSERT_L2(Count <= size());

        return {data() - Count, Count};
    }

    template <size_t Offset, size_t Count = dynamic_extent>
    constexpr span<element_type, Count != dynamic_extent    ? Count
                                 : Extent != dynamic_extent ? Extent - Offset
                                                            : dynamic_extent>
    subspan() const noexcept {
        if constexpr (Extent != dynamic_extent) {
            static_assert(Offset <= Extent, "");
            static_assert(Count == dynamic_extent || Count <= Extent - Offset, "");
        } else {
            WJR_ASSERT_L2(Offset <= size());
            if constexpr (Count != dynamic_extent) {
                WJR_ASSERT_L2(Count <= size() - Offset);
            }
        }
        return {begin() + Offset, Count == dynamic_extent ? size() - Offset : Count};
    }

    constexpr span<element_type, dynamic_extent>
    subspan(size_type Offset, size_type Count = dynamic_extent) const noexcept {
        WJR_ASSERT_L2(Offset <= size());

        return {begin() + Offset, Count == dynamic_extent ? size() - Offset : Count};
    }

    // extension :

    /**
     * @brief Construct a span from a container.
     *
     * @details The container must have a `data()` member function that returns a @ref
     * __is_span_iterator. The container must also have a `size()` member function that
     * can be converted to `size_type`.
     *
     */
    template <typename Container, WJR_REQUIRES(span_detail::__is_span_like_v<
                                               Container, element_type> &&__is_dynamic)>
    constexpr span(Container &&c) noexcept : storage(std::data(c), std::size(c)) {}

    /**
     * @brief Construct a span from a container.
     *
     * @details Like @ref span(Container &&), but the span is not dynamic-sized, so the
     * construct must be explicit.
     *
     */
    template <typename Container,
              WJR_REQUIRES(span_detail::__is_span_like_v<Container, element_type> &&
                           !__is_dynamic)>
    constexpr explicit span(Container &&c) noexcept
        : storage(std::data(c), std::size(c)) {}

private:
    __storage storage;
};

template <typename T, size_t Extent>
span(T (&)[Extent]) -> span<T, Extent>;

template <typename T, size_t Size>
span(std::array<T, Size> &) -> span<T, Size>;

template <typename T, size_t Size>
span(const std::array<T, Size> &) -> span<const T, Size>;

template <typename It, typename End, WJR_REQUIRES(is_contiguous_iterator_v<It>)>
span(It, End) -> span<iterator_contiguous_value_t<It>>;

template <typename Container, WJR_REQUIRES(span_detail::__is_container_like_v<Container>)>
span(Container &&) -> span<
    iterator_contiguous_value_t<decltype(std::data(std::declval<Container &>()))>>;

} // namespace wjr

#endif // WJR_SPAN_HPP__

namespace wjr {

#if WJR_DEBUG_LEVEL > 2
#define WJR_HAS_DEBUG_SAFE_POINTER WJR_HAS_DEF
#endif

#if WJR_HAS_DEBUG(SAFE_POINTER)

template <typename T>
class safe_pointer {
public:
    using element_type = T;
    using value_type = std::remove_cv_t<T>;
    using pointer = T *;
    using reference = T &;
    using difference_type = ptrdiff_t;
    using size_type = size_t;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(safe_pointer);

    constexpr safe_pointer &reset_range() noexcept {
        m_length -= m_offset;
        m_offset = 0;
        return *this;
    }

    constexpr pointer get() const noexcept { return m_ptr; }
    constexpr pointer data() const noexcept { return m_ptr; }
    constexpr reference operator[](size_type i) const noexcept { return m_ptr[i]; }

    constexpr safe_pointer(span<T> s) noexcept
        : m_ptr(s.data()), m_offset(0), m_size(s.size()), m_length(s.size()) {}

    constexpr safe_pointer first(size_type count) const noexcept {
        WJR_ASSERT_L3(m_ptr != nullptr, "safe_pointer: nullptr");
        WJR_ASSERT_L3(count <= m_size, "safe_pointer: out of range");
        return {m_ptr, m_offset, count, m_length};
    }

    constexpr safe_pointer subspan(size_type offset, size_type count) const noexcept {
        WJR_ASSERT_L3(m_ptr != nullptr, "safe_pointer: nullptr");
        WJR_ASSERT_L3(offset + count <= m_size, "safe_pointer: out of range");
        return {m_ptr + offset, m_offset + offset, count, m_length};
    }

    constexpr safe_pointer &append(size_type length) noexcept {
        WJR_ASSERT_L3(m_offset + m_size + length <= m_length);
        m_size += length;
        return *this;
    }

    constexpr safe_pointer &operator=(span<T> s) noexcept {
        m_ptr = s.data();
        m_offset = 0;
        m_size = s.size();
        m_length = s.size();
        return *this;
    }

    constexpr safe_pointer &operator=(std::nullptr_t) noexcept {
        m_ptr = nullptr;
        m_offset = 0;
        m_size = 0;
        m_length = 0;
        return *this;
    }

    constexpr safe_pointer &operator+=(size_type n) noexcept {
        WJR_ASSERT_L3(m_ptr != nullptr, "safe_pointer: nullptr");
        WJR_ASSERT_L3(n <= m_size, "safe_pointer: out of range");
        m_ptr += n;
        m_offset += n;
        m_size -= n;
        return *this;
    }

    constexpr friend safe_pointer operator+(safe_pointer lhs, size_type rhs) noexcept {
        return lhs += rhs;
    }

    constexpr friend safe_pointer operator+(size_type lhs, safe_pointer rhs) noexcept {
        return rhs += lhs;
    }

    constexpr safe_pointer &operator++() noexcept {
        (*this) += 1;
        return *this;
    }

    constexpr safe_pointer operator++(int) noexcept {
        safe_pointer tmp = *this;
        ++*this;
        return tmp;
    }

    constexpr safe_pointer &operator-=(size_type n) noexcept {
        WJR_ASSERT_L3(m_ptr != nullptr, "safe_pointer: nullptr");
        WJR_ASSERT_L3(m_offset >= n, "safe_pointer: out of range");
        m_ptr -= n;
        m_offset -= n;
        m_size += n;
        return *this;
    }

    constexpr friend safe_pointer operator-(safe_pointer lhs, size_type rhs) noexcept {
        return lhs -= rhs;
    }

    constexpr friend ptrdiff_t operator-(const safe_pointer &lhs,
                                         const safe_pointer &rhs) noexcept {
        return lhs.m_ptr - rhs.m_ptr;
    }

    constexpr safe_pointer &operator--() noexcept {
        (*this) -= 1;
        return *this;
    }

    constexpr safe_pointer operator--(int) noexcept {
        safe_pointer tmp = *this;
        --*this;
        return tmp;
    }

private:
    constexpr safe_pointer(pointer ptr, size_type offset, size_type size,
                           size_type length) noexcept
        : m_ptr(ptr), m_offset(offset), m_size(size), m_length(length) {}

    pointer m_ptr = nullptr;
    size_type m_offset;
    size_type m_size;
    size_type m_length;
};

#else

template <typename T>
class safe_pointer {
public:
    using element_type = T;
    using value_type = std::remove_cv_t<T>;
    using pointer = T *;
    using reference = T &;
    using difference_type = ptrdiff_t;
    using size_type = size_t;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(safe_pointer);

    constexpr safe_pointer &reset_range() noexcept { return *this; }

    constexpr pointer get() const noexcept { return m_ptr; }
    constexpr pointer data() const noexcept { return m_ptr; }
    constexpr reference operator[](size_type i) const noexcept { return m_ptr[i]; }

    constexpr safe_pointer(span<T> s) noexcept : m_ptr(s.data()) {}

    constexpr safe_pointer first(WJR_MAYBE_UNUSED size_type count) const noexcept {
        return safe_pointer{m_ptr};
    }

    constexpr safe_pointer subspan(size_type offset,
                                   WJR_MAYBE_UNUSED size_type count) const noexcept {
        return safe_pointer{m_ptr + offset};
    }

    constexpr safe_pointer &operator=(span<T> s) noexcept {
        m_ptr = s.data();
        return *this;
    }

    constexpr safe_pointer &operator=(std::nullptr_t) noexcept {
        m_ptr = nullptr;
        return *this;
    }

    constexpr safe_pointer &operator+=(size_type n) noexcept {
        m_ptr += n;
        return *this;
    }

    constexpr friend safe_pointer operator+(safe_pointer lhs, size_type rhs) noexcept {
        return lhs += rhs;
    }

    constexpr friend safe_pointer operator+(size_type lhs, safe_pointer rhs) noexcept {
        return rhs += lhs;
    }

    constexpr safe_pointer &operator-=(size_type n) noexcept {
        m_ptr -= n;
        return *this;
    }

    constexpr friend safe_pointer operator-(safe_pointer lhs, size_type rhs) noexcept {
        return lhs -= rhs;
    }

    constexpr friend ptrdiff_t operator-(const safe_pointer &lhs,
                                         const safe_pointer &rhs) noexcept {
        return lhs.m_ptr - rhs.m_ptr;
    }

private:
    T *m_ptr;
};

#endif

} // namespace wjr

#endif // WJR_MEMORY_SAFE_POINTER_HPP__

#if defined(WJR_MSVC) && defined(WJR_X86)
#define WJR_HAS_BUILTIN_MSVC_MULH64 WJR_HAS_DEF
#endif

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_MUL_HPP__
#define WJR_X86_MATH_MUL_HPP__

// Already included
#ifndef WJR_X86_MATH_MUL_IMPL_HPP__
#define WJR_X86_MATH_MUL_IMPL_HPP__

// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

namespace wjr {

#define WJR_HAS_BUILTIN_UMUL128 WJR_HAS_DEF

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_UMUL128 WJR_HAS_DEF
#elif WJR_HAS_FEATURE(INT128)
#define WJR_HAS_BUILTIN_INT128_UMUL128 WJR_HAS_DEF
#elif defined(WJR_MSVC)
#define WJR_HAS_BUILTIN_MSVC_UMUL128 WJR_HAS_DEF
#else
#undef WJR_HAS_BUILTIN_UMUL128
#endif

#if defined(__BMI2__)
#define WJR_HAS_BUILTIN_MULX_U64 WJR_HAS_DEF
#endif

#if defined(__BMI2__)

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_MUL_1 WJR_HAS_DEF
#elif defined(WJR_ENABLE_ASSEMBLY)
#define WJR_HAS_BUILTIN_ASM_MUL_1 WJR_HAS_DEF_VAR(3)
#endif

#endif

#if defined(__BMI2__) && defined(__ADX__)

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_ADDMUL_1 WJR_HAS_DEF
#elif defined(WJR_ENABLE_ASSEMBLY)
#define WJR_HAS_BUILTIN_ASM_ADDMUL_1 WJR_HAS_DEF_VAR(3)
#endif

#endif

#if defined(__BMI2__) && defined(__ADX__)

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_SUBMUL_1 WJR_HAS_DEF
#elif defined(WJR_ENABLE_ASSEMBLY)
#define WJR_HAS_BUILTIN_ASM_SUBMUL_1 WJR_HAS_DEF_VAR(3)
#endif

#endif

#if defined(__BMI2__)

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_ADDLSH_N WJR_HAS_DEF
#define WJR_HAS_BUILTIN_ASM_RSBLSH_N WJR_HAS_DEF
#elif defined(WJR_ENABLE_ASSEMBLY)
#define WJR_HAS_BUILTIN_ASM_ADDLSH_N WJR_HAS_DEF_VAR(3)
#define WJR_HAS_BUILTIN_ASM_RSBLSH_N WJR_HAS_DEF_VAR(3)
#endif

#endif

#if defined(__BMI2__) && defined(__ADX__)

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_BASECASE_MUL_S WJR_HAS_DEF
#define WJR_HAS_BUILTIN_ASM_BASECASE_SQR WJR_HAS_DEF
#elif defined(WJR_ENABLE_ASSEMBLY)
#define WJR_HAS_BUILTIN_ASM_BASECASE_MUL_S WJR_HAS_DEF_VAR(3)
#define WJR_HAS_BUILTIN_ASM_BASECASE_SQR WJR_HAS_DEF_VAR(3)
#endif

#endif

} // namespace wjr

#endif // WJR_X86_MATH_MUL_IMPL_HPP__

#if WJR_HAS_BUILTIN(MSVC_UMUL128)
// Already included
#endif

namespace wjr {

#if WJR_HAS_BUILTIN(UMUL128)

WJR_INTRINSIC_INLINE uint64_t builtin_umul128(uint64_t a, uint64_t b,
                                              uint64_t &hi) noexcept {
#if WJR_HAS_BUILTIN(ASM_UMUL128)
    uint64_t lo;
    asm("mul{q %3| %3}\n\t" : "=a,a"(lo), "=d,d"(hi) : "%a,r"(a), "r,a"(b) : "cc");
    return lo;
#elif WJR_HAS_BUILTIN(INT128_UMUL128)
    const __uint128_t x = static_cast<__uint128_t>(a) * b;
    hi = x >> 64;
    return static_cast<uint64_t>(x);
#else
    return _umul128(a, b, &hi);
#endif
}

#endif

#if WJR_HAS_BUILTIN(ASM_MUL_1)

#if WJR_HAS_BUILTIN(ASM_MUL_1) == 1
extern uint64_t __wjr_asm_mul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                uint64_t rdx) noexcept;
#else
extern "C" WJR_MS_ABI uint64_t __wjr_asm_mul_1(uint64_t *dst, const uint64_t *src,
                                               size_t n, uint64_t rdx) noexcept;
#endif

WJR_INTRINSIC_INLINE uint64_t asm_mul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                        uint64_t rdx) noexcept {
    return __wjr_asm_mul_1(dst, src, n, rdx);
}

#endif

#if WJR_HAS_BUILTIN(ASM_ADDMUL_1)

#if WJR_HAS_BUILTIN(ASM_ADDMUL_1) == 1
extern uint64_t __wjr_asm_addmul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                   uint64_t rdx) noexcept;
#else
extern "C" WJR_MS_ABI uint64_t __wjr_asm_addmul_1(uint64_t *dst, const uint64_t *src,
                                                  size_t n, uint64_t rdx) noexcept;
#endif

WJR_INTRINSIC_INLINE uint64_t asm_addmul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                           uint64_t rdx) noexcept {
    return __wjr_asm_addmul_1(dst, src, n, rdx);
}

#endif

#if WJR_HAS_BUILTIN(ASM_SUBMUL_1)

#if WJR_HAS_BUILTIN(ASM_SUBMUL_1) == 1
// slower than asm_addmul_1
extern uint64_t __wjr_asm_submul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                   uint64_t rdx) noexcept;
#else
extern "C" WJR_MS_ABI uint64_t __wjr_asm_submul_1(uint64_t *dst, const uint64_t *src,
                                                  size_t n, uint64_t rdx) noexcept;
#endif

WJR_INTRINSIC_INLINE uint64_t asm_submul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                           uint64_t rdx) noexcept {
    return __wjr_asm_submul_1(dst, src, n, rdx);
}

#endif

#if WJR_HAS_BUILTIN(ASM_ADDLSH_N)
#define WJR_ADDSUB_I 1
// WJR_ADDSUB_I :
// 0 : SUB
// 1 : ADD

#ifndef WJR_ADDSUB_I
#error "abort"
#endif

#if WJR_ADDSUB_I == 1
#define WJR_addsub add
#define WJR_adcsbb adc
#define __WJR_TEST_ASSEMBLY ASM_ADDLSH_N
#else
#define WJR_addsub rsb
#define WJR_adcsbb sbb
#define __WJR_TEST_ASSEMBLY ASM_RSBLSH_N
#endif

#if WJR_HAS_BUILTIN(__WJR_TEST_ASSEMBLY) == 1

extern uint64_t WJR_PP_CONCAT(__wjr_asm_, WJR_PP_CONCAT(WJR_addsub, lsh_n))(
    uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n,
    uint64_t cl) noexcept;

#else

extern "C" WJR_MS_ABI uint64_t WJR_PP_CONCAT(
    __wjr_asm_, WJR_PP_CONCAT(WJR_addsub, lsh_n))(uint64_t *dst, const uint64_t *src0,
                                                  const uint64_t *src1, size_t n,
                                                  uint64_t cl) noexcept;

#endif

WJR_INTRINSIC_INLINE uint64_t WJR_PP_CONCAT(asm_, WJR_PP_CONCAT(WJR_addsub, lsh_n))(
    uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n,
    uint64_t cl) noexcept {
    return WJR_PP_CONCAT(__wjr_asm_, WJR_PP_CONCAT(WJR_addsub, lsh_n))(dst, src0, src1, n,
                                                                       cl);
}

#undef __WJR_TEST_ASSEMBLY
#undef WJR_adcsbb
#undef WJR_addsub

#undef WJR_ADDSUB_I
#endif

#if WJR_HAS_BUILTIN(ASM_RSBLSH_N)
#define WJR_ADDSUB_I 0
// WJR_ADDSUB_I :
// 0 : SUB
// 1 : ADD

#ifndef WJR_ADDSUB_I
#error "abort"
#endif

#if WJR_ADDSUB_I == 1
#define WJR_addsub add
#define WJR_adcsbb adc
#define __WJR_TEST_ASSEMBLY ASM_ADDLSH_N
#else
#define WJR_addsub rsb
#define WJR_adcsbb sbb
#define __WJR_TEST_ASSEMBLY ASM_RSBLSH_N
#endif

#if WJR_HAS_BUILTIN(__WJR_TEST_ASSEMBLY) == 1

extern uint64_t WJR_PP_CONCAT(__wjr_asm_, WJR_PP_CONCAT(WJR_addsub, lsh_n))(
    uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n,
    uint64_t cl) noexcept;

#else

extern "C" WJR_MS_ABI uint64_t WJR_PP_CONCAT(
    __wjr_asm_, WJR_PP_CONCAT(WJR_addsub, lsh_n))(uint64_t *dst, const uint64_t *src0,
                                                  const uint64_t *src1, size_t n,
                                                  uint64_t cl) noexcept;

#endif

WJR_INTRINSIC_INLINE uint64_t WJR_PP_CONCAT(asm_, WJR_PP_CONCAT(WJR_addsub, lsh_n))(
    uint64_t *dst, const uint64_t *src0, const uint64_t *src1, size_t n,
    uint64_t cl) noexcept {
    return WJR_PP_CONCAT(__wjr_asm_, WJR_PP_CONCAT(WJR_addsub, lsh_n))(dst, src0, src1, n,
                                                                       cl);
}

#undef __WJR_TEST_ASSEMBLY
#undef WJR_adcsbb
#undef WJR_addsub

#undef WJR_ADDSUB_I
#endif

#if WJR_HAS_BUILTIN(ASM_BASECASE_MUL_S)

#if WJR_HAS_BUILTIN(ASM_BASECASE_MUL_S) == 1
extern void __wjr_asm_basecase_mul_s_impl(uint64_t *dst, const uint64_t *src0, size_t rdx,
                                          const uint64_t *src1, size_t m) noexcept;
#else
extern "C" WJR_MS_ABI void __wjr_asm_basecase_mul_s_impl(uint64_t *dst,
                                                         const uint64_t *src0, size_t rdx,
                                                         const uint64_t *src1,
                                                         size_t m) noexcept;
#endif

inline void asm_basecase_mul_s(uint64_t *dst, const uint64_t *src0, size_t n,
                               const uint64_t *src1, size_t m) noexcept {
    WJR_ASSERT(n >= m);
    WJR_ASSERT(m >= 1);
    __wjr_asm_basecase_mul_s_impl(dst, src0, n, src1, m);
}

#endif

#if WJR_HAS_BUILTIN(ASM_BASECASE_SQR)

#if WJR_HAS_BUILTIN(ASM_BASECASE_SQR) == 1
extern void __wjr_asm_basecase_sqr_impl(uint64_t *dst, const uint64_t *src,
                                        size_t rdx) noexcept;
#else
extern "C" WJR_MS_ABI void __wjr_asm_basecase_sqr_impl(uint64_t *dst, const uint64_t *src,
                                                       size_t rdx) noexcept;
#endif

inline void asm_basecase_sqr(uint64_t *dst, const uint64_t *src, size_t n) noexcept {
    WJR_ASSERT(n >= 1);
    __wjr_asm_basecase_sqr_impl(dst, src, n);
}

#endif

} // namespace wjr

#endif // WJR_X86_MATH_MUL_HPP__
#endif

#if WJR_HAS_BUILTIN(MSVC_MULH64)
// Already included
#endif

namespace wjr {

template <typename T>
WJR_INTRINSIC_CONSTEXPR T fallback_mul(T a, T b, T &hi) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;
    using T2 = uint_t<nd * 2>;
    T2 x = static_cast<T2>(a) * b;
    hi = x >> nd;
    return static_cast<T>(x);
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t fallback_mul64(uint64_t a, uint64_t b,
                                                  uint64_t &hi) noexcept {
    uint64_t ah = a >> 32;
    uint64_t al = a & 0xFFFFFFFF;
    uint64_t bh = b >> 32;
    uint64_t bl = b & 0xFFFFFFFF;

    uint64_t rh = ah * bh;
    uint64_t rm0 = ah * bl;
    uint64_t rm1 = al * bh;
    uint64_t rl = al * bl;

    __add_128(rl, rh, rl, rh, rm0 << 32, rm0 >> 32);
    __add_128(rl, rh, rl, rh, rm1 << 32, rm1 >> 32);

    hi = rh;
    return rl;
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t __mul_u64(uint64_t a, uint64_t b,
                                             uint64_t &hi) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(a)) {
        if (a == 0) {
            hi = 0;
            return 0;
        }

        if (is_zero_or_single_bit(a)) {
            const auto shift = constexpr_ctz(a);
            hi = b >> (64 - shift);
            return b << shift;
        }
    }

    if (WJR_BUILTIN_CONSTANT_P(b)) {
        if (b == 0) {
            hi = 0;
            return 0;
        }

        if (is_zero_or_single_bit(b)) {
            const auto shift = constexpr_ctz(b);
            hi = a >> (64 - shift);
            return a << shift;
        }
    }

#if WJR_HAS_BUILTIN(UMUL128)
    if (is_constant_evaluated()
#if WJR_HAS_BUILTIN(ASM_UMUL128)
        || (WJR_BUILTIN_CONSTANT_P(a) && WJR_BUILTIN_CONSTANT_P(b))
#endif
    ) {
        return fallback_mul64(a, b, hi);
    }

#if WJR_HAS_BUILTIN(ASM_UMUL128)
    // mov b to rax, then mul a
    // instead of mov a to rax, mov b to register, then mul
    if (WJR_BUILTIN_CONSTANT_P(b)) {
        return builtin_umul128(b, a, hi);
    }
#endif
    return builtin_umul128(a, b, hi);
#else
    return fallback_mul64(a, b, hi);
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 T mul(T a, T b, T &hi) noexcept {
    constexpr auto nd = std::numeric_limits<T>::digits;

    if constexpr (nd < 64) {
        return fallback_mul(a, b, hi);
    } else {
        return __mul_u64(a, b, hi);
    }
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 T mulhi(T a, T b) noexcept {
#if WJR_HAS_BUILTIN(MSVC_MULH64)
    constexpr auto nd = std::numeric_limits<T>::digits;
    if constexpr (nd < 64) {
#endif
        T ret = 0;
        (void)mul(a, b, ret);
        return ret;
#if WJR_HAS_BUILTIN(MSVC_MULH64)
    } else {
        return __umulh(a, b);
    }
#endif
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_CONST WJR_INTRINSIC_CONSTEXPR T mullo(T a, T b) noexcept {
    return a * b;
}

#if WJR_HAS_BUILTIN(__builtin_mul_overflow)
#define WJR_HAS_BUILTIN_MUL_OVERFLOW WJR_HAS_DEF
#endif

template <typename T>
WJR_INTRINSIC_CONSTEXPR20 bool fallback_mul_overflow(T a, T b, T &ret) noexcept {
    T hi;
    ret = mul(a, b, hi);
    return hi != 0;
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 bool mul_overflow(type_identity_t<T> a, type_identity_t<T> b,
                                            T &ret) noexcept {
#if WJR_HAS_BUILTIN(MUL_OVERFLOW)
    if (is_constant_evaluated() ||
        (WJR_BUILTIN_CONSTANT_P(a) && WJR_BUILTIN_CONSTANT_P(b))) {
        return fallback_mul_overflow(a, b, ret);
    }

    return __builtin_mul_overflow(a, b, &ret);
#else
    return fallback_mul_overflow(a, b, ret);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t fallback_mul_1(uint64_t *dst, const uint64_t *src,
                                                  size_t n, uint64_t ml) noexcept {
    uint64_t lo = 0, hi = 0;
    uint64_t c_in = 0;

    for (size_t i = 0; i < n; ++i) {
        lo = mul(src[i], ml, hi);
        dst[i] = addc(lo, c_in, 0, c_in);
        c_in += hi;
    }

    return c_in;
}

/*
require :
1. n >= 1
2. WJR_IS_SAME_OR_INCR_P(dst, n, src, n)
*/
WJR_INTRINSIC_CONSTEXPR20 uint64_t mul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                         uint64_t ml) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src, n));

    if (WJR_BUILTIN_CONSTANT_P_TRUE(ml == 1)) {
        if (src != dst) {
            std::copy(src, src + n, dst);
        }

        return 0;
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(is_zero_or_single_bit(ml))) {
        if (ml == 0) {
            set_n(dst, 0, n);
            return 0;
        }

        const unsigned int c = ctz(ml);
        return lshift_n(dst, src, n, c);
    }

#if WJR_HAS_BUILTIN(ASM_MUL_1)
    if (is_constant_evaluated()) {
        return fallback_mul_1(dst, src, n, ml);
    }

    return asm_mul_1(dst, src, n, ml);
#else
    return fallback_mul_1(dst, src, n, ml);
#endif
}

// dst = src0 + (src1 << cl)
WJR_INTRINSIC_CONSTEXPR20 uint64_t addlsh_n(uint64_t *dst, const uint64_t *src0,
                                            const uint64_t *src1, size_t n,
                                            uint64_t cl) noexcept;

// dst = (src1 << cl) - src0
WJR_INTRINSIC_CONSTEXPR20 uint64_t rsblsh_n(uint64_t *dst, const uint64_t *src0,
                                            const uint64_t *src1, size_t n,
                                            uint64_t cl) noexcept;

WJR_INTRINSIC_CONSTEXPR20 uint64_t fallback_addmul_1(uint64_t *dst, const uint64_t *src,
                                                     size_t n, uint64_t ml) noexcept {
    uint64_t lo = 0, hi = 0;
    uint64_t o_in = 0, c_in = 0;

    for (size_t i = 0; i < n; ++i) {
        lo = mul(src[i], ml, hi);
        lo = addc(lo, c_in, 0, c_in);
        dst[i] = addc(lo, dst[i], 0, o_in);
        c_in += hi + o_in;
    }

    return c_in;
}

/*
require :
1. n >= 1
2. WJR_IS_SAME_OR_INCR_P(dst, n, src, n)
*/
WJR_INTRINSIC_CONSTEXPR20 uint64_t addmul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                            uint64_t ml) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src, n));

    if (WJR_BUILTIN_CONSTANT_P_TRUE(ml == 1)) {
        return addc_n(dst, dst, src, n);
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(is_zero_or_single_bit(ml))) {
        if (ml == 0) {
            return 0;
        }

        const unsigned int c = ctz(ml);
        return addlsh_n(dst, dst, src, n, c);
    }

#if WJR_HAS_BUILTIN(ASM_ADDMUL_1)
    if (is_constant_evaluated()) {
        return fallback_addmul_1(dst, src, n, ml);
    }

    return asm_addmul_1(dst, src, n, ml);
#else
    return fallback_addmul_1(dst, src, n, ml);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t fallback_submul_1(uint64_t *dst, const uint64_t *src,
                                                     size_t n, uint64_t ml) noexcept {
    uint64_t lo = 0, hi = 0;
    uint64_t o_in = 0, c_in = 0;

    for (size_t i = 0; i < n; ++i) {
        lo = mul(src[i], ml, hi);
        lo = addc(lo, c_in, 0, c_in);
        dst[i] = subc(dst[i], lo, 0, o_in);
        c_in += hi + o_in;
    }

    return c_in;
}

/*
require :
1. n >= 1
2. WJR_IS_SAME_OR_INCR_P(dst, n, src, n)
*/
WJR_INTRINSIC_CONSTEXPR20 uint64_t submul_1(uint64_t *dst, const uint64_t *src, size_t n,
                                            uint64_t ml) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src, n));

    if (WJR_BUILTIN_CONSTANT_P_TRUE(ml == 0)) {
        return 0;
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(ml == 1)) {
        return subc_n(dst, dst, src, n);
    }

#if WJR_HAS_BUILTIN(ASM_SUBMUL_1)
    if (is_constant_evaluated()) {
        return fallback_submul_1(dst, src, n, ml);
    }

    return asm_submul_1(dst, src, n, ml);
#else
    return fallback_submul_1(dst, src, n, ml);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t fallback_addlsh_n(uint64_t *dst, const uint64_t *src0,
                                                     const uint64_t *src1, size_t n,
                                                     uint64_t cl) noexcept {
    uint64_t tcl = std::numeric_limits<uint64_t>::digits - cl;
    uint64_t lo = 0, hi = 0;
    uint64_t c_in = 0, x = 0;

    for (size_t i = 0; i < n; ++i) {
        lo = src1[i] << cl;
        hi = src1[i] >> tcl;

        lo += x;
        dst[i] = addc(lo, src0[i], c_in, c_in);
        x = hi;
    }

    return x + c_in;
}

/*
dst = src0 + (src1 << cl);

require :
1. n >= 1
2. WJR_IS_SAME_OR_INCR_P(dst, n, src, n)
3. WJR_IS_SAME_OR_INCR_P(sdt, n, src1, n)
*/
WJR_INTRINSIC_CONSTEXPR20 uint64_t addlsh_n(uint64_t *dst, const uint64_t *src0,
                                            const uint64_t *src1, size_t n,
                                            uint64_t cl) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_ASSUME(cl < std::numeric_limits<uint64_t>::digits);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src0, n));
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src1, n));

    if (WJR_UNLIKELY(cl == 0)) {
        return addc_n(dst, src0, src1, n);
    }

#if WJR_HAS_BUILTIN(ASM_ADDLSH_N)
    if (is_constant_evaluated()) {
        return fallback_addlsh_n(dst, src0, src1, n, cl);
    }

    return asm_addlsh_n(dst, src0, src1, n, cl);
#else
    return fallback_addlsh_n(dst, src0, src1, n, cl);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t fallback_rsblsh_n(uint64_t *dst, const uint64_t *src0,
                                                     const uint64_t *src1, size_t n,
                                                     uint64_t cl) noexcept {
    uint64_t tcl = std::numeric_limits<uint64_t>::digits - cl;
    uint64_t lo = 0, hi = 0;
    uint64_t c_in = 0, x = 0;

    for (size_t i = 0; i < n; ++i) {
        lo = src1[i] << cl;
        hi = src1[i] >> tcl;

        lo += x;
        dst[i] = subc(lo, src0[i], c_in, c_in);
        x = hi;
    }

    return x - c_in;
}

/*
dst = (src1 << cl) - src0;

require :
1. n >= 1
2. WJR_IS_SAME_OR_INCR_P(dst, n, src, n)
3. WJR_IS_SAME_OR_INCR_P(sdt, n, src1, n)
*/
WJR_INTRINSIC_CONSTEXPR20 uint64_t rsblsh_n(uint64_t *dst, const uint64_t *src0,
                                            const uint64_t *src1, size_t n,
                                            uint64_t cl) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_ASSUME(cl < std::numeric_limits<uint64_t>::digits);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src0, n));
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src1, n));

    if (WJR_UNLIKELY(cl == 0)) {
        return uint64_t{0} - subc_n(dst, src1, src0, n);
    }

#if WJR_HAS_BUILTIN(ASM_RSBLSH_N)
    if (is_constant_evaluated()) {
        return fallback_rsblsh_n(dst, src0, src1, n, cl);
    }

    return asm_rsblsh_n(dst, src0, src1, n, cl);
#else
    return fallback_rsblsh_n(dst, src0, src1, n, cl);
#endif
}

template <uint64_t maxn = in_place_max>
WJR_INTRINSIC_CONSTEXPR20 uint64_t try_addmul_1(uint64_t *dst, const uint64_t *src,
                                                size_t n, uint64_t ml) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_INCR_P(dst, n, src, n));

    WJR_ASSERT_ASSUME(ml <= maxn);

    if constexpr (maxn == 0) {
        return 0;
    } else {
        if constexpr (maxn <= 3) {
            if (ml == 0) {
                return 0;
            }

            if constexpr (maxn == 1) {
                return addc_n(dst, dst, src, n);
            } else {
                if (ml == 1) {
                    return addc_n(dst, dst, src, n);
                }

                if constexpr (maxn == 2) {
                    return addlsh_n(dst, dst, src, n, 1);
                } else {
                    if (ml == 2) {
                        return addlsh_n(dst, dst, src, n, 1);
                    }

                    return addmul_1(dst, src, n, ml);
                }
            }
        } else {
            if (WJR_UNLIKELY(ml <= 2)) {
                switch (ml) {
                case 0: {
                    return 0;
                }
                case 1: {
                    return addc_n(dst, dst, src, n);
                }
                default: {
                    return addlsh_n(dst, dst, src, n, 1);
                }
                }
            }

            return addmul_1(dst, src, n, ml);
        }
    }
}

inline constexpr size_t toom22_mul_threshold = WJR_TOOM22_MUL_THRESHOLD;
inline constexpr size_t toom33_mul_threshold = WJR_TOOM33_MUL_THRESHOLD;

inline constexpr size_t toom2_sqr_threshold = WJR_TOOM2_SQR_THRESHOLD;
inline constexpr size_t toom3_sqr_threshold = WJR_TOOM3_SQR_THRESHOLD;

enum class __mul_mode : uint8_t {
    toom22 = 0x00,
    toom33 = 0x01,
    all = 0x03,
};

WJR_INTRINSIC_INLINE void mul_s(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                size_t n, const uint64_t *src1, size_t m) noexcept;

WJR_INTRINSIC_INLINE void mul_n(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                const uint64_t *src1, size_t n) noexcept;

WJR_INTRINSIC_INLINE void basecase_mul_s(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                         size_t n, const uint64_t *src1,
                                         size_t m) noexcept;

WJR_INTRINSIC_INLINE void basecase_sqr(uint64_t *WJR_RESTRICT dst, const uint64_t *src,
                                       size_t n) noexcept;

WJR_INTRINSIC_INLINE void sqr(uint64_t *WJR_RESTRICT dst, const uint64_t *src,
                              size_t n) noexcept;

struct toom_interpolation_5p_struct {
    bool neg1;
    uint64_t cf1;
    uint64_t cf2;
    uint64_t cf3;
};

struct toom_interpolation_6p_struct {
    uint8_t neg1 : 1;
    uint8_t neg3 : 1;
    uint64_t cf1;
    uint64_t cf2;
    uint64_t cf3;
    uint64_t cf4;
};

struct toom_interpolation_7p_struct {
    uint8_t neg1 : 1;
    uint8_t neg3 : 1;
    uint64_t cf1;
    uint64_t cf2;
    uint64_t cf3;
    uint64_t cf4;
    uint64_t cf5;
};

template <size_t P>
using toom_interpolation_high_p_struct = std::array<uint64_t, P - 2>;

/*
 all toom-cook need to ensure rn + rm >= l to reserve memory
 for toom-cook-u-v
 1. (v-1) * n + g <= u * m
    g = (u-1)^2 + (u-1)*v
    e.g.
    TOOM-COOK32 :
    g = 8
    n + 8 <= 3 * m
 2. v * n >= (u - 1) * m + g
    g = (v-1)^2 + (v-1)*u
    e.g.
    TOOM-COOK32 :
    g = 4
    2 * n >= 2 * m + 4 => n >= m + 2
*/

/*
 l = ceIl(n/2)
 stk usage : l * 2
*/
extern void toom22_mul_s(uint64_t *WJR_RESTRICT dst, const uint64_t *src0, size_t n,
                         const uint64_t *src1, size_t m,
                         safe_pointer<uint64_t> stk) noexcept;

extern void toom2_sqr(uint64_t *WJR_RESTRICT dst, const uint64_t *src, size_t n,
                      safe_pointer<uint64_t> stk) noexcept;

/*
 l = ceil(n/3)
 stk usage : l * 4
*/
extern void toom33_mul_s(uint64_t *WJR_RESTRICT dst, const uint64_t *src0, size_t n,
                         const uint64_t *src1, size_t m,
                         safe_pointer<uint64_t> stk) noexcept;

extern void toom3_sqr(uint64_t *WJR_RESTRICT dst, const uint64_t *src, size_t n,
                      safe_pointer<uint64_t> stk) noexcept;

WJR_CONST WJR_INTRINSIC_CONSTEXPR size_t toom22_s_itch(size_t m) noexcept {
    return m * 4 + (m / 2) + 64;
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR20 size_t toom22_n_itch(size_t n) noexcept {
    return n * 2 + bit_width(n);
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR size_t toom33_s_itch(size_t m) noexcept {
    return m * 4 + (m / 2) + 64;
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR size_t toom33_n_itch(size_t m) noexcept {
    return m * 2 + 64;
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR size_t toom44_n_itch(size_t m) noexcept {
    return m * 2 + 64;
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR size_t toom55_n_itch(size_t m) noexcept {
    return m * 3 + (m / 2) + 32;
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR bool toom44_ok(size_t n, size_t m) noexcept {
    return 3 * n + 21 <= 4 * m;
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR bool toom55_ok(size_t n, size_t m) noexcept {
    return 4 * n + 36 <= 5 * m;
}

extern void __noinline_mul_s_impl(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                  size_t n, const uint64_t *src1, size_t m) noexcept;

WJR_INTRINSIC_INLINE void mul_s(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                size_t n, const uint64_t *src1, size_t m) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == m)) {
        return mul_n(dst, src0, src1, n);
    }

    return __noinline_mul_s_impl(dst, src0, n, src1, m);
}

template <typename T>
safe_pointer<uint64_t> __mul_s_allocate(T &al, WJR_MAYBE_UNUSED size_t n) noexcept {
    if constexpr (std::is_same_v<T, safe_pointer<uint64_t>>) {
        return al;
    } else {
        return span<uint64_t>(static_cast<uint64_t *>(al.allocate(sizeof(uint64_t) * n)),
                              n);
    }
}

template <__mul_mode mode>
void __inline_mul_n_impl(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                         const uint64_t *src1, size_t n,
                         safe_pointer<uint64_t> mal) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SEPARATE_P(dst, n * 2, src0, n));
    WJR_ASSERT_L2(WJR_IS_SEPARATE_P(dst, n * 2, src1, n));

    if (n < toom22_mul_threshold) {
        return basecase_mul_s(dst, src0, n, src1, n);
    }

    if (mode <= __mul_mode::toom22 || n < toom33_mul_threshold) {
        safe_pointer<uint64_t> stk = __mul_s_allocate(mal, toom22_n_itch(n));
        return toom22_mul_s(dst, src0, n, src1, n, stk);
    }

    safe_pointer<uint64_t> stk = __mul_s_allocate(mal, toom33_n_itch(n));
    return toom33_mul_s(dst, src0, n, src1, n, stk);
}

extern void __noinline_mul_n_impl(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                  const uint64_t *src1, size_t n) noexcept;

template <__mul_mode mode>
WJR_INTRINSIC_INLINE void __mul_n(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                  const uint64_t *src1, size_t n,
                                  WJR_MAYBE_UNUSED safe_pointer<uint64_t> stk) noexcept {
    if constexpr (mode <= __mul_mode::toom33) {
        __inline_mul_n_impl<mode>(dst, src0, src1, n, stk);
    } else {
        mul_n(dst, src0, src1, n);
    }
}

template <__mul_mode mode, uint64_t m0 = in_place_max, uint64_t m1 = in_place_max>
void __mul_n(uint64_t *WJR_RESTRICT dst, const uint64_t *src0, const uint64_t *src1,
             size_t n, safe_pointer<uint64_t> stk, uint64_t &c_out, uint64_t cf0,
             uint64_t cf1) noexcept {
    WJR_ASSERT_ASSUME(cf0 <= m0);
    WJR_ASSERT_ASSUME(cf1 <= m1);

    __mul_n<mode>(dst, src0, src1, n, stk);

    if constexpr (m0 == 0 || m1 == 0) {
        c_out = 0;
    } else if constexpr (m0 == 1 || m1 == 1) {
        if constexpr (m0 == 1 && m1 == 1) {
            c_out = cf0 && cf1;
        } else if constexpr (m0 == 1) {
            c_out = cf0 ? cf1 : 0;
        } else {
            c_out = cf1 ? cf0 : 0;
        }
    } else {
        c_out = cf0 * cf1;
    }

    c_out += try_addmul_1<m0>(dst + n, src1, n, cf0);
    c_out += try_addmul_1<m1>(dst + n, src0, n, cf1);
}

WJR_INTRINSIC_INLINE void mul_n(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                const uint64_t *src1, size_t n) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(src0 == src1)) {
        return sqr(dst, src0, n);
    }

    return __noinline_mul_n_impl(dst, src0, src1, n);
}

template <__mul_mode mode>
inline void __inline_sqr_impl(uint64_t *WJR_RESTRICT dst, const uint64_t *src, size_t n,
                              safe_pointer<uint64_t> mal) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SEPARATE_P(dst, n * 2, src, n));

    if (n < toom2_sqr_threshold) {
        return basecase_sqr(dst, src, n);
    }

    if (mode <= __mul_mode::toom22 || n < toom3_sqr_threshold) {
        safe_pointer<uint64_t> stk = __mul_s_allocate(mal, toom22_n_itch(n));
        return toom2_sqr(dst, src, n, stk);
    }

    safe_pointer<uint64_t> stk = __mul_s_allocate(mal, toom33_n_itch(n));
    return toom3_sqr(dst, src, n, stk);
}

extern void __noinline_sqr_impl(uint64_t *WJR_RESTRICT dst, const uint64_t *src,
                                size_t n) noexcept;

template <__mul_mode mode>
void __sqr(uint64_t *WJR_RESTRICT dst, const uint64_t *src, size_t n,
           WJR_MAYBE_UNUSED safe_pointer<uint64_t> stk) noexcept {
    if constexpr (mode <= __mul_mode ::toom33) {
        __inline_sqr_impl<mode>(dst, src, n, stk);
    } else {
        sqr(dst, src, n);
    }
}

template <__mul_mode mode, uint64_t m = in_place_max>
void __sqr(uint64_t *WJR_RESTRICT dst, const uint64_t *src, size_t n,
           safe_pointer<uint64_t> stk, uint64_t &c_out, uint64_t cf) noexcept {
    WJR_ASSERT_ASSUME(cf <= m);

    __sqr<mode>(dst, src, n, stk);

    if constexpr (m == 0) {
        c_out = 0;
    } else if constexpr (m == 1) {
        c_out = cf;
    } else {
        c_out = cf * cf;
    }

    constexpr auto m2 = in_range<uint32_t>(m) ? m * 2 : m;
    c_out += try_addmul_1<m2>(dst + n, src, n, 2 * cf);
}

WJR_INTRINSIC_INLINE void sqr(uint64_t *WJR_RESTRICT dst, const uint64_t *src,
                              size_t n) noexcept {
    return __noinline_sqr_impl(dst, src, n);
}

WJR_INTRINSIC_INLINE void fallback_basecase_mul_s(uint64_t *WJR_RESTRICT dst,
                                                  const uint64_t *src0, size_t n,
                                                  const uint64_t *src1,
                                                  size_t m) noexcept {
    dst[n] = mul_1(dst, src0, n, src1[0]);
    for (size_t i = 1; i < m; ++i) {
        ++dst;
        dst[n] = addmul_1(dst, src0, n, src1[i]);
    }
}

/*
require :
1. m >= 1
2. n >= m
3. WJR_IS_SAME_OR_SEPARATE_P(dst, n + m, src0, n)
4. WJR_IS_SAME_OR_SEPARATE_P(dst, n + m, src1, m)
*/
WJR_INTRINSIC_INLINE void basecase_mul_s(uint64_t *WJR_RESTRICT dst, const uint64_t *src0,
                                         size_t n, const uint64_t *src1,
                                         size_t m) noexcept {
    WJR_ASSERT_ASSUME(m >= 1);
    WJR_ASSERT_ASSUME(n >= m);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_SEPARATE_P(dst, n + m, src0, n));
    WJR_ASSERT_L2(WJR_IS_SAME_OR_SEPARATE_P(dst, n + m, src1, m));

#if WJR_HAS_BUILTIN(ASM_BASECASE_MUL_S)
    return asm_basecase_mul_s(dst, src0, n, src1, m);
#else
    return fallback_basecase_mul_s(dst, src0, n, src1, m);
#endif
}

WJR_INTRINSIC_INLINE void basecase_sqr(uint64_t *WJR_RESTRICT dst, const uint64_t *src,
                                       size_t n) noexcept {
#if WJR_HAS_BUILTIN(ASM_BASECASE_SQR)
    return asm_basecase_sqr(dst, src, n);
#else
    return basecase_mul_s(dst, src, n, src, n);
#endif
}

} // namespace wjr

#endif // WJR_MATH_MUL_HPP__
// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_FORMAT_CHARCONV_HPP__
#define WJR_X86_FORMAT_CHARCONV_HPP__

// Already included
// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

namespace wjr {

#if WJR_HAS_SIMD(SSE4_1)
#define WJR_HAS_BUILTIN_TO_CHARS_UNROLL_8_FAST WJR_HAS_DEF

#define WJR_HAS_BUILTIN_FROM_CHARS_UNROLL_4_FAST WJR_HAS_DEF
#define WJR_HAS_BUILTIN_FROM_CHARS_UNROLL_8_FAST WJR_HAS_DEF
#define WJR_HAS_BUILTIN_FROM_CHARS_UNROLL_16_FAST WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(TO_CHARS_UNROLL_8_FAST)

namespace to_chars_detail {

const static __m128i mul10p4 = simd_cast<uint32_t, __m128i_t>(3518437209);
const static __m128i mul10p4x = simd_cast<uint32_t, __m128i_t>(10000);
const static __m128i mul10p2 = sse::set1_epi16(5243);
const static __m128i mul10p2x = sse::set1_epi16(100);
const static __m128i mul10p1 = sse::set1_epi16((short)52429u);
const static __m128i mul10p1x = sse::set1_epi16(10);

const static __m128i shuf =
    sse::setr_epi8(0, 8, 4, 12, 2, 10, 6, 14, 1, 1, 1, 1, 1, 1, 1, 1);

} // namespace to_chars_detail

#endif

#if WJR_HAS_BUILTIN(TO_CHARS_UNROLL_8_FAST)

inline uint64_t builtin_to_chars_unroll_8_fast_10(uint32_t in) noexcept {

    __m128i x = simd_cast<uint32_t, __m128i_t>(in);
    __m128i q, r;

    q = _mm_mul_epu32(x, to_chars_detail::mul10p4);
    q = _mm_srli_epi64(q, 45);

    r = _mm_sub_epi32(x, _mm_mul_epu32(q, to_chars_detail::mul10p4x));
    x = _mm_packus_epi32(q, r);

    q = _mm_mulhi_epu16(x, to_chars_detail::mul10p2);
    q = _mm_srli_epi16(q, 3);

    r = _mm_sub_epi16(x, _mm_mullo_epi16(q, to_chars_detail::mul10p2x));
    x = _mm_packus_epi16(q, r);

    q = _mm_mulhi_epu16(x, to_chars_detail::mul10p1);
    q = _mm_srli_epi16(q, 3);

    r = _mm_sub_epi16(x, _mm_mullo_epi16(q, to_chars_detail::mul10p1x));
    x = _mm_packus_epi16(q, r);

    return simd_cast<__m128i_t, uint64_t>(sse::shuffle_epi8(x, to_chars_detail::shuf));
}

template <uint64_t Base>
uint64_t builtin_to_chars_unroll_8_fast(uint32_t in) noexcept {
    if constexpr (Base == 10) {
        return builtin_to_chars_unroll_8_fast_10(in);
    } else {
        static_assert(Base == 10, "");
    }
}

template <uint64_t Base>
void builtin_to_chars_unroll_8_fast(void *ptr, uint32_t in, char_converter_t) noexcept {
    const uint64_t x = builtin_to_chars_unroll_8_fast<Base>(in) + 0x3030303030303030ull;
    write_memory<uint64_t>(ptr, x);
}

template <uint64_t Base>
void builtin_to_chars_unroll_8_fast(void *ptr, uint32_t in, origin_converter_t) noexcept {
    const uint64_t x = builtin_to_chars_unroll_8_fast<Base>(in);
    write_memory<uint64_t>(ptr, x);
}

#endif

#if WJR_HAS_BUILTIN(FROM_CHARS_UNROLL_8_FAST) ||                                         \
    WJR_HAS_BUILTIN(FROM_CHARS_UNROLL_16_FAST)

namespace from_chars_detail {

/// @private
template <uint64_t Base>
inline constexpr uint64_t __base2 = Base * Base;

/// @private
template <uint64_t Base>
inline constexpr uint64_t __base4 = __base2<Base> * __base2<Base>;

/// @private
template <uint64_t Base>
inline constexpr uint64_t __base8 = __base4<Base> * __base4<Base>;

/// @private
template <uint64_t Base>
const static __m128i mulp1x = sse::setr_epi8(Base, 1, Base, 1, Base, 1, Base, 1, Base, 1,
                                             Base, 1, Base, 1, Base, 1);

/// @private
template <uint64_t Base>
const static __m128i mulp2x = sse::setr_epi16(__base2<Base>, 1, __base2<Base>, 1,
                                              __base2<Base>, 1, __base2<Base>, 1);

/// @private
template <uint64_t Base>
const static __m128i mulp4x = sse::setr_epi16(__base4<Base>, 1, __base4<Base>, 1,
                                              __base4<Base>, 1, __base4<Base>, 1);

/// @private
template <uint64_t Base>
const static __m128i baseu8 =
    sse::setr_epi8(Base, Base, Base, Base, Base, Base, Base, 0xff, 0xff, 0xff, 0xff, 0xff,
                   0xff, 0xff, 0xff, 0xff);

/// @private
static __m128i ascii = sse::set1_epi8(0x30);

} // namespace from_chars_detail

#endif

#if WJR_HAS_BUILTIN(FROM_CHARS_UNROLL_8_FAST)

template <uint64_t Base>
uint32_t builtin_from_chars_unroll_8_fast(__m128i in) noexcept {
    const __m128i t1 = _mm_maddubs_epi16(in, from_chars_detail::mulp1x<Base>);
    const __m128i t2 = _mm_madd_epi16(t1, from_chars_detail::mulp2x<Base>);
    const __m128i t3 = _mm_packus_epi32(t2, t2);
    const __m128i t4 = _mm_madd_epi16(t3, from_chars_detail::mulp4x<Base>);

    return simd_cast<__m128i_t, uint32_t>(t4);
}

template <uint64_t Base>
uint32_t builtin_from_chars_unroll_8_fast(const void *ptr, char_converter_t) noexcept {
    static_assert(Base <= 10, "");
    const __m128i in = _mm_sub_epi8(sse::loadu_si64(ptr), from_chars_detail::ascii);
    return builtin_from_chars_unroll_8_fast<Base>(in);
}

template <uint64_t Base>
uint32_t builtin_from_chars_unroll_8_fast(const void *ptr, origin_converter_t) noexcept {
    static_assert(Base <= 10, "");
    const __m128i in = sse::loadu_si64(ptr);
    return builtin_from_chars_unroll_8_fast<Base>(in);
}

#endif

#if WJR_HAS_BUILTIN(FROM_CHARS_UNROLL_16_FAST)

template <uint64_t Base>
uint64_t builtin_from_chars_unroll_16_fast(__m128i in) noexcept {
    const __m128i t1 = _mm_maddubs_epi16(in, from_chars_detail::mulp1x<Base>);
    const __m128i t2 = _mm_madd_epi16(t1, from_chars_detail::mulp2x<Base>);
    const __m128i t3 = _mm_packus_epi32(t2, t2);
    const __m128i t4 = _mm_madd_epi16(t3, from_chars_detail::mulp4x<Base>);

    const uint64_t val = simd_cast<__m128i_t, uint64_t>(t4);
    const auto lo = static_cast<uint32_t>(val);
    const auto hi = static_cast<uint32_t>(val >> 32);

    return lo * from_chars_detail::__base8<Base> + hi;
}

template <uint64_t Base>
uint64_t builtin_from_chars_unroll_16_fast(const void *ptr, char_converter_t) noexcept {
    static_assert(Base <= 10, "");
    const __m128i in = _mm_sub_epi8(sse::loadu(ptr), from_chars_detail::ascii);
    return builtin_from_chars_unroll_16_fast<Base>(in);
}

template <uint64_t Base>
uint64_t builtin_from_chars_unroll_16_fast(const void *ptr, origin_converter_t) noexcept {
    static_assert(Base <= 10, "");
    const __m128i in = sse::loadu(ptr);
    return builtin_from_chars_unroll_16_fast<Base>(in);
}

#endif

} // namespace wjr

#endif // WJR_X86_FORMAT_CHARCONV_HPP__
#endif

namespace wjr {

static_assert(sizeof(char) == sizeof(uint8_t), "Not support currently.");

namespace charconv_detail {

WJR_CONST constexpr bool isspace(uint8_t ch) noexcept {
    return char_converter.from(ch) == 64;
}

template <typename T>
struct __is_fast_convert_value
    : std::conjunction<std::is_trivial<T>, std::bool_constant<sizeof(T) == 1>> {};

template <typename T>
inline constexpr bool __is_fast_convert_value_v = __is_fast_convert_value<T>::value;

template <typename Iter, typename = void>
struct __is_fast_convert_iterator_helper : std::false_type {};

template <typename Iter>
struct __is_fast_convert_iterator_helper<Iter,
                                         std::enable_if_t<is_contiguous_iterator_v<Iter>>>
    : __is_fast_convert_value<iterator_contiguous_value_t<Iter>> {};

template <typename Iter>
struct __is_fast_convert_iterator : __is_fast_convert_iterator_helper<Iter> {};

/**
 * @brief Iterator concept that can be used in fast_convert.
 *
 * @details The iterator must be contiguous iterator and the value_type must be
 * trivial and sizeof(value_type) == 1. Cast to_address(iter) to uint8_t*(to_chars)/const
 * uint8_t*(from_chars) in fast_convert.
 *
 */
template <typename Iter>
inline constexpr bool __is_fast_convert_iterator_v =
    __is_fast_convert_iterator<Iter>::value;

template <typename Value, typename Converter>
struct __is_valid_converter : std::false_type {};

template <typename Value>
struct __is_valid_converter<Value, char_converter_t> : is_nonbool_integral<Value> {};

template <typename Value>
struct __is_valid_converter<Value, origin_converter_t>
    : is_nonbool_unsigned_integral<Value> {};

template <typename Value, typename Converter>
inline constexpr bool __is_valid_converter_v =
    __is_valid_converter<Value, Converter>::value;

WJR_REGISTER_HAS_TYPE(to_chars_fast_fn_fast_conv,
                      MyBase::__fast_conv(std::declval<void *>(),
                                          std::declval<Args>()...),
                      MyBase);

WJR_REGISTER_HAS_TYPE(from_chars_fast_fn_fast_conv,
                      MyBase::__fast_conv(std::declval<const void *>(),
                                          std::declval<Args>()...),
                      MyBase);

template <typename Iter, typename = void>
struct fast_buffer {
private:
    using value_type = iterator_value_t<Iter>;

public:
    using type =
        std::conditional_t<__is_fast_convert_value_v<value_type>, value_type, char>;
};

// back_inserter or inserter
template <typename Iter>
struct fast_buffer<Iter, std::enable_if_t<is_any_insert_iterator_v<Iter>>> {
private:
    using value_type = typename Iter::container_type::value_type;

public:
    using type =
        std::conditional_t<__is_fast_convert_value_v<value_type>, value_type, char>;
};

template <typename Iter>
using fast_buffer_t = typename fast_buffer<Iter>::type;

template <typename Container>
struct __fast_container_inserter_test {
private:
    using traits_type = container_traits<Container>;

public:
    static constexpr int value =
        traits_type::is_trivially_contiguous_v &&
                has_container_resize_v<Container, size_t>
            ? (has_container_resize_v<Container, size_t, dctor_t> ? 2 : 1)
            : 0;

    static_assert(value != 2 || has_container_append_v<Container, size_t, dctor_t>, "");
};

template <typename Iter, typename = void>
struct __is_fast_container_inserter {
    static constexpr int value = 0;
};

template <typename Iter>
struct __is_fast_container_inserter<
    Iter,
    std::void_t<
        decltype(std::declval<std::enable_if_t<is_any_insert_iterator_v<Iter>>>(),
                 __fast_container_inserter_test<typename Iter::container_type>::value)>> {
private:
    using container_type = typename Iter::container_type;

public:
    static constexpr int value =
        __is_fast_convert_value_v<typename container_type::value_type> &&
                is_trivially_allocator_constructible_v<
                    typename container_type::allocator_type>
            ? __fast_container_inserter_test<container_type>::value
            : 0;
};

template <typename Iter>
inline constexpr int is_fast_container_inserter_v =
    __is_fast_container_inserter<Iter>::value;

} // namespace charconv_detail

// require operator() of Converter is constexpr
template <typename Converter, uint64_t Base, int Unroll>
class __char_converter_table_t {
    static constexpr uint64_t pw2 = Unroll == 2 ? Base * Base : Base * Base * Base * Base;

public:
    constexpr __char_converter_table_t() : table() {
        for (uint64_t i = 0, j = 0; i < pw2; ++i, j += Unroll) {
            int x = i;
            for (int k = Unroll - 1; ~k; --k) {
                table[j + k] = Converter::to(x % Base);
                x /= Base;
            }
        }
    }

    WJR_CONST constexpr char operator[](unsigned int idx) const noexcept {
        return table[idx];
    }

    WJR_CONST constexpr const char *data() const noexcept { return table.data(); }

private:
    std::array<char, pw2 * Unroll> table;
};

template <typename Converter, uint64_t Base, int Unroll>
inline constexpr __char_converter_table_t<Converter, Base, Unroll>
    __char_converter_table{};

template <uint64_t Base>
class __to_chars_unroll_2_fast_fn_impl_base {
public:
    template <typename Converter>
    WJR_INTRINSIC_INLINE static void __fast_conv(void *ptr, uint32_t val,
                                                 Converter) noexcept {
        auto *const str = static_cast<char *>(ptr);
        if constexpr (Base * Base <= 16) {
            constexpr auto &table = __char_converter_table<Converter, Base, 4>;
            std::memcpy(str, table.data() + val * 4 + 2, 2);
        } else {
            constexpr auto &table = __char_converter_table<Converter, Base, 2>;
            std::memcpy(str, table.data() + val * 2, 2);
        }
    }
};

template <uint64_t Base>
class __to_chars_unroll_2_fast_fn_impl {};

template <>
class __to_chars_unroll_2_fast_fn_impl<2>
    : public __to_chars_unroll_2_fast_fn_impl_base<2> {};

template <>
class __to_chars_unroll_2_fast_fn_impl<8>
    : public __to_chars_unroll_2_fast_fn_impl_base<8> {};

template <>
class __to_chars_unroll_2_fast_fn_impl<10>
    : public __to_chars_unroll_2_fast_fn_impl_base<10> {};

template <>
class __to_chars_unroll_2_fast_fn_impl<16>
    : public __to_chars_unroll_2_fast_fn_impl_base<16> {};

template <uint64_t Base>
class __to_chars_unroll_4_fast_fn_impl_base {
public:
    template <typename Converter>
    WJR_INTRINSIC_INLINE static void __fast_conv(void *ptr, uint32_t val,
                                                 Converter) noexcept {
        auto *const str = static_cast<char *>(ptr);
        if constexpr (Base * Base <= 16) {
            constexpr auto &table = __char_converter_table<Converter, Base, 4>;
            std::memcpy(str, table.data() + val * 4, 4);
        } else {
            constexpr auto &table = __char_converter_table<Converter, Base, 2>;
            constexpr auto Base2 = Base * Base;
            const uint32_t hi = val / Base2;
            const uint32_t lo = val % Base2;

            std::memcpy(str, table.data() + hi * 2, 2);
            std::memcpy(str + 2, table.data() + lo * 2, 2);
        }
    }
};

template <uint64_t Base>
class __to_chars_unroll_4_fast_fn_impl {};

template <>
class __to_chars_unroll_4_fast_fn_impl<2>
    : public __to_chars_unroll_4_fast_fn_impl_base<2> {};

template <>
class __to_chars_unroll_4_fast_fn_impl<8>
    : public __to_chars_unroll_4_fast_fn_impl_base<8> {};

template <>
class __to_chars_unroll_4_fast_fn_impl<10>
    : public __to_chars_unroll_4_fast_fn_impl_base<10> {};

template <>
class __to_chars_unroll_4_fast_fn_impl<16>
    : public __to_chars_unroll_4_fast_fn_impl_base<16> {};

template <uint64_t Base>
class __to_chars_unroll_8_fast_fn_impl_base {
#if WJR_HAS_BUILTIN(TO_CHARS_UNROLL_8_FAST)
public:
    template <typename Converter>
    WJR_INTRINSIC_INLINE static void __fast_conv(void *ptr, uint64_t val,
                                                 Converter conv) noexcept {
        builtin_to_chars_unroll_8_fast<Base>(ptr, static_cast<uint32_t>(val), conv);
    }
#endif
};

template <uint64_t Base>
class __to_chars_unroll_8_fast_fn_impl {};

template <>
class __to_chars_unroll_8_fast_fn_impl<10>
    : public __to_chars_unroll_8_fast_fn_impl_base<10> {};

template <uint64_t Base>
class __to_chars_unroll_2_fn : public __to_chars_unroll_2_fast_fn_impl<Base> {
    using Mybase = __to_chars_unroll_2_fast_fn_impl<Base>;

public:
    template <typename Converter>
    WJR_INTRINSIC_INLINE void operator()(uint8_t *ptr, uint32_t val,
                                         Converter conv) const noexcept {
        if constexpr (charconv_detail::has_to_chars_fast_fn_fast_conv_v<Mybase, uint32_t,
                                                                        Converter>) {
            Mybase::__fast_conv(ptr, val, conv);
        } else {
            ptr[0] = conv.template to<Base>(val / Base);
            ptr[1] = conv.template to<Base>(val % Base);
        }
    }
};

template <uint64_t Base>
inline constexpr __to_chars_unroll_2_fn<Base> __to_chars_unroll_2{};

template <uint64_t Base>
class __to_chars_unroll_4_fn_impl : public __to_chars_unroll_4_fast_fn_impl<Base> {
    using Mybase = __to_chars_unroll_4_fast_fn_impl<Base>;

public:
    template <typename Converter>
    WJR_INTRINSIC_INLINE void operator()(uint8_t *ptr, uint32_t val,
                                         Converter conv) const noexcept {
        if constexpr (charconv_detail::has_to_chars_fast_fn_fast_conv_v<Mybase, uint32_t,
                                                                        Converter>) {
            Mybase::__fast_conv(ptr, val, conv);
        } else {
            constexpr auto Base2 = Base * Base;
            __to_chars_unroll_2<Base>(ptr, val / Base2, conv);
            __to_chars_unroll_2<Base>(ptr + 2, val % Base2, conv);
        }
    }
};

template <uint64_t Base>
inline constexpr __to_chars_unroll_4_fn_impl<Base> __to_chars_unroll_4{};

template <uint64_t Base>
class __to_chars_unroll_8_fn_impl : public __to_chars_unroll_8_fast_fn_impl<Base> {
    using Mybase = __to_chars_unroll_8_fast_fn_impl<Base>;

public:
    template <typename Converter>
    WJR_INTRINSIC_INLINE void operator()(uint8_t *ptr, uint64_t val,
                                         Converter conv) const noexcept {
        if constexpr (charconv_detail::has_to_chars_fast_fn_fast_conv_v<Mybase, uint64_t,
                                                                        Converter>) {
            Mybase::__fast_conv(ptr, val, conv);
        } else {
            constexpr auto Base4 = Base * Base * Base * Base;
            __to_chars_unroll_4<Base>(ptr, val / Base4, conv);
            __to_chars_unroll_4<Base>(ptr + 4, val % Base4, conv);
        }
    }
};

template <uint64_t Base>
inline constexpr __to_chars_unroll_8_fn_impl<Base> __to_chars_unroll_8{};

template <uint64_t Base>
class __from_chars_unroll_4_fast_fn_impl_base {
protected:
    WJR_CONST WJR_INTRINSIC_INLINE static uint32_t __fast_conv(uint32_t val) noexcept {
        return digits_literal_detail::__fast_conv_4<Base>(val);
    }

public:
    WJR_PURE WJR_INTRINSIC_INLINE static uint32_t __fast_conv(const void *ptr,
                                                              char_converter_t) noexcept {
        return __fast_conv(read_memory<uint32_t>(ptr) - 0x30303030u);
    }

    WJR_PURE WJR_INTRINSIC_INLINE static uint32_t
    __fast_conv(const void *ptr, origin_converter_t) noexcept {
        return __fast_conv(read_memory<uint32_t>(ptr));
    }
};

template <uint64_t Base>
class __from_chars_unroll_8_fast_fn_impl_base {
protected:
    WJR_CONST WJR_INTRINSIC_INLINE static uint32_t __fast_conv(uint64_t val) noexcept {
        return digits_literal_detail::__fast_conv_8<Base>(val);
    }

public:
    WJR_PURE WJR_INTRINSIC_INLINE static uint32_t
    __fast_conv(const void *ptr, WJR_MAYBE_UNUSED char_converter_t conv) noexcept {
#if WJR_HAS_BUILTIN(FROM_CHARS_UNROLL_8_FAST)
        return builtin_from_chars_unroll_8_fast<Base>(ptr, conv);
#else
        return __fast_conv(read_memory<uint64_t>(ptr) - 0x3030303030303030ull);
#endif
    }

    WJR_PURE WJR_INTRINSIC_INLINE static uint32_t
    __fast_conv(const void *ptr, WJR_MAYBE_UNUSED origin_converter_t conv) noexcept {
#if WJR_HAS_BUILTIN(FROM_CHARS_UNROLL_8_FAST)
        return builtin_from_chars_unroll_8_fast<Base>(ptr, conv);
#else
        return __fast_conv(read_memory<uint64_t>(ptr));
#endif
    }
};

template <uint64_t Base>
class __from_chars_unroll_16_fast_fn_impl_base {
#if WJR_HAS_BUILTIN(FROM_CHARS_UNROLL_16_FAST)
public:
    template <typename Converter>
    WJR_PURE WJR_INTRINSIC_INLINE static uint64_t __fast_conv(const void *ptr,
                                                              Converter conv) noexcept {
        return builtin_from_chars_unroll_16_fast<Base>(ptr, conv);
    }
#endif
};

template <uint64_t Base>
class __from_chars_unroll_4_fast_fn_impl {};

template <>
class __from_chars_unroll_4_fast_fn_impl<2>
    : public __from_chars_unroll_4_fast_fn_impl_base<2> {};

template <>
class __from_chars_unroll_4_fast_fn_impl<8>
    : public __from_chars_unroll_4_fast_fn_impl_base<8> {};

template <>
class __from_chars_unroll_4_fast_fn_impl<10>
    : public __from_chars_unroll_4_fast_fn_impl_base<10> {};

template <uint64_t Base>
class __from_chars_unroll_8_fast_fn_impl {};

template <>
class __from_chars_unroll_8_fast_fn_impl<2>
    : public __from_chars_unroll_8_fast_fn_impl_base<2> {};

template <>
class __from_chars_unroll_8_fast_fn_impl<8>
    : public __from_chars_unroll_8_fast_fn_impl_base<8> {};

template <>
class __from_chars_unroll_8_fast_fn_impl<10>
    : public __from_chars_unroll_8_fast_fn_impl_base<10> {};

template <uint64_t Base>
class __from_chars_unroll_16_fast_fn_impl {};

template <>
class __from_chars_unroll_16_fast_fn_impl<2>
    : public __from_chars_unroll_16_fast_fn_impl_base<2> {};

template <>
class __from_chars_unroll_16_fast_fn_impl<8>
    : public __from_chars_unroll_16_fast_fn_impl_base<8> {};

template <>
class __from_chars_unroll_16_fast_fn_impl<10>
    : public __from_chars_unroll_16_fast_fn_impl_base<10> {};

template <uint64_t Base>
class __from_chars_unroll_4_fn : public __from_chars_unroll_4_fast_fn_impl<Base> {
    using Mybase = __from_chars_unroll_4_fast_fn_impl<Base>;

public:
    template <typename Converter>
    WJR_PURE WJR_INTRINSIC_INLINE uint64_t operator()(const uint8_t *ptr,
                                                      Converter conv) const noexcept {
        if constexpr (charconv_detail::has_from_chars_fast_fn_fast_conv_v<Mybase,
                                                                          Converter>) {
            return Mybase::__fast_conv(ptr, conv);
        } else {
            uint64_t value = 0;
            value = conv.template from<Base>(*ptr++);
            value = value * Base + conv.template from<Base>(*ptr++);
            value = value * Base + conv.template from<Base>(*ptr++);
            return value * Base + conv.template from<Base>(*ptr++);
        }
    }
};

template <uint64_t Base>
inline constexpr __from_chars_unroll_4_fn<Base> __from_chars_unroll_4{};

template <uint64_t Base>
class __from_chars_unroll_8_fn : public __from_chars_unroll_8_fast_fn_impl<Base> {
    using Mybase = __from_chars_unroll_8_fast_fn_impl<Base>;

public:
    template <typename Converter>
    WJR_PURE WJR_INTRINSIC_INLINE uint64_t operator()(const uint8_t *ptr,
                                                      Converter conv) const noexcept {
        if constexpr (charconv_detail::has_from_chars_fast_fn_fast_conv_v<Mybase,
                                                                          Converter>) {
            return Mybase::__fast_conv(ptr, conv);
        } else {
            constexpr uint64_t Base4 = Base * Base * Base * Base;
            return __from_chars_unroll_4<Base>(ptr, conv) * Base4 +
                   __from_chars_unroll_4<Base>(ptr + 4, conv);
        }
    }
};

template <uint64_t Base>
inline constexpr __from_chars_unroll_8_fn<Base> __from_chars_unroll_8{};

WJR_INTRINSIC_INLINE uint32_t parse_eight_digits_unrolled(const char *src) noexcept {
    return __from_chars_unroll_8_fast_fn_impl_base<10>::__fast_conv(src, char_converter);
}

template <uint64_t Base>
class __from_chars_unroll_16_fn : public __from_chars_unroll_16_fast_fn_impl<Base> {
    using Mybase = __from_chars_unroll_16_fast_fn_impl<Base>;

public:
    template <typename Converter>
    WJR_PURE WJR_INTRINSIC_INLINE uint64_t operator()(const uint8_t *ptr,
                                                      Converter conv) const noexcept {
        if constexpr (charconv_detail::has_from_chars_fast_fn_fast_conv_v<Mybase,
                                                                          Converter>) {
            return Mybase::__fast_conv(ptr, conv);
        } else {
            constexpr uint64_t Base4 = Base * Base * Base * Base;
            constexpr uint64_t Base8 = Base4 * Base4;
            return __from_chars_unroll_8<Base>(ptr, conv) * Base8 +
                   __from_chars_unroll_8<Base>(ptr + 8, conv);
        }
    }
};

template <uint64_t Base>
inline constexpr __from_chars_unroll_16_fn<Base> __from_chars_unroll_16{};

template <typename UnsignedValue>
constexpr int fallback_count_digits10(UnsignedValue n) noexcept {
    int count = 0;

    if (WJR_UNLIKELY(n >= 1000)) {
        do {
            n /= 10000;
            count += 4;
        } while (n >= 1000);

        if (n == 0) {
            return count;
        }
    }

    if (n < 10) {
        return count + 1;
    }

    if (n < 100) {
        return count + 2;
    }

    return count + 3;
}

namespace charconv_detail {

#define WJR_INC(T) (((sizeof(#T) - 1ull) << 32) - T)

static constexpr uint64_t __count_digits10_u32_table[] = {
    WJR_INC(0),          WJR_INC(0),          WJR_INC(0),          // 8
    WJR_INC(10),         WJR_INC(10),         WJR_INC(10),         // 64
    WJR_INC(100),        WJR_INC(100),        WJR_INC(100),        // 512
    WJR_INC(1000),       WJR_INC(1000),       WJR_INC(1000),       // 4096
    WJR_INC(10000),      WJR_INC(10000),      WJR_INC(10000),      // 32k
    WJR_INC(100000),     WJR_INC(100000),     WJR_INC(100000),     // 256k
    WJR_INC(1000000),    WJR_INC(1000000),    WJR_INC(1000000),    // 2048k
    WJR_INC(10000000),   WJR_INC(10000000),   WJR_INC(10000000),   // 16M
    WJR_INC(100000000),  WJR_INC(100000000),  WJR_INC(100000000),  // 128M
    WJR_INC(1000000000), WJR_INC(1000000000), WJR_INC(1000000000), // 1024M
    WJR_INC(1000000000), WJR_INC(1000000000)                       // 4B
};

#undef WJR_INC

#define WJR_POWERS_OF_10(factor)                                                         \
    factor * 10, (factor)*100, (factor)*1000, (factor)*10000, (factor)*100000,           \
        (factor)*1000000, (factor)*10000000, (factor)*100000000, (factor)*1000000000

static constexpr uint8_t __count_digits10_u64_bsr2log10[] = {
    1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  4,  5,  5,  5,
    6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9,  10, 10, 10,
    10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15,
    15, 16, 16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 19, 20};

static constexpr const uint64_t __count_digits10_u64_zero_or_powers_of_10[] = {
    0, 0, WJR_POWERS_OF_10(1U), WJR_POWERS_OF_10(1000000000ull), 10000000000000000000ull};

#undef WJR_POWERS_OF_10

} // namespace charconv_detail

WJR_INTRINSIC_CONSTEXPR20 int builtin_count_digits10_u32(uint32_t n) noexcept {
    const auto inc = charconv_detail::__count_digits10_u32_table[clz(n | 1) ^ 31];
    return static_cast<int>((n + inc) >> 32);
}

WJR_INTRINSIC_CONSTEXPR20 int builtin_count_digits10_u64(uint64_t n) noexcept {
    const auto t = charconv_detail::__count_digits10_u64_bsr2log10[clz(n | 1) ^ 63];
    return t - (n < charconv_detail::__count_digits10_u64_zero_or_powers_of_10[t]);
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR20 int count_digits10_impl(T n) noexcept {
    if (is_constant_evaluated() || WJR_BUILTIN_CONSTANT_P(n)) {
        return fallback_count_digits10(n);
    }

    if constexpr (sizeof(T) <= sizeof(uint32_t)) {
        return builtin_count_digits10_u32(static_cast<uint32_t>(n));
    } else {
        return builtin_count_digits10_u64(static_cast<uint64_t>(n));
    }
}

template <uint64_t Base>
struct count_digits_fn {};

template <uint64_t Base>
inline constexpr count_digits_fn<Base> count_digits{};

template <>
struct count_digits_fn<2> {
    template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
    WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int operator()(T n) const noexcept {
        return bit_width(n);
    }
};

template <>
struct count_digits_fn<8> {
    template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
    WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int operator()(T n) const noexcept {
        return __ceil_div(to_unsigned(bit_width(n)), 3);
    }
};

template <>
struct count_digits_fn<16> {
    template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
    WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int operator()(T n) const noexcept {
        return __ceil_div(to_unsigned(bit_width(n)), 4);
    }
};

template <>
struct count_digits_fn<1> {
    template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
    WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int operator()(T n, int bits) const noexcept {
        return (bit_width(n) + bits - 1) / bits;
    }
};

template <>
struct count_digits_fn<10> {
    template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
    WJR_CONST WJR_INTRINSIC_CONSTEXPR20 int operator()(T n) const noexcept {
        const int ret = count_digits10_impl(n);
        WJR_ASSUME(1 <= ret && ret <= std::numeric_limits<T>::digits10 + 1);
        return ret;
    }
};

// Base :
// 0 : dynamic base
// 1 : base is power of two
template <uint64_t Base>
class __unsigned_to_chars_backward_unchecked_fn {};

template <uint64_t Base>
inline constexpr __unsigned_to_chars_backward_unchecked_fn<Base>
    __unsigned_to_chars_backward_unchecked{};

template <>
class __unsigned_to_chars_backward_unchecked_fn<2> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE uint8_t *operator()(uint8_t *ptr, int n, UnsignedValue x,
                                             Converter conv) const noexcept {
        constexpr auto nd = std::numeric_limits<UnsignedValue>::digits;
        WJR_ASSERT_L2(x != 0);
        WJR_ASSERT_ASSUME(1 <= n && n <= nd);

        if (WJR_UNLIKELY(n >= 4)) {
            do {
                __to_chars_unroll_4<2>(ptr - 4, x & 0x0f, conv);
                ptr -= 4;
                x >>= 4;
                n -= 4;
            } while (WJR_LIKELY(n >= 4));

            if (n == 0) {
                return ptr;
            }
        }

        switch (n) {
        case 3: {
            *--ptr = conv.template to<2>(x & 1);
            x >>= 1;
            WJR_FALLTHROUGH;
        }
        case 2: {
            __to_chars_unroll_2<2>(ptr - 2, static_cast<uint32_t>(x), conv);
            ptr -= 2;
            break;
        }
        case 1: {
            *--ptr = conv.template to<2>(x);
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }

        return ptr;
    }
};

template <>
class __unsigned_to_chars_backward_unchecked_fn<8> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE uint8_t *operator()(uint8_t *ptr, int n, UnsignedValue x,
                                             Converter conv) const noexcept {
        constexpr auto nd = std::numeric_limits<UnsignedValue>::digits;
        WJR_ASSERT_L2(x != 0);
        WJR_ASSERT_ASSUME(1 <= n && n <= (nd + 2) / 3);

        if constexpr (nd >= 16) {
            if (WJR_UNLIKELY(n >= 4)) {
                do {
                    __to_chars_unroll_4<8>(ptr - 4, x & 0x0fff, conv);
                    ptr -= 4;
                    x >>= 12;
                    n -= 4;
                } while (WJR_LIKELY(n >= 4));

                if (n == 0) {
                    return ptr;
                }
            }
        }

        switch (n) {
        case 3: {
            *--ptr = conv.template to<8>(x & 0x07);
            x >>= 3;
            WJR_FALLTHROUGH;
        }
        case 2: {
            __to_chars_unroll_2<8>(ptr - 2, x, conv);
            ptr -= 2;
            break;
        }
        case 1: {
            *--ptr = conv.template to<8>(x);
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }

        return ptr;
    }
};

template <>
class __unsigned_to_chars_backward_unchecked_fn<16> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE uint8_t *operator()(uint8_t *ptr, int n, UnsignedValue x,
                                             Converter conv) const noexcept {
        constexpr auto nd = std::numeric_limits<UnsignedValue>::digits;
        WJR_ASSERT_L2(x != 0);
        WJR_ASSERT_ASSUME(1 <= n && n <= (nd + 3) / 4);

        if constexpr (nd >= 16) {
            if (WJR_UNLIKELY(n >= 4)) {
                do {
                    __to_chars_unroll_4<16>(ptr - 4, x & 0xffff, conv);
                    ptr -= 4;
                    x >>= 16;
                    n -= 4;
                } while (WJR_LIKELY(n >= 4));

                if (n == 0) {
                    return ptr;
                }
            }
        }

        switch (n) {
        case 3: {
            *--ptr = conv.to(x & 0x0f);
            x >>= 4;
            WJR_FALLTHROUGH;
        }
        case 2: {
            __to_chars_unroll_2<16>(ptr - 2, x, conv);
            ptr -= 2;
            break;
        }
        case 1: {
            *--ptr = conv.to(x);
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }

        return ptr;
    }
};

template <>
class __unsigned_to_chars_backward_unchecked_fn<1> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE uint8_t *operator()(uint8_t *ptr, int n, UnsignedValue x,
                                             int bits, Converter conv) const noexcept {
        WJR_ASSERT_L2(x != 0);
        WJR_ASSERT_ASSUME(1 <= n && n <= std::numeric_limits<UnsignedValue>::digits);

        const unsigned int mask = (1u << bits) - 1;

        do {
            *--ptr = conv.to(x & mask);
            x >>= bits;
            --n;
        } while (WJR_LIKELY(n != 0));

        return ptr;
    }
};

template <>
class __unsigned_to_chars_backward_unchecked_fn<10> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE uint8_t *operator()(uint8_t *ptr, UnsignedValue val,
                                             Converter conv) const noexcept {
        WJR_ASSERT_ASSUME(val != 0);

        if (WJR_LIKELY(val >= 100)) {
            do {
                __to_chars_unroll_2<10>(ptr - 2, val % 100, conv);
                ptr -= 2;
                val /= 100;
            } while (WJR_LIKELY(val >= 100));
        }

        if (val < 10) {
            *--ptr = conv.template to<10>(val);
            return ptr;
        }

        __to_chars_unroll_2<10>(ptr - 2, static_cast<uint32_t>(val), conv);
        ptr -= 2;
        return ptr;
    }
};

template <typename Value, typename IBase, typename Converter>
uint8_t *__fast_to_chars_backward_unchecked_impl(uint8_t *ptr, Value val, IBase ibase,
                                                 Converter conv) noexcept {
    if (WJR_UNLIKELY(val == 0)) {
        *--ptr = conv.template to<1>(0);
        return ptr;
    }

    auto uVal = to_unsigned(val);
    int sign = 0;

    if constexpr (std::is_signed_v<Value>) {
        if (val < 0) {
            sign = 1;
            uVal = -val;
        }
    }

    const unsigned int base = ibase;

    switch (base) {
    case 2: {
        ptr = __unsigned_to_chars_backward_unchecked<2>(ptr, count_digits<2>(uVal), uVal,
                                                        conv);
        break;
    }
    case 8: {
        ptr = __unsigned_to_chars_backward_unchecked<8>(ptr, count_digits<8>(uVal), uVal,
                                                        conv);
        break;
    }
    case 16: {
        ptr = __unsigned_to_chars_backward_unchecked<16>(ptr, count_digits<16>(uVal),
                                                         uVal, conv);
        break;
    }
    case 4:
    case 32: {
        const int bits = base == 4 ? 2 : 5;
        ptr = __unsigned_to_chars_backward_unchecked<1>(ptr, count_digits<1>(uVal, bits),
                                                        uVal, bits, conv);
        break;
    }
    case 10: {
        ptr = __unsigned_to_chars_backward_unchecked<10>(ptr, uVal, conv);
        break;
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

    if constexpr (std::is_signed_v<Value>) {
        if (sign) {
            *--ptr = '-';
        }
    }

    return ptr;
}

template <typename Iter, typename Value, typename IBase, typename Converter>
Iter __to_chars_backward_unchecked_impl(Iter first, Value val, IBase ibase,
                                        Converter conv) noexcept {
    const auto __ptr = reinterpret_cast<uint8_t *>(wjr::to_address(first));
    const auto __end = __fast_to_chars_backward_unchecked_impl(__ptr, val, ibase, conv);
    return first + std::distance(__ptr, __end);
}

/**
 * @brief Convert an unsigned integer to a string in reverse order without checking
 * buf size.
 *
 * @details Only use fast_convert mode.
 *
 */
template <typename Iter, typename Value, unsigned int IBase = 10,
          typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_fast_convert_iterator_v<Iter>
                           &&charconv_detail::__is_valid_converter_v<Value, Converter>)>
Iter to_chars_backward_unchecked(Iter first, Value val,
                                 integral_constant<unsigned int, IBase> ic = {},
                                 Converter conv = {}) noexcept {
    return __to_chars_backward_unchecked_impl(first, val, ic, conv);
}

template <typename Iter, typename Value, typename Converter>
Iter to_chars_backward_unchecked_dynamic(Iter first, Value val, unsigned int base,
                                         Converter conv) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(base)) {
        switch (base) {
        case 2: {
            return to_chars_backward_unchecked(first, val, 2_u, conv);
        }
        case 8: {
            return to_chars_backward_unchecked(first, val, 8_u, conv);
        }
        case 16: {
            return to_chars_backward_unchecked(first, val, 16_u, conv);
        }
        case 10: {
            return to_chars_backward_unchecked(first, val, 10_u, conv);
        }
        default: {
            break;
        }
        }
    }

    return __to_chars_backward_unchecked_impl(first, val, base, conv);
}

/**
 * @brief Convert an unsigned integer to a string in reverse order without checking
 * buf size.
 *
 *
 */
template <typename Iter, typename Value, typename IBase,
          typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_fast_convert_iterator_v<Iter>
                           &&charconv_detail::__is_valid_converter_v<Value, Converter>
                               &&is_nonbool_integral_v<IBase>)>
Iter to_chars_backward_unchecked(Iter first, Value val, IBase base,
                                 Converter conv = {}) noexcept {
    return to_chars_backward_unchecked_dynamic(first, val,
                                               static_cast<unsigned int>(base), conv);
}

template <typename Value, typename IBase, typename Converter>
to_chars_result<uint8_t *> __fast_to_chars_impl(uint8_t *first, uint8_t *last, Value val,
                                                IBase ibase, Converter conv) noexcept {
    if (WJR_UNLIKELY(val == 0)) {
        if (WJR_UNLIKELY(first == last)) {
            return {last, std::errc::value_too_large};
        }

        *first++ = conv.template to<1>(0);
        return {first, std::errc{}};
    }

    auto uVal = to_unsigned(val);

    if constexpr (std::is_signed_v<Value>) {
        if (val < 0) {
            if (WJR_UNLIKELY(first == last)) {
                return {last, std::errc::value_too_large};
            }

            *first++ = '-';
            uVal = -val;
        }
    }

    const unsigned int base = ibase;
    const auto size = std::distance(first, last);

#define WJR_TO_CHARS_VALIDATE_IMPL(BASE, DIGITS, CALL)                                   \
    const int n = count_digits<BASE> DIGITS;                                             \
    if (WJR_LIKELY(n <= size)) {                                                         \
        first += n;                                                                      \
        (void)__unsigned_to_chars_backward_unchecked<BASE>(                              \
            first, WJR_PP_QUEUE_EXPAND(CALL), conv);                                     \
        return {first, std::errc{}};                                                     \
    }                                                                                    \
    return { last, std::errc::value_too_large }

    switch (base) {
    case 2: {
        WJR_TO_CHARS_VALIDATE_IMPL(2, (uVal), (n, uVal));
    }
    case 8: {
        WJR_TO_CHARS_VALIDATE_IMPL(8, (uVal), (n, uVal));
    }
    case 16: {
        WJR_TO_CHARS_VALIDATE_IMPL(16, (uVal), (n, uVal));
    }
    case 4:
    case 32: {
        const int bits = base == 4 ? 2 : 5;
        WJR_TO_CHARS_VALIDATE_IMPL(1, (uVal, bits), (n, uVal, bits));
    }
    case 10: {
        WJR_TO_CHARS_VALIDATE_IMPL(10, (uVal), (uVal));
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

#undef WJR_TO_CHARS_VALIDATE_IMPL
}

template <typename Iter, typename Value, typename IBase, typename Converter>
to_chars_result<Iter> __fallback_to_chars_impl(Iter first, Iter last, Value val,
                                               IBase ibase, Converter conv) noexcept {
    constexpr auto is_signed = std::is_signed_v<Value>;
    constexpr auto base_2_table = std::numeric_limits<Value>::digits;
    constexpr auto base_10_table = std::numeric_limits<Value>::digits10 + 1;
    constexpr auto is_random_access = is_random_access_iterator_v<Iter>;

    if (WJR_UNLIKELY(val == 0)) {
        if (WJR_UNLIKELY(first == last)) {
            return {last, std::errc::value_too_large};
        }

        *first++ = conv.template to<1>(0);
        return {first, std::errc{}};
    }

    auto uVal = to_unsigned(val);
    int sign = 0;

    if constexpr (is_signed) {
        if constexpr (is_random_access) {
            if (val < 0) {
                if (WJR_UNLIKELY(first == last)) {
                    return {last, std::errc::value_too_large};
                }

                sign = 1;
                uVal = -val;
            }
        } else {
            if (val < 0) {
                if (WJR_UNLIKELY(first == last)) {
                    return {last, std::errc::value_too_large};
                }

                *first++ = '-';
                uVal = -val;
            }
        }
    }

    const unsigned int base = ibase;

#define WJR_TO_CHARS_VALIDATE_IMPL(BASE, TABLE, CALL)                                    \
    if constexpr (is_random_access) {                                                    \
        const auto size = std::distance(first, last);                                    \
        WJR_PP_QUEUE_EXPAND(                                                             \
            WJR_PP_BOOL_IF(WJR_PP_NE(BASE, 10),                                          \
                           (                                                             \
                               if constexpr (is_signed) {                                \
                                   if (WJR_UNLIKELY(n + sign > size)) {                  \
                                       return {last, std::errc::value_too_large};        \
                                   }                                                     \
                               } else {                                                  \
                                   if (WJR_UNLIKELY(n > size)) {                         \
                                       return {last, std::errc::value_too_large};        \
                                   }                                                     \
                               }),                                                       \
                           ()))                                                          \
                                                                                         \
        charconv_detail::fast_buffer_t<Iter> buffer[TABLE + is_signed];                  \
        const auto __end = buffer + TABLE + is_signed;                                   \
        auto __ptr = (charconv_detail::fast_buffer_t<Iter> *)                            \
            __unsigned_to_chars_backward_unchecked<BASE>(                                \
                (uint8_t *)__end, WJR_PP_QUEUE_EXPAND(CALL), conv);                      \
                                                                                         \
        WJR_PP_QUEUE_EXPAND(                                                             \
            WJR_PP_BOOL_IF(WJR_PP_EQ(BASE, 10),                                          \
                           (                                                             \
                               const auto n = __end - __ptr;                             \
                                                                                         \
                               if constexpr (is_signed) {                                \
                                   if (WJR_UNLIKELY(n + sign > size)) {                  \
                                       return {last, std::errc::value_too_large};        \
                                   }                                                     \
                               } else {                                                  \
                                   if (WJR_UNLIKELY(n > size)) {                         \
                                       return {last, std::errc::value_too_large};        \
                                   }                                                     \
                               }),                                                       \
                           ()))                                                          \
                                                                                         \
        if constexpr (is_signed) {                                                       \
            if (sign) {                                                                  \
                *--__ptr = '-';                                                          \
            }                                                                            \
        }                                                                                \
                                                                                         \
        return wjr::copy(__ptr, __end, first);                                           \
    } else {                                                                             \
        charconv_detail::fast_buffer_t<Iter> buffer[TABLE];                              \
        const auto __end = buffer + TABLE;                                               \
        auto __ptr = (charconv_detail::fast_buffer_t<Iter> *)                            \
            __unsigned_to_chars_backward_unchecked<BASE>(                                \
                (uint8_t *)__end, WJR_PP_QUEUE_EXPAND(CALL), conv);                      \
                                                                                         \
        do {                                                                             \
            if (WJR_UNLIKELY(first == last)) {                                           \
                return {last, std::errc::value_too_large};                               \
            }                                                                            \
                                                                                         \
            *first++ = *__ptr++;                                                         \
        } while (__ptr != __end);                                                        \
                                                                                         \
        return {first, std::errc{}};                                                     \
    }

    switch (base) {
    case 2: {
        const int n = count_digits<2>(uVal);
        WJR_TO_CHARS_VALIDATE_IMPL(2, base_2_table, (n, uVal));
    }
    case 8: {
        const int n = count_digits<8>(uVal);
        WJR_TO_CHARS_VALIDATE_IMPL(8, (base_2_table + 2) / 3, (n, uVal));
    }
    case 16: {
        const int n = count_digits<16>(uVal);
        WJR_TO_CHARS_VALIDATE_IMPL(16, (base_2_table + 3) / 4, (n, uVal));
    }
    case 4:
    case 32: {
        const int bits = base == 4 ? 2 : 5;
        const int n = count_digits<1>(uVal, bits);
        WJR_TO_CHARS_VALIDATE_IMPL(1, (base_2_table + 1) / 2, (n, uVal, bits));
    }
    case 10: {
        WJR_TO_CHARS_VALIDATE_IMPL(10, base_10_table, (uVal));
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

#undef WJR_TO_CHARS_VALIDATE_IMPL
}

template <typename Iter, typename Value, typename IBase, typename Converter>
to_chars_result<Iter> __to_chars_impl(Iter first, Iter last, Value val, IBase ibase,
                                      Converter conv) noexcept {
    if constexpr (charconv_detail::__is_fast_convert_iterator_v<Iter>) {
        const auto __first = reinterpret_cast<uint8_t *>(wjr::to_address(first));
        const auto __last = reinterpret_cast<uint8_t *>(wjr::to_address(last));
        const auto __result = __fast_to_chars_impl(__first, __last, val, ibase, conv);
        return {first + std::distance(__first, __result.ptr), __result.ec};
    } else {
        return __fallback_to_chars_impl(first, last, val, ibase, conv);
    }
}

template <typename Value, typename IBase, typename Converter>
uint8_t *__fast_to_chars_unchecked_impl(uint8_t *ptr, Value val, IBase ibase,
                                        Converter conv) noexcept {
    if (WJR_UNLIKELY(val == 0)) {
        *ptr++ = conv.template to<1>(0);
        return ptr;
    }

    auto uVal = to_unsigned(val);

    if constexpr (std::is_signed_v<Value>) {
        if (val < 0) {
            *ptr++ = '-';
            uVal = -val;
        }
    }

    const unsigned int base = ibase;

    switch (base) {
    case 2: {
        const int n = count_digits<2>(uVal);
        ptr += n;
        (void)__unsigned_to_chars_backward_unchecked<2>(ptr, n, uVal, conv);
        return ptr;
    }
    case 8: {
        const int n = count_digits<8>(uVal);
        ptr += n;
        (void)__unsigned_to_chars_backward_unchecked<8>(ptr, n, uVal, conv);
        return ptr;
    }
    case 16: {
        const int n = count_digits<16>(uVal);
        ptr += n;
        (void)__unsigned_to_chars_backward_unchecked<16>(ptr, n, uVal, conv);
        return ptr;
    }
    case 4:
    case 32: {
        const int bits = base == 4 ? 2 : 5;
        const int n = count_digits<1>(uVal, bits);
        ptr += n;
        (void)__unsigned_to_chars_backward_unchecked<1>(ptr, n, uVal, bits, conv);
        return ptr;
    }
    case 10: {
        const int n = count_digits<10>(uVal);
        ptr += n;
        (void)__unsigned_to_chars_backward_unchecked<10>(ptr, uVal, conv);
        return ptr;
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }
}

template <typename Iter, typename Value, typename IBase, typename Converter>
Iter __fallback_to_chars_unchecked_impl(Iter ptr, Value val, IBase ibase,
                                        Converter conv) noexcept {
    constexpr auto is_signed = std::is_signed_v<Value>;
    constexpr auto base_2_table = std::numeric_limits<Value>::digits;
    constexpr auto base_10_table = std::numeric_limits<Value>::digits10 + 1;

    if (WJR_UNLIKELY(val == 0)) {
        *ptr++ = conv.template to<1>(0);
        return ptr;
    }

    auto uVal = to_unsigned(val);
    int sign = 0;

    if constexpr (is_signed) {
        if (val < 0) {
            sign = 1;
            uVal = -val;
        }
    }

    const unsigned int base = ibase;

#define WJR_TO_CHARS_IMPL(BASE, TABLE, CALL)                                             \
    constexpr auto __fast_container_inserter_v =                                         \
        charconv_detail::is_fast_container_inserter_v<Iter>;                             \
    if constexpr (__fast_container_inserter_v != 0) {                                    \
        WJR_PP_BOOL_IF(WJR_PP_EQ(BASE, 10), const int n = count_digits<10>(uVal), );     \
        auto &cont = get_inserter_container(ptr);                                        \
        if constexpr (__fast_container_inserter_v == 1) {                                \
            resize(cont, cont.size() + n + sign);                                        \
        } else {                                                                         \
            append(cont, n + sign, dctor);                                               \
        }                                                                                \
        const auto __end = wjr::to_address(cont.data() + cont.size());                   \
        auto __ptr = (charconv_detail::fast_buffer_t<Iter> *)                            \
            __unsigned_to_chars_backward_unchecked<BASE>(                                \
                (uint8_t *)__end, WJR_PP_QUEUE_EXPAND(CALL), conv);                      \
                                                                                         \
        if constexpr (is_signed) {                                                       \
            if (sign) {                                                                  \
                *--__ptr = '-';                                                          \
            }                                                                            \
        }                                                                                \
                                                                                         \
        return ptr;                                                                      \
    } else {                                                                             \
        charconv_detail::fast_buffer_t<Iter> buffer[TABLE + is_signed];                  \
        const auto __end = buffer + TABLE + is_signed;                                   \
        auto __ptr = (charconv_detail::fast_buffer_t<Iter> *)                            \
            __unsigned_to_chars_backward_unchecked<BASE>(                                \
                (uint8_t *)__end, WJR_PP_QUEUE_EXPAND(CALL), conv);                      \
                                                                                         \
        if constexpr (is_signed) {                                                       \
            if (sign) {                                                                  \
                *--__ptr = '-';                                                          \
            }                                                                            \
        }                                                                                \
                                                                                         \
        return wjr::copy(__ptr, __end, ptr);                                             \
    }

    switch (base) {
    case 2: {
        const int n = count_digits<2>(uVal);
        WJR_TO_CHARS_IMPL(2, base_2_table, (n, uVal));
    }
    case 8: {
        const int n = count_digits<8>(uVal);
        WJR_TO_CHARS_IMPL(8, (base_2_table + 2) / 3, (n, uVal));
    }
    case 16: {
        const int n = count_digits<16>(uVal);
        WJR_TO_CHARS_IMPL(16, (base_2_table + 3) / 4, (n, uVal));
    }
    case 4:
    case 32: {
        const int bits = base == 4 ? 2 : 5;
        const int n = count_digits<1>(uVal, bits);
        WJR_TO_CHARS_IMPL(1, (base_2_table + 1) / 2, (n, uVal, bits));
    }
    case 10: {
        WJR_TO_CHARS_IMPL(10, base_10_table, (uVal));
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

#undef WJR_TO_CHARS_IMPL
}

template <typename Iter, typename Value, typename IBase, typename Converter>
Iter __to_chars_unchecked_impl(Iter ptr, Value val, IBase ibase,
                               Converter conv) noexcept {
    if constexpr (charconv_detail::__is_fast_convert_iterator_v<Iter>) {
        const auto __ptr = reinterpret_cast<uint8_t *>(wjr::to_address(ptr));
        const auto __result = __fast_to_chars_unchecked_impl(__ptr, val, ibase, conv);
        return ptr + std::distance(__ptr, __result);
    } else {
        return __fallback_to_chars_unchecked_impl(ptr, val, ibase, conv);
    }
}
/**
 * @brief Convert an unsigned integer to a string with checking buf size.
 *
 *
 * @return to_chars_result<Iter> If the conversion is successful, return {ans,
 * std::errc{}}. Otherwise, return {last, std::errc::value_too_large}.
 *
 */
template <typename Iter, typename Value, unsigned int IBase = 10,
          typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_valid_converter_v<Value, Converter>)>
to_chars_result<Iter> to_chars(Iter ptr, Iter last, Value val,
                               integral_constant<unsigned int, IBase> ic = {},
                               Converter conv = {}) noexcept {
    return __to_chars_impl(ptr, last, val, ic, conv);
}

template <typename Iter, typename Value, typename Converter>
to_chars_result<Iter> to_chars_dynamic(Iter ptr, Iter last, Value val, unsigned int base,
                                       Converter conv) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(base)) {
        switch (base) {
        case 2: {
            return to_chars(ptr, last, val, 2_u, conv);
        }
        case 8: {
            return to_chars(ptr, last, val, 8_u, conv);
        }
        case 16: {
            return to_chars(ptr, last, val, 16_u, conv);
        }
        case 10: {
            return to_chars(ptr, last, val, 10_u, conv);
        }
        default: {
            break;
        }
        }
    }

    return __to_chars_impl(ptr, last, val, base, conv);
}

/**
 * @brief Convert an unsigned integer to a string with checking buf size.
 *
 * @return to_chars_result<Iter> If the conversion is successful, return {ans,
 * std::errc{}}. Otherwise, return {last, std::errc::value_too_large}.
 *
 */
template <typename Iter, typename Value, typename IBase,
          typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_valid_converter_v<Value, Converter>
                           &&is_nonbool_integral_v<IBase>)>
to_chars_result<Iter> to_chars(Iter ptr, Iter last, Value val, IBase base,
                               Converter conv = {}) noexcept {
    return to_chars_dynamic(ptr, last, val, static_cast<unsigned int>(base), conv);
}

/**
 * @brief Convert an unsigned integer to a string without checking buf size.
 *
 * @details Iter can be any output iterator. Support fast_convert mode and fallback mode.
 * \n fast_convert mode : \n fast_convert mode is used when
 * __is_fast_convert_iterator_v<Iter> is true. \n caclulate the number of digits and
 * convert the integer to a string in reverse order. \n fallback mode : \n use buffer to
 * store the result and use @ref wjr::copy to copy the result to the output iterator. \n
 *
 */
template <typename Iter, typename Value, unsigned int IBase = 10,
          typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_valid_converter_v<Value, Converter>)>
Iter to_chars_unchecked(Iter ptr, Value val,
                        integral_constant<unsigned int, IBase> ic = {},
                        Converter conv = {}) noexcept {
    return __to_chars_unchecked_impl(ptr, val, ic, conv);
}

template <typename Iter, typename Value, typename Converter>
Iter to_chars_unchecked_dynamic(Iter ptr, Value val, unsigned int base,
                                Converter conv) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(base)) {
        switch (base) {
        case 2: {
            return to_chars_unchecked(ptr, val, 2_u, conv);
        }
        case 8: {
            return to_chars_unchecked(ptr, val, 8_u, conv);
        }
        case 16: {
            return to_chars_unchecked(ptr, val, 16_u, conv);
        }
        case 10: {
            return to_chars_unchecked(ptr, val, 10_u, conv);
        }
        default: {
            break;
        }
        }
    }

    return __to_chars_unchecked_impl(ptr, val, base, conv);
}

/**
 * @brief Convert an unsigned integer to a string without checking buf size.
 *
 * @tparam Iter The iterator type. Must be random access iterator.
 * @tparam Value The value type. If Converter is origin_converter_t, Value must be
 * non-bool unsigned integral type. Otherwise, Value must be non-bool integral type.
 *
 */
template <typename Iter, typename Value, typename IBase,
          typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_valid_converter_v<Value, Converter>
                           &&is_nonbool_integral_v<IBase>)>
Iter to_chars_unchecked(Iter ptr, Value val, IBase base, Converter conv = {}) noexcept {
    return to_chars_unchecked_dynamic(ptr, val, static_cast<unsigned int>(base), conv);
}

template <uint64_t Base>
class __unsigned_from_chars_unchecked_fn {};

template <uint64_t Base>
inline constexpr __unsigned_from_chars_unchecked_fn<Base>
    __unsigned_from_chars_unchecked{};

template <>
class __unsigned_from_chars_unchecked_fn<2> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE void operator()(const uint8_t *first, const uint8_t *last,
                                         UnsignedValue &val,
                                         Converter conv) const noexcept {
        constexpr auto nd = std::numeric_limits<UnsignedValue>::digits;

        auto n = std::distance(first, last);
        WJR_ASSERT_ASSUME(1 <= n && n <= nd);

        if constexpr (nd >= 16) {
            if (WJR_UNLIKELY(n >= 8)) {
                do {
                    val = (val << 8) + __from_chars_unroll_8<2>(first, conv);
                    first += 8;
                    n -= 8;
                } while (WJR_LIKELY(n >= 8));

                if (n == 0) {
                    return;
                }
            }
        } else if constexpr (nd == 8) {
            if (WJR_UNLIKELY(n == 8)) {
                val = __from_chars_unroll_8<2>(first, conv);
                first += 8;
                return;
            }
        }

        switch (n) {
        case 7: {
            val = (val << 1) + conv.template from<2>(*first++);
            WJR_FALLTHROUGH;
        }
        case 6: {
            val = (val << 1) + conv.template from<2>(*first++);
            WJR_FALLTHROUGH;
        }
        case 5: {
            val = (val << 1) + conv.template from<2>(*first++);
            WJR_FALLTHROUGH;
        }
        case 4: {
            val <<= 4;
            val += __from_chars_unroll_4<2>(first, conv);
            first += 4;
            break;
        }
        case 3: {
            val = (val << 1) + conv.template from<2>(*first++);
            WJR_FALLTHROUGH;
        }
        case 2: {
            val = (val << 1) + conv.template from<2>(*first++);
            WJR_FALLTHROUGH;
        }
        case 1: {
            val = (val << 1) + conv.template from<2>(*first++);
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }
    }
};

template <>
class __unsigned_from_chars_unchecked_fn<8> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE void operator()(const uint8_t *first, const uint8_t *last,
                                         UnsignedValue &val,
                                         Converter conv) const noexcept {
        constexpr auto nd = std::numeric_limits<UnsignedValue>::digits;

        auto n = std::distance(first, last);
        WJR_ASSERT_ASSUME(1 <= n && n <= (nd + 2) / 3);

        if constexpr (nd >= 32) {
            if (WJR_UNLIKELY(n >= 8)) {
                do {
                    val = (val << 24) + __from_chars_unroll_8<8>(first, conv);
                    first += 8;
                    n -= 8;
                } while (WJR_LIKELY(n >= 8));

                if (n == 0) {
                    return;
                }
            }
        }

        switch (n) {
        case 7: {
            val = (val << 3) + conv.template from<8>(*first++);
            WJR_FALLTHROUGH;
        }
        case 6: {
            val = (val << 3) + conv.template from<8>(*first++);
            WJR_FALLTHROUGH;
        }
        case 5: {
            val = (val << 3) + conv.template from<8>(*first++);
            WJR_FALLTHROUGH;
        }
        case 4: {
            val <<= 12;
            val += __from_chars_unroll_4<8>(first, conv);
            first += 4;
            break;
        }
        case 3: {
            val = (val << 3) + conv.template from<8>(*first++);
            WJR_FALLTHROUGH;
        }
        case 2: {
            val = (val << 3) + conv.template from<8>(*first++);
            WJR_FALLTHROUGH;
        }
        case 1: {
            val = (val << 3) + conv.template from<8>(*first++);
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }
    }
};

template <>
class __unsigned_from_chars_unchecked_fn<16> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE void operator()(const uint8_t *first, const uint8_t *last,
                                         UnsignedValue &val,
                                         Converter conv) const noexcept {
        constexpr auto nd = std::numeric_limits<UnsignedValue>::digits;

        auto n = std::distance(first, last);
        WJR_ASSERT_ASSUME(1 <= n && n <= (nd + 3) / 4);

        if constexpr (nd >= 64) {
            if (WJR_UNLIKELY(n >= 8)) {
                do {
                    val = (val << 32) + __from_chars_unroll_8<16>(first, conv);
                    first += 8;
                    n -= 8;
                } while (WJR_LIKELY(n >= 8));

                if (n == 0) {
                    return;
                }
            }
        } else if constexpr (nd == 32) {
            if (WJR_UNLIKELY(n == 8)) {
                val = __from_chars_unroll_8<16>(first, conv);
                first += 8;
                return;
            }
        }

        switch (n) {
        case 7: {
            val = (val << 4) + conv.template from<16>(*first++);
            WJR_FALLTHROUGH;
        }
        case 6: {
            val = (val << 4) + conv.template from<16>(*first++);
            WJR_FALLTHROUGH;
        }
        case 5: {
            val = (val << 4) + conv.template from<16>(*first++);
            WJR_FALLTHROUGH;
        }
        case 4: {
            val <<= 16;
            val += __from_chars_unroll_4<16>(first, conv);
            first += 4;
            break;
        }
        case 3: {
            val = (val << 4) + conv.template from<16>(*first++);
            WJR_FALLTHROUGH;
        }
        case 2: {
            val = (val << 4) + conv.template from<16>(*first++);
            WJR_FALLTHROUGH;
        }
        case 1: {
            val = (val << 4) + conv.template from<16>(*first++);
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }
    }
};

template <>
class __unsigned_from_chars_unchecked_fn<1> {};

template <>
class __unsigned_from_chars_unchecked_fn<10> {
public:
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE void operator()(const uint8_t *first, const uint8_t *last,
                                         UnsignedValue &val,
                                         Converter conv) const noexcept {
        constexpr auto nd = std::numeric_limits<UnsignedValue>::digits10 + 1;

        const auto n = std::distance(first, last);
        WJR_ASSUME(1 <= n && n <= nd);

        if constexpr (nd >= 8) {
            if (WJR_UNLIKELY(n >= 8)) {

                if constexpr (nd >= 16) {
                    if (WJR_UNLIKELY(n >= 16)) {
                        val = __from_chars_unroll_16<10>(first, conv);

                        if (n >= 19) {
                            val = val * 10 + conv.template from<10>(first[16]);
                            val = val * 10 + conv.template from<10>(first[17]);
                            val = val * 10 + conv.template from<10>(first[18]);

                            if (n == 19) {
                                return;
                            }

                            val = val * 10 + conv.template from<10>(first[19]);
                            return;
                        }

                        if (n == 16) {
                            return;
                        }

                        val = val * 10 + conv.template from<10>(first[16]);

                        if (n == 17) {
                            return;
                        }

                        val = val * 10 + conv.template from<10>(first[17]);
                        return;
                    }
                }

                val = __from_chars_unroll_8<10>(first, conv);

                if (WJR_UNLIKELY(n >= 12)) {
                    val = (val * 10000) + __from_chars_unroll_4<10>(first + 8, conv);

                    if (n == 12) {
                        return;
                    }

                    val = val * 10 + conv.template from<10>(first[12]);

                    if (n == 13) {
                        return;
                    }

                    val = val * 10 + conv.template from<10>(first[13]);

                    if (n == 14) {
                        return;
                    }

                    val = val * 10 + conv.template from<10>(first[14]);
                    return;
                }

                if (n == 8) {
                    return;
                }

                val = val * 10 + conv.template from<10>(first[8]);

                if (n == 9) {
                    return;
                }

                val = val * 10 + conv.template from<10>(first[9]);

                if (n == 10) {
                    return;
                }

                val = val * 10 + conv.template from<10>(first[10]);
                return;
            }
        }

        if (WJR_UNLIKELY(n >= 4)) {
            val = __from_chars_unroll_4<10>(first, conv);

            if (n == 4) {
                return;
            }

            val = val * 10 + conv.template from<10>(first[4]);

            if (n == 5) {
                return;
            }

            val = val * 10 + conv.template from<10>(first[5]);

            if (n == 6) {
                return;
            }

            val = val * 10 + conv.template from<10>(first[6]);
            return;
        }

        val = conv.template from<10>(first[0]);

        if (n == 1) {
            return;
        }

        val = val * 10 + conv.template from<10>(first[1]);

        if (n == 2) {
            return;
        }

        val = val * 10 + conv.template from<10>(first[2]);
    }
};

template <typename Value, typename IBase, typename Converter>
void __fast_from_chars_unchecked_impl(const uint8_t *first, const uint8_t *last,
                                      Value &val, IBase ibase, Converter conv) noexcept {
    int sign = 0;

    if constexpr (std::is_signed_v<Value>) {
        WJR_ASSERT(first != last);

        if (*first == '-') {
            ++first;
            sign = 1;
        }
    }

    std::make_unsigned_t<Value> uVal = 0;

    const unsigned int base = ibase;

    switch (base) {
    case 2: {
        __unsigned_from_chars_unchecked<2>(first, last, uVal, conv);
        break;
    }
    case 8: {
        __unsigned_from_chars_unchecked<8>(first, last, uVal, conv);
        break;
    }
    case 16: {
        __unsigned_from_chars_unchecked<16>(first, last, uVal, conv);
        break;
    }
    case 10: {
        __unsigned_from_chars_unchecked<10>(first, last, uVal, conv);
        break;
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

    if (sign) {
        val = -static_cast<Value>(uVal);
    } else {
        val = static_cast<Value>(uVal);
    }
}

template <typename Iter, typename Value, typename IBase, typename Converter>
void __from_chars_unchecked_impl(Iter first, Iter last, Value &val, IBase ibase,
                                 Converter conv) noexcept {
    const auto __first = reinterpret_cast<const uint8_t *>(wjr::to_address(first));
    const auto __last = reinterpret_cast<const uint8_t *>(wjr::to_address(last));
    __fast_from_chars_unchecked_impl(__first, __last, val, ibase, conv);
}

template <typename Iter, typename Value, unsigned int IBase = 10,
          typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_fast_convert_iterator_v<Iter>
                           &&charconv_detail::__is_valid_converter_v<Value, Converter>)>
void from_chars_unchecked(Iter first, Iter last, Value &val,
                          integral_constant<unsigned int, IBase> ic = {},
                          Converter conv = {}) noexcept {
    __from_chars_unchecked_impl(first, last, val, ic, conv);
}

template <typename Iter, typename Value, typename IBase, typename Converter>
void from_chars_unchecked_dynamic(Iter first, Iter last, Value &val, unsigned int base,
                                  Converter conv) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(base)) {
        switch (base) {
        case 2: {
            __from_chars_unchecked_impl(first, last, val, 2_u, conv);
            return;
        }
        case 8: {
            __from_chars_unchecked_impl(first, last, val, 8_u, conv);
            return;
        }
        case 16: {
            __from_chars_unchecked_impl(first, last, val, 16_u, conv);
            return;
        }
        case 10: {
            __from_chars_unchecked_impl(first, last, val, 10_u, conv);
            return;
        }
        default: {
            break;
        }
        }
    }

    __from_chars_unchecked_impl(first, last, val, base, conv);
}

template <typename Iter, typename Value, typename IBase,
          typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_fast_convert_iterator_v<Iter>
                           &&charconv_detail::__is_valid_converter_v<Value, Converter>
                               &&is_nonbool_integral_v<IBase>)>
void from_chars_unchecked(Iter first, Iter last, Value &val, IBase base,
                          Converter conv = {}) noexcept {
    from_chars_unchecked_dynamic(first, last, val, static_cast<unsigned int>(base), conv);
}

template <uint64_t Base>
struct __unsigned_from_chars_fn {};

/** @todo Can be optimized. */
template <uint64_t Base>
inline constexpr __unsigned_from_chars_fn<Base> __unsigned_from_chars{};

template <>
struct __unsigned_from_chars_fn<2> {
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE from_chars_result<const uint8_t *>
    operator()(const uint8_t *first, const uint8_t *last, UnsignedValue &value,
               Converter conv) const noexcept {
        constexpr auto nd = std::numeric_limits<UnsignedValue>::digits;
        constexpr auto zero = conv.template to<2>(0);
        constexpr auto one = conv.template to<2>(1);

        WJR_ASSERT_ASSUME(first != last);

        uint8_t ch = *first;

        // The probability that the first character is 1 is greater than 0
        if (ch != one) {
            if (WJR_UNLIKELY(ch != zero)) {
                return {{}, std::errc::invalid_argument};
            }

            do {
                ++first;
                if (first == last) {
                    value = 0;
                    return {first, std::errc{}};
                }

                ch = *first;
            } while (ch == zero);

            if (ch != one) {
                value = 0;
                return {first, std::errc{}};
            }
        }

        const auto __first = first;

        ++first;
        value = 1;

        if (WJR_UNLIKELY(first == last)) {
            return {first, std::errc{}};
        }

        ch = conv.template from<2>(*first);

        if (WJR_UNLIKELY(ch >= 2)) {
            return {first, std::errc{}};
        }

        do {
            ++first;
            value = value << 1 | ch;

            if (first == last) {
                break;
            }

            ch = conv.template from<2>(*first);
        } while (ch < 2);

        if (WJR_LIKELY(first - __first <= nd)) {
            return {first, std::errc{}};
        }

        return {first, std::errc::result_out_of_range};
    }
};

template <>
struct __unsigned_from_chars_fn<10> {
    template <typename UnsignedValue, typename Converter>
    WJR_INTRINSIC_INLINE from_chars_result<const uint8_t *>
    operator()(const uint8_t *first, const uint8_t *last, UnsignedValue &value,
               Converter conv) const noexcept {
        constexpr auto zero = conv.template to<10>(0);
        constexpr auto nine = conv.template to<10>(9);

        constexpr auto __try_match = [](uint8_t &ch) {
            if constexpr (zero != 0) {
                ch -= zero;
                return ch <= nine;
            } else {
                return ch <= nine;
            }
        };

        constexpr auto __match = [](uint8_t ch) {
            if constexpr (zero != 0) {
                return zero <= ch && ch <= nine;
            } else {
                return ch <= nine;
            }
        };

        WJR_ASSERT_ASSUME(first != last);

        uint8_t ch = *first;

        // Clear all leading zeros
        if (WJR_UNLIKELY(!__try_match(ch))) {
            return {{}, std::errc::invalid_argument};
        }

        value = 0;

        if (WJR_UNLIKELY(ch == 0)) {
            // this is a optimization for Clang to reduce code size.

            goto LOOP_HEAD;

            do {
                ch = *first;
                if (ch != zero) {
                    goto LOOP_END;
                }

            LOOP_HEAD:
                ++first;
            } while (first != last);
            return {first, std::errc{}};
        LOOP_END:

            if (!__try_match(ch)) {
                return {first, std::errc{}};
            }
        }

        do {
            ++first;
            if (WJR_UNLIKELY(mul_overflow(value, 10, value) ||
                             add_overflow(value, ch, value))) {
                while (first != last && __match(*first)) {
                    ++first;
                }

                return {first, std::errc::result_out_of_range};
            }

            if (first == last) {
                break;
            }

            ch = *first;
        } while (__try_match(ch));

        return {first, std::errc{}};
    }
};

template <typename Value, typename IBase, typename Converter>
WJR_INTRINSIC_INLINE from_chars_result<const uint8_t *>
__fast_from_chars_impl(const uint8_t *first, const uint8_t *last, Value &val, IBase ibase,
                       Converter conv) noexcept {
    constexpr auto is_signed = std::is_signed_v<Value>;

    if (WJR_UNLIKELY(first == last)) {
        return {first, std::errc::invalid_argument};
    }

    int sign = 0;

    if constexpr (is_signed) {
        if (*first == '-') {
            sign = 1;
            if (++first == last) {
                return {first, std::errc::invalid_argument};
            }
        }
    }

    using UnsignedValue = std::make_unsigned_t<Value>;
    UnsignedValue uVal;

    from_chars_result<const uint8_t *> ret;

    const unsigned int base = ibase;
    switch (base) {
    case 2: {
        ret = __unsigned_from_chars<2>(first, last, uVal, conv);
        break;
    }
    case 10: {
        ret = __unsigned_from_chars<10>(first, last, uVal, conv);
        break;
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

    if (WJR_LIKELY(ret)) {
        if constexpr (is_signed) {
            if (sign) {
                if (uVal >
                    static_cast<UnsignedValue>(std::numeric_limits<Value>::min())) {
                    ret.ec = std::errc::result_out_of_range;
                } else {
                    val = -static_cast<Value>(uVal);
                }
            } else {
                if (uVal >
                    static_cast<UnsignedValue>(std::numeric_limits<Value>::max())) {
                    ret.ec = std::errc::result_out_of_range;
                } else {
                    val = static_cast<Value>(uVal);
                }
            }
        } else {
            val = uVal;
        }
    } else if (ret.ec == std::errc::invalid_argument) {
        ret.ptr = first;
    }

    return ret;
}

template <typename Value, typename IBase, typename Converter>
WJR_INTRINSIC_INLINE from_chars_result<const char *>
__from_chars_impl(const char *first, const char *last, Value &val, IBase ibase,
                  Converter conv) noexcept {
    using type = usint_t<sizeof(Value) * 8, std::is_signed_v<Value>>;

    const auto __first = reinterpret_cast<const uint8_t *>(first);
    const auto __last = reinterpret_cast<const uint8_t *>(last);

    const auto ret = __fast_from_chars_impl(__first, __last,
                                            reinterpret_cast<type &>(val), ibase, conv);

    return {reinterpret_cast<const char *>(ret.ptr), ret.ec};
}

template <typename Value, unsigned int IBase = 10, typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_valid_converter_v<Value, Converter>)>
WJR_INTRINSIC_INLINE from_chars_result<const char *>
from_chars(const char *first, const char *last, Value &val,
           integral_constant<unsigned int, IBase> ic = {}, Converter conv = {}) noexcept {
    return __from_chars_impl(first, last, val, ic, conv);
}

template <typename Value, typename Converter,
          WJR_REQUIRES(charconv_detail::__is_valid_converter_v<Value, Converter>)>
from_chars_result<const char *> from_chars_dynamic(const char *first, const char *last,
                                                   Value &val, unsigned int base,
                                                   Converter conv) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(base)) {
        switch (base) {
        case 2: {
            return __from_chars_impl(first, last, val, 2_u, conv);
        }
        case 10: {
            return __from_chars_impl(first, last, val, 10_u, conv);
        }
        default: {
            break;
        }
        }
    }

    return __from_chars_impl(first, last, val, base, conv);
}

template <typename Value, typename IBase, typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_valid_converter_v<Value, Converter>
                           &&is_nonbool_integral_v<IBase>)>
from_chars_result<const char *> from_chars(const char *first, const char *last,
                                           Value &val, IBase base,
                                           Converter conv = {}) noexcept {
    return from_chars_dynamic(first, last, val, base, conv);
}

template <typename Converter>
struct __check_digits_helper {
    static constexpr uint8_t hi_expe8 =
        std::is_same_v<Converter, char_converter_t> ? 0x30 : 0x00;
    static constexpr uint32_t hi_expe32 = broadcast<uint8_t, uint32_t>(hi_expe8);
    static constexpr uint64_t hi_expe64 = broadcast<uint8_t, uint64_t>(hi_expe8);
};

template <branch type = branch::free>
struct check_eight_digits_fn {
private:
    template <typename Converter>
    WJR_PURE WJR_INTRINSIC_INLINE bool operator()(const char *ptr, unsigned int base,
                                                  Converter conv) const noexcept {
        WJR_ASSERT_L2(base <= 16);

        if (WJR_BUILTIN_CONSTANT_P(base)) {
            switch (base) {
            case 2: {
                return this->operator()(ptr, 2_u, conv);
            }
            case 8: {
                return this->operator()(ptr, 8_u, conv);
            }
            case 10: {
                return this->operator()(ptr, 10_u, conv);
            }
            case 16: {
                return this->operator()(ptr, 16_u, conv);
            }
            default: {
                break;
            }
            }
        }

        constexpr uint64_t mask = 0xF0F0F0F0'F0F0F0F0;
        constexpr uint64_t hi_expe64 = __check_digits_helper<Converter>::hi_expe64;

        const uint64_t added = broadcast<uint8_t, uint64_t>(16 - base);
        const uint64_t memory = read_memory<uint64_t>(ptr);

        return (memory & (memory + added) & mask) == hi_expe64;
    }

public:
    template <unsigned int IBase = 10, typename Converter = char_converter_t,
              WJR_REQUIRES(IBase <= 16)>
    WJR_PURE WJR_INTRINSIC_INLINE bool
    operator()(const char *ptr, integral_constant<unsigned int, IBase> = {},
               Converter = {}) const noexcept {
        constexpr uint64_t mask = 0xF0F0F0F0'F0F0F0F0;
        constexpr uint64_t added = broadcast<uint8_t, uint64_t>(16 - IBase);
        constexpr uint64_t hi_expe64 = __check_digits_helper<Converter>::hi_expe64;

        const uint64_t memory = read_memory<uint64_t>(ptr);

        return (memory & (memory + added) & mask) == hi_expe64;
    }

    template <typename IBase, typename Converter = char_converter_t,
              WJR_REQUIRES(is_nonbool_integral_v<IBase>)>
    WJR_PURE WJR_INTRINSIC_INLINE bool operator()(const char *ptr, IBase base,
                                                  Converter conv = {}) const noexcept {

        return this->operator()(ptr, base, conv);
    }
};

template <>
struct check_eight_digits_fn<branch::full> {
private:
    template <typename Converter>
    WJR_PURE WJR_INTRINSIC_INLINE bool operator()(const char *ptr, unsigned int base,
                                                  Converter conv) const noexcept {
        WJR_ASSERT_L2(base <= 16);

        if (WJR_BUILTIN_CONSTANT_P(base)) {
            switch (base) {
            case 2: {
                return this->operator()(ptr, 2_u, conv);
            }
            case 8: {
                return this->operator()(ptr, 8_u, conv);
            }
            case 10: {
                return this->operator()(ptr, 10_u, conv);
            }
            case 16: {
                return this->operator()(ptr, 16_u, conv);
            }
            default: {
                break;
            }
            }
        }

        constexpr uint64_t mask = 0xF0F0F0F0'F0F0F0F0;
        constexpr uint64_t hi_expe64 = __check_digits_helper<Converter>::hi_expe64;

        const uint64_t added = broadcast<uint8_t, uint64_t>(16 - base);
        const uint64_t memory = read_memory<uint64_t>(ptr);

        return (memory & mask) == hi_expe64 && ((memory + added) & mask) == hi_expe64;
    }

public:
    template <unsigned int IBase = 10, typename Converter = char_converter_t,
              WJR_REQUIRES(IBase <= 16)>
    WJR_PURE WJR_INTRINSIC_INLINE bool
    operator()(const char *ptr, integral_constant<unsigned int, IBase> = {},
               Converter = {}) const noexcept {
        constexpr uint64_t mask = 0xF0F0F0F0'F0F0F0F0;
        constexpr uint64_t added = broadcast<uint8_t, uint64_t>(16 - IBase);
        constexpr uint64_t hi_expe64 = __check_digits_helper<Converter>::hi_expe64;

        const uint64_t memory = read_memory<uint64_t>(ptr);

        return (memory & mask) == hi_expe64 && ((memory + added) & mask) == hi_expe64;
    }

    template <typename IBase, typename Converter = char_converter_t,
              WJR_REQUIRES(is_nonbool_integral_v<IBase>)>
    WJR_PURE WJR_INTRINSIC_INLINE bool operator()(const char *ptr, IBase base,
                                                  Converter conv = {}) const noexcept {

        return this->operator()(ptr, base, conv);
    }
};

template <branch type>
inline constexpr check_eight_digits_fn<type> check_eight_digits{};

} // namespace wjr

#endif // WJR_FORMAT_CHARCONV_HPP__

#ifndef WJR_MATH_DIV_HPP__
#define WJR_MATH_DIV_HPP__

#ifndef WJR_MATH_UINT128_T_HPP__
#define WJR_MATH_UINT128_T_HPP__

#ifndef WJR_MATH_DIV_IMPL_HPP__
#define WJR_MATH_DIV_IMPL_HPP__

#include <utility>

// Already included

namespace wjr {

template <typename T>
class div2by1_divider;

template <typename T>
class div3by2_divider;

template <typename T>
class divexact1_divider;

class uint128_t;

WJR_INLINE_CONSTEXPR20 uint64_t
div128by64to64(uint64_t &rem, uint64_t lo, uint64_t hi,
               const div2by1_divider<uint64_t> &divider) noexcept;

WJR_INLINE_CONSTEXPR20 uint64_t div128by64to64(uint64_t &rem, uint64_t lo, uint64_t hi,
                                               uint64_t div) noexcept;

inline uint128_t div128by64to128(uint64_t &rem, uint64_t lo, uint64_t hi,
                                 const div2by1_divider<uint64_t> &divider) noexcept;

inline uint128_t div128by64to128(uint64_t &rem, uint64_t lo, uint64_t hi,
                                 uint64_t div) noexcept;

WJR_INTRINSIC_INLINE void div_qr_1(uint64_t *dst, uint64_t &rem, const uint64_t *src,
                                   size_t n,
                                   const div2by1_divider<uint64_t> &div) noexcept;

WJR_INTRINSIC_INLINE void div_qr_1(uint64_t *dst, uint64_t &rem, const uint64_t *src,
                                   size_t n, uint64_t div) noexcept;

WJR_INTRINSIC_INLINE void div_qr_2(uint64_t *dst, uint64_t *rem, const uint64_t *src,
                                   size_t n,
                                   const div3by2_divider<uint64_t> &div) noexcept;

WJR_INTRINSIC_INLINE void div_qr_2(uint64_t *dst, uint64_t *rem, const uint64_t *src,
                                   size_t n, const uint64_t *div) noexcept;

WJR_INTRINSIC_INLINE void div_qr_s(uint64_t *dst, uint64_t *rem, const uint64_t *src,
                                   size_t n, const uint64_t *div, size_t m) noexcept;

WJR_INTRINSIC_CONSTEXPR20 uint64_t divexact_dbm1c(uint64_t *dst, const uint64_t *src,
                                                  size_t n, uint64_t bd,
                                                  uint64_t h) noexcept;

WJR_INTRINSIC_CONSTEXPR20 void divexact_dbm1c_shift(uint64_t *dst, const uint64_t *src,
                                                    size_t n, uint64_t bd, uint64_t cl,
                                                    uint64_t hicf) noexcept;

template <uint64_t c>
WJR_INTRINSIC_CONSTEXPR20 void divexact_byc(uint64_t *dst, const uint64_t *src, size_t n,
                                            integral_constant<uint64_t, c>,
                                            WJR_MAYBE_UNUSED uint64_t cf) noexcept;

WJR_INTRINSIC_CONSTEXPR20 void
divexact_1(uint64_t *dst, const uint64_t *src, size_t n,
           const divexact1_divider<uint64_t> &div) noexcept;

WJR_INTRINSIC_CONSTEXPR20 void divexact_1(uint64_t *dst, const uint64_t *src, size_t n,
                                          uint64_t div) noexcept;

WJR_PURE WJR_INTRINSIC_CONSTEXPR20 uint64_t
mod_1(const uint64_t *src, size_t n, const div2by1_divider<uint64_t> &div) noexcept;

WJR_PURE WJR_INTRINSIC_CONSTEXPR20 uint64_t mod_1(const uint64_t *src, size_t n,
                                                  uint64_t div) noexcept;

} // namespace wjr

#endif // WJR_MATH_DIV_IMPL_HPP__
#ifndef WJR_MATH_DIVIDER_HPP__
#define WJR_MATH_DIVIDER_HPP__

#include <array>

#ifndef WJR_MATH_CMP_HPP__
#define WJR_MATH_CMP_HPP__

// Already included
// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_COMPARE_HPP__
#define WJR_X86_MATH_COMPARE_HPP__

#ifndef WJR_X86_MATH_LARGE_COMPARE_IMPL_HPP__
#define WJR_X86_MATH_LARGE_COMPARE_IMPL_HPP__

// Already included
// Already included
// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

namespace wjr {

#if WJR_HAS_SIMD(SSE4_1)
#define WJR_HAS_BUILTIN_COMPARE_N WJR_HAS_DEF
#define WJR_HAS_BUILTIN_REVERSE_COMPARE_N WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(COMPARE_N)

/**
 * @brief Use SIMD to compare two arrays of uint64_t.
 *
 */
template <typename T>
WJR_PURE int large_builtin_compare_n(const T *src0, const T *src1, size_t n) noexcept {
#define WJR_REGISTER_COMPARE_NOT_N_2(index)                                              \
    do {                                                                                 \
        const auto x = sse::loadu(src0 + (index));                                       \
        const auto y = sse::loadu(src1 + (index));                                       \
        const auto r = sse::cmpeq_epi64(x, y);                                           \
                                                                                         \
        const sse::mask_type mask = ~sse::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            if (mask == 0xFF00) {                                                        \
                return src0[(index) + 1] < src1[(index) + 1] ? -1 : 1;                   \
            }                                                                            \
            return src0[index] < src1[index] ? -1 : 1;                                   \
        }                                                                                \
    } while (0)

#if WJR_HAS_SIMD(AVX2)
#define WJR_REGISTER_COMPARE_NOT_N_4(index)                                              \
    do {                                                                                 \
        const auto x = avx::loadu(src0 + (index));                                       \
        const auto y = avx::loadu(src1 + (index));                                       \
        const auto r = avx::cmpeq_epi64(x, y);                                           \
                                                                                         \
        const avx::mask_type mask = ~avx::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            const auto offset = ctz(mask) / 8;                                           \
            return src0[(index) + offset] < src1[(index) + offset] ? -1 : 1;             \
        }                                                                                \
    } while (0)
#else
#define WJR_REGISTER_COMPARE_NOT_N_4(index)                                              \
    WJR_REGISTER_COMPARE_NOT_N_2(index);                                                 \
    WJR_REGISTER_COMPARE_NOT_N_2((index) + 2)
#endif

#define WJR_REGISTER_COMPARE_NOT_N_ADVANCE(index)                                        \
    src0 += index;                                                                       \
    src1 += index
#define WJR_REGISTER_COMPARE_NOT_N_RET(index) 0

    WJR_ASSUME(n > 2);

    WJR_REGISTER_X86_NORMAL_SIMD_FUNCTION(
        n, WJR_REGISTER_COMPARE_NOT_N_2, WJR_REGISTER_COMPARE_NOT_N_4, WJR_HAS_SIMD(AVX2),
        WJR_REGISTER_COMPARE_NOT_N_ADVANCE, , WJR_REGISTER_COMPARE_NOT_N_RET);

#if !WJR_HAS_SIMD(AVX2)
    do {
        const auto r0 = sse::cmpeq_epi64(sse::loadu(src0), sse::loadu(src1));
        const auto r1 = sse::cmpeq_epi64(sse::loadu(src0 + 2), sse::loadu(src1 + 2));
        const auto r2 = sse::cmpeq_epi64(sse::loadu(src0 + 4), sse::loadu(src1 + 4));
        const auto r3 = sse::cmpeq_epi64(sse::loadu(src0 + 6), sse::loadu(src1 + 6));

        const auto z = sse::And(sse::And(r0, r1), sse::And(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_ones(z))) {
            sse::mask_type mask = ~sse::movemask_epi8(r0);
            if (mask != 0) {
                if (mask == 0xFF00) {
                    return src0[1] < src1[1] ? -1 : 1;
                }
                return src0[0] < src1[0] ? -1 : 1;
            }

            mask = ~sse::movemask_epi8(r1);
            if (mask != 0) {
                if (mask == 0xFF00) {
                    return src0[3] < src1[3] ? -1 : 1;
                }
                return src0[2] < src1[2] ? -1 : 1;
            }

            mask = ~sse::movemask_epi8(r2);
            if (mask != 0) {
                if (mask == 0xFF00) {
                    return src0[5] < src1[5] ? -1 : 1;
                }
                return src0[4] < src1[4] ? -1 : 1;
            }

            mask = ~sse::movemask_epi8(r3);
            if (mask == 0xFF00) {
                return src0[7] < src1[7] ? -1 : 1;
            }
            return src0[6] < src1[6] ? -1 : 1;
        }

        src0 += 8;
        src1 += 8;
        n -= 8;
    } while (WJR_LIKELY(n != 0));
#else
    do {
        const auto r0 = avx::cmpeq_epi64(avx::loadu(src0), avx::loadu(src1));
        const auto r1 = avx::cmpeq_epi64(avx::loadu(src0 + 4), avx::loadu(src1 + 4));
        const auto r2 = avx::cmpeq_epi64(avx::loadu(src0 + 8), avx::loadu(src1 + 8));
        const auto r3 = avx::cmpeq_epi64(avx::loadu(src0 + 12), avx::loadu(src1 + 12));

        const auto z = avx::And(avx::And(r0, r1), avx::And(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_ones(z))) {
            avx::mask_type mask = ~avx::movemask_epi8(r0);
            if (mask != 0) {
                const auto offset = ctz(mask) / 8;
                return src0[offset] < src1[offset] ? -1 : 1;
            }

            mask = ~avx::movemask_epi8(r1);
            if (mask != 0) {
                const auto offset = ctz(mask) / 8;
                return src0[offset + 4] < src1[offset + 4] ? -1 : 1;
            }

            mask = ~avx::movemask_epi8(r2);
            if (mask != 0) {
                const auto offset = ctz(mask) / 8;
                return src0[offset + 8] < src1[offset + 8] ? -1 : 1;
            }

            mask = ~avx::movemask_epi8(r3);
            const auto offset = ctz(mask) / 8;
            return src0[offset + 12] < src1[offset + 12] ? -1 : 1;
        }

        src0 += 16;
        src1 += 16;
        n -= 16;
    } while (WJR_LIKELY(n != 0));
#endif

    return 0;

#undef WJR_REGISTER_COMPARE_NOT_N_RET
#undef WJR_REGISTER_COMPARE_NOT_N_ADVANCE
#undef WJR_REGISTER_COMPARE_NOT_N_4
#undef WJR_REGISTER_COMPARE_NOT_N_2
}

extern template WJR_PURE int large_builtin_compare_n<uint64_t>(const uint64_t *src0,
                                                               const uint64_t *src1,
                                                               size_t n) noexcept;

#endif

#if WJR_HAS_BUILTIN(REVERSE_COMPARE_N)

/**
 * @brief Use SIMD to compare two arrays of uint64_t in reverse order.
 *
 * @details @ref large_builtin_compare_n in reverse order.
 *
 */
template <typename T>
WJR_PURE int large_builtin_reverse_compare_n(const T *src0, const T *src1,
                                             size_t n) noexcept {
#define WJR_REGISTER_REVERSE_COMPARE_NOT_N_2(index)                                      \
    do {                                                                                 \
        const auto x = sse::loadu(src0 + (index));                                       \
        const auto y = sse::loadu(src1 + (index));                                       \
        const auto r = sse::cmpeq_epi64(x, y);                                           \
                                                                                         \
        const sse::mask_type mask = ~sse::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            if (mask == 0x00FF) {                                                        \
                return src0[index] < src1[index] ? -1 : 1;                               \
            }                                                                            \
            return src0[(index) + 1] < src1[(index) + 1] ? -1 : 1;                       \
        }                                                                                \
    } while (0)

#if WJR_HAS_SIMD(AVX2)
#define WJR_REGISTER_REVERSE_COMPARE_NOT_N_4(index)                                      \
    do {                                                                                 \
        const auto x = avx::loadu(src0 + (index));                                       \
        const auto y = avx::loadu(src1 + (index));                                       \
        const auto r = avx::cmpeq_epi64(x, y);                                           \
                                                                                         \
        const avx::mask_type mask = ~avx::movemask_epi8(r);                              \
        if (WJR_UNLIKELY(mask != 0)) {                                                   \
            const auto offset = clz(mask) / 8;                                           \
            return src0[(index) + 3 - offset] < src1[(index) + 3 - offset] ? -1 : 1;     \
        }                                                                                \
    } while (0)
#else
#define WJR_REGISTER_REVERSE_COMPARE_NOT_N_4(index)                                      \
    WJR_REGISTER_REVERSE_COMPARE_NOT_N_2((index) + 2);                                   \
    WJR_REGISTER_REVERSE_COMPARE_NOT_N_2(index)
#endif

#define WJR_REGISTER_REVERSE_COMPARE_NOT_N_ADVANCE(index)                                \
    src0 += index;                                                                       \
    src1 += index

#define WJR_REGISTER_REVERSE_COMPARE_NOT_N_RET(index) 0

    WJR_ASSUME(n > 2);

    WJR_REGISTER_X86_NORMAL_REVERSE_SIMD_FUNCTION(
        n, WJR_REGISTER_REVERSE_COMPARE_NOT_N_2, WJR_REGISTER_REVERSE_COMPARE_NOT_N_4,
        WJR_HAS_SIMD(AVX2), WJR_REGISTER_REVERSE_COMPARE_NOT_N_ADVANCE, ,
        WJR_REGISTER_REVERSE_COMPARE_NOT_N_RET);

#if !WJR_HAS_SIMD(AVX2)
    do {
        const auto r0 = sse::cmpeq_epi64(sse::loadu(src0 - 8), sse::loadu(src1 - 8));
        const auto r1 = sse::cmpeq_epi64(sse::loadu(src0 - 6), sse::loadu(src1 - 6));
        const auto r2 = sse::cmpeq_epi64(sse::loadu(src0 - 4), sse::loadu(src1 - 4));
        const auto r3 = sse::cmpeq_epi64(sse::loadu(src0 - 2), sse::loadu(src1 - 2));

        const auto z = sse::And(sse::And(r0, r1), sse::And(r2, r3));

        if (WJR_UNLIKELY(!sse::test_all_ones(z))) {
            sse::mask_type mask = ~sse::movemask_epi8(r3);
            if (mask != 0) {
                if (mask == 0x00FF) {
                    return src0[-2] < src1[-2] ? -1 : 1;
                }
                return src0[-1] < src1[-1] ? -1 : 1;
            }

            mask = ~sse::movemask_epi8(r2);
            if (mask != 0) {
                if (mask == 0x00FF) {
                    return src0[-4] < src1[-4] ? -1 : 1;
                }
                return src0[-3] < src1[-3] ? -1 : 1;
            }

            mask = ~sse::movemask_epi8(r1);
            if (mask != 0) {
                if (mask == 0x00FF) {
                    return src0[-6] < src1[-6] ? -1 : 1;
                }
                return src0[-5] < src1[-5] ? -1 : 1;
            }

            mask = ~sse::movemask_epi8(r0);
            if (mask == 0x00FF) {
                return src0[-8] < src1[-8] ? -1 : 1;
            }
            return src0[-7] < src1[-7] ? -1 : 1;
        }

        src0 -= 8;
        src1 -= 8;
        n -= 8;
    } while (WJR_LIKELY(n != 0));
#else
    do {
        const auto r0 = avx::cmpeq_epi64(avx::loadu(src0 - 16), avx::loadu(src1 - 16));
        const auto r1 = avx::cmpeq_epi64(avx::loadu(src0 - 12), avx::loadu(src1 - 12));
        const auto r2 = avx::cmpeq_epi64(avx::loadu(src0 - 8), avx::loadu(src1 - 8));
        const auto r3 = avx::cmpeq_epi64(avx::loadu(src0 - 4), avx::loadu(src1 - 4));

        const auto z = avx::And(avx::And(r0, r1), avx::And(r2, r3));

        if (WJR_UNLIKELY(!avx::test_all_ones(z))) {
            avx::mask_type mask = ~avx::movemask_epi8(r3);
            if (mask != 0) {
                const auto offset = clz(mask) / 8;
                return src0[-1 - offset] < src1[-1 - offset] ? -1 : 1;
            }

            mask = ~avx::movemask_epi8(r2);
            if (mask != 0) {
                const auto offset = clz(mask) / 8;
                return src0[-5 - offset] < src1[-5 - offset] ? -1 : 1;
            }

            mask = ~avx::movemask_epi8(r1);
            if (mask != 0) {
                const auto offset = clz(mask) / 8;
                return src0[-9 - offset] < src1[-9 - offset] ? -1 : 1;
            }

            mask = ~avx::movemask_epi8(r0);
            const auto offset = clz(mask) / 8;
            return src0[-13 - offset] < src1[-13 - offset] ? -1 : 1;
        }

        src0 -= 16;
        src1 -= 16;
        n -= 16;
    } while (WJR_LIKELY(n != 0));
#endif

    return 0;

#undef WJR_REGISTER_REVERSE_COMPARE_NOT_N_RET
#undef WJR_REGISTER_REVERSE_COMPARE_NOT_N_ADVANCE
#undef WJR_REGISTER_REVERSE_COMPARE_NOT_N_4
#undef WJR_REGISTER_REVERSE_COMPARE_NOT_N_2
}

extern template WJR_PURE int
large_builtin_reverse_compare_n<uint64_t>(const uint64_t *src0, const uint64_t *src1,
                                          size_t n) noexcept;

#endif

} // namespace wjr

#endif // WJR_X86_MATH_LARGE_COMPARE_IMPL_HPP__

namespace wjr {

#if WJR_HAS_BUILTIN(COMPARE_N)

/**
 * @brief Compare two arrays of uint64_t.
 *
 * @details Inline detection of the first two positions, then use @ref
 * large_builtin_compare_n to compare the rest.
 *
 * @tparam T Requires uint64_t currently.
 * @param src0 Pointer to the first array.
 * @param src1 Pointer to the second array.
 * @param n Number of elements to compare.
 * @return
 * \code
 * negative : src0 < src1
 * 0        : src0 == src1
 * positive : src0 > src1
 * \endcode
 */
template <typename T>
WJR_INTRINSIC_INLINE int builtin_compare_n(const T *src0, const T *src1,
                                           size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0)) {
        return 0;
    }

    if (WJR_LIKELY(src0[0] != src1[0])) {
        return src0[0] < src1[0] ? -1 : 1;
    }

    if (WJR_UNLIKELY(n == 1)) {
        return 0;
    }

    if (WJR_LIKELY(src0[1] != src1[1])) {
        return src0[1] < src1[1] ? -1 : 1;
    }

    if (WJR_UNLIKELY(n == 2)) {
        return 0;
    }

    return large_builtin_compare_n(src0, src1, n);
}

#endif

#if WJR_HAS_BUILTIN(REVERSE_COMPARE_N)

/**
 * @brief Compare two arrays of uint64_t in reverse order.
 *
 * @details @ref builtin_compare_n in reverse order.
 */
template <typename T>
WJR_INTRINSIC_INLINE int builtin_reverse_compare_n(const T *src0, const T *src1,
                                                   size_t n) noexcept {
    if (WJR_UNLIKELY(n == 0)) {
        return 0;
    }

    if (WJR_LIKELY(src0[n - 1] != src1[n - 1])) {
        return src0[n - 1] < src1[n - 1] ? -1 : 1;
    }

    if (WJR_UNLIKELY(n == 1)) {
        return 0;
    }

    if (WJR_LIKELY(src0[n - 2] != src1[n - 2])) {
        return src0[n - 2] < src1[n - 2] ? -1 : 1;
    }

    if (WJR_UNLIKELY(n == 2)) {
        return 0;
    }

    return large_builtin_reverse_compare_n(src0, src1, n);
}

#endif

// __uint128_t has certain bugs in GCC 13.2, resulting in low performance
#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN___ASM_LESS_128 WJR_HAS_DEF
#define WJR_HAS_BUILTIN___ASM_LESS_EQUAL_128 WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(__ASM_LESS_128)

WJR_CONST WJR_INTRINSIC_INLINE bool __asm_less_128(uint64_t lo0, uint64_t hi0,
                                                   uint64_t lo1, uint64_t hi1) noexcept {
    bool ret;
    asm("cmp{q %[lo1], %[lo0]| %[lo0], %[lo1]}\n\t"
        "sbb{q %[hi1], %[hi0]| %[hi0], %[hi1]}\n\t" WJR_ASM_CCSET(b)
        : WJR_ASM_CCOUT(b)(ret), [lo0] "+&r"(lo0), [hi0] "+r"(hi0)
        : [lo1] "r"(lo1), [hi1] "r"(hi1)
        : "cc");
    return ret;
}

#endif

#if WJR_HAS_BUILTIN(__ASM_LESS_EQUAL_128)

WJR_CONST WJR_INTRINSIC_INLINE bool
__asm_less_equal_128(uint64_t lo0, uint64_t hi0, uint64_t lo1, uint64_t hi1) noexcept {
    bool ret;
    asm("cmp{q %[lo0], %[lo1]| %[lo1], %[lo0]}\n\t"
        "sbb{q %[hi0], %[hi1]| %[hi1], %[hi0]}\n\t" WJR_ASM_CCSET(ae)
        : WJR_ASM_CCOUT(ae)(ret), [lo1] "+&r"(lo1), [hi1] "+r"(hi1)
        : [lo0] "r"(lo0), [hi0] "r"(hi0)
        : "cc");
    return ret;
}

#endif

} // namespace wjr

#endif // WJR_X86_MATH_COMPARE_HPP__
#endif

namespace wjr {

template <typename T>
WJR_INTRINSIC_CONSTEXPR int fallback_compare_n(const T *src0, const T *src1,
                                               size_t n) noexcept {
    for (size_t idx = 0; idx < n; ++idx) {
        if (src0[idx] != src1[idx]) {
            return src0[idx] < src1[idx] ? -1 : 1;
        }
    }

    return 0;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 int compare_n(const T *src0, const T *src1,
                                                 size_t n) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(src0 == src1)) {
        return 0;
    }

#if WJR_HAS_BUILTIN(COMPARE_N)
    if constexpr (sizeof(T) == 8) {
        static_assert(sizeof(T) != 8 || std::is_unsigned_v<T>,
                      "T must be unsigned if sizeof(T) == 8");

        if (is_constant_evaluated()) {
            return fallback_compare_n(src0, src1, n);
        }

        return builtin_compare_n(src0, src1, n);
    } else {
        return fallback_compare_n(src0, src1, n);
    }
#else
    return fallback_compare_n(src0, src1, n);
#endif
}

template <typename T>
WJR_INTRINSIC_CONSTEXPR int fallback_reverse_compare_n(const T *src0, const T *src1,
                                                       size_t n) noexcept {
    src0 += n;
    src1 += n;

    for (size_t idx = 0; idx < n; ++idx) {
        if (src0[-1 - idx] != src1[-1 - idx]) {
            return src0[-1 - idx] < src1[-1 - idx] ? -1 : 1;
        }
    }

    return 0;
}

template <typename T>
WJR_PURE WJR_INTRINSIC_CONSTEXPR20 int reverse_compare_n(const T *src0, const T *src1,
                                                         size_t n) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(src0 == src1)) {
        return 0;
    }

#if WJR_HAS_BUILTIN(COMPARE_N)
    if constexpr (sizeof(T) == 8) {
        static_assert(sizeof(T) != 8 || std::is_unsigned_v<T>,
                      "T must be unsigned if sizeof(T) == 8");

        if (is_constant_evaluated()) {
            return fallback_reverse_compare_n(src0, src1, n);
        }

        return builtin_reverse_compare_n(src0, src1, n);
    } else {
        return fallback_reverse_compare_n(src0, src1, n);
    }
#else
    return fallback_reverse_compare_n(src0, src1, n);
#endif
}

#if WJR_HAS_FEATURE(FAST_INT128_COMPARE)
#define WJR_HAS_BUILTIN___BUILTIN_LESS_128 WJR_HAS_DEF
#define WJR_HAS_BUILTIN___BUILTIN_LESS_EQUAL_128 WJR_HAS_DEF
#endif

WJR_INTRINSIC_CONSTEXPR20 bool __fallback_less_128(uint64_t lo0, uint64_t hi0,
                                                   uint64_t lo1, uint64_t hi1) noexcept {
    uint8_t f = lo0 < lo1;
    (void)subc_cc(hi0, hi1, f, f);
    WJR_ASSUME(f <= 1);
    return f != 0;
}

#if WJR_HAS_BUILTIN(__BUILTIN_LESS_128)

WJR_INTRINSIC_INLINE bool __builtin_less_128(uint64_t lo0, uint64_t hi0, uint64_t lo1,
                                             uint64_t hi1) noexcept {
    const auto x0 = static_cast<__uint128_t>(hi0) << 64 | lo0;
    const auto x1 = static_cast<__uint128_t>(hi1) << 64 | lo1;

    return x0 < x1;
}

#endif

// return <hi0, lo0> < <hi1, lo1>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 bool __less_128(uint64_t lo0, uint64_t hi0,
                                                    uint64_t lo1, uint64_t hi1) noexcept {
#if WJR_HAS_BUILTIN(__BUILTIN_LESS_128) || WJR_HAS_BUILTIN(__ASM_LESS_128)
    if (is_constant_evaluated()) {
        return __fallback_less_128(lo0, hi0, lo1, hi1);
    }

    return WJR_PP_BOOL_IF(WJR_HAS_BUILTIN(__BUILTIN_LESS_128), __builtin_less_128,
                          __asm_less_128)(lo0, hi0, lo1, hi1);
#else
    return __fallback_less_128(lo0, hi0, lo1, hi1);
#endif
}

WJR_INTRINSIC_CONSTEXPR20 bool __fallback_less_equal_128(uint64_t lo0, uint64_t hi0,
                                                         uint64_t lo1,
                                                         uint64_t hi1) noexcept {
    return !__less_128(lo1, hi1, lo0, hi0);
}

#if WJR_HAS_BUILTIN(__BUILTIN_LESS_EQUAL_128)

WJR_INTRINSIC_INLINE bool __builtin_less_equal_128(uint64_t lo0, uint64_t hi0,
                                                   uint64_t lo1, uint64_t hi1) noexcept {
    const auto x0 = static_cast<__uint128_t>(hi0) << 64 | lo0;
    const auto x1 = static_cast<__uint128_t>(hi1) << 64 | lo1;

    return x0 <= x1;
}

#endif

// return <hi0, lo0> < <hi1, lo1>
WJR_CONST WJR_INTRINSIC_CONSTEXPR20 bool
__less_equal_128(uint64_t lo0, uint64_t hi0, uint64_t lo1, uint64_t hi1) noexcept {
#if WJR_HAS_BUILTIN(__BUILTIN_LESS_EQUAL_128) || WJR_HAS_BUILTIN(__ASM_LESS_EQUAL_128)
    if (is_constant_evaluated()) {
        return __fallback_less_equal_128(lo0, hi0, lo1, hi1);
    }

    return WJR_PP_BOOL_IF(WJR_HAS_BUILTIN(__BUILTIN_LESS_EQUAL_128),
                          __builtin_less_equal_128,
                          __asm_less_equal_128)(lo0, hi0, lo1, hi1);
#else
    return __fallback_less_equal_128(lo0, hi0, lo1, hi1);
#endif
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR20 bool
__greater_128(uint64_t lo0, uint64_t hi0, uint64_t lo1, uint64_t hi1) noexcept {
    return __less_128(lo1, hi1, lo0, hi0);
}

WJR_CONST WJR_INTRINSIC_CONSTEXPR20 bool
__greater_equal_128(uint64_t lo0, uint64_t hi0, uint64_t lo1, uint64_t hi1) noexcept {
    return __less_equal_128(lo1, hi1, lo0, hi0);
}

} // namespace wjr

#endif // WJR_MATH_CMP_HPP__
// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_DIVIDER_HPP__
#define WJR_X86_MATH_DIVIDER_HPP__

// Already included

namespace wjr {

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_DIV2BY1_ADJUST WJR_HAS_DEF

#if defined(WJR_COMPILER_CLANG) && !WJR_HAS_CLANG(13, 0, 0)
#define WJR_HAS_BUILTIN_ASM_DIV2BY1_ADJUST_BRANCH WJR_HAS_DEF
#endif

#endif

#if WJR_HAS_BUILTIN(ASM_DIV2BY1_ADJUST)

template <typename T, WJR_REQUIRES(std::is_same_v<T, uint64_t>)>
WJR_INTRINSIC_INLINE void asm_div2by1_adjust(T rax, T div, T &r8, T &rdx) noexcept {
    T r9 = r8 + div;
    asm("cmp{q %[rax], %[r8]| %[r8], %[rax]}\n\t"
        "cmovb{q %[r8], %[r9]| %[r9], %[r8]}\n\t"
        "adc{q $-1, %[rdx]| %[rdx], -1}"
        : [r9] "+r"(r9), [r8] "+r"(r8), [rdx] "+r"(rdx)
        : [rax] "r"(rax)
        : "cc", "memory");
    r8 = r9;
}

#endif

#if WJR_HAS_BUILTIN(ASM_DIV2BY1_ADJUST_BRANCH)

template <typename T, WJR_REQUIRES(std::is_same_v<T, uint64_t>)>
WJR_INTRINSIC_INLINE void asm_div2by1_adjust_branch(T div, T &lo) noexcept {
    asm("sub %1, %0" : "+r"(lo) : "r"(div));
}

#endif

} // namespace wjr

#endif // WJR_X86_MATH_DIVIDER_HPP__
#endif

namespace wjr {

namespace math_detail {

inline constexpr std::array<uint16_t, 0x100> div2by1_u64_lookup = {
    0x7fd, 0x7f5, 0x7ed, 0x7e5, 0x7dd, 0x7d5, 0x7ce, 0x7c6, 0x7bf, 0x7b7, 0x7b0, 0x7a8,
    0x7a1, 0x79a, 0x792, 0x78b, 0x784, 0x77d, 0x776, 0x76f, 0x768, 0x761, 0x75b, 0x754,
    0x74d, 0x747, 0x740, 0x739, 0x733, 0x72c, 0x726, 0x720, 0x719, 0x713, 0x70d, 0x707,
    0x700, 0x6fa, 0x6f4, 0x6ee, 0x6e8, 0x6e2, 0x6dc, 0x6d6, 0x6d1, 0x6cb, 0x6c5, 0x6bf,
    0x6ba, 0x6b4, 0x6ae, 0x6a9, 0x6a3, 0x69e, 0x698, 0x693, 0x68d, 0x688, 0x683, 0x67d,
    0x678, 0x673, 0x66e, 0x669, 0x664, 0x65e, 0x659, 0x654, 0x64f, 0x64a, 0x645, 0x640,
    0x63c, 0x637, 0x632, 0x62d, 0x628, 0x624, 0x61f, 0x61a, 0x616, 0x611, 0x60c, 0x608,
    0x603, 0x5ff, 0x5fa, 0x5f6, 0x5f1, 0x5ed, 0x5e9, 0x5e4, 0x5e0, 0x5dc, 0x5d7, 0x5d3,
    0x5cf, 0x5cb, 0x5c6, 0x5c2, 0x5be, 0x5ba, 0x5b6, 0x5b2, 0x5ae, 0x5aa, 0x5a6, 0x5a2,
    0x59e, 0x59a, 0x596, 0x592, 0x58e, 0x58a, 0x586, 0x583, 0x57f, 0x57b, 0x577, 0x574,
    0x570, 0x56c, 0x568, 0x565, 0x561, 0x55e, 0x55a, 0x556, 0x553, 0x54f, 0x54c, 0x548,
    0x545, 0x541, 0x53e, 0x53a, 0x537, 0x534, 0x530, 0x52d, 0x52a, 0x526, 0x523, 0x520,
    0x51c, 0x519, 0x516, 0x513, 0x50f, 0x50c, 0x509, 0x506, 0x503, 0x500, 0x4fc, 0x4f9,
    0x4f6, 0x4f3, 0x4f0, 0x4ed, 0x4ea, 0x4e7, 0x4e4, 0x4e1, 0x4de, 0x4db, 0x4d8, 0x4d5,
    0x4d2, 0x4cf, 0x4cc, 0x4ca, 0x4c7, 0x4c4, 0x4c1, 0x4be, 0x4bb, 0x4b9, 0x4b6, 0x4b3,
    0x4b0, 0x4ad, 0x4ab, 0x4a8, 0x4a5, 0x4a3, 0x4a0, 0x49d, 0x49b, 0x498, 0x495, 0x493,
    0x490, 0x48d, 0x48b, 0x488, 0x486, 0x483, 0x481, 0x47e, 0x47c, 0x479, 0x477, 0x474,
    0x472, 0x46f, 0x46d, 0x46a, 0x468, 0x465, 0x463, 0x461, 0x45e, 0x45c, 0x459, 0x457,
    0x455, 0x452, 0x450, 0x44e, 0x44b, 0x449, 0x447, 0x444, 0x442, 0x440, 0x43e, 0x43b,
    0x439, 0x437, 0x435, 0x432, 0x430, 0x42e, 0x42c, 0x42a, 0x428, 0x425, 0x423, 0x421,
    0x41f, 0x41d, 0x41b, 0x419, 0x417, 0x414, 0x412, 0x410, 0x40e, 0x40c, 0x40a, 0x408,
    0x406, 0x404, 0x402, 0x400};

// invert of (2 * i + 1) mod 256
inline constexpr std::array<uint8_t, 0x80> divexact1_lookup = {
    0x01, 0xAB, 0xCD, 0xB7, 0x39, 0xA3, 0xC5, 0xEF, 0xF1, 0x1B, 0x3D, 0xA7, 0x29,
    0x13, 0x35, 0xDF, 0xE1, 0x8B, 0xAD, 0x97, 0x19, 0x83, 0xA5, 0xCF, 0xD1, 0xFB,
    0x1D, 0x87, 0x09, 0xF3, 0x15, 0xBF, 0xC1, 0x6B, 0x8D, 0x77, 0xF9, 0x63, 0x85,
    0xAF, 0xB1, 0xDB, 0xFD, 0x67, 0xE9, 0xD3, 0xF5, 0x9F, 0xA1, 0x4B, 0x6D, 0x57,
    0xD9, 0x43, 0x65, 0x8F, 0x91, 0xBB, 0xDD, 0x47, 0xC9, 0xB3, 0xD5, 0x7F, 0x81,
    0x2B, 0x4D, 0x37, 0xB9, 0x23, 0x45, 0x6F, 0x71, 0x9B, 0xBD, 0x27, 0xA9, 0x93,
    0xB5, 0x5F, 0x61, 0x0B, 0x2D, 0x17, 0x99, 0x03, 0x25, 0x4F, 0x51, 0x7B, 0x9D,
    0x07, 0x89, 0x73, 0x95, 0x3F, 0x41, 0xEB, 0x0D, 0xF7, 0x79, 0xE3, 0x05, 0x2F,
    0x31, 0x5B, 0x7D, 0xE7, 0x69, 0x53, 0x75, 0x1F, 0x21, 0xCB, 0xED, 0xD7, 0x59,
    0xC3, 0xE5, 0x0F, 0x11, 0x3B, 0x5D, 0xC7, 0x49, 0x33, 0x55, 0xFF};

} // namespace math_detail

template <typename T>
class div2by1_divider_noshift {
    static_assert(std::is_same_v<T, uint64_t>, "Currently only support uint64_t");

public:
    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(div2by1_divider_noshift);

    explicit div2by1_divider_noshift(T divisor) noexcept : m_divisor(divisor) {
        m_value = reciprocal(divisor);
    }

    constexpr div2by1_divider_noshift(T divisor, T value) noexcept
        : m_divisor(divisor), m_value(value) {}

    constexpr T get_divisor() const noexcept { return m_divisor; }
    constexpr T get_value() const noexcept { return m_value; }

    constexpr bool is_zero_or_single_bit() const noexcept {
        return m_divisor == (1ull << 63);
    }

    WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 T divide(T lo, T &hi) const noexcept {
        return divide(m_divisor, m_value, lo, hi);
    }

    WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 static T divide(T divisor, T value, T lo,
                                                            T &hi) noexcept {
        WJR_ASSERT_ASSUME_L3(__has_high_bit(divisor));

        if (WJR_BUILTIN_CONSTANT_P_TRUE(lo == 0)) {
            return divide_lo0(divisor, value, lo, hi);
        }

        return basic_divide(divisor, value, lo, hi);
    }

    WJR_CONST WJR_CONSTEXPR20 static T reciprocal(T d) noexcept {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(d == 1ull << 63)) {
            return in_place_max;
        }

        return __reciprocal_impl(d);
    }

private:
    WJR_CONST WJR_CONSTEXPR20 static T __reciprocal_impl(T d) noexcept;

    WJR_INTRINSIC_CONSTEXPR static void fallback_div2by1_adjust(T rax, T div, T &r8,
                                                                T &rdx) noexcept {
        const T r9 = r8 + div;
        bool f = r8 < rax;
        r8 = f ? r8 : r9;
        rdx += -1 + f;
    }

    // see fallback_div2by1_adjust
    WJR_INTRINSIC_CONSTEXPR20 static void div2by1_adjust(T rax, T div, T &r8,
                                                         T &rdx) noexcept {
#if WJR_HAS_BUILTIN(ASM_DIV2BY1_ADJUST)
        if (is_constant_evaluated()) {
            return fallback_div2by1_adjust(rax, div, r8, rdx);
        }

        return asm_div2by1_adjust(rax, div, r8, rdx);
#else
        return fallback_div2by1_adjust(rax, div, r8, rdx);
#endif
    }

    WJR_INTRINSIC_CONSTEXPR20 static T basic_divide(T divisor, T value, T lo,
                                                    T &hi) noexcept {
        const T hi1 = hi + 1;

        T rax, rdx;

        rax = mul(hi, value, rdx);
        __add_128(rax, rdx, rax, rdx, lo, hi1);

        lo -= mullo(rdx, divisor);

        div2by1_adjust(rax, divisor, lo, rdx);

        if (WJR_UNLIKELY(lo >= divisor)) {
#if !WJR_HAS_BUILTIN(ASM_DIV2BY1_ADJUST_BRANCH)
            lo -= divisor;
#else
            // low version clang may have some performance issue here
            // so we use asm to avoid use cmov
            asm_div2by1_adjust_branch(divisor, lo);
#endif
            ++rdx;
        }

        hi = lo;
        return rdx;
    }

    WJR_INTRINSIC_CONSTEXPR20 static T divide_lo0(T divisor, T value, T lo,
                                                  T &hi) noexcept {
        const T hi1 = hi + 1;
        T rax, rdx;

        rax = mul(hi, value, rdx);
        rdx += hi1;

        lo -= mullo(rdx, divisor);

        div2by1_adjust(rax, divisor, lo, rdx);

        hi = lo;
        return rdx;
    }

protected:
    T m_divisor;
    T m_value;
};

template <typename T>
WJR_CONST WJR_CONSTEXPR20 T div2by1_divider_noshift<T>::__reciprocal_impl(T d) noexcept {
    WJR_ASSERT_ASSUME_L2(__has_high_bit(d));

    uint64_t d40 = 0, d63 = 0;
    uint32_t v0 = 0;
    uint64_t v1 = 0, v2 = 0, v3 = 0, v4 = 0;
    uint64_t t0 = 0, t1 = 0;

    // 40 bit
    d40 = (d >> 24) + 1;
    // 63 bit
    d63 = (d + 1) >> 1;
    // 11 bit
    v0 = math_detail::div2by1_u64_lookup[((d >> 55) - 0x100)];
    // 22 bit
    v1 = (v0 << 11) - (mullo<uint64_t>(mullo<uint32_t>(v0, v0), d40) >> 40) - 1;

    t1 = mulhi<uint64_t>(v1 << 17, (1ull << 60) - mullo<uint64_t>(v1, d40));
    // 35 bit
    v2 = (v1 << 13) + t1;

    t0 = 0 - mul<uint64_t>(v2, d63, t1);
    if (d & 1) {
        t0 += v2 >> 1;
    }

    v3 = (v2 << 31) + (mulhi<uint64_t>(t0, v2) >> 1);

    v1 = v3 + 1;

    if (WJR_UNLIKELY(v1 == 0)) {
        v4 = ~(d * 2);
    } else {
        v4 = v3 - mulhi<uint64_t>(v1, d) - d;
    }

    return v4;
}

template <typename T>
class div2by1_divider : public div2by1_divider_noshift<T> {
private:
    using Mybase = div2by1_divider_noshift<T>;
    // disable member divide function of Mybase
    using Mybase::divide;
    using Mybase::m_divisor;
    using Mybase::m_value;

public:
    static_assert(std::is_same_v<T, uint64_t>, "Currently only support uint64_t");

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(div2by1_divider);

    constexpr explicit div2by1_divider(const Mybase &base) noexcept
        : Mybase(base), m_shift(0) {}

    WJR_INTRINSIC_CONSTEXPR20 explicit div2by1_divider(T divisor) noexcept {
        m_divisor = divisor;
        initialize();
    }

    constexpr div2by1_divider(T divisor, T value, unsigned int shift) noexcept
        : Mybase(divisor, value), m_shift(shift) {}

    constexpr unsigned int get_shift() const noexcept { return m_shift; }

    constexpr const Mybase &get_base() const noexcept { return *this; }

    // enable static divide function of Mybase
    // This function needs to ensure that lo and hi have been adjusted
    WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 static T divide(T divisor, T value, T lo,
                                                            T &hi) noexcept {
        return Mybase::divide(divisor, value, lo, hi);
    }

private:
    // make sure m_shift/one_single_bit(divisor) can be inlined
    WJR_INTRINSIC_CONSTEXPR20 void initialize() noexcept {
        if (WJR_UNLIKELY(!__has_high_bit(m_divisor))) {
            m_shift = clz(m_divisor);
            m_divisor <<= m_shift;

            WJR_ASSUME(m_shift != 0u);
        } else {
            WJR_ASSUME(m_shift == 0u);
        }

        WJR_ASSUME(__has_high_bit(m_divisor));
        m_value = Mybase::reciprocal(m_divisor);
    }

    unsigned int m_shift = 0;
};

template <typename T>
class div3by2_divider_noshift {
public:
    static_assert(std::is_same_v<T, uint64_t>, "");

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(div3by2_divider_noshift);

    WJR_INTRINSIC_CONSTEXPR20 div3by2_divider_noshift(T d0, T d1) noexcept
        : m_divisor0(d0), m_divisor1(d1) {
        m_value = reciprocal(d0, d1);
    }

    WJR_INTRINSIC_CONSTEXPR div3by2_divider_noshift(T d0, T d1, T value) noexcept
        : m_divisor0(d0), m_divisor1(d1), m_value(value) {}

    constexpr T get_divisor0() const noexcept { return m_divisor0; }
    constexpr T get_divisor1() const noexcept { return m_divisor1; }
    constexpr T get_value() const noexcept { return m_value; }

    WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 T divide(T u0, T &u1, T &u2) const noexcept {
        return divide(m_divisor0, m_divisor1, m_value, u0, u1, u2);
    }

    WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 static T
    divide(T divisor0, T divisor1, T value, T u0, T &u1, T &u2) noexcept;

    WJR_CONST WJR_CONSTEXPR20 static T reciprocal(T d0, T d1) noexcept;

protected:
    T m_divisor0 = 0;
    T m_divisor1 = 0;
    T m_value = 0;
};

template <typename T>
WJR_INTRINSIC_CONSTEXPR20 T div3by2_divider_noshift<T>::divide(T divisor0, T divisor1,
                                                               T value, T u0, T &u1,
                                                               T &u2) noexcept {
    WJR_ASSERT_ASSUME_L3(__has_high_bit(divisor1));

    T q1, q0;
    q0 = mul<T>(value, u2, q1);
    __add_128(q0, q1, q0, q1, u1, u2);

    T r1, r0;
    r1 = u1 - mullo<T>(q1, divisor1);
    T t1;
    r0 = mul<T>(divisor0, q1, t1);

    __sub_128(r0, r1, u0, r1, r0, t1);
    __sub_128(r0, r1, r0, r1, divisor0, divisor1);
    ++q1;

    if (r1 >= q0) {
        --q1;
        __add_128(r0, r1, r0, r1, divisor0, divisor1);
    }

    if (WJR_UNLIKELY(__less_equal_128(divisor0, divisor1, r0, r1))) {
        ++q1;
        __sub_128(r0, r1, r0, r1, divisor0, divisor1);
    }

    u1 = r0;
    u2 = r1;
    return q1;
}

template <typename T>
WJR_CONST WJR_CONSTEXPR20 T div3by2_divider_noshift<T>::reciprocal(T d0, T d1) noexcept {
    WJR_ASSERT_ASSUME_L2(__has_high_bit(d1));

    T v = div2by1_divider<T>::reciprocal(d1);
    T p = mullo<T>(d1, v);
    p += d0;
    if (p < d0) {
        --v;
        if (p >= d1) {
            --v;
            p -= d1;
        }
        p -= d1;
    }

    T t0 = 0, t1 = 0;
    t0 = mul<T>(d0, v, t1);
    p += t1;
    if (p < t1) {
        --v;
        if (__less_equal_128(d0, d1, t0, p)) {
            --v;
        }
    }

    return v;
}

template <typename T>
class div3by2_divider : public div3by2_divider_noshift<T> {
    using Mybase = div3by2_divider_noshift<T>;
    using Mybase::divide;
    using Mybase::m_divisor0;
    using Mybase::m_divisor1;
    using Mybase::m_value;

public:
    static_assert(std::is_same_v<T, uint64_t>, "");

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(div3by2_divider);

    constexpr explicit div3by2_divider(const Mybase &base) noexcept
        : Mybase(base), m_shift(0) {}

    WJR_INTRINSIC_CONSTEXPR20 div3by2_divider(T d0, T d1) noexcept {
        m_divisor0 = d0;
        m_divisor1 = d1;
        initialize();
    }

    WJR_INTRINSIC_CONSTEXPR div3by2_divider(T d0, T d1, T value,
                                            unsigned int shift) noexcept
        : Mybase(d0, d1, value), m_shift(shift) {}

    constexpr unsigned int get_shift() const noexcept { return m_shift; }

    constexpr const Mybase &get_base() const noexcept { return *this; }

    WJR_NODISCARD WJR_INTRINSIC_CONSTEXPR20 static T
    divide(T divisor0, T divisor1, T value, T u0, T &u1, T &u2) noexcept {
        return Mybase::divide(divisor0, divisor1, value, u0, u1, u2);
    }

private:
    WJR_INTRINSIC_CONSTEXPR20 void initialize() noexcept {
        if (WJR_UNLIKELY(!__has_high_bit(m_divisor1))) {
            m_shift = clz(m_divisor1);
            m_divisor1 = shld(m_divisor1, m_divisor0, m_shift);
            m_divisor0 <<= m_shift;

            WJR_ASSUME(m_shift != 0);
        } else {
            WJR_ASSUME(m_shift == 0);
        }

        WJR_ASSUME(__has_high_bit(m_divisor1));

        m_value = Mybase::reciprocal(m_divisor0, m_divisor1);
    }

    unsigned int m_shift = 0;
};

// divexact1_divider
// m_value is invert of m_divisor mod 2 ^ N
// m_divisor is odd
template <typename T>
class divexact1_divider {
public:
    static_assert(std::is_same_v<T, uint64_t>, "Currently only support uint64_t");

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(divexact1_divider);

    WJR_INTRINSIC_CONSTEXPR20 explicit divexact1_divider(T divisor) noexcept
        : m_divisor(divisor) {
        initialize();
    }

    constexpr divexact1_divider(T divisor, T value, unsigned int shift)
        : m_divisor(divisor), m_value(value), m_shift(shift) {}

    constexpr T get_divisor() const noexcept { return m_divisor; }
    constexpr T get_value() const noexcept { return m_value; }
    constexpr unsigned int get_shift() const noexcept { return m_shift; }

    constexpr bool is_zero_or_single_bit() const noexcept { return m_divisor == 1; }

    WJR_CONST constexpr static T reciprocal(T divisor) noexcept {
        T inv = math_detail::divexact1_lookup[(divisor & 0xFF) >> 1];
        inv = inv * (2 - inv * divisor);
        inv = inv * (2 - inv * divisor);
        inv = inv * (2 - inv * divisor);
        return inv;
    }

private:
    WJR_INTRINSIC_CONSTEXPR20 void initialize() noexcept {
        if (WJR_UNLIKELY(!(m_divisor & 1))) {
            m_shift = ctz(m_divisor);
            m_divisor >>= m_shift;

            WJR_ASSUME(m_shift != 0);
        } else {
            WJR_ASSUME(m_shift == 0);
        }

        WJR_ASSUME((m_divisor & 1) != 0);

        m_value = reciprocal(m_divisor);
    }

    T m_divisor = 0;
    T m_value = 0;
    unsigned int m_shift = 0;
};

} // namespace wjr

#endif // WJR_MATH_DIVIDER_HPP__

namespace wjr {

/**
 * @brief temporary uint128_t for divide 128
 *
 * @todo implement more functions
 *
 */
class uint128_t {
public:
    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(uint128_t);

    template <size_t I>
    constexpr uint64_t &get() & noexcept {
        if constexpr (I == 0) {
            return low;
        } else {
            return high;
        }
    }

    template <size_t I>
    constexpr const uint64_t &get() const & noexcept {
        if constexpr (I == 0) {
            return low;
        } else {
            return high;
        }
    }

    template <size_t I>
    constexpr uint64_t &&get() && noexcept {
        if constexpr (I == 0) {
            return std::move(low);
        } else {
            return std::move(high);
        }
    }

    template <size_t I>
    constexpr const uint64_t &&get() const && noexcept {
        if constexpr (I == 0) {
            return std::move(low);
        } else {
            return std::move(high);
        }
    }

    constexpr uint128_t(uint64_t lo_, uint64_t hi_) noexcept : low(lo_), high(hi_) {}

    template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
    constexpr uint128_t(T value) noexcept : low(value), high(0) {}

    template <typename T, WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
    constexpr uint128_t(T value) noexcept
        : low(static_cast<T>(value)), high(static_cast<T>(value >= 0 ? 0 : -1)) {}

    WJR_CONSTEXPR20 uint128_t &operator+=(uint128_t other) noexcept {
        __add_128(low, high, low, high, other.low, other.high);
        return *this;
    }

    friend WJR_CONST WJR_CONSTEXPR20 uint128_t operator+(uint128_t lhs,
                                                         uint128_t rhs) noexcept {
        return lhs += rhs;
    }

    WJR_CONSTEXPR20 uint128_t &operator-=(uint128_t other) noexcept {
        __sub_128(low, high, low, high, other.low, other.high);
        return *this;
    }

    friend WJR_CONST WJR_CONSTEXPR20 uint128_t operator-(uint128_t lhs,
                                                         uint128_t rhs) noexcept {
        return lhs -= rhs;
    }

    WJR_CONSTEXPR20 uint128_t &operator*=(uint128_t other) noexcept {
        const auto [__lo, __hi] = other;
        const uint64_t tmp = low * __hi + high * __lo;
        low = mul(low, __lo, high);
        high += tmp;
        return *this;
    }

private:
    static WJR_CONST WJR_CONSTEXPR20 uint128_t mul_u64(uint128_t lhs,
                                                       uint64_t value) noexcept {
        const auto [low, high] = lhs;
        uint128_t tmp;
        tmp.low = mul(low, value, tmp.high);
        tmp.high += high * value;
        return tmp;
    }

    static WJR_CONST WJR_CONSTEXPR20 uint128_t mul_i64(uint128_t lhs,
                                                       int64_t value) noexcept {
        const auto [low, high] = lhs;
        const uint64_t uvalue = to_unsigned(value);
        uint128_t tmp;
        tmp.low = mul(low, uvalue, tmp.high);
        tmp.high += high * uvalue + (value >= 0 ? 0 : -low);
        return tmp;
    }

public:
    template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
    WJR_CONSTEXPR20 uint128_t &operator*=(T value) noexcept {
        return (*this) = mul_u64(*this, value);
    }

    template <typename T, WJR_REQUIRES(is_nonbool_signed_integral_v<T>)>
    WJR_CONSTEXPR20 uint128_t &operator*=(T value) noexcept {
        return (*this) = mul_i64(*this, value);
    }

    friend WJR_CONST WJR_CONSTEXPR20 uint128_t operator*(uint128_t lhs,
                                                         uint128_t rhs) noexcept {
        return lhs *= rhs;
    }

    template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
    friend WJR_CONST WJR_CONSTEXPR20 uint128_t operator*(uint128_t lhs, T rhs) noexcept {
        return lhs *= rhs;
    }

    template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
    friend WJR_CONST WJR_CONSTEXPR20 uint128_t operator*(T lhs, uint128_t rhs) noexcept {
        return rhs *= lhs;
    }

    friend WJR_CONST WJR_CONSTEXPR20 bool operator<(uint128_t lhs,
                                                    uint128_t rhs) noexcept {
        return __less_128(lhs.low, lhs.high, rhs.low, rhs.high);
    }

    friend WJR_CONST WJR_CONSTEXPR20 bool operator>(uint128_t lhs,
                                                    uint128_t rhs) noexcept {
        return rhs < lhs;
    }

    friend WJR_CONST WJR_CONSTEXPR20 bool operator<=(uint128_t lhs,
                                                     uint128_t rhs) noexcept {
        return __less_equal_128(lhs.low, lhs.high, rhs.low, rhs.high);
    }

    friend WJR_CONST WJR_CONSTEXPR20 bool operator>=(uint128_t lhs,
                                                     uint128_t rhs) noexcept {
        return rhs <= lhs;
    }

    friend WJR_CONST WJR_CONSTEXPR20 bool operator==(uint128_t lhs,
                                                     uint128_t rhs) noexcept {
        return lhs.low == rhs.low && lhs.high == rhs.high;
    }

    friend WJR_CONST WJR_CONSTEXPR20 bool operator!=(uint128_t lhs,
                                                     uint128_t rhs) noexcept {
        return !(lhs == rhs);
    }

    uint64_t low;
    uint64_t high;
};

WJR_INTRINSIC_CONSTEXPR20 uint128_t mul64x64to128(uint64_t a, uint64_t b) noexcept {
    uint64_t low, high;
    low = mul(a, b, high);
    return uint128_t(low, high);
}

} // namespace wjr

namespace std {

template <>
struct tuple_size<wjr::uint128_t> : std::integral_constant<size_t, 2> {};

template <size_t I>
struct tuple_element<I, wjr::uint128_t> {
    using type = uint64_t;
};

template <size_t I>
WJR_NODISCARD constexpr uint64_t &get(wjr::uint128_t &u) noexcept {
    return u.get<I>();
}

template <size_t I>
WJR_NODISCARD constexpr const uint64_t &get(const wjr::uint128_t &u) noexcept {
    return u.get<I>();
}

template <size_t I>
WJR_NODISCARD constexpr uint64_t &&get(wjr::uint128_t &&u) noexcept {
    return std::move(u).get<I>();
}

template <size_t I>
WJR_NODISCARD constexpr const uint64_t &&get(const wjr::uint128_t &&u) noexcept {
    return std::move(u).get<I>();
}

} // namespace std

#endif // WJR_MATH_UINT128_T_HPP__

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_DIV_HPP__
#define WJR_X86_MATH_DIV_HPP__

// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

namespace wjr {

#if defined(__BMI2__)

#if WJR_HAS_FEATURE(GCC_STYLE_INLINE_ASM)
#define WJR_HAS_BUILTIN_ASM_DIVEXACT_DBM1C WJR_HAS_DEF
#elif defined(WJR_ENABLE_ASSEMBLY)
#define WJR_HAS_BUILTIN_ASM_DIVEXACT_DBM1C WJR_HAS_DEF_VAR(3)
#endif

#endif

#if WJR_HAS_BUILTIN(ASM_DIVEXACT_DBM1C)

#if WJR_HAS_BUILTIN(ASM_DIVEXACT_DBM1C) == 1

// TODO : optimize pipeline
inline uint64_t asm_divexact_dbm1c(uint64_t *dst, const uint64_t *src, size_t n,
                                   uint64_t bd, uint64_t h) noexcept {
    uint64_t r8 = h, r9 = n, r10, r11 = static_cast<uint32_t>(n);

    src += r9;
    dst += r9;
    r9 = -r9;

    asm volatile(
        "and{l $3, %k[r11]| %k[r11], 3}\n\t"
        "je .Lb0%=\n\t"
        "lea{q -4(%[r9], %[r11], 1), %[r9]| %[r9], [%[r9] + %[r11] * 1 - 4]}\n\t"
        "cmp{l $2, %k[r11]| %k[r11], 2}\n\t"
        "jb .Lb1%=\n\t"
        "je .Lb2%=\n\t"
        "jmp .Lb3%=\n\t"

        ".Lloop%=:\n\t"

        ".Lb0%=:\n\t"
        "mulx{q (%[src], %[r9], 8), %[r10], %[r11]| %[r11], %[r10], [%[src] + %[r9] * 8]}\n\t"
        "sub{q %[r10], %[r8]| %[r8], %[r10]}\n\t"
        "mov{q %[r8], (%[dst], %[r9], 8)| [%[dst] + %[r9] * 8], %[r8]}\n\t"
        "sbb{q %[r11], %[r8]| %[r8], %[r11]}\n\t"

        ".Lb3%=:\n\t"
        "mulx{q 8(%[src], %[r9], 8), %[r10], %[r11]| %[r11], %[r10], [%[src] + %[r9] * 8 + 8]}\n\t"
        "sub{q %[r10], %[r8]| %[r8], %[r10]}\n\t"
        "mov{q %[r8], 8(%[dst], %[r9], 8)| [%[dst] + %[r9] * 8 + 8], %[r8]}\n\t"
        "sbb{q %[r11], %[r8]| %[r8], %[r11]}\n\t"

        ".Lb2%=:\n\t"
        "mulx{q 16(%[src], %[r9], 8), %[r10], %[r11]| %[r11], %[r10], [%[src] + %[r9] * 8 + 16]}\n\t"
        "sub{q %[r10], %[r8]| %[r8], %[r10]}\n\t"
        "mov{q %[r8], 16(%[dst], %[r9], 8)| [%[dst] + %[r9] * 8 + 16], %[r8]}\n\t"
        "sbb{q %[r11], %[r8]| %[r8], %[r11]}\n\t"

        ".Lb1%=:\n\t"
        "mulx{q 24(%[src], %[r9], 8), %[r10], %[r11]| %[r11], %[r10], [%[src] + %[r9] * 8 + 24]}\n\t"
        "sub{q %[r10], %[r8]| %[r8], %[r10]}\n\t"
        "mov{q %[r8], 24(%[dst], %[r9], 8)| [%[dst] + %[r9] * 8 + 24], %[r8]}\n\t"
        "sbb{q %[r11], %[r8]| %[r8], %[r11]}\n\t"

        "add{q $4, %[r9]| %[r9], 4}\n\t"
        "jne .Lloop%=\n\t"

        : [r8] "+&r"(r8), [r9] "+&r"(r9), [r10] "=&r"(r10), [r11] "+&r"(r11)
        : "d"(bd), [dst] "r"(dst), [src] "r"(src)
        : "cc", "memory");

    return r8;
}

#else

extern "C" WJR_MS_ABI uint64_t __wjr_asm_divexact_dbm1c(uint64_t *dst,
                                                        const uint64_t *src, size_t n,
                                                        uint64_t bd, uint64_t h) noexcept;

WJR_INTRINSIC_INLINE uint64_t asm_divexact_dbm1c(uint64_t *dst, const uint64_t *src,
                                                 size_t n, uint64_t bd,
                                                 uint64_t h) noexcept {
    return __wjr_asm_divexact_dbm1c(dst, src, n, bd, h);
}

#endif

#endif

} // namespace wjr

#endif // WJR_X86_MATH_DIV_HPP__
#endif

namespace wjr {

/*
 TODO :
 1. __div_constant_128
 2. __mod_constant_128
 3. __div_qr_constant_128
 4. optimize constant divisor of div_qr_1
 1, 2, 3, 4: constant numbers that can be divisible by (uint64_t)(-1),
*/

WJR_INLINE_CONSTEXPR20 uint64_t
div128by64to64_noshift(uint64_t &rem, uint64_t lo, uint64_t hi,
                       const wjr::div2by1_divider_noshift<uint64_t> &divider) noexcept {
    const uint64_t result = divider.divide(lo, hi);
    rem = hi;
    return result;
}

WJR_INLINE_CONSTEXPR20 uint64_t
div128by64to64_shift(uint64_t &rem, uint64_t lo, uint64_t hi,
                     const wjr::div2by1_divider<uint64_t> &divider) noexcept {
    const auto shift = divider.get_shift();
    hi = shld(hi, lo, shift);
    lo <<= shift;
    const uint64_t result = divider.get_base().divide(lo, hi);
    rem = hi >> shift;
    return result;
}

WJR_INLINE_CONSTEXPR20 uint64_t
div128by64to64_impl(uint64_t &rem, uint64_t lo, uint64_t hi,
                    const wjr::div2by1_divider<uint64_t> &divider) noexcept {
    if (divider.get_shift() == 0) {
        return div128by64to64_noshift(rem, lo, hi, divider);
    }

    return div128by64to64_shift(rem, lo, hi, divider);
}

/*
 not optimize for divider that is power of 2,
 manually consider whether it needs to be optimized
*/
WJR_INLINE_CONSTEXPR20 uint64_t
div128by64to64(uint64_t &rem, uint64_t lo, uint64_t hi,
               const div2by1_divider<uint64_t> &divider) noexcept {
    return div128by64to64_impl(rem, lo, hi, divider);
}

/*
 not optimize for divider that is power of 2,
 manually consider whether it needs to be optimized
*/
WJR_INLINE_CONSTEXPR20 uint64_t div128by64to64(uint64_t &rem, uint64_t lo, uint64_t hi,
                                               uint64_t div) noexcept {
    return div128by64to64_impl(rem, lo, hi, wjr::div2by1_divider<uint64_t>(div));
}

inline uint128_t
div128by64to128_noshift(uint64_t &rem, uint64_t lo, uint64_t hi,
                        const div2by1_divider_noshift<uint64_t> &divider) noexcept {
    const auto divisor = divider.get_divisor();
    uint64_t q0, q1 = 0;

    if (hi >= divisor) {
        q1 = 1;
        hi -= divisor;
    }

    q0 = divider.divide(lo, hi);
    rem = hi;
    return {q0, q1};
}

inline uint128_t
div128by64to128_shift(uint64_t &rem, uint64_t lo, uint64_t hi,
                      const div2by1_divider<uint64_t> &divider) noexcept {
    const auto shift = divider.get_shift();
    uint64_t u0, u1, u2;
    uint64_t q0, q1;

    u2 = hi >> (64 - shift);
    u1 = shld(hi, lo, shift);
    u0 = lo << shift;

    const auto &div = divider.get_base();
    q1 = div.divide(u1, u2);
    q0 = div.divide(u0, u2);

    rem = u2 >> shift;
    return {q0, q1};
}

inline uint128_t div128by64to128_impl(uint64_t &rem, uint64_t lo, uint64_t hi,
                                      const div2by1_divider<uint64_t> &divider) noexcept {
    if (divider.get_shift() == 0) {
        return div128by64to128_noshift(rem, lo, hi, divider);
    }

    return div128by64to128_shift(rem, lo, hi, divider);
}

/*
 not optimize for divider that is power of 2,
 manually consider whether it needs to be optimized
*/
inline uint128_t div128by64to128(uint64_t &rem, uint64_t lo, uint64_t hi,
                                 const div2by1_divider<uint64_t> &divider) noexcept {
    return div128by64to128_impl(rem, lo, hi, divider);
}

/*
 not optimize for divider that is power of 2,
 manually consider whether it needs to be optimized
*/
inline uint128_t div128by64to128(uint64_t &rem, uint64_t lo, uint64_t hi,
                                 uint64_t div) noexcept {
    return div128by64to128_impl(rem, lo, hi, div2by1_divider<uint64_t>(div));
}

// reference : https://ieeexplore.ieee.org/document/5487506
inline uint64_t div_qr_1_noshift(uint64_t *dst, uint64_t &rem, const uint64_t *src,
                                 size_t n,
                                 const div2by1_divider_noshift<uint64_t> &div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_L2(WJR_IS_SAME_OR_DECR_P(dst, n - 1, src, n - 1));

    const uint64_t divisor = div.get_divisor();
    const uint64_t value = div.get_value();

    uint64_t qh = 0;
    uint64_t lo, hi;

    hi = src[n - 1];

    if (hi >= divisor) {
        hi -= divisor;
        qh = 1;
    }

    do {
        if (WJR_UNLIKELY(n == 1)) {
            break;
        }

        --n;

        do {
            lo = src[n - 1];
            dst[n - 1] = div.divide(divisor, value, lo, hi);
            --n;
        } while (WJR_LIKELY(n != 0));

    } while (0);

    rem = hi;
    return qh;
}

extern uint64_t div_qr_1_shift(uint64_t *dst, uint64_t &rem, const uint64_t *src,
                               size_t n, const div2by1_divider<uint64_t> &div) noexcept;

WJR_INTRINSIC_INLINE uint64_t
div_qr_1_impl(uint64_t *dst, uint64_t &rem, const uint64_t *src, size_t n,
              const div2by1_divider<uint64_t> &div) noexcept {
    if (div.get_shift() == 0) {
        return div_qr_1_noshift(dst, rem, src, n, div);
    }

    return div_qr_1_shift(dst, rem, src, n, div);
}

// return high quotient limb
WJR_INTRINSIC_INLINE void div_qr_1(uint64_t *dst, uint64_t &rem, const uint64_t *src,
                                   size_t n,
                                   const div2by1_divider<uint64_t> &div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);

    if (WJR_UNLIKELY(div.is_zero_or_single_bit())) {
        const unsigned int c = 63 - div.get_shift();
        rem = src[0] & ((1ull << c) - 1);
        (void)rshift_n(dst, src, n, c);
        return;
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == 2)) {
        const auto [ax, dx] = div128by64to128(rem, src[0], src[1], div);
        dst[0] = ax;
        dst[1] = dx;
        return;
    }

    dst[n - 1] = div_qr_1_impl(dst, rem, src, n, div);
}

WJR_INTRINSIC_INLINE void div_qr_1(uint64_t *dst, uint64_t &rem, const uint64_t *src,
                                   size_t n, type_identity_t<uint64_t> div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_ASSUME(div != 0);

    if (WJR_UNLIKELY(is_zero_or_single_bit(div))) {
        const unsigned int c = ctz(div);
        rem = src[0] & ((1ull << c) - 1);
        (void)rshift_n(dst, src, n, c);
        return;
    }

    if (WJR_UNLIKELY(n == 1)) {
        const uint64_t tmp = src[0];

        if (__has_high_bit(div)) {
            if (tmp >= div) {
                rem = tmp - div;
                dst[0] = 1;
                return;
            }
            rem = tmp;
            dst[0] = 0;
            return;
        }

        dst[0] = tmp / div;
        rem = tmp % div;
        return;
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == 2)) {
        const auto [ax, dx] = div128by64to128(rem, src[0], src[1], div);
        dst[0] = ax;
        dst[1] = dx;
        return;
    }

    dst[n - 1] = div_qr_1_impl(dst, rem, src, n, div2by1_divider<uint64_t>(div));
}

extern uint64_t div_qr_2_noshift(uint64_t *dst, uint64_t *rem, const uint64_t *src,
                                 size_t n,
                                 const div3by2_divider_noshift<uint64_t> &div) noexcept;

extern uint64_t div_qr_2_shift(uint64_t *dst, uint64_t *rem, const uint64_t *src,
                               size_t n, const div3by2_divider<uint64_t> &div) noexcept;

WJR_INTRINSIC_INLINE uint64_t
div_qr_2_impl(uint64_t *dst, uint64_t *rem, const uint64_t *src, size_t n,
              const div3by2_divider<uint64_t> &div) noexcept {
    if (div.get_shift() == 0) {
        return div_qr_2_noshift(dst, rem, src, n, div);
    }

    return div_qr_2_shift(dst, rem, src, n, div);
}

WJR_INTRINSIC_INLINE void div_qr_2(uint64_t *dst, uint64_t *rem, const uint64_t *src,
                                   size_t n,
                                   const div3by2_divider<uint64_t> &div) noexcept {
    WJR_ASSERT_ASSUME(n >= 2);

    dst[n - 2] = div_qr_2_impl(dst, rem, src, n, div);
}

WJR_INTRINSIC_INLINE void div_qr_2(uint64_t *dst, uint64_t *rem, const uint64_t *src,
                                   size_t n, const uint64_t *div) noexcept {
    WJR_ASSERT_ASSUME(n >= 2);

    dst[n - 2] =
        div_qr_2_impl(dst, rem, src, n, div3by2_divider<uint64_t>(div[0], div[1]));
}

// reference : GMP
// return qh;
extern uint64_t sb_div_qr_s(uint64_t *dst, uint64_t *src, size_t n, const uint64_t *div,
                            size_t m, uint64_t dinv) noexcept;

extern uint64_t dc_div_qr_s(uint64_t *dst, uint64_t *src, size_t n, const uint64_t *div,
                            size_t m, uint64_t dinv) noexcept;

extern void __div_qr_s_impl(uint64_t *dst, uint64_t *rem, const uint64_t *src, size_t n,
                            const uint64_t *div, size_t m) noexcept;

WJR_INTRINSIC_INLINE void div_qr_s(uint64_t *dst, uint64_t *rem, const uint64_t *src,
                                   size_t n, const uint64_t *div, size_t m) noexcept {
    WJR_ASSERT_ASSUME(m >= 1);
    WJR_ASSERT_ASSUME(n >= m);

    if (WJR_BUILTIN_CONSTANT_P(m)) {
        switch (m) {
        case 0: {
            WJR_UNREACHABLE();
            break;
        }
        case 1: {
            return div_qr_1(dst, rem[0], src, n, div[0]);
        }
        case 2: {
            return div_qr_2(dst, rem, src, n, div);
        }
        default: {
            break;
        }
        }
    }

    return __div_qr_s_impl(dst, rem, src, n, div, m);
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t fallback_divexact_dbm1c(uint64_t *dst,
                                                           const uint64_t *src, size_t n,
                                                           uint64_t bd,
                                                           uint64_t h) noexcept {
    uint64_t a = 0;
    uint64_t p0, p1, cf;

    // GCC can't optimize well
    WJR_UNROLL(4)
    for (size_t i = 0; i < n; i++) {
        a = src[i];
        p0 = mul(a, bd, p1);
        h = subc(h, p0, 0, cf);
        dst[i] = h;
        h -= p1 + cf;
    }

    return h;
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t divexact_dbm1c(uint64_t *dst, const uint64_t *src,
                                                  size_t n, uint64_t bd,
                                                  uint64_t h) noexcept {
#if WJR_HAS_BUILTIN(ASM_DIVEXACT_DBM1C)
    if (is_constant_evaluated()) {
        return fallback_divexact_dbm1c(dst, src, n, bd, h);
    }

    return asm_divexact_dbm1c(dst, src, n, bd, h);
#else
    return fallback_divexact_dbm1c(dst, src, n, bd, h);
#endif
}

// reference : ftp://ftp.risc.uni-linz.ac.at/pub/techreports/1992/92-35.ps.gz
WJR_INLINE_CONSTEXPR20
void fallback_divexact_1_noshift(uint64_t *dst, const uint64_t *src, size_t n,
                                 const divexact1_divider<uint64_t> &div) noexcept {
    const uint64_t divisor = div.get_divisor();
    const uint64_t value = div.get_value();

    uint64_t rdx = 0, r10 = 0;
    uint64_t cf = 0;
    size_t idx = 0;

    --n;

    if (WJR_LIKELY(n != 0)) {
        do {
            r10 = src[idx];
            r10 = subc(r10, rdx, cf, cf);
            r10 = mullo(r10, value);
            dst[idx] = r10;
            ++idx;
            rdx = mulhi(r10, divisor);
        } while (WJR_LIKELY(idx != n));
    }

    r10 = src[n];
    r10 -= rdx + cf;
    r10 = mullo(r10, value);
    dst[n] = r10;
    return;
}

WJR_INLINE_CONSTEXPR20 void
fallback_divexact_1_shift(uint64_t *dst, const uint64_t *src, size_t n,
                          const divexact1_divider<uint64_t> &div,
                          uint64_t hicf = 0) noexcept {
    const uint64_t divisor = div.get_divisor();
    const uint64_t value = div.get_value();
    const auto shift = div.get_shift();

    uint64_t rdx = 0, r10 = 0;
    uint64_t cf = 0;
    size_t idx = 0;

    --n;
    r10 = src[0];

    if (WJR_LIKELY(n != 0)) {
        do {
            uint64_t r11 = src[idx + 1];
            r10 = shrd(r10, r11, shift);
            r10 = subc(r10, rdx, cf, cf);
            r10 = mullo(r10, value);
            dst[idx] = r10;
            ++idx;
            rdx = mulhi(r10, divisor);
            r10 = r11;
        } while (WJR_LIKELY(idx != n));
    }

    r10 = shrd(r10, hicf, shift);
    r10 -= rdx + cf;
    r10 = mullo(r10, value);
    dst[n] = r10;
    return;
}

template <uint64_t c>
WJR_INTRINSIC_CONSTEXPR uint64_t __divexact_get_impl() noexcept {
    return 1;
}

template <uint64_t c, uint64_t p, uint64_t... ps>
WJR_INTRINSIC_CONSTEXPR uint64_t __divexact_get_impl() noexcept {
    constexpr auto ret = __divexact_get_impl<c, ps...>();
    if constexpr (c % p == 0) {
        return ret * p;
    } else {
        return ret;
    }
}

template <uint64_t c>
WJR_INTRINSIC_CONSTEXPR uint64_t __divexact_get() noexcept {
    return __divexact_get_impl<c, 3, 5, 17>();
}

struct __divexact_get_struct {
    int mode;
    int cl;
    uint64_t p0, p1;
};

template <uint64_t c>
constexpr __divexact_get_struct __divexact_init() noexcept {
    if constexpr (is_zero_or_single_bit(c)) {
        return {0, constexpr_ctz(c), 0, 0};
    } else {
        constexpr auto p0 = __divexact_get<c>();
        if constexpr (p0 == 1) {
            return {1, 0, 0, 0};
        } else {
            constexpr auto c0 = c / p0;
            if constexpr (is_zero_or_single_bit(c0)) {
                return {2, constexpr_ctz(c), p0, 0};
            } else {
                constexpr auto p1 = __divexact_get<c0>();
                if constexpr (p1 == 1) {
                    return {1, 0, 0, 0};
                } else {
                    constexpr auto c1 = c0 / p1;
                    if constexpr (is_zero_or_single_bit(c1)) {
                        return {3, constexpr_ctz(c1), p0, p1};
                    } else {
                        return {1, 0, 0, 0};
                    }
                }
            }
        }
    }
}

template <uint64_t c>
WJR_INTRINSIC_CONSTEXPR20 void divexact_byc(uint64_t *dst, const uint64_t *src, size_t n,
                                            integral_constant<uint64_t, c>,
                                            uint64_t cf) noexcept {
    // cost : divexact_dbm1c * 2 + shift * 1 <= divexact_1
    static_assert(c != 0, "");
    constexpr auto ss = __divexact_init<c>();

    if constexpr (ss.mode == 0) {
        (void)rshift_n(dst, src, n, ss.cl, cf);
    }

    if constexpr (ss.mode == 1) {
        constexpr auto shift = constexpr_ctz(c);
        using divider_t = divexact1_divider<uint64_t>;
        constexpr auto divisor = c >> shift;
        constexpr auto value = divider_t::reciprocal(divisor);
        constexpr auto divider = divider_t(divisor, value, shift);

        static_assert(!divider.is_zero_or_single_bit(), "");

        if constexpr (shift == 0) {
            fallback_divexact_1_noshift(dst, src, n, divider);
        } else {
            fallback_divexact_1_shift(dst, src, n, divider, cf);
        }
    }

    if constexpr (ss.mode == 2 || ss.mode == 3) {
        constexpr uint64_t maxn = UINT64_MAX;

        if constexpr (ss.cl == 0) {
            (void)divexact_dbm1c(dst, src, n, maxn / ss.p0, 0);
        } else {
            (void)rshift_n(dst, src, n, ss.cl, cf);
            (void)divexact_dbm1c(dst, dst, n, maxn / ss.p0, 0);
        }

        if constexpr (ss.mode == 3) {
            (void)divexact_dbm1c(dst, dst, n, maxn / ss.p1, 0);
        }
    }
}

WJR_INTRINSIC_CONSTEXPR20 void
fallback_divexact_1(uint64_t *dst, const uint64_t *src, size_t n,
                    const divexact1_divider<uint64_t> &div) noexcept {
    if (div.get_shift() == 0) {
        return fallback_divexact_1_noshift(dst, src, n, div);
    }

    return fallback_divexact_1_shift(dst, src, n, div);
}

WJR_INTRINSIC_CONSTEXPR20 void
divexact_1(uint64_t *dst, const uint64_t *src, size_t n,
           const divexact1_divider<uint64_t> &div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);

    if (WJR_UNLIKELY(div.is_zero_or_single_bit())) {
        unsigned int c = div.get_shift();
        (void)rshift_n(dst, src, n, c);
        return;
    }

    return fallback_divexact_1(dst, src, n, div);
}

WJR_INTRINSIC_CONSTEXPR20 void divexact_1(uint64_t *dst, const uint64_t *src, size_t n,
                                          uint64_t div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_ASSUME(div != 0);

    if (WJR_UNLIKELY(is_zero_or_single_bit(div))) {
        const unsigned int c = ctz(div);
        (void)rshift_n(dst, src, n, c);
        return;
    }

    return fallback_divexact_1(dst, src, n, divexact1_divider<uint64_t>(div));
}

WJR_PURE WJR_INLINE_CONSTEXPR20 uint64_t
mod_1_noshift(const uint64_t *src, size_t n,
              const div2by1_divider_noshift<uint64_t> &div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);

    const uint64_t divisor = div.get_divisor();
    const uint64_t value = div.get_value();

    uint64_t lo, hi;

    hi = src[n - 1];

    if (hi >= divisor) {
        hi -= divisor;
    }

    do {
        if (WJR_UNLIKELY(n == 1)) {
            break;
        }

        --n;

        do {
            lo = src[n - 1];
            (void)div.divide(divisor, value, lo, hi);
            --n;
        } while (WJR_LIKELY(n != 0));

    } while (0);

    return hi;
}

WJR_PURE WJR_INLINE_CONSTEXPR20 uint64_t mod_1_shift(
    const uint64_t *src, size_t n, const div2by1_divider<uint64_t> &div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT(div.get_shift() != 0);

    const uint64_t divisor = div.get_divisor();
    const uint64_t value = div.get_value();
    const auto shift = div.get_shift();

    uint64_t lo, hi;

    uint64_t rbp = src[n - 1];
    --n;
    hi = rbp >> (64 - shift);

    do {
        if (WJR_UNLIKELY(n == 0)) {
            (void)div.divide(divisor, value, rbp << shift, hi);
            break;
        }

        lo = src[n - 1];
        (void)div.divide(divisor, value, shld(rbp, lo, shift), hi);
        rbp = lo;
        --n;

        if (WJR_LIKELY(n != 0)) {
            do {
                lo = src[n - 1];
                (void)div.divide(divisor, value, shld(rbp, lo, shift), hi);
                rbp = lo;
                --n;
            } while (WJR_LIKELY(n != 0));
        }

        (void)div.divide(divisor, value, rbp << shift, hi);
    } while (0);

    return hi >> shift;
}

WJR_PURE WJR_INTRINSIC_CONSTEXPR20 uint64_t
mod_1_impl(const uint64_t *src, size_t n, const div2by1_divider<uint64_t> &div) noexcept {
    if (div.get_shift() == 0) {
        return mod_1_noshift(src, n, div);
    }

    return mod_1_shift(src, n, div);
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t mod_1(const uint64_t *src, size_t n,
                                         const div2by1_divider<uint64_t> &div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);

    if (WJR_UNLIKELY(div.is_zero_or_single_bit())) {
        const unsigned int c = 63 - div.get_shift();
        return src[0] & ((1ull << c) - 1);
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == 2)) {
        uint64_t rem;
        (void)div128by64to128(rem, src[0], src[1], div);
        return rem;
    }

    return mod_1_impl(src, n, div);
}

WJR_INTRINSIC_CONSTEXPR20 uint64_t mod_1(const uint64_t *src, size_t n,
                                         type_identity_t<uint64_t> div) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    WJR_ASSERT_ASSUME(div != 0);

    if (WJR_UNLIKELY(is_zero_or_single_bit(div))) {
        const unsigned int c = ctz(div);
        return src[0] & ((1ull << c) - 1);
    }

    if (WJR_UNLIKELY(n == 1)) {
        const uint64_t tmp = src[0];

        if (__has_high_bit(div)) {
            if (tmp >= div) {
                return tmp - div;
            }

            return tmp;
        }

        return tmp % div;
    }

    if (WJR_BUILTIN_CONSTANT_P_TRUE(n == 2)) {
        uint64_t rem;
        (void)div128by64to128(rem, src[0], src[1], div);
        return rem;
    }

    return mod_1_impl(src, n, div2by1_divider<uint64_t>(div));
}

} // namespace wjr

#endif // WJR_MATH_DIV_HPP__
#ifndef WJR_MATH_PRECOMPUTE_CHARS_CONVERT_HPP__
#define WJR_MATH_PRECOMPUTE_CHARS_CONVERT_HPP__

// Already included

namespace wjr {

struct precompute_chars_convert_16n_t {
    uint64_t big_base;
    size_t n;
    int digits_in_one_base;
    int digits_in_sixteen_base;
    uint64_t arr[16];
};

struct precompute_chars_convert_t {
    const uint64_t *ptr;
    size_t n;
    size_t shift;
    size_t digits_in_base;
    unsigned int base;
};

extern const std::array<const precompute_chars_convert_16n_t *, 37>
    precompute_chars_convert_16n_ptr;

extern precompute_chars_convert_t *
precompute_chars_convert(precompute_chars_convert_t *pre_table, size_t n,
                         unsigned int base, uint64_t *mem_table) noexcept;

} // namespace wjr

#endif // WJR_MATH_PRECOMPUTE_CHARS_CONVERT_HPP__
#ifndef WJR_MATH_STACK_ALLOCATOR_HPP__
#define WJR_MATH_STACK_ALLOCATOR_HPP__

#ifndef WJR_STACK_ALLOCATOR_HPP__
#define WJR_STACK_ALLOCATOR_HPP__

#include <algorithm>

// Already included
// Already included

namespace wjr {

template <typename StackAllocator>
class unique_stack_allocator;

template <size_t Cache>
class stack_allocator_object {
    template <typename StackAllocator>
    friend class unique_stack_allocator;

    constexpr static uint16_t bufsize = 5;

    struct alloc_node {
        char *ptr;
        char *end;
    };

    struct large_stack_top {
        large_stack_top *prev;
    };

public:
    struct stack_top {
        char *ptr;
        uint16_t idx;
        large_stack_top *large;
    };

private:
    WJR_CONSTEXPR20 void *__large_allocate(size_t n, stack_top &top) noexcept {
        auto *const buffer =
            static_cast<large_stack_top *>(malloc(sizeof(large_stack_top) + n));
        buffer->prev = top.large;
        top.large = buffer;
        return buffer + 1;
    }

    WJR_NOINLINE WJR_CONSTEXPR20 void __small_reallocate(stack_top &top) noexcept {
        if (WJR_UNLIKELY(top.idx == UINT16_MAX)) {
            top.idx = m_idx;
        }

        ++m_idx;
        if (WJR_UNLIKELY(m_idx == m_size)) {

            if (WJR_UNLIKELY(m_size == m_capacity)) {
                const uint16_t new_capacity = m_idx + 2 * (bufsize - 1);
                memory_pool<alloc_node> pool;
                auto *const new_ptr = pool.chunk_allocate(new_capacity);
                if (WJR_LIKELY(m_idx != 0)) {
                    std::copy_n(m_ptr, m_idx, new_ptr);
                    pool.chunk_deallocate(m_ptr, m_capacity);
                }
                m_ptr = new_ptr;
                m_capacity = new_capacity;
            }

            ++m_size;

            const size_t capacity = Cache << ((3 * m_idx + 2) / 5);
            memory_pool<char> pool;
            auto *const buffer = pool.chunk_allocate(capacity);
            const alloc_node node = {buffer, buffer + capacity};
            m_ptr[m_idx] = node;

            if (WJR_UNLIKELY(m_idx == 0)) {
                top.ptr = node.ptr;
                top.idx = 0;
            }

            m_cache = node;
        } else {
            m_cache = m_ptr[m_idx];
        }

        WJR_ASSERT(top.ptr != nullptr);
    }

    WJR_NOINLINE WJR_CONSTEXPR20 void __small_redeallocate() noexcept {
        const uint16_t new_size = m_idx + bufsize - 1;
        memory_pool<char> pool;

        for (uint16_t i = new_size; i < m_size; ++i) {
            pool.chunk_deallocate(m_ptr[i].ptr, m_ptr[i].end - m_ptr[i].ptr);
        }

        m_size = new_size;
    }

    WJR_CONSTEXPR20 void __small_deallocate(const stack_top &top) noexcept {
        if (WJR_UNLIKELY(top.ptr == nullptr)) {
            return;
        }

        m_cache.ptr = top.ptr;

        if (WJR_UNLIKELY(top.idx != UINT16_MAX)) {
            const uint16_t idx = top.idx;
            m_cache.end = m_ptr[idx].end;
            m_idx = idx;
            if (WJR_UNLIKELY(m_size - idx >= bufsize)) {
                __small_redeallocate();
            }
        }
    }

    WJR_MALLOC WJR_CONSTEXPR20 void *__small_allocate(size_t n, stack_top &top) noexcept {
        if (WJR_UNLIKELY(static_cast<size_t>(m_cache.end - m_cache.ptr) < n)) {
            __small_reallocate(top);
        }

        WJR_ASSERT_ASSUME_L2(m_cache.ptr != nullptr);
        WJR_ASSERT_ASSUME_L2(top.ptr != nullptr);

        auto *const ret = m_cache.ptr;
        m_cache.ptr += n;
        return ret;
    }

public:
    using value_type = void;
    using size_type = size_t;
    using difference_type = ptrdiff_t;
    using propagate_on_container_move_assignment = std::true_type;

    stack_allocator_object() = default;
    stack_allocator_object(stack_allocator_object &) = delete;
    stack_allocator_object(stack_allocator_object &&) = delete;
    stack_allocator_object &operator=(stack_allocator_object &) = delete;
    stack_allocator_object &operator=(stack_allocator_object &&) = delete;
    ~stack_allocator_object() = default;

    WJR_NODISCARD WJR_MALLOC WJR_CONSTEXPR20 void *allocate(size_t n, stack_top &top,
                                                            size_t threshold) noexcept {
        if (WJR_UNLIKELY(n >= threshold)) {
            return __large_allocate(n, top);
        }

        return __small_allocate(n, top);
    }

    WJR_CONSTEXPR20 void deallocate(const stack_top &top) noexcept {
        __small_deallocate(top);

        auto *buffer = top.large;
        while (WJR_UNLIKELY(buffer != nullptr)) {
            auto *const prev = buffer->prev;
            free(buffer);
            buffer = prev;
        }
    }

    WJR_CONSTEXPR20 void set(stack_top &top) const noexcept {
        top.ptr = m_cache.ptr;
        top.idx = UINT16_MAX;
        top.large = nullptr;
    }

private:
    alloc_node m_cache = {nullptr, nullptr};
    uint16_t m_idx = UINT16_MAX;
    uint16_t m_size = 0;
    uint16_t m_capacity = 0;
    alloc_node *m_ptr = nullptr;
};

/**
 * @brief A stack allocator for fast simulation of stack memory on the heap, singleton
 * mode.
 *
 * @tparam Cache The size of the first heap memory allocation
 */
template <size_t Cache, size_t DefaultThreshold>
struct singleton_stack_allocator_object {
    using Instance = stack_allocator_object<Cache>;
    constexpr static size_t __default_threshold = DefaultThreshold;

    static_assert(DefaultThreshold < Cache, "DefaultThreshold must be less than Cache.");

    static Instance &get_instance() noexcept {
        static thread_local Instance instance;
        return instance;
    }
};

/**
 * @details Used for container. This allocator won't deallocate memory allocated by
 * __small_allocate until container is destroyed.
 *
 */
template <typename T, typename StackAllocator>
class weak_stack_allocator;

/**
 * @brief A unique stack allocator for fast simulation of stack memory on the heap.
 *
 * @details When a unique_stack_allocator object is destroyed, all the memory it allocates
 * is released.\n And a new unique_stack_allocator constructed in the lifetime of a
 * unique_stack_allocator object must be destroyed in the current lifetime.
 *
 */
template <typename StackAllocator>
class unique_stack_allocator {
    using Instance = typename StackAllocator::Instance;
    using stack_top = typename Instance::stack_top;

    constexpr static size_t __default_threshold = StackAllocator::__default_threshold;

    template <typename T, typename S>
    friend class weak_stack_allocator;

public:
    WJR_INTRINSIC_INLINE unique_stack_allocator(const StackAllocator &al) noexcept
        : m_instance(&(al.get_instance())) {
        m_instance->set(m_top);
    }

    unique_stack_allocator(const unique_stack_allocator &) = delete;
    unique_stack_allocator(unique_stack_allocator &&) = delete;
    unique_stack_allocator &operator=(const unique_stack_allocator &) = delete;
    unique_stack_allocator &operator=(unique_stack_allocator &&) = delete;

    ~unique_stack_allocator() noexcept { m_instance->deallocate(m_top); }

    WJR_NODISCARD WJR_MALLOC WJR_INTRINSIC_INLINE void *
    allocate(size_t n, size_t threshold = __default_threshold) noexcept {
        return m_instance->allocate(n, m_top, threshold);
    }

private:
    WJR_NODISCARD WJR_MALLOC WJR_INTRINSIC_INLINE void *
    __small_allocate(size_t n) noexcept {
        return m_instance->__small_allocate(n, m_top);
    }

    Instance *m_instance;
    stack_top m_top;
};

template <typename StackAllocator>
unique_stack_allocator(const StackAllocator &) -> unique_stack_allocator<StackAllocator>;

/**
 * @brief Point to unique_stack_allocator.
 *
 * @details Use a pointer to unique_stack_allocator to allocate memory. This class must be
 * used carefully. If recursively using it as a reference and allocating memory,
 * unique_stack_allocator should be avoided from being reused in the current function.
 *
 */
template <typename T, size_t Cache, size_t DefaultThreshold>
class weak_stack_allocator<T, singleton_stack_allocator_object<Cache, DefaultThreshold>> {
    using StackAllocator = singleton_stack_allocator_object<Cache, DefaultThreshold>;
    using UniqueStackAllocator = unique_stack_allocator<StackAllocator>;

    constexpr static size_t __default_threshold = StackAllocator::__default_threshold;

    template <typename U, typename A>
    friend class weak_stack_allocator;

public:
    using value_type = T;
    using size_type = size_t;
    using difference_type = ptrdiff_t;
    using propagate_on_container_move_assignment = std::true_type;
    using is_trivially_allocator = std::true_type;

    template <typename Other>
    struct rebind {
        using other = weak_stack_allocator<Other, StackAllocator>;
    };

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(weak_stack_allocator);

    weak_stack_allocator(UniqueStackAllocator &alloc) noexcept : m_alloc(&alloc) {}

    template <typename U>
    weak_stack_allocator(const weak_stack_allocator<U, StackAllocator> &other) noexcept
        : m_alloc(other.m_alloc) {}

    WJR_NODISCARD WJR_MALLOC WJR_CONSTEXPR20 T *allocate(size_type n) noexcept {
        const size_t size = n * sizeof(T);
        if (WJR_UNLIKELY(size >= __default_threshold)) {
            return static_cast<T *>(malloc(size));
        }

        return static_cast<T *>(m_alloc->__small_allocate(size));
    }

    WJR_CONSTEXPR20 void deallocate(WJR_MAYBE_UNUSED T *ptr,
                                    WJR_MAYBE_UNUSED size_type n) noexcept {
        const size_t size = n * sizeof(T);
        if (WJR_UNLIKELY(size >= __default_threshold)) {
            free(ptr);
        }
    }

private:
    UniqueStackAllocator *m_alloc = nullptr;
};

} // namespace wjr

#endif // WJR_STACK_ALLOCATOR_HPP__

namespace wjr::math_detail {

using stack_alloc_object = singleton_stack_allocator_object<36 * 1024, 16 * 1024>;
inline constexpr stack_alloc_object stack_alloc = {};

using unique_stack_alloc = unique_stack_allocator<stack_alloc_object>;

template <typename T>
using weak_stack_alloc = weak_stack_allocator<T, stack_alloc_object>;

} // namespace wjr::math_detail

#endif // WJR_MATH_STACK_ALLOCATOR_HPP__

namespace wjr {

inline constexpr size_t dc_bignum_to_chars_threshold = WJR_DC_BIGNUM_TO_CHARS_THRESHOLD;
inline constexpr size_t dc_bignum_to_chars_precompute_threshold =
    WJR_DC_BIGNUM_TO_CHARS_THRESHOLD;

inline constexpr size_t dc_bignum_from_chars_threshold =
    WJR_DC_BIGNUM_FROM_CHARS_THRESHOLD;
inline constexpr size_t dc_bignum_from_chars_precompute_threshold =
    WJR_DC_BIGNUM_FROM_CHARS_PRECOMPUTE_THRESHOLD;

inline constexpr auto div2by1_divider_noshift_of_big_base_10 =
    div2by1_divider_noshift<uint64_t>(10'000'000'000'000'000'000ull,
                                      15'581'492'618'384'294'730ull);

inline constexpr auto div3by2_divider_shift_of_big_base_10 = div3by2_divider<uint64_t>(
    1374799102801346560ull, 10842021724855044340ull, 12'938'764'603'223'852'203ull, 1);

template <typename Converter>
size_t __biginteger_to_chars_2_impl(uint8_t *first, const uint64_t *up, size_t n,
                                    Converter conv) noexcept {
    WJR_ASSERT_L2(up[n - 1] != 0);
    WJR_ASSERT_ASSUME(n >= 2);

    uint64_t x = up[n - 1];
    --n;
    const int pc = clz(x);
    const int hbits = 64 - pc;
    WJR_ASSUME(1 <= hbits && hbits <= 64);

    const size_t len = hbits + 64 * n;
    first += len;

    do {
        x = *up;

        for (int i = 0; i < 8; ++i) {
            __to_chars_unroll_8<2>(first - 8, x & 0xff, conv);
            first -= 8;
            x >>= 8;
        }

        ++up;
        --n;
    } while (n != 0);
    x = *up;

    (void)__unsigned_to_chars_backward_unchecked<2>(first, hbits, x, conv);
    return len;
}

template <typename Converter>
size_t __biginteger_to_chars_8_impl(uint8_t *first, const uint64_t *up, size_t n,
                                    Converter conv) noexcept {
    WJR_ASSERT_L2(up[n - 1] != 0);
    WJR_ASSERT_ASSUME(n >= 2);

    uint64_t x = up[n - 1];
    --n;
    const int pc = clz(x);
    int hbits = 64 - pc;
    WJR_ASSUME(1 <= hbits && hbits <= 64);

    const size_t len = (hbits + 64 * n + 2) / 3;
    first += len;

    int rest = 0;
    unsigned int last = 0;

    do {
        x = *up;

        switch (rest) {
        case 0: {
            rest = 2;
            break;
        }
        case 2: {
            __to_chars_unroll_2<8>(first - 2, last | ((x & 0x03) << 4), conv);
            first -= 2;
            x >>= 2;
            rest = 4;
            break;
        }
        case 4: {
            __to_chars_unroll_2<8>(first - 2, last | ((x & 0x0f) << 2), conv);
            first -= 2;
            x >>= 4;
            rest = 0;
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }

        __to_chars_unroll_8<8>(first - 8, x & 0xff'ffff, conv);
        x >>= 24;
        __to_chars_unroll_8<8>(first - 16, x & 0xff'ffff, conv);
        x >>= 24;
        __to_chars_unroll_4<8>(first - 20, x & 0x0fff, conv);
        x >>= 12;
        first -= 20;

        last = x;

        ++up;
        --n;
    } while (n);
    x = *up;

    switch (rest) {
    case 0: {
        break;
    }
    case 2: {
        __to_chars_unroll_2<8>(first - 2, last | ((x & 0x03) << 4), conv);
        first -= 2;
        if (hbits <= 2) {
            goto DONE;
        }
        hbits -= 2;
        x >>= 2;
        break;
    }
    case 4: {
        if (WJR_UNLIKELY(hbits == 1)) {
            *--first = conv.template to<8>(x << 2 | last);
            goto DONE;
        }

        __to_chars_unroll_2<8>(first - 2, last | ((x & 0x0f) << 2), conv);
        first -= 2;
        if (hbits <= 4) {
            goto DONE;
        }
        hbits -= 4;
        x >>= 4;
        break;
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

    if (WJR_LIKELY(hbits + 2 >= 12)) {
        do {
            __to_chars_unroll_4<8>(first - 4, x & 0x0fff, conv);
            first -= 4;
            x >>= 12;
            hbits -= 12;
        } while (WJR_LIKELY(hbits + 2 >= 12));
    }

    switch ((hbits + 2) / 3) {
    case 3: {
        *--first = conv.template to<8>(x & 0x07);
        x >>= 3;
        WJR_FALLTHROUGH;
    }
    case 2: {
        __to_chars_unroll_2<8>(first - 2, x, conv);
        break;
    }
    case 1: {
        *--first = conv.template to<8>(x);
        WJR_FALLTHROUGH;
    }
    case 0: {
        break;
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

DONE:
    return len;
}

template <typename Converter>
size_t __biginteger_to_chars_16_impl(uint8_t *first, const uint64_t *up, size_t n,
                                     Converter conv) noexcept {
    WJR_ASSERT_L2(up[n - 1] != 0);
    WJR_ASSERT_ASSUME(n >= 2);

    uint64_t x = up[n - 1];
    --n;
    const int pc = clz(x);
    int hbits = 64 - pc;
    WJR_ASSUME(1 <= hbits && hbits <= 64);
    hbits = (hbits + 3) / 4;

    const size_t len = hbits + 16 * n;
    first += len;

    do {
        x = *up;

        __to_chars_unroll_8<16>(first - 8, x & 0xffff'ffff, conv);
        __to_chars_unroll_8<16>(first - 16, x >> 32, conv);
        first -= 16;

        ++up;
        --n;
    } while (n);
    x = *up;

    (void)__unsigned_to_chars_backward_unchecked<16>(first, hbits, x, conv);

    return len;
}

template <typename Converter>
size_t __biginteger_to_chars_power_of_two_impl(uint8_t *first, const uint64_t *up,
                                               size_t n, unsigned int base,
                                               Converter conv) noexcept {
    WJR_ASSERT_L2(up[n - 1] != 0);
    WJR_ASSERT_ASSUME(n >= 2);

    const int bits = ctz(base);
    const unsigned int mask = (1u << bits) - 1;

    uint64_t x = up[n - 1];
    --n;
    const int pc = clz(x);
    const int hbits = 64 - pc;
    WJR_ASSUME(1 <= hbits && hbits <= 64);

    const size_t len = (hbits + 64 * n + bits - 1) / bits;
    first += len;

    int rest = 0;
    unsigned int last = 0;

    do {
        x = *up;

        if (rest) {
            int fix = bits - rest;
            unsigned int val = ((x & ((1u << fix) - 1)) << rest) | last;
            x >>= fix;
            rest = 64 - fix;
            *--first = conv.to(val);
        } else {
            rest = 64;
        }

        do {
            *--first = conv.to(x & mask);
            x >>= bits;
            rest -= bits;
        } while (rest >= bits);

        last = x;

        ++up;
        --n;
    } while (n);
    x = *up;

    WJR_ASSERT_ASSUME(rest < bits);

    if (WJR_UNLIKELY(rest != 0)) {
        int fix = bits - rest;
        unsigned int val = ((x & ((1u << fix) - 1)) << rest) | last;
        x >>= fix;
        *--first = conv.to(val);
        rest = hbits - fix;
        if (WJR_UNLIKELY(rest == 0)) {
            goto DONE;
        }
    } else {
        rest = hbits;
    }

    do {
        *--first = conv.to(x & mask);
        x >>= bits;
        rest -= bits;
    } while (WJR_LIKELY(rest > 0));

DONE:
    return len;
}

template <typename Converter>
uint8_t *basecase_to_chars_10(uint8_t *buf, uint64_t *up, size_t n,
                              Converter conv) noexcept {
    if (n > 4) {
        do {
            uint64_t q;
            uint64_t rem[2];
            q = div_qr_2_shift(up, rem, up, n, div3by2_divider_shift_of_big_base_10);
            if (q != 0) {
                up[n - 2] = q;
                n -= 1;
            } else {
                n -= 2;
            }

            uint64_t lo, hi;
            hi = div128by64to64_noshift(lo, rem[0], rem[1],
                                        div2by1_divider_noshift_of_big_base_10);

            __to_chars_unroll_8<10>(buf - 8, lo % 1'0000'0000, conv);
            lo /= 1'0000'0000;
            __to_chars_unroll_8<10>(buf - 16, lo % 1'0000'0000, conv);
            lo /= 1'0000'0000;
            __to_chars_unroll_2<10>(buf - 18, lo % 100, conv);
            lo /= 100;
            buf[-19] = conv.template to<10>(lo);
            buf -= 19;

            __to_chars_unroll_8<10>(buf - 8, hi % 1'0000'0000, conv);
            hi /= 1'0000'0000;
            __to_chars_unroll_8<10>(buf - 16, hi % 1'0000'0000, conv);
            hi /= 1'0000'0000;
            __to_chars_unroll_2<10>(buf - 18, hi % 100, conv);
            hi /= 100;
            buf[-19] = conv.template to<10>(hi);
            buf -= 19;
        } while (n > 4);
    }

    do {
        if (WJR_UNLIKELY(n == 1)) {
            return __unsigned_to_chars_backward_unchecked<10>(buf, up[0], conv);
        }

        uint64_t q, rem;

        q = div_qr_1_noshift(up, rem, up, n, div2by1_divider_noshift_of_big_base_10);
        n -= q == 0;
        if (q != 0) {
            up[n - 1] = q;
        }

        __to_chars_unroll_8<10>(buf - 8, rem % 1'0000'0000, conv);
        rem /= 1'0000'0000;
        __to_chars_unroll_8<10>(buf - 16, rem % 1'0000'0000, conv);
        rem /= 1'0000'0000;
        __to_chars_unroll_2<10>(buf - 18, rem % 100, conv);
        rem /= 100;
        buf[-19] = conv.template to<10>(rem);

        buf -= 19;
    } while (n);

    WJR_UNREACHABLE();
}

extern template uint8_t *
basecase_to_chars_10<char_converter_t>(uint8_t *, uint64_t *, size_t,
                                       char_converter_t) noexcept;

template <typename Converter>
uint8_t *basecase_to_chars(uint8_t *first, size_t len, uint64_t *up, size_t n,
                           unsigned int base, Converter conv) noexcept {
    constexpr size_t buf_len = dc_bignum_to_chars_precompute_threshold * 64 * 7 / 11;
    uint8_t buf[buf_len];
    uint8_t *const end = buf + buf_len;
    uint8_t *start;

    if (WJR_LIKELY(base == 10)) {
        start = basecase_to_chars_10(end, up, n, conv);
    } else {
        start = end;
    }

    if (const size_t rlen = end - start; len > rlen) {
        first = std::fill_n(first, len - rlen, conv.template to<1>(0));
    }

    return std::copy(start, end, first);
}

template <typename Converter>
uint8_t *dc_to_chars(uint8_t *first, size_t len, uint64_t *up, size_t n,
                     precompute_chars_convert_t *pre, uint64_t *stk,
                     Converter conv) noexcept {
    WJR_ASSERT_ASSUME(n >= 1);
    if (n < dc_bignum_to_chars_threshold) {
        return basecase_to_chars(first, len, up, n, pre->base, conv);
    }

    const auto *const pp = pre->ptr;
    const auto pn = pre->n;
    const auto ps = pre->shift;

    WJR_ASSERT((pn + ps) * 5 >= n * 2);

    if (n < pn + ps || (n == pn + ps && reverse_compare_n(up + ps, pp, pn) < 0)) {
        return dc_to_chars(first, len, up, n, pre - 1, stk, conv);
    }

    const auto pd = pre->digits_in_base;
    auto *qp = stk;

    div_qr_s(qp, up + ps, up + ps, n - ps, pp, pn);

    size_t qn = n - pn - ps;
    qn += qp[qn] != 0;

    if (len != 0) {
        len = len - pd;
    }

    pre -= qn * 2 <= n;

    first = dc_to_chars(first, len, qp, qn, pre, stk + qn, conv);
    first = dc_to_chars(first, pd, up, pn + ps, pre, stk, conv);
    return first;
}

template <typename Converter>
uint8_t *__biginteger_basecase_to_chars(uint8_t *first, const uint64_t *up, size_t n,
                                        unsigned int base, Converter conv) noexcept {
    if (WJR_LIKELY(n < dc_bignum_to_chars_precompute_threshold)) {
        uint64_t upbuf[dc_bignum_to_chars_precompute_threshold];
        std::copy_n(up, n, upbuf);
        return basecase_to_chars(first, 0, upbuf, n, base, conv);
    }

    precompute_chars_convert_t pre[64 - 3];

    unique_stack_allocator stkal(math_detail::stack_alloc);
    auto *stk =
        static_cast<uint64_t *>(stkal.allocate((n * 18 / 5 + 192) * sizeof(uint64_t)));
    auto *const __up = stk;
    std::copy_n(up, n, __up);
    stk += n;
    auto *const first_pre = precompute_chars_convert(pre, n, base, stk);
    stk += n * 8 / 5 + 128;
    return dc_to_chars(first, 0, __up, n, first_pre, stk, conv);
}

template <typename Converter>
uint8_t *__fast_biginteger_large_to_chars_impl(uint8_t *first, const uint64_t *up,
                                               size_t n, unsigned int base,
                                               Converter conv) noexcept {
    switch (base) {
    case 2: {
        return first + __biginteger_to_chars_2_impl(first, up, n, conv);
    }
    case 8: {
        return first + __biginteger_to_chars_8_impl(first, up, n, conv);
    }
    case 16: {
        return first + __biginteger_to_chars_16_impl(first, up, n, conv);
    }
    case 4:
    case 32: {
        return first + __biginteger_to_chars_power_of_two_impl(first, up, n, base, conv);
    }
    default: {
        break;
    }
    }

    return __biginteger_basecase_to_chars(first, up, n, base, conv);
}

template <typename Iter, typename Converter>
Iter __fallback_biginteger_large_to_chars_impl(Iter ptr, const uint64_t *up, size_t n,
                                               unsigned int base,
                                               Converter conv) noexcept {
#define WJR_BIGINTEGER_TO_CHARS_IMPL(BASE, NAME, TAIL, SIZE, CALL)                       \
    constexpr auto __fast_container_inserter_v =                                         \
        charconv_detail::is_fast_container_inserter_v<Iter>;                             \
    if constexpr (__fast_container_inserter_v != 0) {                                    \
        auto &cont = get_inserter_container(ptr);                                        \
        const auto __presize = cont.size();                                              \
        if constexpr (__fast_container_inserter_v == 1) {                                \
            resize(cont, __presize + SIZE);                                              \
        } else {                                                                         \
            append(cont, SIZE, dctor);                                                   \
        }                                                                                \
        auto *const __ptr =                                                              \
            reinterpret_cast<uint8_t *>(wjr::to_address(cont.data())) + __presize;       \
        const auto __size = NAME(__ptr, WJR_PP_QUEUE_EXPAND(CALL), conv) TAIL;           \
        WJR_ASSERT((size_t)__size <= SIZE);                                              \
        if constexpr (__fast_container_inserter_v == 1) {                                \
            resize(cont, __presize + __size);                                            \
        } else {                                                                         \
            resize(cont, __presize + __size, dctor);                                     \
        }                                                                                \
                                                                                         \
        return ptr;                                                                      \
    } else {                                                                             \
        unique_stack_allocator stkal(math_detail::stack_alloc);                          \
        auto *const __ptr =                                                              \
            static_cast<uint8_t *>(stkal.allocate(SIZE * sizeof(uint64_t)));             \
        const auto __size = NAME(__ptr, WJR_PP_QUEUE_EXPAND(CALL), conv) TAIL;           \
                                                                                         \
        return wjr::copy_n((charconv_detail::fast_buffer_t<Iter> *)__ptr, __size, ptr);  \
    }

    switch (base) {
    case 2: {
        const size_t capacity = 64 * n;
        WJR_BIGINTEGER_TO_CHARS_IMPL(2, __biginteger_to_chars_2_impl, , capacity,
                                     (up, n));
    }
    case 8: {
        const size_t capacity = (64 * n + 2) / 3;
        WJR_BIGINTEGER_TO_CHARS_IMPL(8, __biginteger_to_chars_8_impl, , capacity,
                                     (up, n));
    }
    case 16: {
        const size_t capacity = (64 * n + 3) / 4;
        WJR_BIGINTEGER_TO_CHARS_IMPL(16, __biginteger_to_chars_16_impl, , capacity,
                                     (up, n));
    }
    case 4:
    case 32: {
        const int bits = base == 4 ? 2 : 5;
        const size_t capacity = (64 * n + bits - 1) / bits;
        WJR_BIGINTEGER_TO_CHARS_IMPL(base, __biginteger_to_chars_power_of_two_impl, ,
                                     capacity, (up, n, base));
    }
    default: {
        break;
    }
    }

    const size_t capacity = ((64 * n) * 4 + 12) / 13;
    WJR_BIGINTEGER_TO_CHARS_IMPL(base, __biginteger_basecase_to_chars, -__ptr, capacity,
                                 (up, n, base));

#undef WJR_BIGINTEGER_TO_CHARS_IMPL
}

template <typename Iter, typename Converter>
Iter __biginteger_to_chars_impl(Iter first, const uint64_t *up, size_t n,
                                unsigned int base, Converter conv) noexcept {
    if (WJR_UNLIKELY(n == 1)) {
        return to_chars_unchecked(first, up[0], base, conv);
    }

    if constexpr (charconv_detail::__is_fast_convert_iterator_v<Iter>) {
        auto *const __first = reinterpret_cast<uint8_t *>(wjr::to_address(first));
        const auto __result =
            __fast_biginteger_large_to_chars_impl(__first, up, n, base, conv);
        return first + std::distance(__first, __result);
    } else {
        return __fallback_biginteger_large_to_chars_impl(first, up, n, base, conv);
    }
}

/**
 * @brief Convert a biginteger to a string by a given base.
 *
 * @tparam Iter Output iterator type
 * @param[out] first Output iterator
 * @param[in] up Pointer to the biginteger
 * @param[in] n Length of the biginteger
 * @param[in] base Base of the output string. Range: `[2, 36]`,
 * Only support 10 and power of two currently.
 * @return Output iterator after the conversion
 */
template <typename Iter, typename Converter = char_converter_t>
Iter biginteger_to_chars(Iter first, const uint64_t *up, size_t n, unsigned int base = 10,
                         Converter conv = {}) noexcept {
    WJR_ASSERT(base <= 36 && (is_zero_or_single_bit(base) || base == 10));
    WJR_ASSERT_ASSUME(up[n - 1] != 0);

    return __biginteger_to_chars_impl(first, up, n, base, conv);
}

template <typename Converter>
size_t __biginteger_from_chars_2_impl(const uint8_t *first, size_t n, uint64_t *up,
                                      Converter conv) noexcept {
    const size_t hbits = (n - 1) % 64 + 1;
    const size_t len = (n - 1) / 64 + 1;

    uint64_t x = 0;
    up += len;

    __unsigned_from_chars_unchecked<2>(first, first + hbits, x, conv);
    first += hbits;

    *--up = x;

    size_t idx = len - 1;

    if (idx) {
        do {
            x = 0;

            for (int i = 0; i < 4; ++i) {
                x = (x << 16) + __from_chars_unroll_16<2>(first, conv);
                first += 16;
            }

            *--up = x;
        } while (WJR_LIKELY(--idx));
    }

    return len;
}

template <typename Converter>
size_t __biginteger_from_chars_8_impl(const uint8_t *first, size_t n, uint64_t *up,
                                      Converter conv) noexcept {
    size_t len = (n * 3 + 63) / 64;
    const size_t lbits = (64 * (len - 1)) / 3;
    size_t rest = (64 * (len - 1)) % 3;
    const size_t hbits = n - lbits - 1;

    uint64_t x = 0;
    up += len;
    size_t idx = len - 1;

    if (WJR_UNLIKELY(hbits == 0)) {
    } else {
        __unsigned_from_chars_unchecked<8>(first, first + hbits, x, conv);
        first += hbits;
    }

    uint64_t nx = conv.template from<8>(*first++);
    switch (rest) {
    case 0: {
        *--up = x << 3 | nx;
        x = 0;
        break;
    }
    case 1: {
        x = x << 2 | nx >> 1;
        if (WJR_UNLIKELY(x == 0)) {
            --len;
        }

        *--up = x;
        x = nx & 1;
        break;
    }
    case 2: {
        x = x << 1 | nx >> 2;
        if (WJR_UNLIKELY(x == 0)) {
            --len;
        }
        *--up = x;
        x = nx & 3;
        break;
    }
    default: {
        WJR_UNREACHABLE();
        break;
    }
    }

    if (idx) {
        do {
            for (int i = 0; i < 5; ++i) {
                auto x0 = conv.template from<8>(first[0]);
                auto x1 = conv.template from<8>(first[1]);
                auto x2 = conv.template from<8>(first[2]);
                auto x3 = conv.template from<8>(first[3]);

                x = x << 12 | x0 << 9 | x1 << 6 | x2 << 3 | x3;
                first += 4;
            }

            switch (rest) {
            case 0: {
                x = x << 3 | conv.template from<8>(*first++);
                nx = conv.template from<8>(*first++);
                x = x << 1 | nx >> 2;
                *--up = x;
                x = nx & 3;
                rest = 2;
                break;
            }
            case 1: {
                x = x << 3 | conv.template from<8>(*first++);
                *--up = x;
                x = 0;
                rest = 0;
                break;
            }
            case 2: {
                nx = conv.template from<8>(*first++);
                x = x << 2 | nx >> 1;
                *--up = x;
                x = nx & 1;
                rest = 1;
                break;
            }
            default: {
                WJR_UNREACHABLE();
                break;
            }
            }

        } while (WJR_LIKELY(--idx));
    }

    return len;
}

template <typename Converter>
size_t __biginteger_from_chars_16_impl(const uint8_t *first, size_t n, uint64_t *up,
                                       Converter conv) noexcept {
    const size_t hbits = (n - 1) % 16 + 1;
    const size_t len = (n - 1) / 16 + 1;

    uint64_t x = 0;
    up += len;

    __unsigned_from_chars_unchecked<16>(first, first + hbits, x, conv);
    first += hbits;

    *--up = x;

    size_t idx = len - 1;

    if (idx) {
        do {
            x = 0;

            for (int i = 0; i < 4; ++i) {
                auto x0 = conv.template from<16>(first[0]);
                auto x1 = conv.template from<16>(first[1]);
                auto x2 = conv.template from<16>(first[2]);
                auto x3 = conv.template from<16>(first[3]);

                x = x << 16 | x0 << 12 | x1 << 8 | x2 << 4 | x3;
                first += 4;
            }

            *--up = x;
        } while (WJR_LIKELY(--idx));
    }

    return len;
}

template <typename Converter>
size_t basecase_from_chars_10(const uint8_t *first, size_t n, uint64_t *up,
                              Converter conv) noexcept {
    uint64_t x = 0;

    if (n <= 19) {
        __unsigned_from_chars_unchecked<10>(first, first + n, x, conv);
        up[0] = x;

        return up[0] != 0;
    }

    size_t m = (n - 1) % 19 + 1;

    __unsigned_from_chars_unchecked<10>(first, first + m, x, conv);
    up[0] = x;

    first += m;
    n -= m;

    m = up[0] != 0;

    do {
        x = 0;

        x = __from_chars_unroll_16<10>(first, conv);
        first += 16;

        x = x * 10 + conv.template from<10>(*first++);
        x = x * 10 + conv.template from<10>(*first++);
        x = x * 10 + conv.template from<10>(*first++);

        uint64_t cf;

        if (WJR_LIKELY(m == 0)) {
            cf = x;
        } else {
            cf = mul_1(up, up, m, div2by1_divider_noshift_of_big_base_10.get_divisor());
            cf += addc_1(up, up, m, x);
        }

        if (WJR_LIKELY(cf != 0)) {
            up[m++] = cf;
        }

        n -= 19;
    } while (WJR_LIKELY(n != 0));

    return m;
}

template <typename Converter>
size_t basecase_from_chars(const uint8_t *first, size_t n, uint64_t *up,
                           unsigned int base, Converter conv) noexcept {
    if (base == 10) {
        return basecase_from_chars_10(first, n, up, conv);
    } else {
        WJR_UNREACHABLE();
    }
}

template <typename Converter>
size_t dc_from_chars(const uint8_t *first, size_t n, uint64_t *up,
                     precompute_chars_convert_t *pre, uint64_t *stk,
                     Converter conv) noexcept {
    const size_t lo = pre->digits_in_base;
    if (n <= lo) {
        if (n < dc_bignum_from_chars_threshold) {
            return basecase_from_chars(first, n, up, pre->base, conv);
        } else {
            return dc_from_chars(first, n, up, pre - 1, stk, conv);
        }
    }

    const size_t hi = n - lo;
    size_t hn, ln;

    if (hi < dc_bignum_from_chars_threshold) {
        hn = basecase_from_chars(first, hi, stk, pre->base, conv);
    } else {
        hn = dc_from_chars(first, hi, stk, pre - (lo * 2 >= n), up, conv);
    }

    const size_t ps = pre->shift;
    const size_t pn = pre->n;

    if (WJR_LIKELY(hn != 0)) {
        if (pn >= hn) {
            mul_s(up + ps, pre->ptr, pn, stk, hn);
        } else {
            mul_s(up + ps, stk, hn, pre->ptr, pn);
        }
        set_n(up, 0, ps);
    }

    std::advance(first, hi);
    if (lo < dc_bignum_from_chars_threshold) {
        ln = basecase_from_chars(first, lo, stk, pre->base, conv);
    } else {
        ln = dc_from_chars(first, lo, stk, pre - (lo * 2 >= n), stk + pn + ps + 1, conv);
    }

    WJR_ASSERT(ps + pn + 1 >= ln);

    if (WJR_LIKELY(hn != 0)) {
        if (WJR_LIKELY(ln != 0)) {
            auto cf = addc_s(up, up, ps + pn + hn, stk, ln);
            WJR_ASSERT(cf == 0);
            (void)(cf);
        }

        n = ps + pn + hn;
        return n - (up[n - 1] == 0);
    }

    if (WJR_LIKELY(ln != 0)) {
        std::copy_n(stk, ln, up);
    }

    return ln;
}

template <typename Converter>
uint64_t *__biginteger_from_chars_impl(const uint8_t *first, const uint8_t *last,
                                       uint64_t *up, unsigned int base,
                                       Converter conv) noexcept {
    WJR_ASSERT(base <= 36 && (is_zero_or_single_bit(base) || base == 10));

    const size_t n = std::distance(first, last);

    if (is_zero_or_single_bit(base)) {
        switch (base) {
        case 2: {
            return up + __biginteger_from_chars_2_impl(first, n, up, conv);
        }
        case 8: {
            return up + __biginteger_from_chars_8_impl(first, n, up, conv);
        }
        case 16: {
            return up + __biginteger_from_chars_16_impl(first, n, up, conv);
        }
        default: {
            WJR_UNREACHABLE();
        }
        }
    }

    if (WJR_LIKELY(n < dc_bignum_from_chars_precompute_threshold)) {
        return up + basecase_from_chars(first, n, up, base, conv);
    }

    const auto per_digits = precompute_chars_convert_16n_ptr[base]->digits_in_one_base;

    precompute_chars_convert_t pre[64 - 3];

    unique_stack_allocator stkal(math_detail::stack_alloc);
    const size_t un = n / per_digits + 1;
    auto *stk =
        static_cast<uint64_t *>(stkal.allocate((un * 16 / 5 + 192) * sizeof(uint64_t)));
    auto *const first_pre = precompute_chars_convert(pre, un, base, stk);
    stk += un * 8 / 5 + 128;
    return up + dc_from_chars(first, n, up, first_pre, stk, conv);
}

extern template uint64_t *
__biginteger_from_chars_impl<char_converter_t>(const uint8_t *, const uint8_t *,
                                               uint64_t *, unsigned int,
                                               char_converter_t) noexcept;

/**
 * @brief Convert a string to a biginteger by a given base.
 *
 * @tparam Iter Input iterator type
 * @param[in] first Input iterator
 * @param[in] last Input iterator
 * @param[out] up Pointer to the biginteger
 * @param[in] base Base of the input string. Range: `[2, 36]`,
 * Only support 10 and power of two currently.
 * @return Pointer after the conversion
 */
template <typename Iter, typename Converter = char_converter_t,
          WJR_REQUIRES(charconv_detail::__is_fast_convert_iterator_v<Iter>)>
uint64_t *biginteger_from_chars(Iter first, Iter last, uint64_t *up,
                                unsigned int base = 10, Converter conv = {}) noexcept {
    WJR_ASSERT(base <= 36 && (is_zero_or_single_bit(base) || base == 10));

    const auto *const __first = reinterpret_cast<const uint8_t *>(wjr::to_address(first));
    const auto *const __last = reinterpret_cast<const uint8_t *>(wjr::to_address(last));

    return __biginteger_from_chars_impl(__first, __last, up, base, conv);
}

} // namespace wjr

#endif // WJR_MATH_CONVERT_HPP__
#ifndef WJR_MATH_COPY_HPP__
#define WJR_MATH_COPY_HPP__

// Already included

namespace wjr {

/// @private
template <typename InputIt, typename OutputIt>
struct __is_builtin_copy
    : std::conjunction<
          std::is_trivially_copyable<iterator_value_t<InputIt>>,
          std::is_same<iterator_value_t<InputIt>, iterator_value_t<OutputIt>>,
          is_contiguous_iterator<InputIt>, is_contiguous_iterator<OutputIt>> {};

/// @private
template <typename InputIt, typename OutputIt>
inline constexpr bool __is_builtin_copy_v = __is_builtin_copy<InputIt, OutputIt>::value;

} // namespace wjr

#endif // WJR_MATH_COPY_HPP__
#ifndef WJR_MATH_NEG_HPP__
#define WJR_MATH_NEG_HPP__

#ifndef WJR_MATH_NOT_HPP__
#define WJR_MATH_NOT_HPP__

// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_MATH_NOT_HPP__
#define WJR_X86_MATH_NOT_HPP__

// Already included
// Already included

#ifndef WJR_X86
#error "x86 required"
#endif

namespace wjr {

#if WJR_HAS_SIMD(SSE2)
#define WJR_HAS_BUILTIN_COMPLEMENT_N WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(COMPLEMENT_N)

template <typename T>
void large_builtin_not_n(T *dst, const T *src, size_t n) noexcept {
    constexpr auto is_avx = WJR_HAS_SIMD(AVX2);

    using simd = std::conditional_t<is_avx, avx, sse>;
    constexpr auto simd_width = simd::width();
    constexpr auto type_width = simd_width / 64;

    const uintptr_t ptr = reinterpret_cast<uintptr_t>(dst);
    WJR_ASSUME(ptr % sizeof(T) == 0);
    const size_t offset = __align_up_offset(ptr, 32) / sizeof(T);

    WJR_ASSUME(offset < 4);

    const auto y = sse::ones();

    do {
        if (offset == 0) {
            break;
        }

        if (offset == 1) {
            dst[0] = ~src[0];
            break;
        }

        sse::storeu(dst, sse::Xor(sse::loadu(src), y));

        if (offset == 3) {
            dst[2] = ~src[2];
        }
    } while (0);

    dst += offset;
    src += offset;
    n -= offset;

    const auto z = broadcast<__m128i_t, typename simd::int_tag_type>(y);

    size_t m = n & (-type_width * 4);
    n &= (type_width * 4) - 1;
    WJR_ASSUME(m != 0);

    do {
        auto x0 = simd::loadu(src);
        auto x1 = simd::loadu(src + type_width);
        auto x2 = simd::loadu(src + type_width * 2);
        auto x3 = simd::loadu(src + type_width * 3);

        simd::store(dst, simd::Xor(x0, z));
        simd::store(dst + type_width, simd::Xor(x1, z));
        simd::store(dst + type_width * 2, simd::Xor(x2, z));
        simd::store(dst + type_width * 3, simd::Xor(x3, z));

        dst += type_width * 4;
        src += type_width * 4;
        m -= type_width * 4;
    } while (m != 0);

    if (WJR_UNLIKELY(n == 0)) {
        return;
    }

    m = n / type_width;
    WJR_ASSUME(m < 4);

    switch (m) {
    case 3: {
        simd::store(dst, simd::Xor(simd::loadu(src), z));
        WJR_FALLTHROUGH;
    }
    case 2: {
        simd::store(dst + type_width * (m - 2),
                    simd::Xor(simd::loadu(src + type_width * (m - 2)), z));
        WJR_FALLTHROUGH;
    }
    case 1: {
        simd::store(dst + type_width * (m - 1),
                    simd::Xor(simd::loadu(src + type_width * (m - 1)), z));
        WJR_FALLTHROUGH;
    }
    case 0: {
        break;
    }
    default: {
        WJR_UNREACHABLE();
    }
    }

    m = n & (-type_width);

    if (WJR_UNLIKELY(n == m)) {
        return;
    }

    WJR_ASSUME(n - m < 4);

    switch (n - m) {
    case 1: {
        dst[m] = ~src[m];
        break;
    }
    case 2: {
        sse::store(dst + m, sse::Xor(sse::loadu(src + m), y));
        break;
    }

    case 3: {
        sse::store(dst + m, sse::Xor(sse::loadu(src + m), y));
        dst[m + 2] = ~src[m + 2];
        break;
    }

    default: {
        WJR_UNREACHABLE();
    }
    }

    return;
}

template <typename T>
WJR_INTRINSIC_INLINE void unaligned_large_builtin_not_n(T *dst, const T *src,
                                                        size_t n) noexcept {
    size_t idx = 0;
    const auto y = sse::ones();

    if (n & 4) {
        sse::storeu(dst + idx, sse::Xor(sse::loadu(src + idx), y));
        sse::storeu(dst + idx + 2, sse::Xor(sse::loadu(src + idx + 2), y));

        idx += 4;
    }

    if (n & 2) {
        sse::storeu(dst + idx, sse::Xor(sse::loadu(src + idx), y));

        idx += 2;
    }

    if (n & 1) {
        dst[idx] = ~src[idx];

        ++idx;
    }

    if (WJR_UNLIKELY(idx == n)) {
        return;
    }

    WJR_ASSUME((n - idx) % 8 == 0);

    do {
        auto x0 = sse::loadu(src + idx);
        auto x1 = sse::loadu(src + idx + 2);
        auto x2 = sse::loadu(src + idx + 4);
        auto x3 = sse::loadu(src + idx + 6);

        sse::storeu(dst + idx, sse::Xor(x0, y));
        sse::storeu(dst + idx + 2, sse::Xor(x1, y));
        sse::storeu(dst + idx + 4, sse::Xor(x2, y));
        sse::storeu(dst + idx + 6, sse::Xor(x3, y));

        idx += 8;
    } while (idx != n);
}

template <typename T>
WJR_INTRINSIC_INLINE void builtin_not_n(T *dst, const T *src, size_t n) noexcept {
    static_assert(sizeof(T) == 8, "");

    if (WJR_UNLIKELY(n < 4)) {
        if (WJR_UNLIKELY(n == 0)) {
            return;
        }

        if (n == 1) {
            dst[0] = ~src[0];
            return;
        }

        sse::storeu(dst, sse::Xor(sse::loadu(src), sse::ones()));

        if (n == 3) {
            dst[2] = ~src[2];
        }

        return;
    }

    if (WJR_UNLIKELY(n >= 35)) {
        // Can be aligned
        // TODO : Align those that cannot be aligned with T through uint8_t
        if (WJR_LIKELY(reinterpret_cast<uintptr_t>(dst) % sizeof(T) == 0)) {
            return large_builtin_not_n(dst, src, n);
        }
    }

    return unaligned_large_builtin_not_n(dst, src, n);
}

#endif //

} // namespace wjr

#endif // WJR_X86_MATH_NOT_HPP__
#endif

namespace wjr {

template <typename T>
WJR_INTRINSIC_CONSTEXPR void fallback_not_n(T *dst, const T *src, size_t n) noexcept {
    for (size_t i = 0; i < n; ++i) {
        dst[i] = ~src[i];
    }
}

template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T>)>
WJR_INTRINSIC_CONSTEXPR20 void not_n(T *dst, const T *src, size_t n) noexcept {
#if WJR_HAS_BUILTIN(COMPLEMENT_N)
    if constexpr (sizeof(T) == 8) {
        if (is_constant_evaluated()) {
            return fallback_not_n(dst, src, n);
        }

        return builtin_not_n(dst, src, n);
    } else {
        return fallback_not_n(dst, src, n);
    }
#else
    return fallback_not_n(dst, src, n);
#endif
}

} // namespace wjr

#endif // WJR_MATH_NOT_HPP__
// Already included

namespace wjr {

/*
  return true if src is all zero
  calculations : stable n instead of not + inc which maybe n * 2
*/
template <typename T>
WJR_INTRINSIC_CONSTEXPR20 bool negate_n(T *dst, const T *src, size_t n) noexcept {
    const size_t idx = replace_find_not(dst, src, n, 0, 0);

    if (idx == n) {
        return true;
    }

    dst[idx] = -src[idx];
    not_n(dst + idx + 1, src + idx + 1, n - idx - 1);
    return false;
}

} // namespace wjr

#endif // WJR_MATH_NEG_HPP__
// Already included
#ifndef WJR_MATH_RANDOM_HPP__
#define WJR_MATH_RANDOM_HPP__

#include <algorithm>
#include <random>

// Already included

namespace wjr {

template <typename Engine, typename = void>
struct __uniform_random_bit_generator_impl : std::false_type {};

template <typename Engine>
struct __uniform_random_bit_generator_impl<Engine,
                                           std::enable_if_t<has_invocable_v<Engine &>>>
    : std::conjunction<
          is_nonbool_unsigned_integral<std::invoke_result_t<Engine &>>,
          std::is_same<decltype(Engine::min()), std::invoke_result_t<Engine &>>,
          std::is_same<decltype(Engine::max()), std::invoke_result_t<Engine &>>> {};

template <typename Engine>
struct uniform_random_bit_generator : __uniform_random_bit_generator_impl<Engine> {};

template <typename Engine>
inline constexpr bool uniform_random_bit_generator_v =
    uniform_random_bit_generator<Engine>::value;

template <typename Engine>
struct biginteger_uniform_random_bit_generator
    : std::conjunction<
          __uniform_random_bit_generator_impl<Engine>,
          std::is_same<std::invoke_result_t<Engine &>, uint64_t>,
          std::bool_constant<Engine::min() == std::numeric_limits<uint64_t>::min()>,
          std::bool_constant<Engine::max() == std::numeric_limits<uint64_t>::max()>> {};

template <typename Engine>
inline constexpr bool biginteger_uniform_random_bit_generator_v =
    biginteger_uniform_random_bit_generator<Engine>::value;

template <typename Iter, typename Rand>
void random(Iter first, Iter last, Rand &&rd) {
    std::generate(first, last, std::ref(rd));
}

template <typename Iter, typename Rand>
void random_n(Iter First, size_t Count, Rand &&rd) {
    std::generate_n(First, Count, std::ref(rd));
}

} // namespace wjr

#endif // WJR_MATH_RANDOM_HPP__

#endif // WJR_MATH_HPP__
// Already included
// Already included

namespace wjr {

namespace biginteger_detail {

/**
 * @brief Remove leading zeros.
 *
 */
inline uint32_t normalize(const uint64_t *ptr, uint32_t n) noexcept {
    return static_cast<uint32_t>(reverse_find_not_n(ptr, 0, n));
}

} // namespace biginteger_detail

class default_biginteger_size_reference {
public:
    default_biginteger_size_reference() = delete;
    default_biginteger_size_reference(const default_biginteger_size_reference &) = delete;
    default_biginteger_size_reference(default_biginteger_size_reference &&) = default;
    default_biginteger_size_reference &
    operator=(const default_biginteger_size_reference &) = delete;
    default_biginteger_size_reference &
    operator=(default_biginteger_size_reference &&) = default;
    ~default_biginteger_size_reference() = default;

    constexpr explicit default_biginteger_size_reference(int32_t &size) noexcept
        : m_size(&size) {}

    constexpr default_biginteger_size_reference &operator=(uint32_t size) noexcept {
        *m_size = __fasts_negate_with<int32_t>(*m_size, to_signed(size));
        return *this;
    }

    WJR_PURE constexpr operator uint32_t() const noexcept { return __fasts_abs(*m_size); }

    constexpr default_biginteger_size_reference &operator++() noexcept {
        *m_size = __fasts_increment(*m_size);
        return *this;
    }

    constexpr default_biginteger_size_reference &operator--() noexcept {
        *m_size = __fasts_decrement(*m_size);
        return *this;
    }

    constexpr default_biginteger_size_reference &operator+=(uint32_t size) noexcept {
        *m_size = __fasts_add(*m_size, size);
        return *this;
    }

    constexpr default_biginteger_size_reference &operator-=(uint32_t size) noexcept {
        *m_size = __fasts_sub(*m_size, size);
        return *this;
    }

private:
    int32_t *m_size;
};

/// @private
template <>
struct __unref_wrapper_helper<default_biginteger_size_reference> {
    using type = uint32_t &;
};

/**
 * @brief data_type of biginteger
 *
 * @details View the data of biginteger. Used for type erasure. Manage memory allocation
 * and release on your own.
 *
 */
struct biginteger_data {
    WJR_PURE constexpr const uint64_t *data() const noexcept { return m_data; }
    WJR_PURE constexpr uint32_t size() const noexcept { return __fasts_abs(m_size); }

    WJR_PURE constexpr bool empty() const noexcept { return m_size == 0; }
    WJR_PURE constexpr bool is_negate() const noexcept { return m_size < 0; }

    WJR_PURE constexpr int32_t get_ssize() const noexcept { return m_size; }

    uint64_t *m_data = nullptr;
    int32_t m_size = 0;
    uint32_t m_capacity = 0;
};

/**
 * @struct default_biginteger_data
 * @brief The data structure for biginteger
 *
 */
template <typename Alloc>
class default_biginteger_vector_storage {
    using _Alty = typename std::allocator_traits<Alloc>::template rebind_alloc<uint64_t>;
    using _Alty_traits = std::allocator_traits<_Alty>;

public:
    using value_type = uint64_t;
    using pointer = typename _Alty_traits::pointer;
    using const_pointer = typename _Alty_traits::const_pointer;
    using size_type = uint32_t;
    using difference_type = int32_t;
    using allocator_type = Alloc;
    using storage_traits_type = vector_storage_traits<uint64_t, Alloc>;
    using is_reallocatable = std::true_type;

    default_biginteger_vector_storage() = default;

    default_biginteger_vector_storage(const default_biginteger_vector_storage &) = delete;
    default_biginteger_vector_storage(default_biginteger_vector_storage &&) noexcept =
        delete;
    default_biginteger_vector_storage &
    operator=(const default_biginteger_vector_storage &) = delete;
    default_biginteger_vector_storage &
    operator=(default_biginteger_vector_storage &&) = delete;

    ~default_biginteger_vector_storage() = default;

    void destroy(_Alty &al) noexcept {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(data() == nullptr)) {
            return;
        }

        const size_type __size = size();

        if (WJR_BUILTIN_CONSTANT_P_TRUE(__size == 0)) {
            return;
        }

        destroy_n_using_allocator(data(), __size, al);
    }

    void destroy_and_deallocate(_Alty &al) noexcept {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(capacity() == 0)) {
            return;
        }

        if (data()) {
            WJR_ASSERT_ASSUME_L2(capacity() != 0);

            destroy(al);
            al.deallocate(data(), capacity());
        }
    }

    void uninitialized_construct(
        default_biginteger_vector_storage &other, size_type size, size_type capacity,
        _Alty &al) noexcept(noexcept(allocate_at_least(al, capacity))) {
        const auto result = allocate_at_least(al, capacity);

        auto &storage = other.m_storage;
        storage.m_data = result.ptr;
        storage.m_size = __fasts_negate_with<int32_t>(m_storage.m_size, size);
        storage.m_capacity = static_cast<size_type>(result.count);
    }

    void take_storage(default_biginteger_vector_storage &other, _Alty &) noexcept {
        auto &other_storage = other.m_storage;
        m_storage = other_storage;
        other_storage.m_data = nullptr;
        other_storage.m_size = other_storage.m_capacity = 0;
    }

    void swap_storage(default_biginteger_vector_storage &other, _Alty &) noexcept {
        std::swap(m_storage, other.m_storage);
    }

    WJR_PURE default_biginteger_size_reference size() noexcept {
        return default_biginteger_size_reference(m_storage.m_size);
    }

    WJR_PURE size_type size() const noexcept { return __fasts_abs(m_storage.m_size); }
    WJR_PURE size_type capacity() const noexcept { return m_storage.m_capacity; }

    WJR_PURE pointer data() noexcept { return m_storage.m_data; }
    WJR_PURE const_pointer data() const noexcept { return m_storage.m_data; }

    // extension

    WJR_PURE int32_t get_ssize() const noexcept { return m_storage.m_size; }

    template <typename T>
    void set_ssize(T size) = delete;

    void set_ssize(int32_t size) noexcept {
        WJR_ASSERT_ASSUME(__fasts_abs(size) <= capacity());
        m_storage.m_size = size;
    }

    WJR_PURE const biginteger_data *__get_data() const noexcept { return &m_storage; }

private:
    biginteger_data m_storage;
};

template <typename Storage>
class basic_biginteger;

template <typename Alloc>
using default_biginteger = basic_biginteger<default_biginteger_vector_storage<Alloc>>;

using biginteger = default_biginteger<memory_pool<uint64_t>>;

using stack_biginteger = default_biginteger<math_detail::weak_stack_alloc<uint64_t>>;

using default_biginteger_storage =
    default_biginteger_vector_storage<memory_pool<uint64_t>>;

WJR_PURE WJR_INTRINSIC_CONSTEXPR biginteger_data
make_biginteger_data(span<const uint64_t> sp) noexcept {
    return biginteger_data{const_cast<uint64_t *>(sp.data()),
                           static_cast<int32_t>(sp.size()), 0};
}

namespace biginteger_detail {

// const basic_biginteger<Storage>* don't need to get allocator
// use const Storage* instead of const basic_biginteger<Storage>*

/// @private
template <typename S>
WJR_PURE bool __equal_pointer(const basic_biginteger<S> *lhs,
                              const basic_biginteger<S> *rhs) noexcept {
    return lhs == rhs;
}

/// @private
template <typename S0, typename S1>
WJR_PURE bool __equal_pointer(const basic_biginteger<S0> *,
                              const basic_biginteger<S1> *) noexcept {
    return false;
}

/// @private
template <typename S>
WJR_PURE bool __equal_pointer(const basic_biginteger<S> *lhs,
                              const biginteger_data *rhs) noexcept {
    return lhs->__get_data() == rhs;
}

/// @private
template <typename S>
WJR_PURE bool __equal_pointer(const biginteger_data *lhs,
                              const basic_biginteger<S> *rhs) noexcept {
    return lhs == rhs->__get_data();
}

/// @private
WJR_PURE inline bool __equal_pointer(const biginteger_data *lhs,
                                     const biginteger_data *rhs) noexcept {
    return lhs == rhs;
}

/// @private
template <typename S>
from_chars_result<const char *> __from_chars_impl(const char *first, const char *last,
                                                  basic_biginteger<S> *dst,
                                                  unsigned int base) noexcept;

extern template from_chars_result<const char *>
__from_chars_impl<default_biginteger_storage>(
    const char *first, const char *last,
    basic_biginteger<default_biginteger_storage> *dst, unsigned int base) noexcept;

/// @private
WJR_PURE inline int32_t __compare_impl(const biginteger_data *lhs,
                                       const biginteger_data *rhs) noexcept;

/// @private
WJR_PURE inline int32_t __compare_ui_impl(const biginteger_data *lhs,
                                          uint64_t rhs) noexcept;

/// @private
WJR_PURE inline int32_t __compare_si_impl(const biginteger_data *lhs,
                                          int64_t rhs) noexcept;

/// @private
template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_PURE int32_t __compare_impl(const biginteger_data *lhs, T rhs) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(rhs == 0)) {
        const int32_t ssize = lhs->get_ssize();
        return ssize == 0 ? 0 : ssize < 0 ? -1 : 1;
    }

    if constexpr (std::is_unsigned_v<T>) {
        return __compare_ui_impl(lhs, rhs);
    } else {
        if (WJR_BUILTIN_CONSTANT_P_TRUE(rhs >= 0)) {
            return __compare_ui_impl(lhs, to_unsigned(rhs));
        }

        return __compare_si_impl(lhs, rhs);
    }
}

/// @private
template <bool xsign, typename S>
void __addsub_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                   uint64_t rhs) noexcept;

/// @private
template <typename S>
void __ui_sub_impl(basic_biginteger<S> *dst, uint64_t lhs,
                   const biginteger_data *rhs) noexcept;

/// @private
template <bool xsign, typename S>
void __addsub_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                   const biginteger_data *rhs) noexcept;

extern template void __addsub_impl<false, default_biginteger_storage>(
    basic_biginteger<default_biginteger_storage> *dst, const biginteger_data *lhs,
    const biginteger_data *rhs) noexcept;

extern template void __addsub_impl<true, default_biginteger_storage>(
    basic_biginteger<default_biginteger_storage> *dst, const biginteger_data *lhs,
    const biginteger_data *rhs) noexcept;

/// @private
template <typename S>
void __add_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                const biginteger_data *rhs) noexcept {
    __addsub_impl<false>(dst, lhs, rhs);
}

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void __add_impl(basic_biginteger<S> *dst, const biginteger_data *lhs, T rhs) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        __addsub_impl<false>(dst, lhs, rhs);
    } else {
        if (rhs < 0) {
            __addsub_impl<true>(dst, lhs, -to_unsigned(rhs));
        } else {
            __addsub_impl<false>(dst, lhs, to_unsigned(rhs));
        }
    }
}

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void __add_impl(basic_biginteger<S> *dst, T lhs, const biginteger_data *rhs) noexcept {
    __add_impl(dst, rhs, lhs);
}

/// @private
template <typename S>
void __sub_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                const biginteger_data *rhs) noexcept {
    __addsub_impl<true>(dst, lhs, rhs);
}

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void __sub_impl(basic_biginteger<S> *dst, const biginteger_data *lhs, T rhs) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        __addsub_impl<true>(dst, lhs, rhs);
    } else {
        if (rhs < 0) {
            __addsub_impl<false>(dst, lhs, -to_unsigned(rhs));
        } else {
            __addsub_impl<true>(dst, lhs, to_unsigned(rhs));
        }
    }
}

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void __sub_impl(basic_biginteger<S> *dst, T lhs, const biginteger_data *rhs) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        __ui_sub_impl(dst, lhs, rhs);
    } else {
        if (lhs < 0) {
            __addsub_impl<false>(dst, rhs, -to_unsigned(lhs));
            dst->negate();
        } else {
            __ui_sub_impl(dst, to_unsigned(lhs), rhs);
        }
    }
}

/// @private
template <typename S>
void __mul_ui_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                   uint64_t rhs) noexcept;

/// @private
template <typename S>
void __mul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                const biginteger_data *rhs) noexcept;

extern template void
__mul_impl<default_biginteger_storage>(basic_biginteger<default_biginteger_storage> *dst,
                                       const biginteger_data *lhs,
                                       const biginteger_data *rhs) noexcept;

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void __mul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs, T rhs) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        __mul_ui_impl(dst, lhs, rhs);
    } else {
        uint64_t value = to_unsigned(rhs);
        bool cond = false;

        if (rhs < 0) {
            value = -value;
            cond = true;
        }

        __mul_ui_impl(dst, lhs, value);
        dst->conditional_negate(cond);
    }
}

/// @private
template <typename S>
void __sqr_impl(basic_biginteger<S> *dst, const biginteger_data *src) noexcept;

extern template void
__sqr_impl<default_biginteger_storage>(basic_biginteger<default_biginteger_storage> *dst,
                                       const biginteger_data *src) noexcept;

/// @private
template <typename S>
void __addsubmul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs, uint64_t rhs,
                      int32_t xmask) noexcept;

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void __addmul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs, T rhs) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        __addsubmul_impl(dst, lhs, rhs, 0);
    } else {
        uint64_t rvalue = to_unsigned(rhs);
        int32_t xsign = 0;

        if (rhs < 0) {
            rvalue = -rvalue;
            xsign = -1;
        }

        __addsubmul_impl(dst, lhs, rvalue, xsign);
    }
}

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void __submul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs, T rhs) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        __addsubmul_impl(dst, lhs, rhs, -1);
    } else {
        uint64_t rvalue = to_unsigned(rhs);
        int32_t xsign = -1;

        if (rhs < 0) {
            rvalue = -rvalue;
            xsign = 0;
        }

        __addsubmul_impl(dst, lhs, rvalue, xsign);
    }
}

/// @private
template <typename S>
void __addsubmul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                      const biginteger_data *rhs, int32_t xmask) noexcept;

extern template void __addsubmul_impl<default_biginteger_storage>(
    basic_biginteger<default_biginteger_storage> *dst, const biginteger_data *lhs,
    const biginteger_data *rhs, int32_t xmask) noexcept;

/// @private
template <typename S>
void __addmul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                   const biginteger_data *rhs) noexcept {
    __addsubmul_impl(dst, lhs, rhs, 0);
}

/// @private
template <typename S>
void __submul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                   const biginteger_data *rhs) noexcept {
    __addsubmul_impl(dst, lhs, rhs, -1);
}

/// @private
template <typename S>
void __mul_2exp_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                     uint32_t shift) noexcept;

/// @private
template <typename S0, typename S1>
void __tdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                    const biginteger_data *num, const biginteger_data *div) noexcept;

/// @private
template <typename S>
void __tdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                   const biginteger_data *div) noexcept;

/// @private
template <typename S>
void __tdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                   const biginteger_data *div) noexcept;

/// @private
template <typename S0, typename S1>
uint64_t __tdiv_qr_ui_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                           const biginteger_data *num, uint64_t div) noexcept;

/// @private
template <typename S>
uint64_t __tdiv_q_ui_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                          uint64_t div) noexcept;

/// @private
template <typename S>
uint64_t __tdiv_r_ui_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                          uint64_t div) noexcept;

/// @private
template <typename S0, typename S1, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __tdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                        const biginteger_data *num, T div) noexcept;

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __tdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                       T div) noexcept;

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __tdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                       uint64_t div) noexcept;

/// @private
template <typename S0, typename S1>
void __fdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                    const biginteger_data *num, const biginteger_data *div) noexcept;

/// @private
template <typename S>
void __fdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                   const biginteger_data *div) noexcept;

/// @private
template <typename S>
void __fdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                   const biginteger_data *div) noexcept;

/// @private
template <typename S0, typename S1, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __fdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                        const biginteger_data *num, T div) noexcept;

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __fdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                       T div) noexcept;

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __fdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                       uint64_t div) noexcept;

/// @private
template <typename S0, typename S1>
void __cdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                    const biginteger_data *num, const biginteger_data *div) noexcept;

/// @private
template <typename S>
void __cdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                   const biginteger_data *div) noexcept;

/// @private
template <typename S>
void __cdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                   const biginteger_data *div) noexcept;

/// @private
template <typename S0, typename S1, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __cdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                        const biginteger_data *num, T div) noexcept;

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __cdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                       T div) noexcept;

/// @private
template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t __cdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                       uint64_t div) noexcept;

/// @private
template <typename S>
void __tdiv_q_2exp_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                        uint32_t shift) noexcept;

/// @private
template <typename S>
void __tdiv_r_2exp_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                        uint32_t shift) noexcept;

/// @private
template <typename S>
void __cfdiv_q_2exp_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                         uint32_t shift, int32_t xdir) noexcept;

/// @private
template <typename S>
void __cdiv_q_2exp_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                        uint32_t shift) noexcept {
    __cfdiv_q_2exp_impl(quot, num, shift, 1);
}

/// @private
template <typename S>
void __fdiv_q_2exp_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                        uint32_t shift) noexcept {
    __cfdiv_q_2exp_impl(quot, num, shift, -1);
}

/// @private
template <typename S>
void __cfdiv_r_2exp_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                         uint32_t shift, int32_t xdir) noexcept;

/// @private
template <typename S>
void __cdiv_r_2exp_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                        uint32_t shift) noexcept {
    __cfdiv_r_2exp_impl(rem, num, shift, 1);
}

/// @private
template <typename S>
void __fdiv_r_2exp_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                        uint32_t shift) noexcept {
    __cfdiv_r_2exp_impl(rem, num, shift, -1);
}

/// @private
template <typename S, typename Engine,
          WJR_REQUIRES(biginteger_uniform_random_bit_generator_v<Engine>)>
void __urandom_bit_impl(basic_biginteger<S> *dst, uint32_t size, Engine &engine) noexcept;

/// @private
template <typename S, typename Engine,
          WJR_REQUIRES(biginteger_uniform_random_bit_generator_v<Engine>)>
void __urandom_exact_bit_impl(basic_biginteger<S> *dst, uint32_t size,
                              Engine &engine) noexcept;

/// @private
template <typename S, typename Engine,
          WJR_REQUIRES(biginteger_uniform_random_bit_generator_v<Engine>)>
void __urandom_impl(basic_biginteger<S> *dst, const biginteger_data *limit,
                    Engine &engine) noexcept;

/// @private
template <typename S, typename Engine,
          WJR_REQUIRES(biginteger_uniform_random_bit_generator_v<Engine>)>
void __urandom_exact_impl(basic_biginteger<S> *dst, const biginteger_data *limit,
                          Engine &engine) noexcept;

/// @private
WJR_PURE inline uint32_t __bit_width_impl(const biginteger_data *num) noexcept;

/// @private
WJR_PURE inline uint32_t __ctz_impl(const biginteger_data *num) noexcept;

/// @todo optimize
template <typename S>
void __pow_impl(basic_biginteger<S> *dst, const biginteger_data *num,
                uint32_t exp) noexcept;

/// @private
struct __powmod_iterator {
    __powmod_iterator(const uint64_t *ptr_, uint32_t size_) noexcept
        : ptr(ptr_), cache(ptr[0]), size(size_) {}

    constexpr void next() noexcept {
        if (++offset == 64) {
            offset = 0;
            ++pos;
            WJR_ASSERT(pos != size);
            cache = ptr[pos];
        }
    }

    constexpr uint64_t get() const noexcept { return (cache >> offset); }
    constexpr bool end() const noexcept { return pos == size - 1 && get() == 1; }

    const uint64_t *ptr;
    uint64_t cache;
    uint32_t offset = 0;
    uint32_t pos = 0;
    uint32_t size;
};

/// @todo optimize
template <typename S>
void __powmod_impl(basic_biginteger<S> *dst, const biginteger_data *num,
                   __powmod_iterator *iter, const biginteger_data *mod) noexcept;

/// @todo optimize
template <typename S>
void __powmod_impl(basic_biginteger<S> *dst, const biginteger_data *num,
                   const biginteger_data *exp, const biginteger_data *mod) noexcept;

/// @todo optimize
template <typename S>
void __powmod_impl(basic_biginteger<S> *dst, const biginteger_data *num, uint64_t exp,
                   const biginteger_data *mod) noexcept;

} // namespace biginteger_detail

template <typename S>
from_chars_result<const char *> from_chars(const char *first, const char *last,
                                           basic_biginteger<S> &dst,
                                           unsigned int base = 10) noexcept;

template <typename Iter>
Iter to_chars_unchecked(Iter ptr, const biginteger_data &src,
                        unsigned int base = 10) noexcept {
    if (src.empty()) {
        *ptr++ = '0';
        return ptr;
    }

    if (src.is_negate()) {
        *ptr++ = '-';
    }

    return biginteger_to_chars(ptr, src.data(), src.size(), base);
}

template <typename S>
std::istream &operator>>(std::istream &is, basic_biginteger<S> &dst) noexcept;

template <typename Traits>
std::basic_ostream<char, Traits> &operator<<(std::basic_ostream<char, Traits> &os,
                                             const biginteger_data &src) noexcept;

WJR_NODISCARD WJR_PURE inline int32_t compare(const biginteger_data &lhs,
                                              const biginteger_data &rhs) noexcept {
    return biginteger_detail::__compare_impl(&lhs, &rhs);
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_NODISCARD WJR_PURE int32_t compare(const biginteger_data &lhs, T rhs) noexcept {
    return biginteger_detail::__compare_impl(&lhs, rhs);
}

template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
WJR_NODISCARD WJR_PURE int32_t compare(T lhs, const biginteger_data &rhs) noexcept {
    return -compare(rhs, lhs);
}

#define WJR_REGISTER_BIGINTEGER_COMPARE(op)                                              \
    WJR_NODISCARD WJR_PURE inline bool operator op(                                      \
        const biginteger_data &lhs, const biginteger_data &rhs) noexcept {               \
        return compare(lhs, rhs) op 0;                                                   \
    }                                                                                    \
    template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>                        \
    WJR_NODISCARD WJR_PURE bool operator op(const biginteger_data &lhs,                  \
                                            T rhs) noexcept {                            \
        return compare(lhs, rhs) op 0;                                                   \
    }                                                                                    \
    template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>                        \
    WJR_NODISCARD WJR_PURE bool operator op(T lhs,                                       \
                                            const biginteger_data &rhs) noexcept {       \
        return compare(lhs, rhs) op 0;                                                   \
    }

WJR_REGISTER_BIGINTEGER_COMPARE(==)
WJR_REGISTER_BIGINTEGER_COMPARE(!=)
WJR_REGISTER_BIGINTEGER_COMPARE(<)
WJR_REGISTER_BIGINTEGER_COMPARE(>)
WJR_REGISTER_BIGINTEGER_COMPARE(<=)
WJR_REGISTER_BIGINTEGER_COMPARE(>=)

#undef WJR_REGISTER_BIGINTEGER_COMPARE

#define WJR_REGISTER_BIGINTEGER_ADDSUB(ADDSUB)                                           \
    template <typename S>                                                                \
    void ADDSUB(basic_biginteger<S> &dst, const biginteger_data &lhs,                    \
                const biginteger_data &rhs) noexcept {                                   \
        biginteger_detail::WJR_PP_CONCAT(__, WJR_PP_CONCAT(ADDSUB, _impl))(&dst, &lhs,   \
                                                                           &rhs);        \
    }                                                                                    \
    template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>            \
    void ADDSUB(basic_biginteger<S> &dst, const biginteger_data &lhs, T rhs) noexcept {  \
        biginteger_detail::WJR_PP_CONCAT(__, WJR_PP_CONCAT(ADDSUB, _impl))(&dst, &lhs,   \
                                                                           rhs);         \
    }                                                                                    \
    template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>            \
    void ADDSUB(basic_biginteger<S> &dst, T lhs, const biginteger_data &rhs) noexcept {  \
        biginteger_detail::WJR_PP_CONCAT(__, WJR_PP_CONCAT(ADDSUB, _impl))(&dst, lhs,    \
                                                                           &rhs);        \
    }

WJR_REGISTER_BIGINTEGER_ADDSUB(add)
WJR_REGISTER_BIGINTEGER_ADDSUB(sub)

#undef WJR_REGISTER_BIGINTEGER_ADDSUB

template <typename S>
void increment(basic_biginteger<S> &dst) noexcept {
    add(dst, dst, 1u);
}

template <typename S>
void decrement(basic_biginteger<S> &dst) noexcept {
    sub(dst, dst, 1u);
}

template <typename S>
void negate(basic_biginteger<S> &dst) noexcept;

template <typename S>
void absolute(basic_biginteger<S> &dst) noexcept;

template <typename S>
void sqr(basic_biginteger<S> &dst, const biginteger_data &src) noexcept {
    biginteger_detail::__sqr_impl(&dst, &src);
}

template <typename S>
void mul(basic_biginteger<S> &dst, const biginteger_data &lhs,
         const biginteger_data &rhs) noexcept {
    if (WJR_BUILTIN_CONSTANT_P_TRUE(std::addressof(lhs) == std::addressof(rhs))) {
        sqr(dst, lhs);
        return;
    }

    biginteger_detail::__mul_impl(&dst, &lhs, &rhs);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void mul(basic_biginteger<S> &dst, const biginteger_data &lhs, T rhs) noexcept {
    biginteger_detail::__mul_impl(&dst, &lhs, rhs);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void mul(basic_biginteger<S> &dst, T lhs, const biginteger_data &rhs) noexcept {
    biginteger_detail::__mul_impl(&dst, &rhs, lhs);
}

template <typename S>
void addmul(basic_biginteger<S> &dst, const biginteger_data &lhs,
            const biginteger_data &rhs) noexcept {
    biginteger_detail::__addmul_impl(&dst, &lhs, &rhs);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void addmul(basic_biginteger<S> &dst, const biginteger_data &lhs, T rhs) noexcept {
    biginteger_detail::__addmul_impl(&dst, &lhs, rhs);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void addmul(basic_biginteger<S> &dst, T lhs, const biginteger_data &rhs) noexcept {
    biginteger_detail::__addmul_impl(&dst, &rhs, lhs);
}

template <typename S>
void submul(basic_biginteger<S> &dst, const biginteger_data &lhs,
            const biginteger_data &rhs) noexcept {
    biginteger_detail::__submul_impl(&dst, &lhs, &rhs);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void submul(basic_biginteger<S> &dst, const biginteger_data &lhs, T rhs) noexcept {
    biginteger_detail::__submul_impl(&dst, &lhs, rhs);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
void submul(basic_biginteger<S> &dst, T lhs, const biginteger_data &rhs) noexcept {
    biginteger_detail::__submul_impl(&dst, &rhs, lhs);
}

template <typename S>
void mul_2exp(basic_biginteger<S> &dst, const biginteger_data &lhs,
              uint32_t shift) noexcept {
    biginteger_detail::__mul_2exp_impl(&dst, &lhs, shift);
}

template <typename S0, typename S1>
void tdiv_qr(basic_biginteger<S0> &quot, basic_biginteger<S1> &rem,
             const biginteger_data &num, const biginteger_data &div) noexcept {
    biginteger_detail::__tdiv_qr_impl(&quot, &rem, &num, &div);
}

template <typename S>
void tdiv_q(basic_biginteger<S> &quot, const biginteger_data &num,
            const biginteger_data &div) noexcept {
    biginteger_detail::__tdiv_q_impl(&quot, &num, &div);
}

template <typename S0>
void tdiv_r(basic_biginteger<S0> &rem, const biginteger_data &num,
            const biginteger_data &div) noexcept {
    biginteger_detail::__tdiv_r_impl(&rem, &num, &div);
}

template <typename S0, typename S1, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t tdiv_qr(basic_biginteger<S0> &quot, basic_biginteger<S1> &rem,
                 const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__tdiv_qr_impl(&quot, &rem, &num, div);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t tdiv_q(basic_biginteger<S> &quot, const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__tdiv_q_impl(&quot, &num, div);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t tdiv_r(basic_biginteger<S> &rem, const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__tdiv_r_impl(&rem, &num, div);
}

template <typename S0, typename S1>
void fdiv_qr(basic_biginteger<S0> &quot, basic_biginteger<S1> &rem,
             const biginteger_data &num, const biginteger_data &div) noexcept {
    biginteger_detail::__fdiv_qr_impl(&quot, &rem, &num, &div);
}

template <typename S>
void fdiv_q(basic_biginteger<S> &quot, const biginteger_data &num,
            const biginteger_data &div) noexcept {
    biginteger_detail::__fdiv_q_impl(&quot, &num, &div);
}

template <typename S0>
void fdiv_r(basic_biginteger<S0> &rem, const biginteger_data &num,
            const biginteger_data &div) noexcept {
    biginteger_detail::__fdiv_r_impl(&rem, &num, &div);
}

template <typename S0, typename S1, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t fdiv_qr(basic_biginteger<S0> &quot, basic_biginteger<S1> &rem,
                 const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__fdiv_qr_impl(&quot, &rem, &num, div);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t fdiv_q(basic_biginteger<S> &quot, const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__fdiv_q_impl(&quot, &num, div);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t fdiv_r(basic_biginteger<S> &rem, const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__fdiv_r_impl(&rem, &num, div);
}

template <typename S0, typename S1>
void cdiv_qr(basic_biginteger<S0> &quot, basic_biginteger<S1> &rem,
             const biginteger_data &num, const biginteger_data &div) noexcept {
    biginteger_detail::__cdiv_qr_impl(&quot, &rem, &num, &div);
}

template <typename S>
void cdiv_q(basic_biginteger<S> &quot, const biginteger_data &num,
            const biginteger_data &div) noexcept {
    biginteger_detail::__cdiv_q_impl(&quot, &num, &div);
}

template <typename S0>
void cdiv_r(basic_biginteger<S0> &rem, const biginteger_data &num,
            const biginteger_data &div) noexcept {
    biginteger_detail::__cdiv_r_impl(&rem, &num, &div);
}

template <typename S0, typename S1, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t cdiv_qr(basic_biginteger<S0> &quot, basic_biginteger<S1> &rem,
                 const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__cdiv_qr_impl(&quot, &rem, &num, div);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t cdiv_q(basic_biginteger<S> &quot, const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__cdiv_q_impl(&quot, &num, div);
}

template <typename S, typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
uint64_t cdiv_r(basic_biginteger<S> &rem, const biginteger_data &num, T div) noexcept {
    return biginteger_detail::__cdiv_r_impl(&rem, &num, div);
}

template <typename S>
void tdiv_q_2exp(basic_biginteger<S> &quot, const biginteger_data &num,
                 uint32_t shift) noexcept {
    biginteger_detail::__tdiv_q_2exp_impl(&quot, &num, shift);
}

template <typename S>
void tdiv_r_2exp(basic_biginteger<S> &rem, const biginteger_data &num,
                 uint32_t shift) noexcept {
    biginteger_detail::__tdiv_r_2exp_impl(&rem, &num, shift);
}

template <typename S>
void fdiv_q_2exp(basic_biginteger<S> &quot, const biginteger_data &num,
                 uint32_t shift) noexcept {
    biginteger_detail::__fdiv_q_2exp_impl(&quot, &num, shift);
}

template <typename S>
void cdiv_q_2exp(basic_biginteger<S> &quot, const biginteger_data &num,
                 uint32_t shift) noexcept {
    biginteger_detail::__cdiv_q_2exp_impl(&quot, &num, shift);
}

template <typename S>
void cdiv_r_2exp(basic_biginteger<S> &rem, const biginteger_data &num,
                 uint32_t shift) noexcept {
    biginteger_detail::__cdiv_r_2exp_impl(&rem, &num, shift);
}

template <typename S>
void fdiv_r_2exp(basic_biginteger<S> &rem, const biginteger_data &num,
                 uint32_t shift) noexcept {
    biginteger_detail::__fdiv_r_2exp_impl(&rem, &num, shift);
}

template <typename S, typename Engine,
          WJR_REQUIRES(biginteger_uniform_random_bit_generator_v<Engine>)>
void urandom_bit(basic_biginteger<S> &dst, uint32_t size, Engine &engine) noexcept {
    biginteger_detail::__urandom_bit_impl(&dst, size, engine);
}

template <typename S, typename Engine,
          WJR_REQUIRES(biginteger_uniform_random_bit_generator_v<Engine>)>
void urandom_exact_bit(basic_biginteger<S> &dst, uint32_t size, Engine &engine) noexcept {
    biginteger_detail::__urandom_exact_bit_impl(&dst, size, engine);
}

template <typename S, typename Engine,
          WJR_REQUIRES(biginteger_uniform_random_bit_generator_v<Engine>)>
void urandom(basic_biginteger<S> &dst, const biginteger_data &limit,
             Engine &engine) noexcept {
    biginteger_detail::__urandom_impl(&dst, &limit, engine);
}

template <typename S, typename Engine,
          WJR_REQUIRES(biginteger_uniform_random_bit_generator_v<Engine>)>
void urandom_exact(basic_biginteger<S> &dst, const biginteger_data &limit,
                   Engine &engine) noexcept {
    biginteger_detail::__urandom_exact_impl(&dst, &limit, engine);
}

inline uint32_t bit_width(const biginteger_data &num) noexcept {
    return biginteger_detail::__bit_width_impl(&num);
}

inline uint32_t ctz(const biginteger_data &num) noexcept {
    return biginteger_detail::__ctz_impl(&num);
}

template <typename S>
void pow(basic_biginteger<S> &dst, const biginteger_data &num, uint32_t exp) noexcept {
    biginteger_detail::__pow_impl(&dst, &num, exp);
}

/**
 * @todo Need to optimize
 */
template <typename S>
void powmod(basic_biginteger<S> &dst, const biginteger_data &num,
            const biginteger_data &exp, const biginteger_data &mod) noexcept {
    biginteger_detail::__powmod_impl(&dst, &num, &exp, &mod);
}

/**
 * @todo Need to optimize
 */
template <typename S>
void powmod(basic_biginteger<S> &dst, const biginteger_data &num, uint64_t exp,
            const biginteger_data &mod) noexcept {
    biginteger_detail::__powmod_impl(&dst, &num, exp, &mod);
}

template <typename Storage>
class basic_biginteger {

public:
    using storage_type = Storage;
    using vector_type = basic_vector<storage_type>;

    using value_type = typename vector_type::value_type;
    using size_type = typename vector_type::size_type;
    using difference_type = typename vector_type::difference_type;
    using reference = typename vector_type::reference;
    using const_reference = typename vector_type::const_reference;
    using pointer = typename vector_type::pointer;
    using const_pointer = typename vector_type::const_pointer;
    using iterator = typename vector_type::iterator;
    using const_iterator = typename vector_type::const_iterator;
    using reverse_iterator = typename vector_type::reverse_iterator;
    using const_reverse_iterator = typename vector_type::const_reverse_iterator;
    using allocator_type = typename vector_type::allocator_type;

    static_assert(std::is_same_v<value_type, uint64_t>, "value_type must be uint64_t");
    static_assert(std::is_same_v<pointer, uint64_t *>, "pointer must be uint64_t *");
    static_assert(std::is_same_v<const_pointer, const uint64_t *>,
                  "const_pointer must be const uint64_t *");
    static_assert(std::is_same_v<size_type, uint32_t>, "size_type must be uint32_t");
    static_assert(std::is_same_v<difference_type, int32_t>,
                  "difference_type must be int32_t");

    basic_biginteger() = default;
    basic_biginteger(basic_biginteger &&other) = default;
    basic_biginteger &operator=(basic_biginteger &&other) = default;
    ~basic_biginteger() = default;

    basic_biginteger(const basic_biginteger &other,
                     const allocator_type &al = allocator_type())
        : m_vec(other.m_vec, al) {
        set_ssize(other.get_ssize());
    }

    basic_biginteger(size_type n, in_place_reserve_t,
                     const allocator_type &al = allocator_type())
        : m_vec(n, in_place_reserve, al) {}

    explicit basic_biginteger(const allocator_type &al) : m_vec(al) {}

    basic_biginteger(basic_biginteger &&other, const allocator_type &al)
        : m_vec(std::move(other.m_vec), al) {}

    template <typename UnsignedValue,
              WJR_REQUIRES(is_nonbool_unsigned_integral_v<UnsignedValue>)>
    explicit basic_biginteger(UnsignedValue value,
                              const allocator_type &al = allocator_type())
        : m_vec(value != 0, value, al) {}

    template <typename SignedValue,
              WJR_REQUIRES(is_nonbool_signed_integral_v<SignedValue>)>
    explicit basic_biginteger(SignedValue value,
                              const allocator_type &al = allocator_type())
        : m_vec(al) {
        if (value != 0) {
            m_vec.emplace_back(value < 0 ? -to_unsigned(value) : to_unsigned(value));
            set_ssize(__fasts_conditional_negate<int32_t>(value < 0, 1));
        }
    }

    explicit basic_biginteger(span<const char> sp, unsigned int base = 10,
                              const allocator_type &al = allocator_type())
        : m_vec(al) {
        from_string(sp, base);
    }

    template <typename OthterStorage>
    explicit basic_biginteger(const basic_biginteger<OthterStorage> &other,
                              const allocator_type &al = allocator_type())
        : m_vec(other.begin(), other.end(), al) {
        set_ssize(other.get_ssize());
    }

    explicit basic_biginteger(const biginteger_data &data,
                              const allocator_type &al = allocator_type())
        : m_vec(data.data(), data.data() + data.size(), al) {
        set_ssize(data.get_ssize());
    }

    basic_biginteger &operator=(const basic_biginteger &other) {
        m_vec = other.m_vec;
        set_ssize(other.get_ssize());
        return *this;
    }

    template <typename UnsignedValue,
              WJR_REQUIRES(is_nonbool_unsigned_integral_v<UnsignedValue>)>
    basic_biginteger &operator=(UnsignedValue value) {
        clear();
        if (value != 0) {
            m_vec.emplace_back(value);
        }
        return *this;
    }

    template <typename SignedValue,
              WJR_REQUIRES(is_nonbool_signed_integral_v<SignedValue>)>
    basic_biginteger &operator=(SignedValue value) {
        clear();
        if (value != 0) {
            m_vec.emplace_back(value < 0 ? -to_unsigned(value) : to_unsigned(value));
            set_ssize(__fasts_conditional_negate<int32_t>(value < 0, 1));
        }
        return *this;
    }

    basic_biginteger &operator=(span<const char> sp) { return from_string(sp); }

    template <typename OthterStorage>
    basic_biginteger &operator=(const basic_biginteger<OthterStorage> &other) {
        m_vec.assign(other.begin(), other.end());
        set_ssize(other.get_ssize());
        return *this;
    }

    basic_biginteger &operator=(const biginteger_data &data) {
        if (WJR_UNLIKELY(__get_data() == std::addressof(data))) {
            return *this;
        }

        m_vec.assign(data.data(), data.data() + data.size());
        set_ssize(data.get_ssize());
        return *this;
    }

    template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
    explicit operator T() const noexcept {
        if (empty()) {
            return static_cast<T>(0);
        }

        if constexpr (std::is_unsigned_v<T>) {
            return static_cast<T>(front());
        } else {
            const auto ret = front();
            return is_negate() ? -ret : ret;
        }
    }

    basic_biginteger &from_string(span<const char> sp, unsigned int base = 10) noexcept {
        (void)from_chars(sp.data(), sp.data() + sp.size(), *this, base);
        return *this;
    }

    allocator_type &get_allocator() noexcept { return m_vec.get_allocator(); }
    const allocator_type &get_allocator() const noexcept { return m_vec.get_allocator(); }

    WJR_PURE pointer data() noexcept { return m_vec.data(); }
    WJR_PURE const_pointer data() const noexcept { return m_vec.data(); }

    WJR_PURE bool empty() const noexcept { return m_vec.empty(); }
    WJR_PURE size_type size() const noexcept { return m_vec.size(); }
    WJR_PURE size_type capacity() const noexcept { return m_vec.capacity(); }
    WJR_PURE bool zero() const noexcept { return empty(); }

    void reserve(size_type new_capacity) noexcept { m_vec.reserve(new_capacity); }
    void clear_if_reserved(size_type new_capacity) noexcept {
        m_vec.clear_if_reserved(new_capacity);
    }

    void shrink_to_fit() { m_vec.shrink_to_fit(); }

    /// equal to set_ssize(0)
    void clear() { m_vec.clear(); }

    void swap(basic_biginteger &other) noexcept { m_vec.swap(other.m_vec); }

    void conditional_negate(bool condition) noexcept {
        set_ssize(__fasts_conditional_negate<int32_t>(condition, get_ssize()));
    }

    void negate() noexcept { conditional_negate(true); }

    WJR_PURE bool is_negate() const noexcept { return get_ssize() < 0; }

    void absolute() noexcept { set_ssize(__fasts_abs(get_ssize())); }

    basic_biginteger &operator++() {
        increment(*this);
        return *this;
    }

    basic_biginteger &operator--() {
        decrement(*this);
        return *this;
    }

    template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
    basic_biginteger &operator+=(T rhs) {
        add(*this, *this, rhs);
        return *this;
    }

    basic_biginteger &operator+=(const biginteger_data &rhs) {
        add(*this, *this, rhs);
        return *this;
    }

    template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
    basic_biginteger &operator-=(T rhs) {
        sub(*this, *this, rhs);
        return *this;
    }

    basic_biginteger &operator-=(const biginteger_data &rhs) {
        sub(*this, *this, rhs);
        return *this;
    }

    template <typename T, WJR_REQUIRES(is_nonbool_integral_v<T>)>
    basic_biginteger &operator*=(T rhs) {
        mul(*this, *this, rhs);
        return *this;
    }

    basic_biginteger &operator*=(const biginteger_data &rhs) {
        mul(*this, *this, rhs);
        return *this;
    }

    basic_biginteger &operator<<=(uint32_t shift) {
        mul_2exp(*this, *this, shift);
        return *this;
    }

    // extension

    reference at(size_type pos) { return m_vec.at(pos); }
    const_reference at(size_type pos) const { return m_vec.at(pos); }

    reference operator[](size_type pos) noexcept { return m_vec[pos]; }
    const_reference operator[](size_type pos) const noexcept { return m_vec[pos]; }

    reference front() { return m_vec.front(); }
    const_reference front() const { return m_vec.front(); }

    reference back() { return m_vec.back(); }
    const_reference back() const { return m_vec.back(); }

    WJR_PURE iterator begin() noexcept { return m_vec.begin(); }
    WJR_PURE const_iterator begin() const noexcept { return m_vec.begin(); }

    WJR_PURE iterator end() noexcept { return m_vec.end(); }
    WJR_PURE const_iterator end() const noexcept { return m_vec.end(); }

    WJR_PURE const_iterator cbegin() const noexcept { return m_vec.cbegin(); }

    WJR_PURE const_iterator cend() const noexcept { return m_vec.cend(); }

    WJR_PURE reverse_iterator rbegin() noexcept { return m_vec.rbegin(); }
    WJR_PURE const_reverse_iterator rbegin() const noexcept { return m_vec.rbegin(); }

    WJR_PURE reverse_iterator rend() noexcept { return m_vec.rend(); }
    WJR_PURE const_reverse_iterator rend() const noexcept { return m_vec.rend(); }

    WJR_PURE const_reverse_iterator crbegin() const noexcept { return m_vec.crbegin(); }
    WJR_PURE const_reverse_iterator crend() const noexcept { return m_vec.crend(); }

    WJR_PURE int32_t get_ssize() const { return get_storage().get_ssize(); }
    template <typename T, WJR_REQUIRES(is_nonbool_unsigned_integral_v<T> ||
                                       std::is_same_v<T, int32_t>)>
    void set_ssize(T new_size) noexcept {
        if constexpr (std::is_unsigned_v<T>) {
            const auto u32size = static_cast<uint32_t>(new_size);
            WJR_ASSERT_ASSUME(u32size == new_size);
            get_storage().set_ssize(__fasts_from_unsigned(u32size));
        } else {
            get_storage().set_ssize(new_size);
        }
    }

    WJR_CONST static size_type get_growth_capacity(size_type old_capacity,
                                                   size_type new_size) noexcept {
        return vector_type::get_growth_capacity(old_capacity, new_size);
    }

    void take_storage(storage_type &other) noexcept { m_vec.take_storage(other); }

    void uninitialized_construct(storage_type &other, size_type siz,
                                 size_type cap) noexcept {
        m_vec.uninitialized_construct(other, siz, cap);
    }

    WJR_PURE storage_type &get_storage() noexcept { return m_vec.get_storage(); }
    WJR_PURE const storage_type &get_storage() const noexcept {
        return m_vec.get_storage();
    }

    WJR_PURE const biginteger_data *__get_data() const noexcept {
        return get_storage().__get_data();
    }

    WJR_PURE const biginteger_data &__get_ref() const noexcept { return *__get_data(); }
    WJR_PURE operator const biginteger_data &() const noexcept { return __get_ref(); }

private:
    void __check_high_bit() const {
        WJR_ASSERT(size() == 0 || back() != 0, "biginteger should not have leading zero");
    }

    vector_type m_vec;
};

template <typename Storage>
void swap(basic_biginteger<Storage> &lhs, basic_biginteger<Storage> &rhs) noexcept {
    lhs.swap(rhs);
}

namespace biginteger_detail {

template <typename S>
from_chars_result<const char *> __from_chars_impl(const char *first, const char *last,
                                                  basic_biginteger<S> *dst,
                                                  unsigned int base) noexcept {
    const auto *__first = first;

    do {
        if (WJR_UNLIKELY(first == last)) {
            break;
        }

        uint8_t ch;
        ch = *first;

        if (charconv_detail::isspace(ch)) {
            do {
                if (++first == last) {
                    break;
                }

                ch = *first;
            } while (charconv_detail::isspace(ch));
        }

        int sign = 0;
        if (ch == '-') {
            sign = 1;
            if (++first == last) {
                break;
            }

            ch = *first;
        }

        if (base == 0) {
            base = 10;
            if (ch == '0') {
                base = 8;
                if (++first == last) {
                    break;
                }

                ch = *first;
                if (ch == 'x' || ch == 'X') {
                    base = 16;
                    if (++first == last) {
                        break;
                    }

                    ch = *first;
                } else {
                    if (ch == 'b' || ch == 'B') {
                        base = 2;
                        if (++first == last) {
                            break;
                        }

                        ch = *first;
                    }
                }
            }
        }

        if (base <= 10) {
            const auto __try_match = [base](uint8_t &ch) {
                ch -= '0';
                return ch < base;
            };

            if (WJR_UNLIKELY(!__try_match(ch))) {
                break;
            }

            if (WJR_UNLIKELY(ch == 0)) {
                goto LOOP_HEAD_0;

                do {
                    ch = *first;
                    if (ch != '0') {
                        goto LOOP_END_0;
                    }

                LOOP_HEAD_0:
                    ++first;
                } while (first != last);

                dst->set_ssize(0);
                return {first, std::errc{}};
            LOOP_END_0:

                if (!__try_match(ch)) {
                    dst->set_ssize(0);
                    return {first, std::errc{}};
                }
            }

            __first = first;

            if (++first != last) {
                if (last - first >= 8) {
                    do {
                        if (!check_eight_digits<branch::free>(first, base)) {
                            break;
                        }

                        first += 8;
                    } while (last - first >= 8);
                }

                ch = *first;
                if (__try_match(ch)) {
                    do {
                        ++first;
                        ch = *first;
                    } while (__try_match(ch));
                }
            }
        } else {
            const auto __try_match = [base](uint8_t &ch) {
                ch = char_converter.from(ch);
                return ch < base;
            };

            if (WJR_UNLIKELY(!__try_match(ch))) {
                break;
            }

            if (WJR_UNLIKELY(ch == 0)) {
                goto LOOP_HEAD_1;

                do {
                    ch = *first;
                    if (ch != '0') {
                        goto LOOP_END_1;
                    }

                LOOP_HEAD_1:
                    ++first;
                } while (first != last);

                dst->clear();
                return {first, std::errc{}};
            LOOP_END_1:

                if (!__try_match(ch)) {
                    dst->clear();
                    return {first, std::errc{}};
                }
            }

            __first = first;

            do {
                ++first;
                if (first == last) {
                    break;
                }

                ch = *first;
            } while (__try_match(ch));
        }

        const size_t str_size = first - __first;
        size_t capacity;

        switch (base) {
        case 2: {
            capacity = __ceil_div(str_size, 64);
            break;
        }
        case 8: {
            capacity = __ceil_div(str_size * 3, 64);
            break;
        }
        case 16: {
            capacity = __ceil_div(str_size, 16);
            break;
        }
        case 4:
        case 32: {
            const int bits = base == 4 ? 2 : 5;
            capacity = __ceil_div(str_size * bits, 64);
            break;
        }
        case 10: {
            // capacity = (str_size * log2(10) + 63) / 64;
            capacity = __ceil_div(str_size * 10 / 3, 64);
            break;
        }
        default: {
            WJR_UNREACHABLE();
            break;
        }
        }

        dst->clear_if_reserved(capacity);
        auto *const ptr = dst->data();
        int32_t dssize = biginteger_from_chars(__first, first, ptr, base) - ptr;
        dssize = __fasts_conditional_negate<int32_t>(sign, dssize);
        dst->set_ssize(dssize);
        return {first, std::errc{}};
    } while (0);

    dst->clear();
    return {__first, std::errc::invalid_argument};
}

inline int32_t __compare_impl(const biginteger_data *lhs,
                              const biginteger_data *rhs) noexcept {
    const auto lssize = lhs->get_ssize();
    const auto rssize = rhs->get_ssize();

    if (lssize != rssize) {
        return lssize < rssize ? -1 : 1;
    }

    const int32_t ans = reverse_compare_n(lhs->data(), rhs->data(), __fasts_abs(lssize));
    return lssize < 0 ? -ans : ans;
}

inline int32_t __compare_ui_impl(const biginteger_data *lhs, uint64_t rhs) noexcept {
    const auto lssize = lhs->get_ssize();

    if (lssize == 0) {
        return -(rhs != 0);
    }

    if (lssize == 1) {
        const uint64_t lvalue = lhs->data()[0];
        return (lvalue != rhs ? (lvalue < rhs ? -1 : 1) : 0);
    }

    return lssize;
}

inline int32_t __compare_si_impl(const biginteger_data *lhs, int64_t rhs) noexcept {
    const auto lssize = lhs->get_ssize();
    const int32_t rssize = rhs == 0 ? 0 : __fasts_conditional_negate<int32_t>(rhs < 0, 1);

    if (lssize != rssize) {
        return lssize - rssize;
    }

    if (lssize == 0) {
        return 0;
    }

    const uint64_t lvalue = lhs->data()[0];
    const uint64_t rvalue = rhs >= 0 ? to_unsigned(rhs) : -to_unsigned(rhs);

    if (lvalue == rvalue) {
        return 0;
    }

    if (lvalue > rvalue) {
        return lssize;
    }

    return -lssize;
}

template <bool xsign, typename S>
void __addsub_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                   uint64_t rhs) noexcept {
    const int32_t lssize = lhs->get_ssize();
    if (lssize == 0) {
        dst->clear_if_reserved(1);

        if (rhs == 0) {
            dst->set_ssize(0);
        } else {
            dst->front() = rhs;
            dst->set_ssize(__fasts_conditional_negate<int32_t>(xsign, 1));
        }

        return;
    }

    const uint32_t lusize = __fasts_abs(lssize);
    dst->reserve(lusize + 1);

    auto *const dp = dst->data();
    const auto *const lp = lhs->data();

    using compare = std::conditional_t<xsign, std::less<>, std::greater<>>;
    int32_t dssize;

    if (compare{}(lssize, 0)) {
        const uint32_t cf = addc_1(dp, lp, lusize, rhs, 0u);
        dssize = __fasts_conditional_negate<int32_t>(xsign, lusize + cf);
        if (cf) {
            dp[lusize] = 1;
        }
    } else {
        if (lusize == 1 && lp[0] < rhs) {
            dp[0] = rhs - lp[0];
            dssize = __fasts_conditional_negate<int32_t>(xsign, 1);
        } else {
            (void)subc_1(dp, lp, lusize, rhs);
            dssize = __fasts_conditional_negate<int32_t>(!xsign,
                                                         lusize - (dp[lusize - 1] == 0));
        }
    }

    dst->set_ssize(dssize);
}

template <typename S>
void __ui_sub_impl(basic_biginteger<S> *dst, uint64_t lhs,
                   const biginteger_data *rhs) noexcept {
    const auto rssize = rhs->get_ssize();
    if (rssize == 0) {
        dst->clear_if_reserved(1);

        if (lhs == 0) {
            dst->set_ssize(0);
        } else {
            dst->front() = lhs;
            dst->set_ssize(1);
        }

        return;
    }

    const uint32_t rusize = __fasts_abs(rssize);
    dst->clear_if_reserved(rusize);

    auto *const dp = dst->data();
    const auto *const rp = rhs->data();
    int32_t dssize;

    if (rssize < 0) {
        const auto cf = addc_1(dp, rp, rusize, lhs);
        dssize = rusize + cf;
        if (cf) {
            dp[rusize] = 1;
        }
    } else {
        // lhs >= rhs
        if (rusize == 1 && lhs >= rp[0]) {
            dp[0] = lhs - rp[0];
            dssize = dp[0] != 0;
        }
        // lhs < rhs
        else {
            (void)subc_1(dp, rp, rusize, lhs);
            dssize = __fasts_negate<int32_t>(rusize - (dp[rusize - 1] == 0));
        }
    }

    dst->set_ssize(dssize);
}

template <bool xsign, typename S>
void __addsub_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                   const biginteger_data *rhs) noexcept {
    auto lssize = lhs->get_ssize();
    int32_t rssize = __fasts_conditional_negate<int32_t>(xsign, rhs->get_ssize());
    uint32_t lusize = __fasts_abs(lssize);
    uint32_t rusize = __fasts_abs(rssize);

    if (lusize < rusize) {
        std::swap(lhs, rhs);
        std::swap(lssize, rssize);
        std::swap(lusize, rusize);
    }

    dst->reserve(lusize + 1);

    auto *const dp = dst->data();
    const auto *const lp = lhs->data();
    const auto *const rp = rhs->data();
    int32_t dssize;

    if (rusize == 0) {
        if (lp != dp) {
            std::copy_n(lp, lusize, dp);
            dst->set_ssize(lssize);
        }
        return;
    }

    // different sign
    if ((lssize ^ rssize) < 0) {
        const auto ans = static_cast<int32_t>(abs_subc_s_pos(dp, lp, lusize, rp, rusize));
        dssize = __fasts_negate_with<int32_t>(lssize, ans);
    } else {
        const auto cf = addc_s(dp, lp, lusize, rp, rusize);
        dssize = __fasts_negate_with<int32_t>(lssize, lusize + cf);
        if (cf) {
            dp[lusize] = 1;
        }
    }

    dst->set_ssize(dssize);
}

template <typename S>
void __mul_ui_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                   uint64_t rhs) noexcept {
    const auto lssize = lhs->get_ssize();
    const uint32_t lusize = __fasts_abs(lssize);

    if (lusize == 0 || rhs == 0) {
        dst->set_ssize(0);
        return;
    }

    dst->reserve(lusize + 1);

    auto *const dp = dst->data();
    const auto *const lp = lhs->data();

    const auto cf = mul_1(dp, lp, lusize, rhs);
    const uint32_t dusize = lusize + (cf != 0);
    if (cf != 0) {
        dp[lusize] = cf;
    }

    dst->set_ssize(__fasts_conditional_negate<int32_t>(lssize < 0, dusize));
}

template <typename S>
void __mul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                const biginteger_data *rhs) noexcept {
    int32_t lssize = lhs->get_ssize();
    int32_t rssize = rhs->get_ssize();
    uint32_t lusize = __fasts_abs(lssize);
    uint32_t rusize = __fasts_abs(rssize);

    if (lusize < rusize) {
        std::swap(lhs, rhs);
        std::swap(lusize, rusize);
    }

    if (WJR_UNLIKELY(rusize == 0)) {
        dst->set_ssize(0);
        return;
    }

    const int32_t mask = lssize ^ rssize;

    int32_t dssize;
    uint32_t dusize;

    if (rusize == 1) {
        dst->reserve(lusize + 1);
        const auto cf = mul_1(dst->data(), lhs->data(), lusize, rhs->data()[0]);
        dssize = __fasts_negate_with<int32_t>(mask, lusize + (cf != 0));
        if (cf != 0) {
            dst->data()[lusize] = cf;
        }
        dst->set_ssize(dssize);
        return;
    }

    dusize = lusize + rusize;

    using pointer = uint64_t *;

    auto *dp = dst->data();
    auto *lp = const_cast<pointer>(lhs->data());
    auto *rp = const_cast<pointer>(rhs->data());

    unique_stack_allocator stkal(math_detail::stack_alloc);
    std::optional<uninitialized<basic_biginteger<S>>> tmp;

    if (dst->capacity() < dusize) {
        tmp.emplace(dst->get_growth_capacity(dst->capacity(), dusize), in_place_reserve,
                    dst->get_allocator());
        dp = (**tmp).data();
    } else {
        if (dp == lp) {
            lp = static_cast<pointer>(stkal.allocate(lusize * sizeof(uint64_t)));
            if (dp == rp) {
                rp = lp;
            }
            std::copy_n(dp, lusize, lp);
        } else if (dp == rp) {
            rp = static_cast<pointer>(stkal.allocate(rusize * sizeof(uint64_t)));
            std::copy_n(dp, rusize, rp);
        }
    }

    if (WJR_UNLIKELY(lp == rp)) {
        sqr(dp, lp, lusize);
    } else {
        mul_s(dp, lp, lusize, rp, rusize);
    }

    const bool cf = dp[dusize - 1] == 0;
    dssize = __fasts_negate_with<int32_t>(mask, dusize - cf);

    if (tmp.has_value()) {
        *dst = **std::move(tmp);
        tmp->reset();
    }

    dst->set_ssize(dssize);
}

template <typename S>
void __sqr_impl(basic_biginteger<S> *dst, const biginteger_data *src) noexcept {
    int32_t sssize = src->get_ssize();
    uint32_t susize = __fasts_abs(sssize);

    if (WJR_UNLIKELY(susize == 0)) {
        dst->set_ssize(0);
        return;
    }

    int32_t dssize;
    uint32_t dusize;

    if (susize == 1) {
        dst->reserve(susize + 1);
        const uint64_t num = src->data()[0];
        uint64_t cf;
        dst->data()[0] = mul(num, num, cf);
        dssize = 1 + (cf != 0);
        if (cf != 0) {
            dst->data()[1] = cf;
        }
        dst->set_ssize(dssize);
        return;
    }

    dusize = susize * 2;

    using pointer = uint64_t *;

    auto *dp = dst->data();
    auto *sp = const_cast<pointer>(src->data());

    std::optional<uninitialized<basic_biginteger<S>>> tmp;

    unique_stack_allocator stkal(math_detail::stack_alloc);

    if (dst->capacity() < dusize) {
        tmp.emplace(dst->get_growth_capacity(dst->capacity(), dusize), in_place_reserve,
                    dst->get_allocator());
        dp = (**tmp).data();
    } else {
        if (dp == sp) {
            sp = static_cast<pointer>(stkal.allocate(susize * sizeof(uint64_t)));
            std::copy_n(dp, susize, sp);
        }
    }

    sqr(dp, sp, susize);

    const bool cf = dp[dusize - 1] == 0;
    dssize = dusize - cf;

    if (tmp.has_value()) {
        *dst = **std::move(tmp);
        tmp->reset();
    }

    dst->set_ssize(dssize);
}

template <typename S>
void __addsubmul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs, uint64_t rhs,
                      int32_t xmask) noexcept {
    const int32_t lssize = lhs->get_ssize();

    if (lssize == 0 || rhs == 0) {
        return;
    }

    const uint32_t lusize = __fasts_abs(lssize);
    int32_t dssize = dst->get_ssize();

    if (dssize == 0) {
        dst->reserve(lusize + 1);
        const auto dp = dst->data();
        const auto cf = mul_1(dp, lhs->data(), lusize, rhs);
        dssize = lssize + (cf != 0);
        if (cf != 0) {
            dp[lusize] = cf;
        }

        dst->set_ssize(__fasts_negate_with(xmask, dssize));
        return;
    }

    xmask ^= lssize;
    xmask ^= dssize;

    const uint32_t dusize = __fasts_abs(dssize);

    uint32_t new_dusize = std::max(lusize, dusize);
    const uint32_t min_size = std::min(lusize, dusize);
    dst->reserve(new_dusize + 1);

    auto *dp = dst->data();
    const auto *lp = lhs->data();

    uint64_t cf;

    // dst += abs(lhs) * abs(rhs)
    if (xmask >= 0) {
        cf = addmul_1(dp, lp, min_size, rhs);

        dp += min_size;
        lp += min_size;

        int32_t sdelta = lusize - dusize;

        if (sdelta != 0) {
            uint64_t cf2;
            if (sdelta > 0) {
                cf2 = mul_1(dp, lp, sdelta, rhs);
            } else {
                sdelta = -sdelta;
                cf2 = 0;
            }

            cf = cf2 + addc_1(dp, dp, sdelta, cf);
        }

        dp[sdelta] = cf;
        new_dusize += (cf != 0);
    }
    // dst -= abs(lhs) * abs(rhs)
    else {
        cf = submul_1(dp, lp, min_size, rhs);

        do {
            if (dusize >= lusize) {
                if (dusize != lusize) {
                    cf = subc_1(dp + lusize, dp + lusize, dusize - lusize, cf);
                }

                if (cf != 0) {
                    cf += negate_n(dp, dp, new_dusize) - 1;
                    dp[new_dusize] = cf;
                    ++new_dusize;
                    dssize = __fasts_negate(dssize);
                }
            } else {
                cf += negate_n(dp, dp, dusize) - 1;

                const auto cf2 = cf == (uint64_t)in_place_max;
                cf += cf2;

                const auto cf3 = mul_1(dp + dusize, lp + dusize, lusize - dusize, rhs);
                cf = cf3 + addc_1(dp + dusize, dp + dusize, lusize - dusize, cf);

                dp[new_dusize] = cf;
                new_dusize += (cf != 0);

                if (cf2) {
                    (void)subc_1(dp + dusize, dp + dusize, new_dusize - dusize, 1);
                }

                dssize = __fasts_negate(dssize);
            }

            new_dusize = normalize(dp, new_dusize);
        } while (0);
    }

    dst->set_ssize(__fasts_conditional_negate<int32_t>(dssize < 0, new_dusize));
}

template <typename S>
void __addsubmul_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                      const biginteger_data *rhs, int32_t xmask) noexcept {
    int32_t lssize = lhs->get_ssize();
    int32_t rssize = rhs->get_ssize();

    if (lssize == 0 || rssize == 0) {
        return;
    }

    uint32_t lusize = __fasts_abs(lssize);
    uint32_t rusize = __fasts_abs(rssize);

    if (lusize < rusize) {
        std::swap(lhs, rhs);
        std::swap(lssize, rssize);
        std::swap(lusize, rusize);
    }

    xmask ^= rssize;

    if (rusize == 1) {
        __addsubmul_impl(dst, lhs, rhs->data()[0], xmask);
        return;
    }

    xmask ^= lssize;

    int32_t dssize = dst->get_ssize();
    xmask ^= dssize;
    uint32_t dusize = __fasts_abs(dssize);

    uint32_t tusize = lusize + rusize;
    dst->reserve(std::max(tusize, dusize) + 1);
    auto *const dp = dst->data();

    if (dssize == 0) {
        mul_s(dp, lhs->data(), lusize, rhs->data(), rusize);
        tusize -= dp[tusize - 1] == 0;
        dst->set_ssize(__fasts_conditional_negate<int32_t>(xmask < 0, tusize));
        return;
    }

    unique_stack_allocator stkal(math_detail::stack_alloc);
    auto *tp = static_cast<uint64_t *>(stkal.allocate(tusize * sizeof(uint64_t)));

    mul_s(tp, lhs->data(), lusize, rhs->data(), rusize);
    tusize -= tp[tusize - 1] == 0;

    auto *up = dp;
    uint32_t uusize = dusize;

    if (xmask >= 0) {
        if (uusize < tusize) {
            up = tp;
            uusize = tusize;
            tp = dp;
            tusize = dusize;

            dusize = uusize;
        }

        const auto cf = addc_s(dp, up, uusize, tp, tusize);
        dp[uusize] = cf;
        dusize = uusize + (cf != 0);
    } else {
        if (uusize < tusize ||
            (uusize == tusize && reverse_compare_n(up, tp, uusize) < 0)) {
            up = tp;
            uusize = tusize;
            tp = dp;
            tusize = dusize;

            dusize = uusize;

            dssize = __fasts_negate(dssize);
        }

        (void)subc_s(dp, up, uusize, tp, tusize);
        dssize = normalize(dp, dusize);
    }

    dst->set_ssize(__fasts_conditional_negate<int32_t>(dssize < 0, dusize));
}

template <typename S>
void __mul_2exp_impl(basic_biginteger<S> *dst, const biginteger_data *lhs,
                     uint32_t shift) noexcept {
    int32_t lssize = lhs->get_ssize();

    if (lssize == 0) {
        dst->set_ssize(0);
        return;
    }

    uint32_t lusize = __fasts_abs(lssize);
    uint32_t offset = shift / 64;
    shift %= 64;
    uint32_t dusize = lusize + offset;

    dst->reserve(dusize + 1);
    auto *const dp = dst->data();
    const auto *const lp = lhs->data();

    const auto cf = lshift_n(dp + offset, lp, lusize, shift);
    set_n(dp, 0, offset);

    dp[dusize] = cf;
    dusize += (cf != 0);

    dst->set_ssize(__fasts_conditional_negate<int32_t>(lssize < 0, dusize));
}

template <typename S0, typename S1>
void __tdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                    const biginteger_data *num, const biginteger_data *div) noexcept {
    WJR_ASSERT_ASSUME(!__equal_pointer(quot, rem), "quot should not be the same as rem");

    const auto nssize = num->get_ssize();
    const auto dssize = div->get_ssize();
    const auto nusize = __fasts_abs(nssize);
    auto dusize = __fasts_abs(dssize);
    int32_t qssize = nusize - dusize + 1;

    WJR_ASSERT(dusize != 0, "division by zero");

    rem->reserve(dusize);
    auto *rp = rem->data();

    // num < div
    if (qssize <= 0) {
        auto np = num->data();
        if (np != rp) {
            std::copy_n(np, nusize, rp);
            rem->set_ssize(nssize);
        }

        quot->set_ssize(0);
        return;
    }

    using pointer = uint64_t *;

    quot->reserve(qssize);
    auto *qp = quot->data();

    auto *np = const_cast<pointer>(num->data());
    auto *dp = const_cast<pointer>(div->data());

    unique_stack_allocator stkal(math_detail::stack_alloc);

    if (dp == rp || dp == qp) {
        auto *tp = (pointer)stkal.allocate(dusize * sizeof(uint64_t));
        std::copy_n(dp, dusize, tp);
        dp = tp;
    }

    if (np == rp || np == qp) {
        auto *tp = (pointer)stkal.allocate(nusize * sizeof(uint64_t));
        std::copy_n(np, nusize, tp);
        np = tp;
    }

    div_qr_s(qp, rp, np, nusize, dp, dusize);

    qssize -= qp[qssize - 1] == 0;
    dusize = normalize(rp, dusize);

    quot->set_ssize(__fasts_conditional_negate<int32_t>((nssize ^ dssize) < 0, qssize));
    rem->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, dusize));
}

template <typename S>
void __tdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                   const biginteger_data *div) noexcept {
    const auto nssize = num->get_ssize();
    const auto dssize = div->get_ssize();
    const auto nusize = __fasts_abs(nssize);
    const auto dusize = __fasts_abs(dssize);
    int32_t qssize = nusize - dusize + 1;

    WJR_ASSERT(dusize != 0, "division by zero");

    // num < div
    if (qssize <= 0) {
        quot->set_ssize(0);
        return;
    }

    using pointer = uint64_t *;

    quot->reserve(qssize);
    auto qp = quot->data();

    auto np = (pointer)num->data();
    auto dp = (pointer)div->data();

    unique_stack_allocator stkal(math_detail::stack_alloc);

    if (dp == qp) {
        auto tp = (pointer)stkal.allocate(dusize * sizeof(uint64_t));
        std::copy_n(dp, dusize, tp);
        dp = tp;
    }

    if (np == qp) {
        auto tp = (pointer)stkal.allocate(nusize * sizeof(uint64_t));
        std::copy_n(np, nusize, tp);
        np = tp;
    }

    const auto rp = (pointer)stkal.allocate(dusize * sizeof(uint64_t));

    div_qr_s(qp, rp, np, nusize, dp, dusize);

    qssize -= qp[qssize - 1] == 0;

    quot->set_ssize(__fasts_conditional_negate<int32_t>((nssize ^ dssize) < 0, qssize));
}

template <typename S>
void __tdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                   const biginteger_data *div) noexcept {
    const auto nssize = num->get_ssize();
    const auto dssize = div->get_ssize();
    const auto nusize = __fasts_abs(nssize);
    auto dusize = __fasts_abs(dssize);
    const int32_t qssize = nusize - dusize + 1;

    WJR_ASSERT(dusize != 0, "division by zero");

    rem->reserve(dusize);
    auto rp = rem->data();

    // num < div
    if (qssize <= 0) {
        const auto np = num->data();
        if (np != rp) {
            std::copy_n(np, nusize, rp);
            rem->set_ssize(nssize);
        }

        return;
    }

    using pointer = uint64_t *;

    auto np = (pointer)num->data();
    auto dp = (pointer)div->data();

    unique_stack_allocator stkal(math_detail::stack_alloc);

    if (dp == rp) {
        const auto tp = (pointer)stkal.allocate(dusize * sizeof(uint64_t));
        std::copy_n(dp, dusize, tp);
        dp = tp;
    }

    if (np == rp) {
        const auto tp = (pointer)stkal.allocate(nusize * sizeof(uint64_t));
        std::copy_n(np, nusize, tp);
        np = tp;
    }

    const auto qp = (pointer)stkal.allocate(qssize * sizeof(uint64_t));

    div_qr_s(qp, rp, np, nusize, dp, dusize);

    dusize = normalize(rp, dusize);

    rem->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, dusize));
}

template <typename S0, typename S1>
uint64_t __tdiv_qr_ui_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                           const biginteger_data *num, uint64_t div) noexcept {
    const auto nssize = num->get_ssize();

    WJR_ASSERT(div != 0, "division by zero");

    if (nssize == 0) {
        quot->set_ssize(0);
        rem->set_ssize(0);
        return 0;
    }

    const auto nusize = __fasts_abs(nssize);
    quot->reserve(nusize);
    const auto qp = quot->data();
    const auto np = num->data();

    uint64_t remv;
    div_qr_1(qp, remv, np, nusize, div);

    if (remv == 0) {
        rem->set_ssize(0);
    } else {
        rem->reserve(1);
        rem->front() = remv;
        rem->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, 1));
    }

    const auto qusize = nusize - (qp[nusize - 1] == 0);

    quot->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, qusize));
    return remv;
}

template <typename S>
uint64_t __tdiv_q_ui_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                          uint64_t div) noexcept {
    const auto nssize = num->get_ssize();

    WJR_ASSERT(div != 0, "division by zero");

    if (nssize == 0) {
        quot->set_ssize(0);
        return 0;
    }

    const auto nusize = __fasts_abs(nssize);
    quot->reserve(nusize);
    const auto qp = quot->data();
    const auto np = num->data();

    uint64_t remv;
    div_qr_1(qp, remv, np, nusize, div);

    const auto qusize = nusize - (qp[nusize - 1] == 0);

    quot->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, qusize));
    return remv;
}

template <typename S>
uint64_t __tdiv_r_ui_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                          uint64_t div) noexcept {
    const auto nssize = num->get_ssize();

    WJR_ASSERT(div != 0, "division by zero");

    if (nssize == 0) {
        rem->set_ssize(0);
        return 0;
    }

    const auto nusize = __fasts_abs(nssize);
    const auto np = num->data();

    uint64_t remv;
    remv = mod_1(np, nusize, div);

    if (remv == 0) {
        rem->set_ssize(0);
    } else {
        rem->reserve(1);
        rem->front() = remv;
        rem->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, 1));
    }

    return remv;
}

template <typename S0, typename S1, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __tdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                        const biginteger_data *num, T div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        return __tdiv_qr_ui_impl(quot, rem, num, div);
    } else {
        uint64_t udiv = to_unsigned(div);
        bool xsign = false;
        if (div < 0) {
            udiv = -udiv;
            xsign = true;
        }

        uint64_t remv = __tdiv_qr_ui_impl(quot, rem, num, udiv);

        quot->conditional_negate(xsign);
        return remv;
    }
}

template <typename S, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __tdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                       T div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        return __tdiv_q_ui_impl(quot, num, div);
    } else {
        uint64_t udiv = to_unsigned(div);
        bool xsign = false;
        if (div < 0) {
            udiv = -udiv;
            xsign = true;
        }

        uint64_t remv = __tdiv_q_ui_impl(quot, num, udiv);

        quot->conditional_negate(xsign);
        return remv;
    }
}

template <typename S, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __tdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                       uint64_t div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        return __tdiv_q_ui_impl(rem, num, div);
    } else {
        uint64_t udiv = to_unsigned(div);
        if (div < 0) {
            udiv = -udiv;
        }

        return __tdiv_r_ui_impl(rem, num, udiv);
    }
}

template <typename S0, typename S1>
void __fdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                    const biginteger_data *num, const biginteger_data *div) noexcept {

    WJR_ASSERT_ASSUME(!__equal_pointer(quot, rem), "quot should not be the same as rem");

    unique_stack_allocator stkal(math_detail::stack_alloc);

    biginteger_data tmp_div;

    const auto dssize = div->get_ssize();

    if (__equal_pointer(div, quot) || __equal_pointer(div, rem)) {
        const auto dusize = __fasts_abs(dssize);
        const auto ptr = (uint64_t *)stkal.allocate(dusize * sizeof(uint64_t));
        tmp_div = {ptr, dssize, 0};
        std::copy_n(div->data(), dusize, ptr);

        div = &tmp_div;
    }

    const auto xsize = num->get_ssize() ^ dssize;

    __tdiv_qr_impl(quot, rem, num, div);

    if (xsize < 0 && !rem->empty()) {
        __sub_impl(quot, quot->__get_data(), 1u);
        __add_impl(rem, rem->__get_data(), div);
    }
}

template <typename S>
void __fdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                   const biginteger_data *div) noexcept {
    unique_stack_allocator stkal(math_detail::stack_alloc);
    stack_biginteger rem(stkal);

    const auto xsize = num->get_ssize() ^ div->get_ssize();

    __tdiv_qr_impl(quot, &rem, num, div);

    if (xsize < 0 && !rem.empty()) {
        __sub_impl(quot, quot->__get_data(), 1u);
    }
}

template <typename S>
void __fdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                   const biginteger_data *div) noexcept {
    unique_stack_allocator stkal(math_detail::stack_alloc);

    biginteger_data tmp_div;

    const auto dssize = div->get_ssize();

    if (__equal_pointer(div, rem)) {
        const auto dusize = __fasts_abs(dssize);
        const auto ptr = (uint64_t *)stkal.allocate(dusize * sizeof(uint64_t));
        tmp_div = {ptr, dssize, 0};
        std::copy_n(div->data(), dusize, ptr);

        div = &tmp_div;
    }

    const auto xsize = num->get_ssize() ^ dssize;

    __tdiv_r_impl(rem, num, div);

    if (xsize < 0 && !rem->empty()) {
        __add_impl(rem, rem->__get_data(), div);
    }
}

template <typename S0, typename S1, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __fdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                        const biginteger_data *num, T div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        const auto xssize = num->get_ssize();

        uint64_t remv = __tdiv_qr_ui_impl(quot, rem, num, div);

        if (xssize < 0 && remv != 0) {
            WJR_ASSERT(rem->is_negate());

            __sub_impl(quot, quot->__get_data(), 1u);
            rem->set_ssize(1);
            remv = div - remv;
            rem->front() = remv;
        }

        return remv;
    } else {
        uint64_t udiv = to_unsigned(div);
        int32_t xsign = 0;

        if (div < 0) {
            udiv = -udiv;
            xsign = -1;
        }

        const int32_t nssize = num->get_ssize();

        uint64_t remv = __tdiv_qr_ui_impl(quot, rem, num, udiv);

        quot->conditional_negate(xsign);

        if ((nssize ^ xsign) < 0 && remv != 0) {
            __sub_impl(quot, quot->__get_data(), 1u);
            rem->set_ssize(__fasts_conditional_negate(xsign < 0, 1));
            remv = div - remv;
            rem->front() = remv;
        }

        return remv;
    }
}

template <typename S, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __fdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                       T div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        const auto xssize = num->get_ssize();

        uint64_t remv = __tdiv_q_ui_impl(quot, num, div);

        if (xssize < 0 && remv != 0) {
            __sub_impl(quot, quot->__get_data(), 1u);
            remv = div - remv;
        }

        return remv;
    } else {
        uint64_t udiv = to_unsigned(div);
        int32_t xsign = 0;

        if (div < 0) {
            udiv = -udiv;
            xsign = -1;
        }

        const int32_t nssize = num->get_ssize();

        uint64_t remv = __tdiv_q_ui_impl(quot, num, udiv);

        quot->conditional_negate(xsign);

        if ((nssize ^ xsign) < 0 && remv != 0) {
            __sub_impl(quot, quot->__get_data(), 1u);
            remv = div - remv;
        }

        return remv;
    }
}

template <typename S, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __fdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                       uint64_t div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        const auto xssize = num->get_ssize();

        uint64_t remv = __tdiv_r_ui_impl(rem, num, div);

        if (xssize < 0 && remv != 0) {
            WJR_ASSERT(rem->is_negate());

            rem->set_ssize(1);
            remv = div - remv;
            rem->front() = remv;
        }

        return remv;
    } else {
        uint64_t udiv = to_unsigned(div);
        int32_t xsign = 0;

        if (div < 0) {
            udiv = -udiv;
            xsign = -1;
        }

        const int32_t nssize = num->get_ssize();

        uint64_t remv = __tdiv_r_ui_impl(rem, num, udiv);

        if ((nssize ^ xsign) < 0 && remv != 0) {
            rem->set_ssize(__fasts_conditional_negate(xsign < 0, 1));
            remv = div - remv;
            rem->front() = remv;
        }

        return remv;
    }
}

template <typename S0, typename S1>
void __cdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                    const biginteger_data *num, const biginteger_data *div) noexcept {

    WJR_ASSERT_ASSUME(!__equal_pointer(quot, rem), "quot should not be the same as rem");

    unique_stack_allocator stkal(math_detail::stack_alloc);

    biginteger_data tmp_div;

    const auto dssize = div->get_ssize();

    if (__equal_pointer(div, quot) || __equal_pointer(div, rem)) {
        const auto dusize = __fasts_abs(dssize);
        const auto ptr = (uint64_t *)stkal.allocate(dusize * sizeof(uint64_t));
        tmp_div = {ptr, dssize, 0};
        std::copy_n(div->data(), dusize, ptr);

        div = &tmp_div;
    }

    const auto xsize = num->get_ssize() ^ dssize;

    __tdiv_qr_impl(quot, rem, num, div);

    if (xsize >= 0 && !rem->empty()) {
        __add_impl(quot, quot->__get_data(), 1u);
        __sub_impl(rem, rem->__get_data(), div);
    }
}

template <typename S>
void __cdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                   const biginteger_data *div) noexcept {
    unique_stack_allocator stkal(math_detail::stack_alloc);
    stack_biginteger rem(stkal);

    const auto xsize = num->get_ssize() ^ div->get_ssize();

    __tdiv_qr_impl(quot, &rem, num, div);

    if (xsize >= 0 && !rem.empty()) {
        __add_impl(quot, quot->__get_data(), 1u);
    }
}

template <typename S>
void __cdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                   const biginteger_data *div) noexcept {
    unique_stack_allocator stkal(math_detail::stack_alloc);

    biginteger_data tmp_div;

    const auto dssize = div->get_ssize();

    if (__equal_pointer(div, rem)) {
        const auto dusize = __fasts_abs(dssize);
        const auto ptr = (uint64_t *)stkal.allocate(dusize * sizeof(uint64_t));
        tmp_div = {ptr, dssize, 0};
        std::copy_n(div->data(), dusize, ptr);

        div = &tmp_div;
    }

    const auto xsize = num->get_ssize() ^ dssize;

    __tdiv_r_impl(rem, num, div);

    if (xsize >= 0 && !rem->empty()) {
        __sub_impl(rem, rem->__get_data(), div);
    }
}

template <typename S0, typename S1, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __cdiv_qr_impl(basic_biginteger<S0> *quot, basic_biginteger<S1> *rem,
                        const biginteger_data *num, T div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        const auto xssize = num->get_ssize();

        uint64_t remv = __tdiv_qr_ui_impl(quot, rem, num, div);

        if (xssize >= 0 && remv != 0) {
            WJR_ASSERT(rem->is_negate());

            __add_impl(quot, quot->__get_data(), 1u);
            rem->set_ssize(-1);
            remv = div - remv;
            rem->front() = remv;
        }

        return remv;
    } else {
        uint64_t udiv = to_unsigned(div);
        int32_t xsign = 0;

        if (div < 0) {
            udiv = -udiv;
            xsign = -1;
        }

        const int32_t nssize = num->get_ssize();

        uint64_t remv = __tdiv_qr_ui_impl(quot, rem, num, udiv);

        quot->conditional_negate(xsign);

        if ((nssize ^ xsign) >= 0 && remv != 0) {
            __add_impl(quot, quot->__get_data(), 1u);
            rem->set_ssize(__fasts_conditional_negate(xsign >= 0, 1));
            remv = div - remv;
            rem->front() = remv;
        }

        return remv;
    }
}

template <typename S, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __cdiv_q_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                       T div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        const auto xssize = num->get_ssize();

        uint64_t remv = __tdiv_q_ui_impl(quot, num, div);

        if (xssize >= 0 && remv != 0) {
            __add_impl(quot, quot->__get_data(), 1u);
            remv = div - remv;
        }

        return remv;
    } else {
        uint64_t udiv = to_unsigned(div);
        int32_t xsign = 0;

        if (div < 0) {
            udiv = -udiv;
            xsign = -1;
        }

        const int32_t nssize = num->get_ssize();

        uint64_t remv = __tdiv_q_ui_impl(quot, num, udiv);

        quot->conditional_negate(xsign);

        if ((nssize ^ xsign) >= 0 && remv != 0) {
            __add_impl(quot, quot->__get_data(), 1u);
            remv = div - remv;
        }

        return remv;
    }
}

template <typename S, typename T, WJR_REQUIRES_I(is_nonbool_integral_v<T>)>
uint64_t __cdiv_r_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                       uint64_t div) noexcept {
    if constexpr (std::is_unsigned_v<T>) {
        const auto xssize = num->get_ssize();

        uint64_t remv = __tdiv_r_ui_impl(rem, num, div);

        if (xssize >= 0 && remv != 0) {
            WJR_ASSERT(rem->is_negate());

            rem->set_ssize(-1);
            remv = div - remv;
            rem->front() = remv;
        }

        return remv;
    } else {
        uint64_t udiv = to_unsigned(div);
        int32_t xsign = 0;

        if (div < 0) {
            udiv = -udiv;
            xsign = -1;
        }

        const int32_t nssize = num->get_ssize();

        uint64_t remv = __tdiv_r_ui_impl(rem, num, udiv);

        if ((nssize ^ xsign) >= 0 && remv != 0) {
            rem->set_ssize(__fasts_conditional_negate(xsign >= 0, 1));
            remv = div - remv;
            rem->front() = remv;
        }

        return remv;
    }
}

template <typename S>
void __tdiv_q_2exp_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                        uint32_t shift) noexcept {
    int32_t nssize = num->get_ssize();
    uint32_t nusize = __fasts_abs(nssize);
    uint32_t offset = shift / 64;

    int32_t qssize = nusize - offset;

    if (qssize <= 0) {
        quot->set_ssize(0);
        return;
    }

    quot->reserve(qssize);
    const auto qp = quot->data();
    const auto np = num->data();

    (void)rshift_n(qp, np + offset, qssize, shift % 64);
    qssize -= qp[qssize - 1] == 0;

    quot->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, qssize));
}

template <typename S>
void __tdiv_r_2exp_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                        uint32_t shift) noexcept {
    const int32_t nssize = num->get_ssize();
    uint32_t nusize = __fasts_abs(nssize);
    uint32_t offset = shift / 64;

    uint32_t rusize;

    if (nusize <= offset) {
        rusize = nusize;
        offset = nusize;
        rem->reserve(rusize);
    } else {
        uint64_t high = num->data()[offset] & (((uint64_t)(1) << (shift % 64)) - 1);
        if (high != 0) {
            rusize = offset + 1;
            rem->reserve(rusize);
            rem->data()[offset] = high;
        } else {
            rusize = normalize(num->data(), offset);
            offset = rusize;
            rem->reserve(rusize);
        }
    }

    if (!__equal_pointer(rem, num)) {
        std::copy_n(num->data(), offset, rem->data());
    }

    rem->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, rusize));
}

template <typename S>
void __cfdiv_q_2exp_impl(basic_biginteger<S> *quot, const biginteger_data *num,
                         uint32_t shift, int32_t xdir) noexcept {
    int32_t nssize = num->get_ssize();
    uint32_t nusize = __fasts_abs(nssize);
    uint32_t offset = shift / 64;

    int32_t qssize = nusize - offset;

    if (qssize <= 0) {
        if (nssize == 0) {
            quot->set_ssize(0);
            return;
        }

        quot->clear_if_reserved(1);
        quot->data()[0] = 1;

        quot->set_ssize((nssize ^ xdir) < 0 ? 0 : xdir);
        return;
    }

    quot->reserve(qssize + 1);
    const auto qp = quot->data();
    const auto np = num->data();

    uint64_t xmask = (nssize ^ xdir) < 0 ? 0 : (uint64_t)in_place_max;
    uint64_t round = 0;

    if (xmask) {
        // all is zero, then round is zero
        round = find_not_n(np, 0, offset) == offset ? 0 : 1;
    }

    round |= xmask & rshift_n(qp, np + offset, qssize, shift % 64);
    qssize -= qp[qssize - 1] == 0;

    if (WJR_LIKELY(round != 0)) {
        if (WJR_LIKELY(qssize != 0)) {
            const auto cf = addc_1(qp, qp, qssize, 1u);
            if (cf != 0) {
                qp[qssize] = cf;
                ++qssize;
            }
        } else {
            qp[0] = 1;
            qssize = 1;
        }
    }

    quot->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, qssize));
}

template <typename S>
void __cfdiv_r_2exp_impl(basic_biginteger<S> *rem, const biginteger_data *num,
                         uint32_t shift, int32_t xdir) noexcept {
    int32_t nssize = num->get_ssize();

    if (nssize == 0) {
        rem->set_ssize(0);
        return;
    }

    uint32_t nusize = __fasts_abs(nssize);
    uint32_t offset = shift / 64;
    shift %= 64;

    uint64_t *rp;
    auto np = (uint64_t *)(num->data());

    if ((nssize ^ xdir) < 0) {
        if (__equal_pointer(rem, num)) {
            if (nusize <= offset) {
                return;
            }

            rp = np;
        } else {
            const auto size = std::min<uint32_t>(nusize, offset + 1);
            rem->reserve(size);
            rp = rem->data();
            std::copy_n(np, size, rp);

            if (nusize <= offset) {
                rem->set_ssize(nssize);
                return;
            }
        }
    } else {
        do {
            if (nusize <= offset) {
                break;
            }

            if (find_not_n(np, 0, offset) != offset) {
                break;
            }

            if ((np[offset] & (((uint64_t)(1) << shift) - 1)) != 0) {
                break;
            }

            rem->set_ssize(0);
            return;
        } while (0);

        rem->reserve(offset + 1);
        rp = rem->data();
        np = (uint64_t *)(num->data());

        const auto size = std::min<uint32_t>(nusize, offset + 1);
        (void)negate_n(rp, np, size);
        for (uint32_t i = size; i <= offset; ++i) {
            rp[i] = static_cast<uint64_t>(in_place_max);
        }

        nssize = -nssize;
    }

    uint64_t hi = rp[offset] & (((uint64_t)(1) << shift) - 1);
    rp[offset] = hi;

    if (hi == 0) {
        offset = normalize(rp, offset);
    } else {
        ++offset;
    }

    rem->set_ssize(__fasts_conditional_negate<int32_t>(nssize < 0, offset));
}

template <typename S, typename Engine,
          WJR_REQUIRES_I(biginteger_uniform_random_bit_generator_v<Engine>)>
void __urandom_bit_impl(basic_biginteger<S> *dst, uint32_t size,
                        Engine &engine) noexcept {
    const uint32_t dusize = size / 64;
    size %= 64;
    uint32_t dssize = dusize + (size != 0);

    dst->reserve(dssize);
    const auto dp = dst->data();

    do {
        for (uint64_t i = 0; i < dusize; ++i) {
            dp[i] = engine();
        }
    } while (0);

    if (size != 0) {
        dp[dusize] = engine() >> (64 - size);
    }

    dssize = normalize(dp, dssize);
    dst->set_ssize(dssize);
}

template <typename S, typename Engine,
          WJR_REQUIRES_I(biginteger_uniform_random_bit_generator_v<Engine>)>
void __urandom_exact_bit_impl(basic_biginteger<S> *dst, uint32_t size,
                              Engine &engine) noexcept {
    if (WJR_UNLIKELY(size == 0)) {
        dst->set_ssize(0);
        return;
    }

    const uint32_t dusize = (size - 1) / 64;
    size = (size - 1) % 64;
    const uint32_t dssize = dusize + 1;

    dst->reserve(dssize);
    const auto dp = dst->data();

    do {
        for (uint64_t i = 0; i < dusize; ++i) {
            dp[i] = engine();
        }
    } while (0);

    do {
        uint64_t high = (uint64_t)(1) << size;

        if (size != 0) {
            high |= engine() >> (64 - size);
        }

        dp[dusize] = high;
    } while (0);

    dst->set_ssize(dssize);
}

template <typename S, typename Engine,
          WJR_REQUIRES_I(biginteger_uniform_random_bit_generator_v<Engine>)>
void __urandom_impl(basic_biginteger<S> *dst, const biginteger_data *limit,
                    Engine &engine) noexcept {
    std::optional<uninitialized<math_detail::unique_stack_alloc>> stkal;
    uint32_t size = limit->size();

    WJR_ASSERT(size != 0);

    if (WJR_UNLIKELY(size == 1)) {
        std::uniform_int_distribution<uint64_t> head(0, limit->data()[0] - 1);
        const uint64_t gen = head(engine);

        dst->clear_if_reserved(1);
        dst->data()[0] = gen;
        dst->set_ssize(gen == 0 ? 0 : 1);
        return;
    }

    dst->reserve(size);

    const auto dp = dst->data();
    const uint64_t *lp = limit->data();

    if (__equal_pointer(dst, limit)) {
        stkal.emplace(math_detail::stack_alloc);
        const auto tp = (uint64_t *)(*stkal)->allocate(size * sizeof(uint64_t));
        std::copy_n(lp, size, tp);
        lp = tp;
    }

    const uint32_t lst_pos = size - 1;
    const uint64_t lst_val = lp[lst_pos];
    std::uniform_int_distribution<uint64_t> head(0, lst_val);

    while (true) {
        uint64_t gen = head(engine);
        uint32_t pos = lst_pos;

        if (WJR_UNLIKELY(gen == lst_val)) {
            uint64_t now;
            do {
                dp[pos--] = gen;
                gen = engine();
                now = lp[pos];

                if (WJR_LIKELY(gen != now)) {
                    goto NEXT;
                }

            } while (pos);

            continue;

        NEXT:

            if (gen > now) {
                continue;
            }
        }

        dp[pos] = gen;
        while (pos) {
            dp[--pos] = engine();
        }

        break;
    }

    size = normalize(dp, size);
    dst->set_ssize(size);

    if (stkal.has_value()) {
        stkal->reset();
    }
}

template <typename S, typename Engine,
          WJR_REQUIRES_I(biginteger_uniform_random_bit_generator_v<Engine>)>
void __urandom_exact_impl(basic_biginteger<S> *dst, const biginteger_data *limit,
                          Engine &engine) noexcept {
    std::optional<uninitialized<math_detail::unique_stack_alloc>> stkal;
    uint32_t size = limit->size();

    if (WJR_UNLIKELY(size <= 1)) {
        if (size == 0) {
            dst->set_ssize(0);
            return;
        }

        std::uniform_int_distribution<uint64_t> head(0, limit->data()[0]);
        const uint64_t gen = head(engine);

        dst->clear_if_reserved(1);
        dst->data()[0] = gen;
        dst->set_ssize(gen == 0 ? 0 : 1);
        return;
    }

    dst->reserve(size);

    const auto dp = dst->data();
    const uint64_t *lp = limit->data();

    if (__equal_pointer(dst, limit)) {
        stkal.emplace(math_detail::stack_alloc);
        const auto tp = (uint64_t *)(*stkal)->allocate(size * sizeof(uint64_t));
        std::copy_n(lp, size, tp);
        lp = tp;
    }

    const uint32_t lst_pos = size - 1;
    const uint64_t lst_val = lp[lst_pos];
    std::uniform_int_distribution<uint64_t> head(0, lst_val);

    while (true) {
        uint64_t gen = head(engine);
        uint32_t pos = lst_pos;

        if (WJR_UNLIKELY(gen == lst_val)) {
            uint64_t now;
            do {
                dp[pos--] = gen;
                gen = engine();
                now = lp[pos];
            } while (gen == now && pos);

            if (gen > now) {
                continue;
            }
        }

        dp[pos] = gen;

        while (pos) {
            dp[--pos] = engine();
        }

        break;
    }

    size = normalize(dp, size);
    dst->set_ssize(size);

    if (stkal.has_value()) {
        stkal->reset();
    }
}

/// @private
inline uint32_t __bit_width_impl(const biginteger_data *num) noexcept {
    const uint32_t size = num->size();
    if (WJR_UNLIKELY(size == 0)) {
        return 0;
    }

    return 64 * size - clz(num->data()[size - 1]);
}

/// @private
inline uint32_t __ctz_impl(const biginteger_data *num) noexcept {
    if (num->empty()) {
        return 0;
    }

    // can be optimize by using SIMD

    const auto *const ptr = num->data();
    const uint32_t size = num->size();
    const uint32_t idx = static_cast<uint32_t>(find_not_n(ptr, 0, size));
    WJR_ASSERT(idx != size);
    return idx * 64 + ctz(ptr[idx]);
}

template <typename S>
void __pow_impl(basic_biginteger<S> *dst, const biginteger_data *num,
                uint32_t exp) noexcept {
    if (exp == 0) {
        *dst = 1u;
        return;
    }

    const uint32_t nbits = __bit_width_impl(num);
    const uint32_t dbits = nbits * exp;
    const uint32_t max_dusize = (dbits + 63) / 64;

    dst->reserve(max_dusize);
    *dst = *num;

    while (!(exp & 1)) {
        sqr(*dst, *dst);
        exp >>= 1;
    }

    if (exp == 1) {
        return;
    }

    basic_biginteger<S> tmp;
    exp >>= 1;
    sqr(tmp, *dst);

    if (exp & 1) {
        mul(*dst, *dst, tmp);
    }

    if (exp != 1) {
        do {
            exp >>= 1;
            sqr(tmp, tmp);

            if (exp & 1) {
                mul(*dst, *dst, tmp);
            }
        } while (exp != 1);
    }
}

/// @private
template <typename S>
void __powmod_impl(basic_biginteger<S> *dst, const biginteger_data *num,
                   __powmod_iterator *iter, const biginteger_data *mod) noexcept {
    WJR_ASSERT(mod->size() != 0);

    const auto size = iter->size;

    if (size == 0) {
        uint64_t val;
        if (WJR_UNLIKELY(mod->size() == 1 && mod->data()[0] == 1)) {
            val = 0u;
        } else {
            val = 1u;
        }

        *dst = val;
        return;
    }

    tdiv_r(*dst, *num, *mod);

    while (!(iter->get() & 1)) {
        sqr(*dst, *dst);
        tdiv_r(*dst, *dst, *mod);
        iter->next();
    }

    if (iter->end()) {
        return;
    }

    basic_biginteger<S> tmp;
    iter->next();
    sqr(tmp, *dst);
    tdiv_r(tmp, tmp, *mod);

    if (iter->get() & 1) {
        mul(*dst, *dst, tmp);
        tdiv_r(*dst, *dst, *mod);
    }

    if (!iter->end()) {
        do {
            iter->next();
            sqr(tmp, tmp);
            tdiv_r(tmp, tmp, *mod);

            if (iter->get() & 1) {
                mul(*dst, *dst, tmp);
                tdiv_r(*dst, *dst, *mod);
            }
        } while (!iter->end());
    }
}

template <typename S>
void __powmod_impl(basic_biginteger<S> *dst, const biginteger_data *num,
                   const biginteger_data *exp, const biginteger_data *mod) noexcept {
    __powmod_iterator iter(exp->data(), exp->size());
    __powmod_impl(dst, num, &iter, mod);
}

template <typename S>
void __powmod_impl(basic_biginteger<S> *dst, const biginteger_data *num, uint64_t exp,
                   const biginteger_data *mod) noexcept {
    uint64_t tmp[] = {exp};
    __powmod_iterator iter(tmp, exp == 0 ? 0 : 1);
    __powmod_impl(dst, num, &iter, mod);
}

} // namespace biginteger_detail

template <typename S>
from_chars_result<const char *> from_chars(const char *first, const char *last,
                                           basic_biginteger<S> &dst,
                                           unsigned int base) noexcept {
    return biginteger_detail::__from_chars_impl(first, last, &dst, base);
}

template <typename S>
void negate(basic_biginteger<S> &dst) noexcept {
    dst.negate();
}

template <typename S>
void absolute(basic_biginteger<S> &dst) noexcept {
    dst.absolute();
}

template <typename S>
std::istream &operator>>(std::istream &is, basic_biginteger<S> &dst) noexcept {
    std::string str;
    is >> str;
    from_chars(str.data(), str.data() + str.size(), dst, 0);
    return is;
}

template <typename Traits>
std::basic_ostream<char, Traits> &operator<<(std::basic_ostream<char, Traits> &os,
                                             const biginteger_data &src) noexcept {
    std::ios_base::iostate state = std::ios::goodbit;

    if (const std::ostream::sentry ok(os); ok) {
        unique_stack_allocator stkal(math_detail::stack_alloc);

        vector<char, math_detail::weak_stack_alloc<char>> buffer(stkal);
        buffer.clear_if_reserved(128);

        const std::ios_base::fmtflags flags = os.flags();

        if ((flags & std::ios::showpos) && !src.is_negate()) {
            buffer.push_back('+');
        }

        int base = 10;

        if (const auto basefield = flags & std::ios::basefield; basefield != 0) {
            if (basefield == std::ios::oct) {
                base = 8;
                if (flags & std::ios::showbase) {
                    buffer.append({'0'});
                }
            } else if (basefield == std::ios::hex) {
                base = 16;
                if (flags & std::ios::showbase) {
                    buffer.append({'0', 'x'});
                }
            }
        }

        (void)to_chars_unchecked(std::back_inserter(buffer), src, base);

        if (!buffer.empty()) {
            __ostream_insert_unchecked(os, buffer.data(), buffer.size());
        }
    }

    os.setstate(state);
    return os;
}

} // namespace wjr

namespace std {

template <typename Storage>
constexpr void
swap(wjr::basic_biginteger<Storage> &lhs,
     wjr::basic_biginteger<Storage> &rhs) noexcept(noexcept(lhs.swap(rhs))) {
    lhs.swap(rhs);
}

} // namespace std

#endif

#endif // WJR_BIGINTEGER_HPP__
#ifndef WJR_CONTAINER_GENERIC_BPLUS_TREE_HPP__
#define WJR_CONTAINER_GENERIC_BPLUS_TREE_HPP__

/**
 * @file bplus_tree.hpp
 * @brief B+ tree implementation.
 *
 * @details The multiset/multimap/set/map adapter has not been implemented yet. The
 * node_size should be set to 16 by default, and optimization has been made for queries
 * less than or equal to 16. \n
 * After improvement, the number of queries for the i-th query is
 * [1, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10], the average number of queries
 * is 6.56 times. In fact, the probability of querying smaller nodes is slightly greater
 * than that of larger nodes, so the actual number of queries will be less. If the
 * comparison operation of key_type is more complex, it is not recommended to use B+ tree,
 * because the number of queries of B+ tree will be more, thus offsetting the advantages
 * of B+ tree.
 *
 * @todo
 *
 * @version 0.1
 * @date 2024-05-06
 *
 */

// Already included
// Already included
#ifndef WJR_CONTAINER_GENERIC_CONTAINER_TRAITS_HPP__
#define WJR_CONTAINER_GENERIC_CONTAINER_TRAITS_HPP__

#include <memory>
#include <type_traits>

// Already included

namespace wjr {

/**
 * @class container_fn<Alloc>
 * @brief The same characteristics and behavior of all allocator containers
 *
 * @details container must have the following member functions:
 * -# auto& __get_allocator() noexcept
 * -# void __destroy() noexcept
 * -# void __destroy_and_deallocate() noexcept
 * -# void __copy_element(const container& other)
 * -# void __take_storage(container&& other)
 * -# void __move_element(container&& other)
 * -# void __swap_storage(container& other)
 *
 * 1 : is used to manage the allocator of the container. \n
 * 2-3 : is used to destroy the container and deallocate the memory. \n
 * 4-7 : is used to assign the container data. Shouldn't change the allocator.
 *
 */
template <typename Alloc>
class container_fn {
private:
    using allocator_type = Alloc;
    using allocator_traits = std::allocator_traits<allocator_type>;
    using is_always_equal = typename allocator_traits::is_always_equal;
    using propagate_on_container_copy_assignment =
        typename allocator_traits::propagate_on_container_copy_assignment;
    using propagate_on_container_move_assignment =
        typename allocator_traits::propagate_on_container_move_assignment;
    using propagate_on_container_swap =
        typename allocator_traits::propagate_on_container_swap;

public:
    template <typename Container>
    WJR_CONSTEXPR20 static void
    copy_assign(Container &lhs, const Container &rhs) noexcept(
        noexcept(lhs.__copy_element(rhs)) &&
                !propagate_on_container_copy_assignment::value
            ? true
            : (noexcept(lhs.__get_allocator() = rhs.__get_allocator()) &&
                       is_always_equal::value
                   ? true
                   : noexcept(lhs.__destroy_and_deallocate()))) {
        if constexpr (propagate_on_container_copy_assignment::value) {
            auto &lhs_allocator = lhs.__get_allocator();
            auto &rhs_allocator = rhs.__get_allocator();
            if constexpr (!is_always_equal::value) {
                if (lhs_allocator != rhs_allocator) {
                    lhs.__destroy_and_deallocate();
                }
            }

            lhs_allocator = rhs_allocator;
        }

        lhs.__copy_element(rhs);
    }

    template <typename Container>
    WJR_CONSTEXPR20 static void move_assign(Container &lhs, Container &&rhs) noexcept(
        noexcept(lhs.__destroy_and_deallocate()) && noexcept(
            lhs.__take_storage(std::move(rhs))) &&
                std::disjunction_v<propagate_on_container_move_assignment,
                                   is_always_equal>
            ? (!propagate_on_container_move_assignment::value
                   ? true
                   : noexcept(lhs.__get_allocator() = std::move(rhs.__get_allocator())))
            : (noexcept(lhs.__destroy()) && noexcept(
                  lhs.__move_element(std::move(rhs))))) {
        if constexpr (std::disjunction_v<propagate_on_container_move_assignment,
                                         is_always_equal>) {
            lhs.__destroy_and_deallocate();
            if constexpr (propagate_on_container_move_assignment::value) {
                lhs.__get_allocator() = std::move(rhs.__get_allocator());
            }
            lhs.__take_storage(std::move(rhs));
        } else {
            if (lhs.__get_allocator() != rhs.__get_allocator()) {
                lhs.__destroy();
                lhs.__move_element(std::move(rhs));
            } else {
                lhs.__destroy_and_deallocate();
                lhs.__take_storage(std::move(rhs));
            }
        }
    }

    template <typename Container>
    WJR_CONSTEXPR20 static void swap(Container &lhs, Container &rhs) noexcept(
        noexcept(lhs.__swap_storage(rhs)) &&
                !std::conjunction_v<propagate_on_container_swap,
                                    std::negation<is_always_equal>>
            ? true
            : noexcept(std::swap(lhs.__get_allocator(), rhs.__get_allocator()))) {
        if constexpr (std::conjunction_v<propagate_on_container_swap,
                                         std::negation<is_always_equal>>) {
            auto &lhs_allocator = lhs.__get_allocator();
            auto &rhs_allocator = rhs.__get_allocator();
            if (lhs_allocator != rhs_allocator) {
                std::swap(lhs_allocator, rhs_allocator);
            }
        }

        lhs.__swap_storage(rhs);
    }
};

} // namespace wjr

#endif // WJR_CONTAINER_GENERIC_CONTAINER_TRAITS_HPP__
// Already included
// Already included

#if defined(WJR_X86)
#ifndef WJR_X86_CONTAINER_GENERIC_BPLUS_TREE_HPP__
#define WJR_X86_CONTAINER_GENERIC_BPLUS_TREE_HPP__

#include <algorithm>

// Already included

namespace wjr {

#if WJR_HAS_SIMD(SSE2)
#define WJR_HAS_BUILTIN_BPLUS_TREE_COPY WJR_HAS_DEF
#endif

#if WJR_HAS_BUILTIN(BPLUS_TREE_COPY)

template <size_t Min, size_t Max, size_t size>
WJR_INTRINSIC_INLINE void __builtin_bplus_tree_copy_impl(const uint8_t *first,
                                                         const uint8_t *last,
                                                         uint8_t *dest) noexcept {
    const size_t n = last - first;
    WJR_ASSERT_ASSUME_L2(n >= Min * size && n <= Max * size);

    if (WJR_UNLIKELY(n == 0)) {
        return;
    }

    if (WJR_UNLIKELY(n == size)) {
        reinterpret_cast<uint_t<size * 8> *>(dest)[0] =
            reinterpret_cast<const uint_t<size * 8> *>(first)[0];
        return;
    }

    if constexpr (size <= 1) {
        do {
            if (n >= 4) {
                break;
            }

            const auto x0 = read_memory<uint16_t>(first);
            const auto x1 = read_memory<uint16_t>(last - 2);
            write_memory<uint16_t>(dest, x0);
            write_memory<uint16_t>(dest + n - 2, x1);
            return;
        } while (0);
    }

    if constexpr (size <= 2) {
        do {
            if (n >= 8) {
                break;
            }

            const auto x0 = read_memory<uint32_t>(first);
            const auto x1 = read_memory<uint32_t>(last - 4);
            write_memory<uint32_t>(dest, x0);
            write_memory<uint32_t>(dest + n - 4, x1);
            return;
        } while (0);
    }

    if constexpr (size <= 4) {
        do {
            if constexpr (size >= 2) {
                if (n >= 16) {
                    break;
                }
            }

            const auto x0 = read_memory<uint64_t>(first);
            const auto x1 = read_memory<uint64_t>(last - 8);
            write_memory<uint64_t>(dest, x0);
            write_memory<uint64_t>(dest + n - 8, x1);
            return;
        } while (0);
    }

    if constexpr (size >= 2) {
        do {
            if constexpr (size >= 4) {
                if (n >= 32) {
                    break;
                }
            }

            const auto x0 = sse::loadu(first);
            const auto x1 = sse::loadu(last - 16);
            sse::storeu(dest, x0);
            sse::storeu(dest + n - 16, x1);
            return;
        } while (0);
    }

    if constexpr (size >= 4) {
        do {
            if constexpr (size >= 8) {
                if (n >= 64) {
                    break;
                }
            }

#if WJR_HAS_SIMD(AVX2)
            const auto x0 = avx::loadu(first);
            const auto x1 = avx::loadu(last - 32);
            avx::storeu(dest, x0);
            avx::storeu(dest + n - 32, x1);
#else
            const auto x0 = sse::loadu(first);
            const auto x1 = sse::loadu(first + 16);
            const auto x2 = sse::loadu(last - 32);
            const auto x3 = sse::loadu(last - 16);
            sse::storeu((dest), x0);
            sse::storeu((dest + 16), x1);
            sse::storeu((dest + n - 32), x2);
            sse::storeu((dest + n - 16), x3);
#endif
            return;
        } while (0);
    }

    if constexpr (size == 8) {
#if WJR_HAS_SIMD(AVX2)
        const auto x0 = avx::loadu(first);
        const auto x1 = avx::loadu(first + 32);
        const auto x2 = avx::loadu(last - 64);
        const auto x3 = avx::loadu(last - 32);
        avx::storeu((dest), x0);
        avx::storeu((dest + 32), x1);
        avx::storeu((dest + n - 64), x2);
        avx::storeu((dest + n - 32), x3);
#else
        const auto x0 = sse::loadu(first);
        const auto x1 = sse::loadu(first + 16);
        const auto x2 = sse::loadu(first + 32);
        const auto x3 = sse::loadu(first + 48);
        const auto x4 = sse::loadu(last - 64);
        const auto x5 = sse::loadu(last - 48);
        const auto x6 = sse::loadu(last - 32);
        const auto x7 = sse::loadu(last - 16);
        sse::storeu((dest), x0);
        sse::storeu((dest + 16), x1);
        sse::storeu((dest + 32), x2);
        sse::storeu((dest + 48), x3);
        sse::storeu((dest + n - 64), x4);
        sse::storeu((dest + n - 48), x5);
        sse::storeu((dest + n - 32), x6);
        sse::storeu((dest + n - 16), x7);
#endif
    }
}

template <size_t Min, size_t Max, typename Other>
WJR_INTRINSIC_INLINE void builtin_bplus_tree_copy(const Other *first, const Other *last,
                                                  Other *dest) noexcept {
    __builtin_bplus_tree_copy_impl<Min, Max, sizeof(Other)>(
        reinterpret_cast<const uint8_t *>(first), reinterpret_cast<const uint8_t *>(last),
        reinterpret_cast<uint8_t *>(dest));
}

template <size_t Min, size_t Max, size_t size>
WJR_INTRINSIC_INLINE void
__builtin_bplus_tree_copy_backward_impl(const uint8_t *first, const uint8_t *last,
                                        uint8_t *dest) noexcept {
    const size_t n = last - first;
    WJR_ASSERT_ASSUME_L2(n >= Min * size && n <= Max * size);

    if (WJR_UNLIKELY(n == 0)) {
        return;
    }

    if (WJR_UNLIKELY(n == size)) {
        reinterpret_cast<uint_t<size * 8> *>(dest)[-1] =
            reinterpret_cast<const uint_t<size * 8> *>(first)[0];
        return;
    }

    if constexpr (size <= 1) {
        do {
            if (n >= 4) {
                break;
            }

            const auto x0 = read_memory<uint16_t>(first);
            const auto x1 = read_memory<uint16_t>(last - 2);
            write_memory<uint16_t>(dest - n, x0);
            write_memory<uint16_t>(dest - 2, x1);
            return;
        } while (0);
    }

    if constexpr (size <= 2) {
        do {
            if (n >= 8) {
                break;
            }

            const auto x0 = read_memory<uint32_t>(first);
            const auto x1 = read_memory<uint32_t>(last - 4);
            write_memory<uint32_t>(dest - n, x0);
            write_memory<uint32_t>(dest - 4, x1);
            return;
        } while (0);
    }

    if constexpr (size <= 4) {
        do {
            if constexpr (size >= 2) {
                if (n >= 16) {
                    break;
                }
            }

            const auto x0 = read_memory<uint64_t>(first);
            const auto x1 = read_memory<uint64_t>(last - 8);
            write_memory<uint64_t>(dest - n, x0);
            write_memory<uint64_t>(dest - 8, x1);
            return;
        } while (0);
    }

    if constexpr (size >= 2) {
        do {
            if constexpr (size >= 4) {
                if (n >= 32) {
                    break;
                }
            }

            const auto x0 = sse::loadu(first);
            const auto x1 = sse::loadu(last - 16);
            sse::storeu((dest - n), x0);
            sse::storeu((dest - 16), x1);
            return;
        } while (0);
    }

    if constexpr (size >= 4) {
        do {
            if constexpr (size >= 8) {
                if (n >= 64) {
                    break;
                }
            }

#if WJR_HAS_SIMD(AVX2)
            const auto x0 = avx::loadu(first);
            const auto x1 = avx::loadu(last - 32);
            avx::storeu((dest - n), x0);
            avx::storeu((dest - 32), x1);
#else
            const auto x0 = sse::loadu(first);
            const auto x1 = sse::loadu(first + 16);
            const auto x2 = sse::loadu(last - 32);
            const auto x3 = sse::loadu(last - 16);
            sse::storeu((dest - n), x0);
            sse::storeu((dest - n + 16), x1);
            sse::storeu((dest - 32), x2);
            sse::storeu((dest - 16), x3);
#endif
            return;
        } while (0);
    }

    if constexpr (size == 8) {
#if WJR_HAS_SIMD(AVX2)
        const auto x0 = avx::loadu(first);
        const auto x1 = avx::loadu(first + 32);
        const auto x2 = avx::loadu(last - 64);
        const auto x3 = avx::loadu(last - 32);
        avx::storeu((dest - n), x0);
        avx::storeu((dest - n + 32), x1);
        avx::storeu((dest - 64), x2);
        avx::storeu((dest - 32), x3);
#else
        const auto x0 = sse::loadu(first);
        const auto x1 = sse::loadu(first + 16);
        const auto x2 = sse::loadu(first + 32);
        const auto x3 = sse::loadu(first + 48);
        const auto x4 = sse::loadu(last - 64);
        const auto x5 = sse::loadu(last - 48);
        const auto x6 = sse::loadu(last - 32);
        const auto x7 = sse::loadu(last - 16);
        sse::storeu((dest - n), x0);
        sse::storeu((dest - n + 16), x1);
        sse::storeu((dest - n + 32), x2);
        sse::storeu((dest - n + 48), x3);
        sse::storeu((dest - 64), x4);
        sse::storeu((dest - 48), x5);
        sse::storeu((dest - 32), x6);
        sse::storeu((dest - 16), x7);
#endif
    }
}

template <size_t Min, size_t Max, typename Other>
WJR_INTRINSIC_INLINE void builtin_bplus_tree_copy_backward(const Other *first,
                                                           const Other *last,
                                                           Other *dest) noexcept {
    __builtin_bplus_tree_copy_backward_impl<Min, Max, sizeof(Other)>(
        reinterpret_cast<const uint8_t *>(first), reinterpret_cast<const uint8_t *>(last),
        reinterpret_cast<uint8_t *>(dest));
}

#endif

} // namespace wjr

#endif // WJR_X86_CONTAINER_GENERIC_BPLUS_TREE_HPP__

#endif

namespace wjr {

template <typename Traits>
struct bplus_tree_node;

template <typename Traits>
struct bplus_tree_inner_node;

template <typename Traits, bool InlineKeys>
struct bplus_tree_leaf_node;

namespace bplus_tree_detail {

template <typename T, bool Inlined>
class inline_key {
public:
    static_assert(!std::is_const_v<T>, "");

    using value_type = T;
    using reference = std::add_const_t<T> &;
    using pointer = std::add_const_t<T> *;

    inline_key() = default;
    inline_key(const inline_key &other) = default;
    inline_key(inline_key &&other) = default;
    inline_key &operator=(const inline_key &other) = default;
    inline_key &operator=(inline_key &&other) = default;
    ~inline_key() = default;

    constexpr inline_key(reference value) noexcept(
        std::is_nothrow_constructible_v<aligned_storage<T>, reference>)
        : m_storage(value) {}

    constexpr reference operator*() const noexcept { return *m_storage; }
    constexpr reference get() const noexcept { return m_storage.get(); }
    constexpr pointer operator->() const noexcept { return get(); }

private:
    // no need to check
    aligned_storage<T> m_storage;
};

template <typename T>
class inline_key<T, false> {
public:
    static_assert(!std::is_const_v<T>, "");

    using value_type = T;
    using reference = std::add_const_t<T> &;
    using pointer = std::add_const_t<T> *;

    inline_key() = default;
    inline_key(const inline_key &other) = default;
    inline_key(inline_key &&other) = default;
    inline_key &operator=(const inline_key &other) = default;
    inline_key &operator=(inline_key &&other) = default;
    ~inline_key() = default;

    constexpr inline_key(reference value) noexcept : m_ptr(std::addressof(value)) {}

    constexpr reference operator*() const noexcept { return *m_ptr; }
    constexpr pointer operator->() const noexcept { return m_ptr; }
    constexpr reference get() const noexcept { return *m_ptr; }

private:
    pointer m_ptr;
};

template <typename T>
struct is_possible_inline_key : std::is_trivially_copyable<aligned_storage<T>> {};

template <typename T>
inline constexpr bool is_possible_inline_key_v = is_possible_inline_key<T>::value;

template <size_t Min, size_t Max, typename Other>
WJR_INTRINSIC_INLINE static void copy(Other *first, Other *last, Other *dest) noexcept {
#if WJR_HAS_BUILTIN(BPLUS_TREE_COPY)
    if constexpr (Max <= 16 && std::is_trivially_copyable_v<Other>) {
        builtin_bplus_tree_copy<Min, Max>(first, last, dest);
    } else {
#endif
        (void)std::copy(first, last, dest);
#if WJR_HAS_BUILTIN(BPLUS_TREE_COPY)
    }
#endif
}

template <size_t Min, size_t Max, typename Other>
WJR_INTRINSIC_INLINE static void copy_backward(Other *first, Other *last,
                                               Other *dest) noexcept {
#if WJR_HAS_BUILTIN(BPLUS_TREE_COPY)
    if constexpr (Max <= 16 && std::is_trivially_copyable_v<Other>) {
        builtin_bplus_tree_copy_backward<Min, Max>(first, last, dest);
    } else {
#endif
        (void)std::copy_backward(first, last, dest);
#if WJR_HAS_BUILTIN(BPLUS_TREE_COPY)
    }
#endif
}

} // namespace bplus_tree_detail

template <typename Key, typename Value, typename Compare, size_t Size, bool Multi>
struct bplus_tree_traits {
    using key_type = Key;
    using mapped_type = Value;
    static constexpr bool is_map = !std::is_same_v<mapped_type, void>;
    using value_type =
        std::conditional_t<is_map, std::pair<const key_type, mapped_type>, key_type>;
    using key_compare = Compare;

    static constexpr size_t node_size = Size;
    static constexpr bool is_inline_key =
        bplus_tree_detail::is_possible_inline_key_v<std::remove_const_t<key_type>> &&
        sizeof(key_type) <= 8;
    static constexpr bool is_inline_value =
        bplus_tree_detail::is_possible_inline_key_v<std::remove_const_t<value_type>> &&
        sizeof(value_type) <= 8;

    using InlineKey =
        bplus_tree_detail::inline_key<std::remove_const_t<key_type>, is_inline_key>;
    using InlineValue = std::conditional_t<
        is_inline_value,
        bplus_tree_detail::inline_key<std::remove_const_t<value_type>, true>,
        value_type *>;

    using node_type = bplus_tree_node<bplus_tree_traits>;
    using inner_node_type = bplus_tree_inner_node<bplus_tree_traits>;
    using leaf_node_type =
        bplus_tree_leaf_node<bplus_tree_traits, is_inline_key && !is_inline_value>;
    static constexpr bool multi = Multi;

    WJR_INTRINSIC_INLINE static const key_type &
    get_key(const value_type &value) noexcept {
        if constexpr (is_map) {
            return value.first;
        } else {
            return value;
        }
    }

public:
    template <size_t Min = 0, size_t Max = node_size, typename Other = void>
    WJR_INTRINSIC_INLINE static void copy(Other *first, Other *last,
                                          Other *dest) noexcept {
        return bplus_tree_detail::copy<Min, Max>(first, last, dest);
    }

    template <size_t Min = 0, size_t Max = node_size, typename Other = void>
    WJR_INTRINSIC_INLINE static void copy_backward(Other *first, Other *last,
                                                   Other *dest) noexcept {
        return bplus_tree_detail::copy_backward<Min, Max>(first, last, dest);
    }
};

template <typename Traits>
struct bplus_tree_node {
    using key_type = typename Traits::key_type;
    using value_type = typename Traits::value_type;
    constexpr static size_t node_size = Traits::node_size;
    using InlineKey = typename Traits::InlineKey;
    using inner_node_type = typename Traits::inner_node_type;
    using leaf_node_type = typename Traits::leaf_node_type;

    constexpr inner_node_type *as_inner() noexcept;
    constexpr const inner_node_type *as_inner() const noexcept;

    constexpr leaf_node_type *as_leaf() noexcept;
    constexpr const leaf_node_type *as_leaf() const noexcept;

    int m_size;
    unsigned int m_pos;
    bplus_tree_node *m_parent;
};

template <typename Traits>
struct bplus_tree_inner_node : bplus_tree_node<Traits> {
    using key_type = typename Traits::key_type;
    using value_type = typename Traits::value_type;
    constexpr static size_t node_size = Traits::node_size;
    using InlineKey = typename Traits::InlineKey;

    alignas(16) InlineKey m_keys[node_size];
    alignas(16) bplus_tree_node<Traits> *m_sons[node_size + 1];
};

template <typename Traits, bool InlineKeys>
struct bplus_tree_leaf_node : bplus_tree_node<Traits>, list_node<> {
    using key_type = typename Traits::key_type;
    using value_type = typename Traits::value_type;
    constexpr static size_t node_size = Traits::node_size;
    using InlineKey = typename Traits::InlineKey;
    using ListNode = list_node<>;

    const key_type &__get_key(unsigned int pos) const noexcept { return *m_keys[pos]; }

    template <size_t Min = 0, size_t Max = node_size>
    WJR_INTRINSIC_INLINE void __copy(unsigned int start, unsigned int end,
                                     unsigned int dst_start,
                                     bplus_tree_leaf_node *dst) noexcept {
        Traits::template copy<Min, Max>(m_keys + start, m_keys + end,
                                        dst->m_keys + dst_start);
        Traits::template copy<Min, Max>(m_values + start, m_values + end,
                                        dst->m_values + dst_start);
    }

    template <size_t Min = 0, size_t Max = node_size>
    WJR_INTRINSIC_INLINE void __copy_backward(unsigned int start, unsigned int end,
                                              unsigned int dst_end,
                                              bplus_tree_leaf_node *dst) noexcept {
        Traits::template copy_backward<Min, Max>(m_keys + start, m_keys + end,
                                                 dst->m_keys + dst_end);
        Traits::template copy_backward<Min, Max>(m_values + start, m_values + end,
                                                 dst->m_values + dst_end);
    }

    WJR_INTRINSIC_INLINE void __assign(unsigned int idx,
                                       value_type *const value) noexcept {
        m_keys[idx] = Traits::get_key(*value);
        m_values[idx] = value;
    }

    constexpr ListNode *__get_list() noexcept { return this; }
    constexpr const ListNode *__get_list() const noexcept { return this; }

    alignas(16) InlineKey m_keys[node_size];
    alignas(16) value_type *m_values[node_size];
};

template <typename Traits>
struct bplus_tree_leaf_node<Traits, false> : bplus_tree_node<Traits>, list_node<> {
    using key_type = typename Traits::key_type;
    using value_type = typename Traits::value_type;
    constexpr static size_t node_size = Traits::node_size;
    constexpr static bool is_inline_value = Traits::is_inline_value;
    using InlineValue = typename Traits::InlineValue;
    using ListNode = list_node<>;

    const key_type &__get_key(unsigned int pos) const noexcept {
        return Traits::get_key(*m_values[pos]);
    }

    template <size_t Min = 0, size_t Max = node_size>
    WJR_INTRINSIC_INLINE void __copy(unsigned int start, unsigned int end,
                                     unsigned int dst_start,
                                     bplus_tree_leaf_node *dst) noexcept {
        Traits::template copy<Min, Max>(m_values + start, m_values + end,
                                        dst->m_values + dst_start);
    }

    template <size_t Min = 0, size_t Max = node_size>
    WJR_INTRINSIC_INLINE void __copy_backward(unsigned int start, unsigned int end,
                                              unsigned int dst_end,
                                              bplus_tree_leaf_node *dst) noexcept {
        Traits::template copy_backward<Min, Max>(m_values + start, m_values + end,
                                                 dst->m_values + dst_end);
    }

    WJR_INTRINSIC_INLINE void __assign(unsigned int idx, InlineValue value) noexcept {
        m_values[idx] = value;
    }

    constexpr ListNode *__get_list() noexcept { return this; }
    constexpr const ListNode *__get_list() const noexcept { return this; }

    alignas(16) InlineValue m_values[node_size];
};

template <typename Traits>
constexpr typename bplus_tree_node<Traits>::inner_node_type *
bplus_tree_node<Traits>::as_inner() noexcept {
    return static_cast<inner_node_type *>(this);
}

template <typename Traits>
constexpr const typename bplus_tree_node<Traits>::inner_node_type *
bplus_tree_node<Traits>::as_inner() const noexcept {
    return static_cast<const inner_node_type *>(this);
}

template <typename Traits>
constexpr typename bplus_tree_node<Traits>::leaf_node_type *
bplus_tree_node<Traits>::as_leaf() noexcept {
    return static_cast<leaf_node_type *>(this);
}

template <typename Traits>
constexpr const typename bplus_tree_node<Traits>::leaf_node_type *
bplus_tree_node<Traits>::as_leaf() const noexcept {
    return static_cast<const leaf_node_type *>(this);
}

template <typename Traits, typename Alloc>
class basic_bplus_tree;

template <typename Traits>
class bplus_tree_const_iterator {
    using node_type = typename Traits::node_type;
    using inner_node_type = typename Traits::inner_node_type;
    using leaf_node_type = typename Traits::leaf_node_type;

    template <typename Other, typename Alloc>
    friend class basic_bplus_tree;

    using ListNode = list_node<>;

public:
    using iterator_category = std::bidirectional_iterator_tag;
    using value_type = typename Traits::value_type;
    using difference_type = std::ptrdiff_t;
    using pointer = const value_type *;
    using reference = const value_type &;

    bplus_tree_const_iterator() = default;
    bplus_tree_const_iterator(const bplus_tree_const_iterator &) = default;
    bplus_tree_const_iterator(bplus_tree_const_iterator &&) = default;
    bplus_tree_const_iterator &operator=(const bplus_tree_const_iterator &) = default;
    bplus_tree_const_iterator &operator=(bplus_tree_const_iterator &&) = default;
    ~bplus_tree_const_iterator() = default;

protected:
    bplus_tree_const_iterator(const ListNode *list_node, unsigned int pos) noexcept
        : m_node(const_cast<ListNode *>(list_node)), m_pos(pos) {}

    bplus_tree_const_iterator(const leaf_node_type *leaf, unsigned int pos) noexcept
        : bplus_tree_const_iterator(leaf->__get_list(), pos) {}

public:
    reference operator*() const noexcept { return *get_leaf()->m_values[m_pos]; }

    pointer operator->() const noexcept { return get_leaf()->m_values[m_pos]; }

    bplus_tree_const_iterator &operator++() noexcept {
        ++m_pos;
        return __adjust_next();
    }

    bplus_tree_const_iterator operator++(int) noexcept {
        bplus_tree_const_iterator tmp = *this;
        ++*this;
        return tmp;
    }

    bplus_tree_const_iterator &operator--() noexcept {
        if (m_pos != 0) {
            --m_pos;
        } else {
            m_node = prev(m_node);
            m_pos = -get_leaf()->m_size - 1;
        }

        return *this;
    }

    bplus_tree_const_iterator operator--(int) noexcept {
        bplus_tree_const_iterator tmp = *this;
        --*this;
        return tmp;
    }

    bool operator==(const bplus_tree_const_iterator &other) const noexcept {
        return m_node == other.m_node && m_pos == other.m_pos;
    }

    bool operator!=(const bplus_tree_const_iterator &other) const noexcept {
        return !(*this == other);
    }

    leaf_node_type *get_leaf() const noexcept {
        return static_cast<leaf_node_type *>(m_node);
    }

    ListNode *get_node() const noexcept { return m_node; }
    unsigned int get_pos() const noexcept { return m_pos; }

protected:
    bplus_tree_const_iterator &__adjust_next() noexcept {
        if (m_pos == static_cast<unsigned int>(-get_leaf()->m_size)) {
            m_node = next(m_node);
            m_pos = 0;
        }

        return *this;
    }

private:
    ListNode *m_node = nullptr;
    unsigned int m_pos = 0;
};

template <typename Traits>
class bplus_tree_iterator : public bplus_tree_const_iterator<Traits> {
    using Mybase = bplus_tree_const_iterator<Traits>;
    using leaf_node_type = typename Traits::leaf_node_type;

    template <typename Other, typename Alloc>
    friend class basic_bplus_tree;

    using ListNode = list_node<>;

public:
    using Mybase::Mybase;

    using iterator_category = typename Mybase::iterator_category;
    using value_type = typename Mybase::value_type;
    using difference_type = std::ptrdiff_t;
    using pointer = value_type *;
    using reference = value_type &;

    bplus_tree_iterator(const Mybase &other) noexcept : Mybase(other) {}

protected:
    bplus_tree_iterator(const ListNode *list_node, unsigned int pos) noexcept
        : Mybase(list_node, pos) {}

    bplus_tree_iterator(const leaf_node_type *leaf, unsigned int pos) noexcept
        : Mybase(leaf, pos) {}

public:
    value_type &operator*() const noexcept {
        return const_cast<value_type &>(Mybase::operator*());
    }

    value_type *operator->() const noexcept {
        return const_cast<value_type *>(Mybase::operator->());
    }

    bplus_tree_iterator &operator++() noexcept {
        Mybase::operator++();
        return *this;
    }

    bplus_tree_iterator operator++(int) noexcept {
        bplus_tree_iterator tmp = *this;
        ++*this;
        return tmp;
    }

    bplus_tree_iterator &operator--() noexcept {
        Mybase::operator--();
        return *this;
    }

    bplus_tree_iterator operator--(int) noexcept {
        bplus_tree_iterator tmp = *this;
        --*this;
        return tmp;
    }

    bool operator==(const bplus_tree_iterator &other) const noexcept {
        return Mybase::operator==(other);
    }

    bool operator!=(const bplus_tree_iterator &other) const noexcept {
        return Mybase::operator!=(other);
    }

protected:
    bplus_tree_iterator &__adjust_next() noexcept {
        Mybase::__adjust_next();
        return *this;
    }
};

template <typename Traits, typename Alloc>
class basic_bplus_tree {
    using _Alty = typename std::allocator_traits<Alloc>::template rebind_alloc<uint8_t>;
    using _Alty_traits = std::allocator_traits<_Alty>;
    using storage_fn_type = container_fn<_Alty>;

    friend class container_fn<_Alty>;

    using mapped_type = typename Traits::mapped_type;
    static constexpr size_t node_size = Traits::node_size;
    static constexpr bool is_inline_key = Traits::is_inline_key;
    static constexpr bool is_inline_value = Traits::is_inline_value;
    using InlineKey = typename Traits::InlineKey;
    using InlineValue = typename Traits::InlineValue;
    static constexpr size_t floor_half = node_size / 2;
    static constexpr size_t ceil_half = node_size - floor_half;
    static constexpr bool Multi = Traits::Multi;

    using node_type = typename Traits::node_type;
    using inner_node_type = typename Traits::inner_node_type;
    using leaf_node_type = typename Traits::leaf_node_type;

    using ListNode = list_node<>;

public:
    using key_type = typename Traits::key_type;
    using value_type = typename Traits::value_type;
    using key_compare = typename Traits::key_compare;
    using allocator_type = Alloc;
    using size_type = typename _Alty_traits::size_type;
    using difference_type = typename _Alty_traits::difference_type;
    using iterator = bplus_tree_iterator<Traits>;
    using const_iterator = bplus_tree_const_iterator<Traits>;
    using reverse_iterator = std::reverse_iterator<iterator>;
    using const_reverse_iterator = std::reverse_iterator<const_iterator>;

    static_assert(node_size >= 3, "node_size must be greater than or equal to 3.");
    static_assert(node_size <= 255, "node_size must be less than or equal to 255.");

    basic_bplus_tree() noexcept(std::is_nothrow_default_constructible_v<_Alty>) {
        init(&m_sentry);
    }

    // not implemented currently
    basic_bplus_tree(const basic_bplus_tree &) = delete;

    basic_bplus_tree(basic_bplus_tree &&other) noexcept(
        std::is_nothrow_move_constructible_v<key_compare>
            &&std::is_nothrow_move_constructible_v<_Alty>)
        : m_pair(std::piecewise_construct,
                 wjr::forward_as_tuple(std::move(other.key_comp())),
                 wjr::forward_as_tuple(
                     std::piecewise_construct,
                     wjr::forward_as_tuple(std::move(other.__get_allocator())),
                     wjr::forward_as_tuple())) {
        __take_tree(std::move(other));
    }

    basic_bplus_tree &operator=(const basic_bplus_tree &) = delete;

    basic_bplus_tree &operator=(basic_bplus_tree &&other) noexcept(
        noexcept(storage_fn_type::move_assign(*this, std::move(other)))) {
        WJR_ASSERT(this != std::addressof(other));
        storage_fn_type::move_assign(*this, std::move(other));
        return *this;
    }

    ~basic_bplus_tree() noexcept { __destroy_and_deallocate(); }

    constexpr key_compare &key_comp() noexcept { return m_pair.first(); }
    constexpr const key_compare &key_comp() const noexcept { return m_pair.first(); }

    iterator begin() noexcept { return iterator(m_sentry.next(), 0); }
    const_iterator begin() const noexcept { return const_iterator(m_sentry.next(), 0); }
    const_iterator cbegin() const noexcept { return const_iterator(m_sentry.next(), 0); }

    iterator end() noexcept { return iterator(&m_sentry, 0); }
    const_iterator end() const noexcept { return const_iterator(&m_sentry, 0); }
    const_iterator cend() const noexcept { return const_iterator(&m_sentry, 0); }

    reverse_iterator rbegin() noexcept { return reverse_iterator(end()); }
    const_reverse_iterator rbegin() const noexcept {
        return const_reverse_iterator(end());
    }

    const_reverse_iterator crbegin() const noexcept {
        return const_reverse_iterator(cend());
    }

    reverse_iterator rend() noexcept { return reverse_iterator(begin()); }
    const_reverse_iterator rend() const noexcept {
        return const_reverse_iterator(begin());
    }

    const_reverse_iterator crend() const noexcept {
        return const_reverse_iterator(cbegin());
    }

private:
    template <typename... Args>
    InlineValue __create_node(Args &&...args) noexcept {
        if constexpr (is_inline_value) {
            InlineValue ret(std::forward<Args>(args)...);
            return ret;
        } else {
            auto &al = __get_allocator();
            value_type *const xval =
                (value_type *)_Alty_traits::allocate(al, sizeof(value_type));
            uninitialized_construct_using_allocator(xval, al,
                                                    std::forward<Args>(args)...);
            return xval;
        }
    }

    template <typename... Args>
    void __drop_node(InlineValue xval) noexcept {
        if constexpr (!is_inline_value) {
            auto &al = __get_allocator();
            _Alty_traits::destroy(al, xval);
            _Alty_traits::deallocate(al, (uint8_t *)xval, sizeof(value_type));
        }
    }

    const_iterator __get_insert_multi_pos(const key_type &key) const noexcept {
        return __search<true>(key);
    }

    std::pair<const_iterator, bool>
    __get_insert_unique_pos(const key_type &key) const noexcept {
        const const_iterator iter = __search<true>(key);
        const auto pos = iter.get_pos();
        const bool inserted =
            pos == 0 || key_comp()(*iter.get_leaf()->m_values[pos - 1], key);
        return {iter, inserted};
    }

public:
    template <typename... Args>
    iterator __emplace_multi(Args &&...args) noexcept {
        const auto xval = __create_node(std::forward<Args>(args)...);
        const auto iter = __get_insert_multi_pos(Traits::get_key(*xval));
        return __insert_iter(iter, xval);
    }

    template <typename... Args>
    std::pair<iterator, bool> __emplace_unique(Args &&...args) noexcept {
        const auto xval = __create_node(std::forward<Args>(args)...);
        const auto [iter, inserted] = __get_insert_unique_pos(Traits::get_key(*xval));

        if (inserted) {
            return {__insert_iter(iter, xval), true};
        }

        __drop_node(xval);
        return {iterator(iter).__adjust_next(), false};
    }

    const_iterator __insert_multi(const value_type &val) noexcept {
        return __emplace_multi(val);
    }

    const_iterator __insert_multi(value_type &&val) noexcept {
        return __emplace_multi(std::move(val));
    }

    std::pair<const_iterator, bool> __insert_unique(const value_type &val) noexcept {
        return __emplace_unique(val);
    }

    std::pair<const_iterator, bool> __insert_unique(value_type &&val) noexcept {
        return __emplace_unique(std::move(val));
    }

    iterator lower_bound(const key_type &key) noexcept {
        return __search<false>(key).__adjust_next();
    }

    const_iterator lower_bound(const key_type &key) const noexcept {
        return __search<false>(key).__adjust_next();
    }

    iterator upper_bound(const key_type &key) noexcept {
        return __search<true>(key).__adjust_next();
    }

    const_iterator upper_bound(const key_type &key) const noexcept {
        return __search<true>(key).__adjust_next();
    }

    iterator erase(const_iterator iter) noexcept {
        return __erase_iter(iter).__adjust_next();
    }

private:
    void __take_tree(basic_bplus_tree &&other) noexcept {
        const auto root = other.__get_root();
        if (root == nullptr) {
            init(&m_sentry);
            return;
        }

        __get_root() = root;
        other.__get_root() = nullptr;
        replace_uninit(&other.m_sentry, &m_sentry);
        init(&other.m_sentry);
    }

    // member function for container_fn (START)

    WJR_PURE WJR_INTRINSIC_CONSTEXPR _Alty &__get_allocator() noexcept {
        return m_pair.second().first();
    }

    WJR_PURE WJR_INTRINSIC_CONSTEXPR const _Alty &__get_allocator() const noexcept {
        return m_pair.second().first();
    }

    void __destroy_and_deallocate() noexcept {
        node_type *current = __get_root();

        if (WJR_UNLIKELY(current == nullptr)) {
            return;
        }

        auto &al = __get_allocator();
        int cur_size = current->m_size;

        // If root is leaf
        if (cur_size < 0) {
            const auto leaf = current->as_leaf();
            const unsigned int cur_usize = -cur_size;

            for (unsigned int i = 0; i < cur_usize; ++i) {
                __drop_node(leaf->m_values[i]);
            }

            _Alty_traits::deallocate(al, (uint8_t *)leaf, sizeof(leaf_node_type));
            return;
        }

        // skip to the leftmost leaf
        current = begin().get_leaf();
        cur_size = -current->m_size;

        // cache of parent and parent's size
        node_type *parent = current->m_parent;
        unsigned int par_size = parent->m_size;

        // cache of `current' node's position in parent
        unsigned int pos = 0;

        do {
            const auto leaf = current->as_leaf();
            const unsigned int cur_usize = cur_size;

            for (unsigned int i = 0; i < cur_usize; ++i) {
                __drop_node(leaf->m_values[i]);
            }

            ListNode *next = wjr::next(leaf);
            _Alty_traits::deallocate(al, (uint8_t *)leaf, sizeof(leaf_node_type));

            // if `current' is the last child of parent
            if (WJR_UNLIKELY(pos++ == par_size)) {
                do {
                    current = parent;
                    parent = current->m_parent;
                    pos = current->m_pos;
                    _Alty_traits::deallocate(al, (uint8_t *)current,
                                             sizeof(inner_node_type));

                    // if `current' is the rightmost leaf
                    if (parent == nullptr) {
                        return;
                    }

                    // if `current' is the last child of parent
                } while (pos == (unsigned int)parent->m_size);

                // update cache of parent and parent's size
                parent = static_cast<leaf_node_type *>(next)->m_parent;
                par_size = parent->m_size;
                pos = 0;
            }

            WJR_ASSERT(next != &m_sentry);

            current = static_cast<leaf_node_type *>(next);
            cur_size = -current->m_size;
        } while (true);
    }

    void __take_storage(basic_bplus_tree &&other) noexcept {
        key_comp() = std::move(other.key_comp());
        __take_tree(std::move(other));
    }

    // member function for container_fn (END)

    WJR_NOINLINE void __rec_insert_iter(node_type *current, node_type *inst) noexcept {
        auto &al = __get_allocator();

        node_type *parent = current->m_parent;
        InlineKey key = inst->as_leaf()->__get_key(0);

        while (parent != nullptr) {
            inst->m_parent = parent;
            unsigned int pos = current->m_pos + 1;
            current = parent;
            const auto inner = current->as_inner();

            unsigned int cur_size = inner->m_size + 1;
            InlineKey *const keys = inner->m_keys;
            node_type **const sons = inner->m_sons;

            // non-full inner
            if (WJR_LIKELY(cur_size != node_size + 1)) {
                Traits::copy_backward(keys + pos - 1, keys + cur_size - 1,
                                      keys + cur_size);
                Traits::copy_backward(sons + pos, sons + cur_size, sons + cur_size + 1);

                inner->m_size = cur_size;
                keys[pos - 1] = key;
                sons[pos] = inst;

                inst->m_pos = pos;
                for (unsigned int i = pos + 1; i <= cur_size; ++i) {
                    sons[i]->m_pos = i;
                }

                return;
            }

            parent = inner->m_parent;

            const auto tmp_inst =
                (inner_node_type *)_Alty_traits::allocate(al, sizeof(inner_node_type));

            inner->m_size = (int)(ceil_half);
            tmp_inst->m_size = (int)(floor_half);

            InlineKey next_key;

            if (pos <= ceil_half) {
                next_key = keys[ceil_half - 1];

                Traits::template copy<floor_half, floor_half>(
                    keys + ceil_half, keys + node_size, tmp_inst->m_keys);
                Traits::template copy<floor_half + 1, floor_half + 1>(
                    sons + ceil_half, sons + node_size + 1, tmp_inst->m_sons);
                Traits::template copy_backward<0, ceil_half>(
                    keys + pos - 1, keys + ceil_half - 1, keys + ceil_half);
                Traits::template copy_backward<0, ceil_half>(sons + pos, sons + ceil_half,
                                                             sons + ceil_half + 1);

                keys[pos - 1] = key;
                sons[pos] = inst;

                inst->m_pos = pos;
                for (unsigned int i = pos + 1; i <= ceil_half; ++i) {
                    sons[i]->m_pos = i;
                }
            } else {
                if (pos == ceil_half + 1) {
                    next_key = key;

                    Traits::template copy<floor_half, floor_half>(
                        keys + ceil_half, keys + node_size, tmp_inst->m_keys);
                    Traits::template copy<floor_half, floor_half>(
                        sons + ceil_half + 1, sons + node_size + 1, tmp_inst->m_sons + 1);

                    tmp_inst->m_sons[0] = inst;
                } else {
                    next_key = keys[ceil_half];

                    Traits::template copy<0, floor_half - 1>(
                        keys + ceil_half + 1, keys + pos - 1, tmp_inst->m_keys);
                    Traits::template copy<1, floor_half>(sons + ceil_half + 1, sons + pos,
                                                         tmp_inst->m_sons);

                    const unsigned int rpos = pos - ceil_half - 1;

                    Traits::template copy<0, floor_half - 1>(
                        keys + pos - 1, keys + node_size, tmp_inst->m_keys + rpos);
                    Traits::template copy<0, floor_half>(sons + pos, sons + node_size + 1,
                                                         tmp_inst->m_sons + rpos + 1);

                    tmp_inst->m_keys[rpos - 1] = key;
                    tmp_inst->m_sons[rpos] = inst;
                }
            }

            for (unsigned int i = 0; i <= floor_half; ++i) {
                tmp_inst->m_sons[i]->m_parent = tmp_inst;
                tmp_inst->m_sons[i]->m_pos = i;
            }

            key = next_key;
            inst = tmp_inst;
        }

        const auto new_root =
            (inner_node_type *)_Alty_traits::allocate(al, sizeof(inner_node_type));
        new_root->m_size = 1;
        new_root->m_parent = nullptr;
        new_root->m_keys[0] = key;
        new_root->m_sons[0] = current;
        new_root->m_sons[1] = inst;
        current->m_pos = 0;
        inst->m_pos = 1;

        current->m_parent = new_root;
        inst->m_parent = new_root;

        __get_root() = new_root;
        return;
    }

    WJR_NODISCARD iterator __insert_iter(const_iterator iter, InlineValue xval) noexcept {
        auto &al = __get_allocator();

        leaf_node_type *leaf;
        do {
            ListNode *const node = iter.get_node();

            // empty
            if (WJR_UNLIKELY(node == &m_sentry)) {
                leaf = (leaf_node_type *)_Alty_traits::allocate(__get_allocator(),
                                                                sizeof(leaf_node_type));

                __get_root() = leaf;

                leaf->m_size = -1;
                leaf->m_parent = nullptr;
                leaf->__assign(0, xval);
                wjr::push_front(&m_sentry, leaf);
                return iterator(leaf, 0);
            }

            leaf = static_cast<leaf_node_type *>(node);
        } while (0);

        unsigned int pos = iter.get_pos();
        unsigned int cur_size = -leaf->m_size;

        // non-full leaf
        if (WJR_LIKELY(cur_size != node_size)) {
            WJR_ASSERT_ASSUME(pos <= cur_size);

            leaf->__copy_backward(pos, cur_size, cur_size + 1, leaf);

            leaf->m_size = -(cur_size + 1);
            leaf->__assign(pos, xval);
            return iterator(leaf, pos);
        }

        const auto inst =
            (leaf_node_type *)_Alty_traits::allocate(al, sizeof(leaf_node_type));
        push_front(leaf, inst);

        leaf->m_size = -(int)(floor_half + 1);
        inst->m_size = -(int)(node_size - floor_half);

        leaf_node_type *result;

        if (pos <= floor_half) {
            leaf->template __copy<ceil_half, ceil_half>(floor_half, node_size, 0, inst);
            leaf->template __copy_backward<0, floor_half>(pos, floor_half, floor_half + 1,
                                                          leaf);
            leaf->__assign(pos, xval);
            result = leaf;
        } else {
            // pos in inst
            const unsigned int rpos = pos - floor_half - 1;
            leaf->template __copy<0, ceil_half - 1>(floor_half + 1, pos, 0, inst);
            leaf->template __copy<0, ceil_half - 1>(pos, node_size, rpos + 1, inst);
            inst->__assign(rpos, xval);
            result = inst;
            pos = rpos;
        }

        __rec_insert_iter(leaf, inst);
        return iterator(result, pos);
    }

    template <bool Upper>
    WJR_PURE WJR_INTRINSIC_INLINE static bool
    __compare(const key_type &a, const key_type &key, const key_compare &comp) noexcept {
        if constexpr (Upper) {
            return comp(key, a);
        } else {
            return !comp(a, key);
        }
    }

    template <bool Upper>
    WJR_PURE WJR_NOINLINE const_iterator __search(const key_type &key) const noexcept {
        const node_type *current = __get_root();

        if (WJR_UNLIKELY(current == nullptr)) {
            return cend();
        }

        unsigned int pos;

        int cur_size = current->m_size;
        const auto &comp = key_comp();

        // root search
        if (WJR_UNLIKELY(cur_size < 0)) {
            pos = __search<Upper, 1, node_size, 0>(current->as_leaf(), -cur_size, key,
                                                   comp);
            return const_iterator(current->as_leaf(), pos);
        }

        if (!__compare<Upper>(*current->as_inner()->m_keys[0], key, comp)) {
            goto NOT_LEFTMOST_AT_ROOT;
        }

        current = current->as_inner()->m_sons[0];
        cur_size = current->m_size;

        while (cur_size >= 0) {
            if (!__compare<Upper>(*current->as_inner()->m_keys[0], key, comp)) {
                goto NOT_LEFTMOST_AT_INNER;
            }

            current = current->as_inner()->m_sons[0];
            cur_size = current->m_size;
        }

        // leftmost leaf need to check first key
        if (__compare<Upper>(current->as_leaf()->__get_key(0), key, comp)) {
            return const_iterator(current->as_leaf(), 0);
        }

        goto LEAF;

        do {

        NOT_LEFTMOST_AT_ROOT:
            pos = __search<Upper, 1, node_size, 1>(current->as_inner(), cur_size, key,
                                                   comp);

            break;

        NOT_LEFTMOST_AT_INNER:
            pos = __search<Upper, floor_half, node_size, 1>(current->as_inner(), cur_size,
                                                            key, comp);
        } while (0);

        current = current->as_inner()->m_sons[pos];
        cur_size = current->m_size;

        if (cur_size < 0) {
            goto LEAF;
        }

        do {
            pos = __search<Upper, floor_half, node_size, 0>(current->as_inner(), cur_size,
                                                            key, comp);

            current = current->as_inner()->m_sons[pos];
            cur_size = current->m_size;
        } while (cur_size >= 0);

    LEAF:
        pos = __search<Upper, floor_half, node_size, 1>(current->as_leaf(), -cur_size,
                                                        key, comp);
        return const_iterator(current->as_leaf(), pos);
    }

    template <size_t Min, size_t Max, size_t Offset, typename Compare>
    WJR_PURE WJR_INTRINSIC_INLINE static unsigned int
    __search(const node_type *current, unsigned int size, Compare &&comp) noexcept {
        static_assert(Offset == 0 || Offset == 1, "");
        static_assert(Min != 0, "");

        WJR_ASSERT_ASSUME(size >= Min);
        WJR_ASSERT_ASSUME(size <= Max);

        if constexpr (Min == 1 && Offset == 1) {
            if (WJR_UNLIKELY(size == 1)) {
                return 1;
            }
        }

        if constexpr (Max <= 16) {
            if constexpr (Offset == 0) {
                if (comp(current, 0)) {
                    return 0;
                }
            }

#define WJR_REGISTER_BLPUS_SEARCH_2(A, B, C)                                             \
    do {                                                                                 \
        if constexpr (A == Max) {                                                        \
            return A;                                                                    \
        } else if constexpr (B == Max) {                                                 \
            if (size == A || comp(current, A)) {                                         \
                return A;                                                                \
            }                                                                            \
            return B;                                                                    \
        } else if constexpr (C <= Max) {                                                 \
            if constexpr (Min < C) {                                                     \
                if (size < C) {                                                          \
                    if constexpr (Min <= A) {                                            \
                        if (size == A || comp(current, A)) {                             \
                            return A;                                                    \
                        }                                                                \
                    } else {                                                             \
                        if (comp(current, A)) {                                          \
                            return A;                                                    \
                        }                                                                \
                    }                                                                    \
                    return B;                                                            \
                }                                                                        \
            }                                                                            \
            if (comp(current, B)) {                                                      \
                if (comp(current, A)) {                                                  \
                    return A;                                                            \
                }                                                                        \
                return B;                                                                \
            }                                                                            \
        }                                                                                \
    } while (0)
#define WJR_REGISTER_BLPUS_SEARCH_4(A, B, C, D, E)                                       \
    do {                                                                                 \
        if constexpr (E > Max) {                                                         \
            WJR_REGISTER_BLPUS_SEARCH_2(A, B, C);                                        \
            WJR_REGISTER_BLPUS_SEARCH_2(C, D, E);                                        \
        } else {                                                                         \
            if constexpr (Min < E) {                                                     \
                if (size < E) {                                                          \
                    WJR_REGISTER_BLPUS_SEARCH_2(A, B, C);                                \
                    if constexpr (Min <= C) {                                            \
                        if (size == C || comp(current, C)) {                             \
                            return C;                                                    \
                        }                                                                \
                    } else {                                                             \
                        if (comp(current, C)) {                                          \
                            return C;                                                    \
                        }                                                                \
                    }                                                                    \
                    return D;                                                            \
                }                                                                        \
            }                                                                            \
            if (comp(current, D)) {                                                      \
                if (comp(current, B)) {                                                  \
                    if (comp(current, A)) {                                              \
                        return A;                                                        \
                    }                                                                    \
                    return B;                                                            \
                }                                                                        \
                if (comp(current, C)) {                                                  \
                    return C;                                                            \
                }                                                                        \
                return D;                                                                \
            }                                                                            \
        }                                                                                \
    } while (0)

            WJR_REGISTER_BLPUS_SEARCH_2(1, 2, 3);
            WJR_REGISTER_BLPUS_SEARCH_2(3, 4, 5);
            WJR_REGISTER_BLPUS_SEARCH_2(5, 6, 7);
            WJR_REGISTER_BLPUS_SEARCH_2(7, 8, 9);
            WJR_REGISTER_BLPUS_SEARCH_2(9, 10, 11);
            WJR_REGISTER_BLPUS_SEARCH_2(11, 12, 13);
            WJR_REGISTER_BLPUS_SEARCH_2(13, 14, 15);

            if constexpr (Max == 15) {
                return 15;
            } else if constexpr (Max == 16) {
                if (size == 15 || comp(current, 15)) {
                    return 15;
                }

                return 16;
            }

#undef WJR_REGISTER_BLPUS_SEARCH_4
#undef WJR_REGISTER_BLPUS_SEARCH_2
        } else {
            unsigned int pos = Offset;
            do {
                if (comp(current, pos)) {
                    break;
                }
            } while (++pos != size);
            return pos;
        }
    }

    template <bool Upper, size_t Min, size_t Max, size_t Offset>
    WJR_PURE WJR_INTRINSIC_INLINE static unsigned int
    __search(const inner_node_type *current, unsigned int size, const key_type &key,
             const key_compare &comp) noexcept {
        return __search<Min, Max, Offset>(
            current, size, [&key, &comp](const node_type *current, unsigned int pos) {
                return __compare<Upper>(*current->as_inner()->m_keys[pos], key, comp);
            });
    }

    template <bool Upper, size_t Min, size_t Max, size_t Offset>
    WJR_PURE WJR_INTRINSIC_INLINE static unsigned int
    __search(const leaf_node_type *current, unsigned int size, const key_type &key,
             const key_compare &comp) noexcept {
        return __search<Min, Max, Offset>(
            current, size, [&key, &comp](const node_type *current, unsigned int pos) {
                return __compare<Upper>(current->as_leaf()->__get_key(pos), key, comp);
            });
    }

    template <typename T>
    WJR_INTRINSIC_INLINE static unsigned int
    __init_remove_rotate(const inner_node_type *parent, unsigned int pos,
                         unsigned int par_size, T *&lhs, T *&rhs) noexcept {
        unsigned int size;

        do {
            if (pos != par_size) {
                const auto tmp = static_cast<T *>(parent->m_sons[pos + 1]);
                unsigned int tmp_size;

                if constexpr (std::is_same_v<T, leaf_node_type>) {
                    tmp_size = -tmp->m_size;
                } else {
                    tmp_size = tmp->m_size;
                }

                WJR_ASSERT_ASSUME(tmp_size >= floor_half);

                rhs = tmp;
                size = tmp_size;
            } else {
                auto tmp = static_cast<T *>(parent->m_sons[pos - 1]);
                lhs = tmp;

                if constexpr (std::is_same_v<T, leaf_node_type>) {
                    return -tmp->m_size;
                } else {
                    return tmp->m_size;
                }
            }
        } while (0);

        do {
            if (pos != 0) {
                const auto tmp = static_cast<T *>(parent->m_sons[pos - 1]);
                unsigned int tmp_size;

                if constexpr (std::is_same_v<T, leaf_node_type>) {
                    tmp_size = -tmp->m_size;
                } else {
                    tmp_size = tmp->m_size;
                }

                if (tmp_size >= size) {
                    lhs = tmp;
                    size = tmp_size;
                    break;
                }
            }

            lhs = nullptr;
        } while (0);

        return size;
    }

    /**
     * @todo use <Min, Max> to optimize
     *
     */
    WJR_NOINLINE void __rec_erase_iter(node_type *parent, unsigned int par_pos,
                                       unsigned int par_size) noexcept {
        constexpr unsigned int merge_size = floor_half * 2;

        unsigned int pos;
        unsigned int cur_size;
        node_type *current;

        current = parent;
        pos = par_pos;
        cur_size = par_size;
        parent = current->m_parent;

        while (parent != nullptr) {
            WJR_ASSERT_ASSUME(pos > 0);

            const auto inner = current->as_inner();

            InlineKey *const keys = inner->m_keys;
            node_type **const sons = inner->m_sons;

            if (cur_size > floor_half) {
                Traits::copy(keys + pos, keys + cur_size, keys + pos - 1);
                Traits::copy(sons + pos + 1, sons + cur_size + 1, sons + pos);

                for (unsigned int i = pos; i < cur_size; ++i) {
                    sons[i]->m_pos = i;
                }

                inner->m_size = cur_size - 1;
                return;
            }

            WJR_ASSERT_ASSUME(cur_size == floor_half);

            const auto par_inner = parent->as_inner();
            par_pos = inner->m_pos;
            par_size = par_inner->m_size;
            inner_node_type *lhs;
            inner_node_type *rhs;

            unsigned int next_size =
                __init_remove_rotate(par_inner, par_pos, par_size, lhs, rhs);

            do {
                if (lhs != nullptr) {
                    rhs = inner;

                    if (next_size == floor_half) {
                        Traits::copy(keys, keys + pos - 1, lhs->m_keys + floor_half + 1);
                        Traits::copy(sons, sons + pos, lhs->m_sons + floor_half + 1);
                        Traits::copy(keys + pos, keys + floor_half,
                                     lhs->m_keys + floor_half + pos);
                        Traits::copy(sons + pos + 1, sons + floor_half + 1,
                                     lhs->m_sons + floor_half + pos + 1);

                        for (unsigned int i = floor_half; i <= merge_size; ++i) {
                            lhs->m_sons[i]->m_parent = lhs;
                            lhs->m_sons[i]->m_pos = i;
                        }

                        lhs->m_keys[floor_half] = par_inner->m_keys[par_pos - 1];
                        break;
                    }

                    const unsigned int moved_elements = (next_size - floor_half + 1) / 2;

                    InlineKey key = lhs->m_keys[next_size - moved_elements];

                    if (moved_elements != 1) {
                        Traits::copy_backward(keys + pos, keys + floor_half,
                                              keys + floor_half + moved_elements - 1);
                        Traits::copy_backward(sons + pos + 1, sons + floor_half + 1,
                                              sons + floor_half + moved_elements);
                        for (unsigned int i = pos + moved_elements;
                             i < floor_half + moved_elements; ++i) {
                            sons[i]->m_pos = i;
                        }
                    }

                    Traits::copy_backward(keys, keys + pos - 1,
                                          keys + pos + moved_elements - 1);
                    Traits::copy_backward(sons, sons + pos, sons + pos + moved_elements);
                    Traits::copy(lhs->m_keys + next_size - moved_elements + 1,
                                 lhs->m_keys + next_size, keys);
                    Traits::copy(lhs->m_sons + next_size - moved_elements + 1,
                                 lhs->m_sons + next_size + 1, sons);

                    keys[moved_elements - 1] = par_inner->m_keys[par_pos - 1];
                    par_inner->m_keys[par_pos - 1] = key;

                    for (unsigned int i = 0; i < moved_elements; ++i) {
                        sons[i]->m_parent = inner;
                        sons[i]->m_pos = i;
                    }

                    for (unsigned int i = moved_elements; i < pos + moved_elements; ++i) {
                        sons[i]->m_pos = i;
                    }

                    lhs->m_size = next_size - moved_elements;
                    inner->m_size = floor_half + moved_elements - 1;
                } else {
                    WJR_ASSERT_ASSUME(rhs != nullptr);

                    lhs = inner;

                    if (next_size == floor_half) {
                        Traits::copy(keys + pos, keys + floor_half, keys + pos - 1);
                        Traits::copy(sons + pos + 1, sons + floor_half + 1, sons + pos);
                        Traits::copy(rhs->m_keys, rhs->m_keys + floor_half,
                                     keys + floor_half);
                        Traits::copy(rhs->m_sons, rhs->m_sons + floor_half + 1,
                                     sons + floor_half);

                        for (unsigned int i = pos; i < floor_half; ++i) {
                            inner->m_sons[i]->m_pos = i;
                        }

                        for (unsigned int i = floor_half; i <= merge_size; ++i) {
                            inner->m_sons[i]->m_parent = inner;
                            inner->m_sons[i]->m_pos = i;
                        }

                        lhs->m_keys[floor_half - 1] = par_inner->m_keys[par_pos];
                        ++par_pos;
                        break;
                    }

                    const unsigned int moved_elements = (next_size - floor_half + 1) / 2;

                    InlineKey key = rhs->m_keys[moved_elements - 1];

                    Traits::copy(keys + pos, keys + floor_half, keys + pos - 1);
                    Traits::copy(sons + pos + 1, sons + floor_half + 1, sons + pos);
                    Traits::copy(rhs->m_keys, rhs->m_keys + moved_elements - 1,
                                 keys + floor_half);
                    Traits::copy(rhs->m_sons, rhs->m_sons + moved_elements,
                                 sons + floor_half);
                    Traits::copy(rhs->m_keys + moved_elements, rhs->m_keys + next_size,
                                 rhs->m_keys);
                    Traits::copy(rhs->m_sons + moved_elements,
                                 rhs->m_sons + next_size + 1, rhs->m_sons);

                    keys[floor_half - 1] = par_inner->m_keys[par_pos];
                    par_inner->m_keys[par_pos] = key;

                    for (unsigned int i = pos; i < floor_half; ++i) {
                        sons[i]->m_pos = i;
                    }

                    for (unsigned int i = floor_half; i < floor_half + moved_elements;
                         ++i) {
                        sons[i]->m_parent = inner;
                        sons[i]->m_pos = i;
                    }

                    for (unsigned int i = 0; i <= next_size - moved_elements; ++i) {
                        rhs->m_sons[i]->m_pos = i;
                    }

                    rhs->m_size = next_size - moved_elements;
                    inner->m_size = floor_half + moved_elements - 1;
                }

                return;
            } while (0);

            lhs->m_size = merge_size;
            _Alty_traits::deallocate(__get_allocator(), (uint8_t *)rhs,
                                     sizeof(inner_node_type));

            pos = par_pos;
            cur_size = par_size;
            current = parent;
            parent = current->m_parent;
        }

        const auto inner = current->as_inner();

        if (cur_size == 1) {
            _Alty_traits::deallocate(__get_allocator(), (uint8_t *)inner,
                                     sizeof(inner_node_type));
            node_type *root = inner->m_sons[0];
            __get_root() = root;
            root->m_parent = nullptr;
            return;
        }

        Traits::copy(inner->m_keys + pos, inner->m_keys + cur_size,
                     inner->m_keys + pos - 1);
        Traits::copy(inner->m_sons + pos + 1, inner->m_sons + cur_size + 1,
                     inner->m_sons + pos);

        for (unsigned int i = pos; i < cur_size; ++i) {
            inner->m_sons[i]->m_pos = i;
        }

        inner->m_size = cur_size - 1;
    }

    iterator __erase_iter(const_iterator iter) noexcept {
        constexpr unsigned int merge_size = floor_half * 2;

        leaf_node_type *leaf = iter.get_leaf();
        unsigned int pos = iter.get_pos();
        unsigned int cur_size = -leaf->m_size;
        node_type *parent = leaf->m_parent;

        __drop_node(leaf->m_values[pos]);

        if (WJR_LIKELY(cur_size > floor_half)) {
            leaf->__copy(pos + 1, cur_size, pos, leaf);
            leaf->m_size = -(cur_size - 1);

            // first key in leaf is changed
            if (pos == 0 && parent != nullptr) {
                node_type *current = leaf;
                unsigned int tmp_pos;

                do {
                    tmp_pos = current->m_pos;
                    current = parent;
                    parent = current->m_parent;
                } while (tmp_pos == 0 && parent != nullptr);

                if (tmp_pos != 0) {
                    current->as_inner()->m_keys[tmp_pos - 1] = leaf->__get_key(0);
                }
            }

            return iterator(leaf, pos);
        }

        if (parent == nullptr) {
            if (cur_size == 1) {
                _Alty_traits::deallocate(__get_allocator(), (uint8_t *)leaf,
                                         sizeof(leaf_node_type));
                __get_root() = nullptr;
                init(&m_sentry);
                return cend();
            }

            leaf->__copy(pos + 1, cur_size, pos, leaf);
            leaf->m_size = -(cur_size - 1);
            return iterator(leaf, pos);
        }

        WJR_ASSERT_ASSUME(cur_size == floor_half);

        const auto inner = parent->as_inner();
        unsigned int par_pos = leaf->m_pos;
        cur_size = inner->m_size;
        leaf_node_type *lhs;
        leaf_node_type *rhs;

        const unsigned int next_size =
            __init_remove_rotate(inner, par_pos, cur_size, lhs, rhs);

        do {
            constexpr unsigned int max_moved_elements = (ceil_half + 1) / 2;

            if (lhs != nullptr) {
                rhs = leaf;

                if (next_size == floor_half) {
                    leaf->template __copy<0, floor_half>(0, pos, floor_half, lhs);
                    leaf->template __copy<0, floor_half>(pos + 1, floor_half,
                                                         pos + floor_half, lhs);

                    leaf = lhs;
                    pos += floor_half;
                    break;
                }

                const unsigned int moved_elements = (next_size - floor_half + 1) / 2;

                if (moved_elements != 1) {
                    leaf->template __copy_backward<0, floor_half>(
                        pos + 1, floor_half, floor_half + moved_elements - 1, leaf);
                }

                leaf->template __copy_backward<0, floor_half>(0, pos,
                                                              pos + moved_elements, leaf);
                lhs->template __copy<1, max_moved_elements>(next_size - moved_elements,
                                                            next_size, 0, leaf);

                lhs->m_size = -(next_size - moved_elements);
                leaf->m_size = -(floor_half + moved_elements - 1);

                pos += moved_elements;
            } else {
                WJR_ASSERT_ASSUME(rhs != nullptr);

                lhs = leaf;

                leaf->template __copy<0, floor_half>(pos + 1, floor_half, pos, leaf);

                // merge rhs to leaf, and pos of iter is zero, then
                // need to update key in parent
                if (pos == 0) {
                    node_type *current = leaf;

                    unsigned int tmp_pos;
                    node_type *tmp_parent = parent;

                    do {
                        tmp_pos = current->m_pos;
                        current = tmp_parent;
                        tmp_parent = current->m_parent;
                    } while (tmp_pos == 0 && tmp_parent != nullptr);

                    if (tmp_pos != 0) {
                        current->as_inner()->m_keys[tmp_pos - 1] = leaf->__get_key(0);
                    }
                }

                if (next_size == floor_half) {
                    rhs->template __copy<0, floor_half>(0, floor_half, floor_half - 1,
                                                        leaf);

                    ++par_pos;
                    break;
                }

                const unsigned int moved_elements = (next_size - floor_half + 1) / 2;

                rhs->template __copy<1, max_moved_elements>(0, moved_elements,
                                                            floor_half - 1, leaf);
                rhs->template __copy<1, node_size - max_moved_elements>(
                    moved_elements, next_size, 0, rhs);

                rhs->m_size = -(next_size - moved_elements);
                leaf->m_size = -(floor_half + moved_elements - 1);
            }

            node_type *current = rhs;

            unsigned int tmp_pos = current->m_pos;
            current = parent;
            parent = current->m_parent;

            current->as_inner()->m_keys[tmp_pos - 1] = rhs->__get_key(0);

            return iterator(leaf, pos);
        } while (0);

        lhs->m_size = -(merge_size - 1);
        remove_uninit(rhs);
        _Alty_traits::deallocate(__get_allocator(), (uint8_t *)rhs,
                                 sizeof(leaf_node_type));

        __rec_erase_iter(parent, par_pos, cur_size);

        return iterator(leaf, pos);
    }

    WJR_INTRINSIC_CONSTEXPR node_type *&__get_root() noexcept {
        return m_pair.second().second();
    }

    WJR_INTRINSIC_CONSTEXPR const node_type *__get_root() const noexcept {
        return m_pair.second().second();
    }

    compressed_pair<key_compare, compressed_pair<_Alty, node_type *>> m_pair;
    ListNode m_sentry;
};

} // namespace wjr

#endif // WJR_CONTAINER_GENERIC_BPLUS_TREE_HPP__
// Already included
#ifndef WJR_JSON_READER_HPP__
#define WJR_JSON_READER_HPP__

#ifndef WJR_JSON_LEXER_HPP__
#define WJR_JSON_LEXER_HPP__

#ifndef WJR_JSON_LEXER_IMPL_HPP__
#define WJR_JSON_LEXER_IMPL_HPP__

// Already included
// Already included

namespace wjr::json {

namespace lexer_detail {

WJR_CONST WJR_INLINE_CONSTEXPR uint64_t calc_backslash(uint64_t B) noexcept {
    uint64_t maybe_escaped = B << 1;

    uint64_t maybe_escaped_and_odd_bits = maybe_escaped | 0xAAAAAAAAAAAAAAAAULL;
    uint64_t even_series_codes_and_odd_bits = maybe_escaped_and_odd_bits - B;

    return even_series_codes_and_odd_bits ^ 0xAAAAAAAAAAAAAAAAULL;
}

} // namespace lexer_detail

class lexer {
public:
    using size_type = uint32_t;

    lexer() = delete;
    lexer(const lexer &) = delete;
    lexer(lexer &&) = default;
    lexer &operator=(const lexer &) = delete;
    lexer &operator=(lexer &&) = default;
    ~lexer() = default;

    constexpr lexer(span<const char> input) noexcept
        : first(input.data()), last(input.data() + input.size()) {}

    class result_type {

    public:
        constexpr static uint32_t mask = static_cast<uint32_t>(1) << 31;

        WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(result_type);

        constexpr result_type(uint32_t result) noexcept : m_result(result) {}
        constexpr uint32_t get() const noexcept { return m_result & (mask - 1); }
        constexpr bool done() const noexcept { return (m_result & mask) != 0; }

    private:
        uint32_t m_result;
    };

    /**
     * @brief read tokens
     *
     * @details Read at least token_buf_size tokens from the input.
     * token_buf' size must be at least token_buf_size * 2 - 1.
     *
     * @return return the number of tokens read.
     *
     */
    result_type read(uint32_t *token_buf, size_type token_buf_size) noexcept;

    constexpr const char *begin() const noexcept { return first; }
    constexpr const char *end() const noexcept { return last; }

private:
    const char *first;
    const char *last;

    uint64_t prev_in_string = 0;
    uint64_t prev_is_escape = 0;
    uint64_t prev_is_ws = ~0ull;
    uint32_t idx = 0;
};

} // namespace wjr::json

#endif // WJR_JSON_LEXER_IMPL_HPP__

#if defined(WJR_X86)
#ifndef WJR_X86_JSON_LEXER_HPP__
#define WJR_X86_JSON_LEXER_HPP__

// Already included

#if WJR_HAS_SIMD(SSSE3)
#define WJR_HAS_BUILTIN_JSON_LEXER_READER_READ_BUF WJR_HAS_DEF
#endif

#endif // WJR_X86_JSON_LEXER_HPP__
#endif

#endif // WJR_JSON_LEXER_HPP__
// Already included

namespace wjr::json {

/**
 * @brief Save position of all tokens.
 *
 */
class reader {
    using Vector = vector<uint32_t>;

public:
    using value_type = uint32_t;
    using const_pointer = const char *;
    using size_type = typename lexer::size_type;
    using const_iterator = typename Vector::const_iterator;

    WJR_ENABLE_DEFAULT_SPECIAL_MEMBERS(reader);

    reader(span<const char> sp) noexcept { read(sp); }

    WJR_CONSTEXPR20 const_iterator token_begin() const noexcept {
        return m_tokens.begin();
    }

    WJR_CONSTEXPR20 const_iterator token_end() const noexcept { return m_tokens.end(); }

    WJR_CONSTEXPR20 const_pointer data() const noexcept { return m_str.data(); }

    WJR_CONSTEXPR20 size_type size() const noexcept {
        return static_cast<size_type>(m_str.size());
    }

    void read(span<const char> sp) noexcept {
        m_str = sp;

        lexer lex(m_str);
        const size_type n = static_cast<size_type>(m_str.size());
        size_type capacity = n <= 2048 ? n : std::max<size_type>(2048, n / 20);
        size_type buf_size = capacity;
        json::lexer::result_type result;
        m_tokens.clear();

        do {
            m_tokens.reserve(capacity + 64);
            result = lex.read(m_tokens.end_unsafe(), buf_size);
            m_tokens.get_storage().size() += result.get();
            buf_size = capacity;
            capacity <<= 1;
        } while (!result.done());
    }

    void clear() noexcept { m_tokens.clear(); }
    void shrink_to_fit() noexcept { m_tokens.shrink_to_fit(); }

private:
    span<const char> m_str;
    Vector m_tokens;
};

} // namespace wjr::json

#endif // WJR_JSON_READER_HPP__

#ifndef WJR_FORMAT_FASTFLOAT_HPP__
#define WJR_FORMAT_FASTFLOAT_HPP__

// Already included
// Already included

namespace wjr::fastfloat {

template <typename T>
struct default_writer {
    using float_type = T;
    using support_integral = std::false_type;

    default_writer() = delete;
    default_writer(const default_writer &) = default;
    default_writer(default_writer &&) = default;
    default_writer &operator=(const default_writer &) = delete;
    default_writer &operator=(default_writer &&) = delete;
    ~default_writer() = default;

    WJR_INTRINSIC_CONSTEXPR default_writer(T &_value) noexcept : value(_value) {}

    WJR_INTRINSIC_CONSTEXPR T &get_float() noexcept { return value; }

    T &value;
};

template <typename Writer, typename Op>
WJR_NOINLINE from_chars_result<> __from_chars_impl(const char *first, const char *last,
                                                   Writer wr, Op options) noexcept;

extern template from_chars_result<>
__from_chars_impl<default_writer<float>,
                  integral_constant<chars_format, chars_format::general>>(
    const char *first, const char *last, default_writer<float> wr,
    integral_constant<chars_format, chars_format::general> options) noexcept;

extern template from_chars_result<>
__from_chars_impl<default_writer<double>,
                  integral_constant<chars_format, chars_format::general>>(
    const char *first, const char *last, default_writer<double> wr,
    integral_constant<chars_format, chars_format::general> options) noexcept;

extern template from_chars_result<>
__from_chars_impl<default_writer<float>, chars_format>(const char *first,
                                                       const char *last,
                                                       default_writer<float> wr,
                                                       chars_format fmt) noexcept;

extern template from_chars_result<>
__from_chars_impl<default_writer<double>, chars_format>(const char *first,
                                                        const char *last,
                                                        default_writer<double> wr,
                                                        chars_format fmt) noexcept;

/**
 * This function parses the character sequence [first,last) for a number. It parses
 * floating-point numbers expecting a locale-indepent format equivalent to what is used by
 * std::strtod in the default ("C") locale. The resulting floating-point value is the
 * closest floating-point values (using either float or double), using the "round to even"
 * convention for values that would otherwise fall right in-between two values. That is,
 * we provide exact parsing according to the IEEE standard.
 *
 * Given a successful parse, the pointer (`ptr`) in the returned value is set to point
 * right after the parsed number, and the `value` referenced is set to the parsed value.
 * In case of error, the returned `ec` contains a representative error, otherwise the
 * default (`std::errc()`) value is stored.
 *
 * The implementation does not throw and does not allocate memory (e.g., with `new` or
 * `malloc`).
 *
 * Like the C++17 standard, the `fast_float::from_chars` functions take an optional last
 * argument of the type `fast_float::chars_format`. It is a bitset value: we check whether
 * `fmt & fast_float::chars_format::fixed` and `fmt &
 * fast_float::chars_format::scientific` are set to determine whether we allow the fixed
 * point and scientific notation respectively. The default is
 * `fast_float::chars_format::general` which allows both `fixed` and `scientific`.
 */
template <chars_format Fmt = chars_format::general>
from_chars_result<> from_chars(const char *first, const char *last, float &value,
                               integral_constant<chars_format, Fmt> fmt = {}) noexcept {
    return __from_chars_impl(first, last, default_writer<float>(value), fmt);
}

template <chars_format Fmt = chars_format::general>
from_chars_result<> from_chars(const char *first, const char *last, double &value,
                               integral_constant<chars_format, Fmt> fmt = {}) noexcept {
    return __from_chars_impl(first, last, default_writer<double>(value), fmt);
}

template <typename T, WJR_REQUIRES(is_any_of_v<T, float, double>)>
from_chars_result<> from_chars(const char *first, const char *last, T &value,
                               chars_format fmt) noexcept {
    if (WJR_BUILTIN_CONSTANT_P(fmt)) {
        if (fmt == chars_format::general) {
            return from_chars(first, last, value);
        }
    }

    WJR_ASSERT(!(to_underlying(fmt) & to_underlying(chars_format::__json_format)));
    return __from_chars_impl(first, last, default_writer<T>(value), fmt);
}

// Compares two ASCII strings in a case insensitive manner.
WJR_PURE WJR_INTRINSIC_CONSTEXPR bool
fastfloat_strncasecmp(const char *input1, const char *input2, size_t length) {
    char running_diff{0};
    for (size_t i = 0; i < length; i++) {
        running_diff |= (input1[i] ^ input2[i]);
    }
    return (running_diff == 0) || (running_diff == 32);
}

struct adjusted_mantissa {
    uint64_t mantissa{0};
    int32_t power2{0}; // a negative value indicates an invalid result
    WJR_PURE WJR_INTRINSIC_CONSTEXPR bool
    operator==(const adjusted_mantissa &o) const noexcept {
        return mantissa == o.mantissa && power2 == o.power2;
    }
    WJR_PURE WJR_INTRINSIC_CONSTEXPR bool
    operator!=(const adjusted_mantissa &o) const noexcept {
        return mantissa != o.mantissa || power2 != o.power2;
    }
};

// Bias so we can get the real exponent with an invalid adjusted_mantissa.
constexpr static int32_t invalid_am_bias = -0x8000;

constexpr static double powers_of_ten_double[] = {
    1e0,  1e1,  1e2,  1e3,  1e4,  1e5,  1e6,  1e7,  1e8,  1e9,  1e10, 1e11,
    1e12, 1e13, 1e14, 1e15, 1e16, 1e17, 1e18, 1e19, 1e20, 1e21, 1e22};
constexpr static float powers_of_ten_float[] = {1e0, 1e1, 1e2, 1e3, 1e4, 1e5,
                                                1e6, 1e7, 1e8, 1e9, 1e10};
// used for max_mantissa_double and max_mantissa_float
constexpr uint64_t constant_55555 = 5 * 5 * 5 * 5 * 5;
// Largest integer value v so that (5**index * v) <= 1<<53.
// 0x20000000000000 == 1 << 53
constexpr static uint64_t max_mantissa_double[] = {
    0x20000000000000,
    0x20000000000000 / 5,
    0x20000000000000 / (5 * 5),
    0x20000000000000 / (5 * 5 * 5),
    0x20000000000000 / (5 * 5 * 5 * 5),
    0x20000000000000 / (constant_55555),
    0x20000000000000 / (constant_55555 * 5),
    0x20000000000000 / (constant_55555 * 5 * 5),
    0x20000000000000 / (constant_55555 * 5 * 5 * 5),
    0x20000000000000 / (constant_55555 * 5 * 5 * 5 * 5),
    0x20000000000000 / (constant_55555 * constant_55555),
    0x20000000000000 / (constant_55555 * constant_55555 * 5),
    0x20000000000000 / (constant_55555 * constant_55555 * 5 * 5),
    0x20000000000000 / (constant_55555 * constant_55555 * 5 * 5 * 5),
    0x20000000000000 / (constant_55555 * constant_55555 * constant_55555),
    0x20000000000000 / (constant_55555 * constant_55555 * constant_55555 * 5),
    0x20000000000000 / (constant_55555 * constant_55555 * constant_55555 * 5 * 5),
    0x20000000000000 / (constant_55555 * constant_55555 * constant_55555 * 5 * 5 * 5),
    0x20000000000000 / (constant_55555 * constant_55555 * constant_55555 * 5 * 5 * 5 * 5),
    0x20000000000000 /
        (constant_55555 * constant_55555 * constant_55555 * constant_55555),
    0x20000000000000 /
        (constant_55555 * constant_55555 * constant_55555 * constant_55555 * 5),
    0x20000000000000 /
        (constant_55555 * constant_55555 * constant_55555 * constant_55555 * 5 * 5),
    0x20000000000000 /
        (constant_55555 * constant_55555 * constant_55555 * constant_55555 * 5 * 5 * 5),
    0x20000000000000 / (constant_55555 * constant_55555 * constant_55555 *
                        constant_55555 * 5 * 5 * 5 * 5)};
// Largest integer value v so that (5**index * v) <= 1<<24.
// 0x1000000 == 1 << 24
constexpr static uint64_t max_mantissa_float[] = {
    0x1000000,
    0x1000000 / 5,
    0x1000000 / (5 * 5),
    0x1000000 / (5 * 5 * 5),
    0x1000000 / (5 * 5 * 5 * 5),
    0x1000000 / (constant_55555),
    0x1000000 / (constant_55555 * 5),
    0x1000000 / (constant_55555 * 5 * 5),
    0x1000000 / (constant_55555 * 5 * 5 * 5),
    0x1000000 / (constant_55555 * 5 * 5 * 5 * 5),
    0x1000000 / (constant_55555 * constant_55555),
    0x1000000 / (constant_55555 * constant_55555 * 5)};

template <typename T>
struct binary_format {
    using equiv_uint = uint_t<sizeof(T) * 8>;

    static inline constexpr int mantissa_explicit_bits();
    static inline constexpr int minimum_exponent();
    static inline constexpr int infinite_power();
    static inline constexpr int sign_index();
    static inline constexpr int
    min_exponent_fast_path(); // used when fegetround() == FE_TONEAREST
    static inline constexpr int max_exponent_fast_path();
    static inline constexpr int max_exponent_round_to_even();
    static inline constexpr int min_exponent_round_to_even();
    static inline constexpr uint64_t max_mantissa_fast_path(int64_t power);
    static inline constexpr uint64_t
    max_mantissa_fast_path(); // used when fegetround() == FE_TONEAREST
    static inline constexpr int largest_power_of_ten();
    static inline constexpr int smallest_power_of_ten();
    static inline constexpr T exact_power_of_ten(int64_t power);
    static inline constexpr size_t max_digits();
    static inline constexpr equiv_uint exponent_mask();
    static inline constexpr equiv_uint mantissa_mask();
    static inline constexpr equiv_uint hidden_bit_mask();
};

template <>
inline constexpr int binary_format<double>::min_exponent_fast_path() {
#if (FLT_EVAL_METHOD != 1) && (FLT_EVAL_METHOD != 0)
    return 0;
#else
    return -22;
#endif
}

template <>
inline constexpr int binary_format<float>::min_exponent_fast_path() {
#if (FLT_EVAL_METHOD != 1) && (FLT_EVAL_METHOD != 0)
    return 0;
#else
    return -10;
#endif
}

template <>
inline constexpr int binary_format<double>::mantissa_explicit_bits() {
    return 52;
}
template <>
inline constexpr int binary_format<float>::mantissa_explicit_bits() {
    return 23;
}

template <>
inline constexpr int binary_format<double>::max_exponent_round_to_even() {
    return 23;
}

template <>
inline constexpr int binary_format<float>::max_exponent_round_to_even() {
    return 10;
}

template <>
inline constexpr int binary_format<double>::min_exponent_round_to_even() {
    return -4;
}

template <>
inline constexpr int binary_format<float>::min_exponent_round_to_even() {
    return -17;
}

template <>
inline constexpr int binary_format<double>::minimum_exponent() {
    return -1023;
}
template <>
inline constexpr int binary_format<float>::minimum_exponent() {
    return -127;
}

template <>
inline constexpr int binary_format<double>::infinite_power() {
    return 0x7FF;
}
template <>
inline constexpr int binary_format<float>::infinite_power() {
    return 0xFF;
}

template <>
inline constexpr int binary_format<double>::sign_index() {
    return 63;
}
template <>
inline constexpr int binary_format<float>::sign_index() {
    return 31;
}

template <>
inline constexpr int binary_format<double>::max_exponent_fast_path() {
    return 22;
}
template <>
inline constexpr int binary_format<float>::max_exponent_fast_path() {
    return 10;
}
template <>
inline constexpr uint64_t binary_format<double>::max_mantissa_fast_path() {
    return uint64_t(2) << mantissa_explicit_bits();
}
template <>
inline constexpr uint64_t binary_format<double>::max_mantissa_fast_path(int64_t power) {
    // caller is responsible to ensure that
    // power >= 0 && power <= 22
    //
    return max_mantissa_double[power];
}
template <>
inline constexpr uint64_t binary_format<float>::max_mantissa_fast_path() {
    return uint64_t(2) << mantissa_explicit_bits();
}
template <>
inline constexpr uint64_t binary_format<float>::max_mantissa_fast_path(int64_t power) {
    // caller is responsible to ensure that
    // power >= 0 && power <= 10
    //
    return max_mantissa_float[power];
}

template <>
inline constexpr double binary_format<double>::exact_power_of_ten(int64_t power) {
    return powers_of_ten_double[power];
}
template <>
inline constexpr float binary_format<float>::exact_power_of_ten(int64_t power) {
    return powers_of_ten_float[power];
}

template <>
inline constexpr int binary_format<double>::largest_power_of_ten() {
    return 308;
}
template <>
inline constexpr int binary_format<float>::largest_power_of_ten() {
    return 38;
}

template <>
inline constexpr int binary_format<double>::smallest_power_of_ten() {
    return -342;
}
template <>
inline constexpr int binary_format<float>::smallest_power_of_ten() {
    return -65;
}

template <>
inline constexpr size_t binary_format<double>::max_digits() {
    return 769;
}
template <>
inline constexpr size_t binary_format<float>::max_digits() {
    return 114;
}

template <>
inline constexpr binary_format<float>::equiv_uint binary_format<float>::exponent_mask() {
    return 0x7F800000;
}
template <>
inline constexpr binary_format<double>::equiv_uint
binary_format<double>::exponent_mask() {
    return 0x7FF0000000000000;
}

template <>
inline constexpr binary_format<float>::equiv_uint binary_format<float>::mantissa_mask() {
    return 0x007FFFFF;
}
template <>
inline constexpr binary_format<double>::equiv_uint
binary_format<double>::mantissa_mask() {
    return 0x000FFFFFFFFFFFFF;
}

template <>
inline constexpr binary_format<float>::equiv_uint
binary_format<float>::hidden_bit_mask() {
    return 0x00800000;
}
template <>
inline constexpr binary_format<double>::equiv_uint
binary_format<double>::hidden_bit_mask() {
    return 0x0010000000000000;
}

template <typename T>
WJR_INTRINSIC_INLINE void to_float(bool negative, adjusted_mantissa am, T &value) {
    using fastfloat_uint = typename binary_format<T>::equiv_uint;
    fastfloat_uint word = (fastfloat_uint)am.mantissa;
    word |= fastfloat_uint(am.power2) << binary_format<T>::mantissa_explicit_bits();
    word |= fastfloat_uint(negative) << binary_format<T>::sign_index();
    value = bit_cast<T>(word);
}

// Next function can be micro-optimized, but compilers are entirely
// able to optimize it well.
WJR_CONST WJR_INTRINSIC_CONSTEXPR bool is_integer(char c) noexcept {
    return c >= '0' && c <= '9';
}

/**
 * When mapping numbers from decimal to binary,
 * we go from w * 10^q to m * 2^p but we have
 * 10^q = 5^q * 2^q, so effectively
 * we are trying to match
 * w * 2^q * 5^q to m * 2^p. Thus the powers of two
 * are not a concern since they can be represented
 * exactly using the binary notation, only the powers of five
 * affect the binary significand.
 */

/**
 * The smallest non-zero float (binary64) is 2^1074.
 * We take as input numbers of the form w x 10^q where w < 2^64.
 * We have that w * 10^-343  <  2^(64-344) 5^-343 < 2^-1076.
 * However, we have that
 * (2^64-1) * 10^-342 =  (2^64-1) * 2^-342 * 5^-342 > 2^1074.
 * Thus it is possible for a number of the form w * 10^-342 where
 * w is a 64-bit value to be a non-zero floating-point number.
 *********
 * Any number of form w * 10^309 where w>= 1 is going to be
 * infinite in binary64 so we never need to worry about powers
 * of 5 greater than 308.
 */
template <class unused = void>
struct powers_template {
    constexpr static int smallest_power_of_five =
        binary_format<double>::smallest_power_of_ten();
    constexpr static int largest_power_of_five =
        binary_format<double>::largest_power_of_ten();
    constexpr static int number_of_entries =
        2 * (largest_power_of_five - smallest_power_of_five + 1);
    // Powers of five from 5^-342 all the way to 5^308 rounded toward one.
    static const uint64_t power_of_five_128[number_of_entries];
};

template <class unused>
const uint64_t powers_template<unused>::power_of_five_128[number_of_entries] = {
    0xeef453d6923bd65a, 0x113faa2906a13b3f,
    0x9558b4661b6565f8, 0x4ac7ca59a424c507,
    0xbaaee17fa23ebf76, 0x5d79bcf00d2df649,
    0xe95a99df8ace6f53, 0xf4d82c2c107973dc,
    0x91d8a02bb6c10594, 0x79071b9b8a4be869,
    0xb64ec836a47146f9, 0x9748e2826cdee284,
    0xe3e27a444d8d98b7, 0xfd1b1b2308169b25,
    0x8e6d8c6ab0787f72, 0xfe30f0f5e50e20f7,
    0xb208ef855c969f4f, 0xbdbd2d335e51a935,
    0xde8b2b66b3bc4723, 0xad2c788035e61382,
    0x8b16fb203055ac76, 0x4c3bcb5021afcc31,
    0xaddcb9e83c6b1793, 0xdf4abe242a1bbf3d,
    0xd953e8624b85dd78, 0xd71d6dad34a2af0d,
    0x87d4713d6f33aa6b, 0x8672648c40e5ad68,
    0xa9c98d8ccb009506, 0x680efdaf511f18c2,
    0xd43bf0effdc0ba48, 0x212bd1b2566def2,
    0x84a57695fe98746d, 0x14bb630f7604b57,
    0xa5ced43b7e3e9188, 0x419ea3bd35385e2d,
    0xcf42894a5dce35ea, 0x52064cac828675b9,
    0x818995ce7aa0e1b2, 0x7343efebd1940993,
    0xa1ebfb4219491a1f, 0x1014ebe6c5f90bf8,
    0xca66fa129f9b60a6, 0xd41a26e077774ef6,
    0xfd00b897478238d0, 0x8920b098955522b4,
    0x9e20735e8cb16382, 0x55b46e5f5d5535b0,
    0xc5a890362fddbc62, 0xeb2189f734aa831d,
    0xf712b443bbd52b7b, 0xa5e9ec7501d523e4,
    0x9a6bb0aa55653b2d, 0x47b233c92125366e,
    0xc1069cd4eabe89f8, 0x999ec0bb696e840a,
    0xf148440a256e2c76, 0xc00670ea43ca250d,
    0x96cd2a865764dbca, 0x380406926a5e5728,
    0xbc807527ed3e12bc, 0xc605083704f5ecf2,
    0xeba09271e88d976b, 0xf7864a44c633682e,
    0x93445b8731587ea3, 0x7ab3ee6afbe0211d,
    0xb8157268fdae9e4c, 0x5960ea05bad82964,
    0xe61acf033d1a45df, 0x6fb92487298e33bd,
    0x8fd0c16206306bab, 0xa5d3b6d479f8e056,
    0xb3c4f1ba87bc8696, 0x8f48a4899877186c,
    0xe0b62e2929aba83c, 0x331acdabfe94de87,
    0x8c71dcd9ba0b4925, 0x9ff0c08b7f1d0b14,
    0xaf8e5410288e1b6f, 0x7ecf0ae5ee44dd9,
    0xdb71e91432b1a24a, 0xc9e82cd9f69d6150,
    0x892731ac9faf056e, 0xbe311c083a225cd2,
    0xab70fe17c79ac6ca, 0x6dbd630a48aaf406,
    0xd64d3d9db981787d, 0x92cbbccdad5b108,
    0x85f0468293f0eb4e, 0x25bbf56008c58ea5,
    0xa76c582338ed2621, 0xaf2af2b80af6f24e,
    0xd1476e2c07286faa, 0x1af5af660db4aee1,
    0x82cca4db847945ca, 0x50d98d9fc890ed4d,
    0xa37fce126597973c, 0xe50ff107bab528a0,
    0xcc5fc196fefd7d0c, 0x1e53ed49a96272c8,
    0xff77b1fcbebcdc4f, 0x25e8e89c13bb0f7a,
    0x9faacf3df73609b1, 0x77b191618c54e9ac,
    0xc795830d75038c1d, 0xd59df5b9ef6a2417,
    0xf97ae3d0d2446f25, 0x4b0573286b44ad1d,
    0x9becce62836ac577, 0x4ee367f9430aec32,
    0xc2e801fb244576d5, 0x229c41f793cda73f,
    0xf3a20279ed56d48a, 0x6b43527578c1110f,
    0x9845418c345644d6, 0x830a13896b78aaa9,
    0xbe5691ef416bd60c, 0x23cc986bc656d553,
    0xedec366b11c6cb8f, 0x2cbfbe86b7ec8aa8,
    0x94b3a202eb1c3f39, 0x7bf7d71432f3d6a9,
    0xb9e08a83a5e34f07, 0xdaf5ccd93fb0cc53,
    0xe858ad248f5c22c9, 0xd1b3400f8f9cff68,
    0x91376c36d99995be, 0x23100809b9c21fa1,
    0xb58547448ffffb2d, 0xabd40a0c2832a78a,
    0xe2e69915b3fff9f9, 0x16c90c8f323f516c,
    0x8dd01fad907ffc3b, 0xae3da7d97f6792e3,
    0xb1442798f49ffb4a, 0x99cd11cfdf41779c,
    0xdd95317f31c7fa1d, 0x40405643d711d583,
    0x8a7d3eef7f1cfc52, 0x482835ea666b2572,
    0xad1c8eab5ee43b66, 0xda3243650005eecf,
    0xd863b256369d4a40, 0x90bed43e40076a82,
    0x873e4f75e2224e68, 0x5a7744a6e804a291,
    0xa90de3535aaae202, 0x711515d0a205cb36,
    0xd3515c2831559a83, 0xd5a5b44ca873e03,
    0x8412d9991ed58091, 0xe858790afe9486c2,
    0xa5178fff668ae0b6, 0x626e974dbe39a872,
    0xce5d73ff402d98e3, 0xfb0a3d212dc8128f,
    0x80fa687f881c7f8e, 0x7ce66634bc9d0b99,
    0xa139029f6a239f72, 0x1c1fffc1ebc44e80,
    0xc987434744ac874e, 0xa327ffb266b56220,
    0xfbe9141915d7a922, 0x4bf1ff9f0062baa8,
    0x9d71ac8fada6c9b5, 0x6f773fc3603db4a9,
    0xc4ce17b399107c22, 0xcb550fb4384d21d3,
    0xf6019da07f549b2b, 0x7e2a53a146606a48,
    0x99c102844f94e0fb, 0x2eda7444cbfc426d,
    0xc0314325637a1939, 0xfa911155fefb5308,
    0xf03d93eebc589f88, 0x793555ab7eba27ca,
    0x96267c7535b763b5, 0x4bc1558b2f3458de,
    0xbbb01b9283253ca2, 0x9eb1aaedfb016f16,
    0xea9c227723ee8bcb, 0x465e15a979c1cadc,
    0x92a1958a7675175f, 0xbfacd89ec191ec9,
    0xb749faed14125d36, 0xcef980ec671f667b,
    0xe51c79a85916f484, 0x82b7e12780e7401a,
    0x8f31cc0937ae58d2, 0xd1b2ecb8b0908810,
    0xb2fe3f0b8599ef07, 0x861fa7e6dcb4aa15,
    0xdfbdcece67006ac9, 0x67a791e093e1d49a,
    0x8bd6a141006042bd, 0xe0c8bb2c5c6d24e0,
    0xaecc49914078536d, 0x58fae9f773886e18,
    0xda7f5bf590966848, 0xaf39a475506a899e,
    0x888f99797a5e012d, 0x6d8406c952429603,
    0xaab37fd7d8f58178, 0xc8e5087ba6d33b83,
    0xd5605fcdcf32e1d6, 0xfb1e4a9a90880a64,
    0x855c3be0a17fcd26, 0x5cf2eea09a55067f,
    0xa6b34ad8c9dfc06f, 0xf42faa48c0ea481e,
    0xd0601d8efc57b08b, 0xf13b94daf124da26,
    0x823c12795db6ce57, 0x76c53d08d6b70858,
    0xa2cb1717b52481ed, 0x54768c4b0c64ca6e,
    0xcb7ddcdda26da268, 0xa9942f5dcf7dfd09,
    0xfe5d54150b090b02, 0xd3f93b35435d7c4c,
    0x9efa548d26e5a6e1, 0xc47bc5014a1a6daf,
    0xc6b8e9b0709f109a, 0x359ab6419ca1091b,
    0xf867241c8cc6d4c0, 0xc30163d203c94b62,
    0x9b407691d7fc44f8, 0x79e0de63425dcf1d,
    0xc21094364dfb5636, 0x985915fc12f542e4,
    0xf294b943e17a2bc4, 0x3e6f5b7b17b2939d,
    0x979cf3ca6cec5b5a, 0xa705992ceecf9c42,
    0xbd8430bd08277231, 0x50c6ff782a838353,
    0xece53cec4a314ebd, 0xa4f8bf5635246428,
    0x940f4613ae5ed136, 0x871b7795e136be99,
    0xb913179899f68584, 0x28e2557b59846e3f,
    0xe757dd7ec07426e5, 0x331aeada2fe589cf,
    0x9096ea6f3848984f, 0x3ff0d2c85def7621,
    0xb4bca50b065abe63, 0xfed077a756b53a9,
    0xe1ebce4dc7f16dfb, 0xd3e8495912c62894,
    0x8d3360f09cf6e4bd, 0x64712dd7abbbd95c,
    0xb080392cc4349dec, 0xbd8d794d96aacfb3,
    0xdca04777f541c567, 0xecf0d7a0fc5583a0,
    0x89e42caaf9491b60, 0xf41686c49db57244,
    0xac5d37d5b79b6239, 0x311c2875c522ced5,
    0xd77485cb25823ac7, 0x7d633293366b828b,
    0x86a8d39ef77164bc, 0xae5dff9c02033197,
    0xa8530886b54dbdeb, 0xd9f57f830283fdfc,
    0xd267caa862a12d66, 0xd072df63c324fd7b,
    0x8380dea93da4bc60, 0x4247cb9e59f71e6d,
    0xa46116538d0deb78, 0x52d9be85f074e608,
    0xcd795be870516656, 0x67902e276c921f8b,
    0x806bd9714632dff6, 0xba1cd8a3db53b6,
    0xa086cfcd97bf97f3, 0x80e8a40eccd228a4,
    0xc8a883c0fdaf7df0, 0x6122cd128006b2cd,
    0xfad2a4b13d1b5d6c, 0x796b805720085f81,
    0x9cc3a6eec6311a63, 0xcbe3303674053bb0,
    0xc3f490aa77bd60fc, 0xbedbfc4411068a9c,
    0xf4f1b4d515acb93b, 0xee92fb5515482d44,
    0x991711052d8bf3c5, 0x751bdd152d4d1c4a,
    0xbf5cd54678eef0b6, 0xd262d45a78a0635d,
    0xef340a98172aace4, 0x86fb897116c87c34,
    0x9580869f0e7aac0e, 0xd45d35e6ae3d4da0,
    0xbae0a846d2195712, 0x8974836059cca109,
    0xe998d258869facd7, 0x2bd1a438703fc94b,
    0x91ff83775423cc06, 0x7b6306a34627ddcf,
    0xb67f6455292cbf08, 0x1a3bc84c17b1d542,
    0xe41f3d6a7377eeca, 0x20caba5f1d9e4a93,
    0x8e938662882af53e, 0x547eb47b7282ee9c,
    0xb23867fb2a35b28d, 0xe99e619a4f23aa43,
    0xdec681f9f4c31f31, 0x6405fa00e2ec94d4,
    0x8b3c113c38f9f37e, 0xde83bc408dd3dd04,
    0xae0b158b4738705e, 0x9624ab50b148d445,
    0xd98ddaee19068c76, 0x3badd624dd9b0957,
    0x87f8a8d4cfa417c9, 0xe54ca5d70a80e5d6,
    0xa9f6d30a038d1dbc, 0x5e9fcf4ccd211f4c,
    0xd47487cc8470652b, 0x7647c3200069671f,
    0x84c8d4dfd2c63f3b, 0x29ecd9f40041e073,
    0xa5fb0a17c777cf09, 0xf468107100525890,
    0xcf79cc9db955c2cc, 0x7182148d4066eeb4,
    0x81ac1fe293d599bf, 0xc6f14cd848405530,
    0xa21727db38cb002f, 0xb8ada00e5a506a7c,
    0xca9cf1d206fdc03b, 0xa6d90811f0e4851c,
    0xfd442e4688bd304a, 0x908f4a166d1da663,
    0x9e4a9cec15763e2e, 0x9a598e4e043287fe,
    0xc5dd44271ad3cdba, 0x40eff1e1853f29fd,
    0xf7549530e188c128, 0xd12bee59e68ef47c,
    0x9a94dd3e8cf578b9, 0x82bb74f8301958ce,
    0xc13a148e3032d6e7, 0xe36a52363c1faf01,
    0xf18899b1bc3f8ca1, 0xdc44e6c3cb279ac1,
    0x96f5600f15a7b7e5, 0x29ab103a5ef8c0b9,
    0xbcb2b812db11a5de, 0x7415d448f6b6f0e7,
    0xebdf661791d60f56, 0x111b495b3464ad21,
    0x936b9fcebb25c995, 0xcab10dd900beec34,
    0xb84687c269ef3bfb, 0x3d5d514f40eea742,
    0xe65829b3046b0afa, 0xcb4a5a3112a5112,
    0x8ff71a0fe2c2e6dc, 0x47f0e785eaba72ab,
    0xb3f4e093db73a093, 0x59ed216765690f56,
    0xe0f218b8d25088b8, 0x306869c13ec3532c,
    0x8c974f7383725573, 0x1e414218c73a13fb,
    0xafbd2350644eeacf, 0xe5d1929ef90898fa,
    0xdbac6c247d62a583, 0xdf45f746b74abf39,
    0x894bc396ce5da772, 0x6b8bba8c328eb783,
    0xab9eb47c81f5114f, 0x66ea92f3f326564,
    0xd686619ba27255a2, 0xc80a537b0efefebd,
    0x8613fd0145877585, 0xbd06742ce95f5f36,
    0xa798fc4196e952e7, 0x2c48113823b73704,
    0xd17f3b51fca3a7a0, 0xf75a15862ca504c5,
    0x82ef85133de648c4, 0x9a984d73dbe722fb,
    0xa3ab66580d5fdaf5, 0xc13e60d0d2e0ebba,
    0xcc963fee10b7d1b3, 0x318df905079926a8,
    0xffbbcfe994e5c61f, 0xfdf17746497f7052,
    0x9fd561f1fd0f9bd3, 0xfeb6ea8bedefa633,
    0xc7caba6e7c5382c8, 0xfe64a52ee96b8fc0,
    0xf9bd690a1b68637b, 0x3dfdce7aa3c673b0,
    0x9c1661a651213e2d, 0x6bea10ca65c084e,
    0xc31bfa0fe5698db8, 0x486e494fcff30a62,
    0xf3e2f893dec3f126, 0x5a89dba3c3efccfa,
    0x986ddb5c6b3a76b7, 0xf89629465a75e01c,
    0xbe89523386091465, 0xf6bbb397f1135823,
    0xee2ba6c0678b597f, 0x746aa07ded582e2c,
    0x94db483840b717ef, 0xa8c2a44eb4571cdc,
    0xba121a4650e4ddeb, 0x92f34d62616ce413,
    0xe896a0d7e51e1566, 0x77b020baf9c81d17,
    0x915e2486ef32cd60, 0xace1474dc1d122e,
    0xb5b5ada8aaff80b8, 0xd819992132456ba,
    0xe3231912d5bf60e6, 0x10e1fff697ed6c69,
    0x8df5efabc5979c8f, 0xca8d3ffa1ef463c1,
    0xb1736b96b6fd83b3, 0xbd308ff8a6b17cb2,
    0xddd0467c64bce4a0, 0xac7cb3f6d05ddbde,
    0x8aa22c0dbef60ee4, 0x6bcdf07a423aa96b,
    0xad4ab7112eb3929d, 0x86c16c98d2c953c6,
    0xd89d64d57a607744, 0xe871c7bf077ba8b7,
    0x87625f056c7c4a8b, 0x11471cd764ad4972,
    0xa93af6c6c79b5d2d, 0xd598e40d3dd89bcf,
    0xd389b47879823479, 0x4aff1d108d4ec2c3,
    0x843610cb4bf160cb, 0xcedf722a585139ba,
    0xa54394fe1eedb8fe, 0xc2974eb4ee658828,
    0xce947a3da6a9273e, 0x733d226229feea32,
    0x811ccc668829b887, 0x806357d5a3f525f,
    0xa163ff802a3426a8, 0xca07c2dcb0cf26f7,
    0xc9bcff6034c13052, 0xfc89b393dd02f0b5,
    0xfc2c3f3841f17c67, 0xbbac2078d443ace2,
    0x9d9ba7832936edc0, 0xd54b944b84aa4c0d,
    0xc5029163f384a931, 0xa9e795e65d4df11,
    0xf64335bcf065d37d, 0x4d4617b5ff4a16d5,
    0x99ea0196163fa42e, 0x504bced1bf8e4e45,
    0xc06481fb9bcf8d39, 0xe45ec2862f71e1d6,
    0xf07da27a82c37088, 0x5d767327bb4e5a4c,
    0x964e858c91ba2655, 0x3a6a07f8d510f86f,
    0xbbe226efb628afea, 0x890489f70a55368b,
    0xeadab0aba3b2dbe5, 0x2b45ac74ccea842e,
    0x92c8ae6b464fc96f, 0x3b0b8bc90012929d,
    0xb77ada0617e3bbcb, 0x9ce6ebb40173744,
    0xe55990879ddcaabd, 0xcc420a6a101d0515,
    0x8f57fa54c2a9eab6, 0x9fa946824a12232d,
    0xb32df8e9f3546564, 0x47939822dc96abf9,
    0xdff9772470297ebd, 0x59787e2b93bc56f7,
    0x8bfbea76c619ef36, 0x57eb4edb3c55b65a,
    0xaefae51477a06b03, 0xede622920b6b23f1,
    0xdab99e59958885c4, 0xe95fab368e45eced,
    0x88b402f7fd75539b, 0x11dbcb0218ebb414,
    0xaae103b5fcd2a881, 0xd652bdc29f26a119,
    0xd59944a37c0752a2, 0x4be76d3346f0495f,
    0x857fcae62d8493a5, 0x6f70a4400c562ddb,
    0xa6dfbd9fb8e5b88e, 0xcb4ccd500f6bb952,
    0xd097ad07a71f26b2, 0x7e2000a41346a7a7,
    0x825ecc24c873782f, 0x8ed400668c0c28c8,
    0xa2f67f2dfa90563b, 0x728900802f0f32fa,
    0xcbb41ef979346bca, 0x4f2b40a03ad2ffb9,
    0xfea126b7d78186bc, 0xe2f610c84987bfa8,
    0x9f24b832e6b0f436, 0xdd9ca7d2df4d7c9,
    0xc6ede63fa05d3143, 0x91503d1c79720dbb,
    0xf8a95fcf88747d94, 0x75a44c6397ce912a,
    0x9b69dbe1b548ce7c, 0xc986afbe3ee11aba,
    0xc24452da229b021b, 0xfbe85badce996168,
    0xf2d56790ab41c2a2, 0xfae27299423fb9c3,
    0x97c560ba6b0919a5, 0xdccd879fc967d41a,
    0xbdb6b8e905cb600f, 0x5400e987bbc1c920,
    0xed246723473e3813, 0x290123e9aab23b68,
    0x9436c0760c86e30b, 0xf9a0b6720aaf6521,
    0xb94470938fa89bce, 0xf808e40e8d5b3e69,
    0xe7958cb87392c2c2, 0xb60b1d1230b20e04,
    0x90bd77f3483bb9b9, 0xb1c6f22b5e6f48c2,
    0xb4ecd5f01a4aa828, 0x1e38aeb6360b1af3,
    0xe2280b6c20dd5232, 0x25c6da63c38de1b0,
    0x8d590723948a535f, 0x579c487e5a38ad0e,
    0xb0af48ec79ace837, 0x2d835a9df0c6d851,
    0xdcdb1b2798182244, 0xf8e431456cf88e65,
    0x8a08f0f8bf0f156b, 0x1b8e9ecb641b58ff,
    0xac8b2d36eed2dac5, 0xe272467e3d222f3f,
    0xd7adf884aa879177, 0x5b0ed81dcc6abb0f,
    0x86ccbb52ea94baea, 0x98e947129fc2b4e9,
    0xa87fea27a539e9a5, 0x3f2398d747b36224,
    0xd29fe4b18e88640e, 0x8eec7f0d19a03aad,
    0x83a3eeeef9153e89, 0x1953cf68300424ac,
    0xa48ceaaab75a8e2b, 0x5fa8c3423c052dd7,
    0xcdb02555653131b6, 0x3792f412cb06794d,
    0x808e17555f3ebf11, 0xe2bbd88bbee40bd0,
    0xa0b19d2ab70e6ed6, 0x5b6aceaeae9d0ec4,
    0xc8de047564d20a8b, 0xf245825a5a445275,
    0xfb158592be068d2e, 0xeed6e2f0f0d56712,
    0x9ced737bb6c4183d, 0x55464dd69685606b,
    0xc428d05aa4751e4c, 0xaa97e14c3c26b886,
    0xf53304714d9265df, 0xd53dd99f4b3066a8,
    0x993fe2c6d07b7fab, 0xe546a8038efe4029,
    0xbf8fdb78849a5f96, 0xde98520472bdd033,
    0xef73d256a5c0f77c, 0x963e66858f6d4440,
    0x95a8637627989aad, 0xdde7001379a44aa8,
    0xbb127c53b17ec159, 0x5560c018580d5d52,
    0xe9d71b689dde71af, 0xaab8f01e6e10b4a6,
    0x9226712162ab070d, 0xcab3961304ca70e8,
    0xb6b00d69bb55c8d1, 0x3d607b97c5fd0d22,
    0xe45c10c42a2b3b05, 0x8cb89a7db77c506a,
    0x8eb98a7a9a5b04e3, 0x77f3608e92adb242,
    0xb267ed1940f1c61c, 0x55f038b237591ed3,
    0xdf01e85f912e37a3, 0x6b6c46dec52f6688,
    0x8b61313bbabce2c6, 0x2323ac4b3b3da015,
    0xae397d8aa96c1b77, 0xabec975e0a0d081a,
    0xd9c7dced53c72255, 0x96e7bd358c904a21,
    0x881cea14545c7575, 0x7e50d64177da2e54,
    0xaa242499697392d2, 0xdde50bd1d5d0b9e9,
    0xd4ad2dbfc3d07787, 0x955e4ec64b44e864,
    0x84ec3c97da624ab4, 0xbd5af13bef0b113e,
    0xa6274bbdd0fadd61, 0xecb1ad8aeacdd58e,
    0xcfb11ead453994ba, 0x67de18eda5814af2,
    0x81ceb32c4b43fcf4, 0x80eacf948770ced7,
    0xa2425ff75e14fc31, 0xa1258379a94d028d,
    0xcad2f7f5359a3b3e, 0x96ee45813a04330,
    0xfd87b5f28300ca0d, 0x8bca9d6e188853fc,
    0x9e74d1b791e07e48, 0x775ea264cf55347e,
    0xc612062576589dda, 0x95364afe032a819e,
    0xf79687aed3eec551, 0x3a83ddbd83f52205,
    0x9abe14cd44753b52, 0xc4926a9672793543,
    0xc16d9a0095928a27, 0x75b7053c0f178294,
    0xf1c90080baf72cb1, 0x5324c68b12dd6339,
    0x971da05074da7bee, 0xd3f6fc16ebca5e04,
    0xbce5086492111aea, 0x88f4bb1ca6bcf585,
    0xec1e4a7db69561a5, 0x2b31e9e3d06c32e6,
    0x9392ee8e921d5d07, 0x3aff322e62439fd0,
    0xb877aa3236a4b449, 0x9befeb9fad487c3,
    0xe69594bec44de15b, 0x4c2ebe687989a9b4,
    0x901d7cf73ab0acd9, 0xf9d37014bf60a11,
    0xb424dc35095cd80f, 0x538484c19ef38c95,
    0xe12e13424bb40e13, 0x2865a5f206b06fba,
    0x8cbccc096f5088cb, 0xf93f87b7442e45d4,
    0xafebff0bcb24aafe, 0xf78f69a51539d749,
    0xdbe6fecebdedd5be, 0xb573440e5a884d1c,
    0x89705f4136b4a597, 0x31680a88f8953031,
    0xabcc77118461cefc, 0xfdc20d2b36ba7c3e,
    0xd6bf94d5e57a42bc, 0x3d32907604691b4d,
    0x8637bd05af6c69b5, 0xa63f9a49c2c1b110,
    0xa7c5ac471b478423, 0xfcf80dc33721d54,
    0xd1b71758e219652b, 0xd3c36113404ea4a9,
    0x83126e978d4fdf3b, 0x645a1cac083126ea,
    0xa3d70a3d70a3d70a, 0x3d70a3d70a3d70a4,
    0xcccccccccccccccc, 0xcccccccccccccccd,
    0x8000000000000000, 0x0,
    0xa000000000000000, 0x0,
    0xc800000000000000, 0x0,
    0xfa00000000000000, 0x0,
    0x9c40000000000000, 0x0,
    0xc350000000000000, 0x0,
    0xf424000000000000, 0x0,
    0x9896800000000000, 0x0,
    0xbebc200000000000, 0x0,
    0xee6b280000000000, 0x0,
    0x9502f90000000000, 0x0,
    0xba43b74000000000, 0x0,
    0xe8d4a51000000000, 0x0,
    0x9184e72a00000000, 0x0,
    0xb5e620f480000000, 0x0,
    0xe35fa931a0000000, 0x0,
    0x8e1bc9bf04000000, 0x0,
    0xb1a2bc2ec5000000, 0x0,
    0xde0b6b3a76400000, 0x0,
    0x8ac7230489e80000, 0x0,
    0xad78ebc5ac620000, 0x0,
    0xd8d726b7177a8000, 0x0,
    0x878678326eac9000, 0x0,
    0xa968163f0a57b400, 0x0,
    0xd3c21bcecceda100, 0x0,
    0x84595161401484a0, 0x0,
    0xa56fa5b99019a5c8, 0x0,
    0xcecb8f27f4200f3a, 0x0,
    0x813f3978f8940984, 0x4000000000000000,
    0xa18f07d736b90be5, 0x5000000000000000,
    0xc9f2c9cd04674ede, 0xa400000000000000,
    0xfc6f7c4045812296, 0x4d00000000000000,
    0x9dc5ada82b70b59d, 0xf020000000000000,
    0xc5371912364ce305, 0x6c28000000000000,
    0xf684df56c3e01bc6, 0xc732000000000000,
    0x9a130b963a6c115c, 0x3c7f400000000000,
    0xc097ce7bc90715b3, 0x4b9f100000000000,
    0xf0bdc21abb48db20, 0x1e86d40000000000,
    0x96769950b50d88f4, 0x1314448000000000,
    0xbc143fa4e250eb31, 0x17d955a000000000,
    0xeb194f8e1ae525fd, 0x5dcfab0800000000,
    0x92efd1b8d0cf37be, 0x5aa1cae500000000,
    0xb7abc627050305ad, 0xf14a3d9e40000000,
    0xe596b7b0c643c719, 0x6d9ccd05d0000000,
    0x8f7e32ce7bea5c6f, 0xe4820023a2000000,
    0xb35dbf821ae4f38b, 0xdda2802c8a800000,
    0xe0352f62a19e306e, 0xd50b2037ad200000,
    0x8c213d9da502de45, 0x4526f422cc340000,
    0xaf298d050e4395d6, 0x9670b12b7f410000,
    0xdaf3f04651d47b4c, 0x3c0cdd765f114000,
    0x88d8762bf324cd0f, 0xa5880a69fb6ac800,
    0xab0e93b6efee0053, 0x8eea0d047a457a00,
    0xd5d238a4abe98068, 0x72a4904598d6d880,
    0x85a36366eb71f041, 0x47a6da2b7f864750,
    0xa70c3c40a64e6c51, 0x999090b65f67d924,
    0xd0cf4b50cfe20765, 0xfff4b4e3f741cf6d,
    0x82818f1281ed449f, 0xbff8f10e7a8921a4,
    0xa321f2d7226895c7, 0xaff72d52192b6a0d,
    0xcbea6f8ceb02bb39, 0x9bf4f8a69f764490,
    0xfee50b7025c36a08, 0x2f236d04753d5b4,
    0x9f4f2726179a2245, 0x1d762422c946590,
    0xc722f0ef9d80aad6, 0x424d3ad2b7b97ef5,
    0xf8ebad2b84e0d58b, 0xd2e0898765a7deb2,
    0x9b934c3b330c8577, 0x63cc55f49f88eb2f,
    0xc2781f49ffcfa6d5, 0x3cbf6b71c76b25fb,
    0xf316271c7fc3908a, 0x8bef464e3945ef7a,
    0x97edd871cfda3a56, 0x97758bf0e3cbb5ac,
    0xbde94e8e43d0c8ec, 0x3d52eeed1cbea317,
    0xed63a231d4c4fb27, 0x4ca7aaa863ee4bdd,
    0x945e455f24fb1cf8, 0x8fe8caa93e74ef6a,
    0xb975d6b6ee39e436, 0xb3e2fd538e122b44,
    0xe7d34c64a9c85d44, 0x60dbbca87196b616,
    0x90e40fbeea1d3a4a, 0xbc8955e946fe31cd,
    0xb51d13aea4a488dd, 0x6babab6398bdbe41,
    0xe264589a4dcdab14, 0xc696963c7eed2dd1,
    0x8d7eb76070a08aec, 0xfc1e1de5cf543ca2,
    0xb0de65388cc8ada8, 0x3b25a55f43294bcb,
    0xdd15fe86affad912, 0x49ef0eb713f39ebe,
    0x8a2dbf142dfcc7ab, 0x6e3569326c784337,
    0xacb92ed9397bf996, 0x49c2c37f07965404,
    0xd7e77a8f87daf7fb, 0xdc33745ec97be906,
    0x86f0ac99b4e8dafd, 0x69a028bb3ded71a3,
    0xa8acd7c0222311bc, 0xc40832ea0d68ce0c,
    0xd2d80db02aabd62b, 0xf50a3fa490c30190,
    0x83c7088e1aab65db, 0x792667c6da79e0fa,
    0xa4b8cab1a1563f52, 0x577001b891185938,
    0xcde6fd5e09abcf26, 0xed4c0226b55e6f86,
    0x80b05e5ac60b6178, 0x544f8158315b05b4,
    0xa0dc75f1778e39d6, 0x696361ae3db1c721,
    0xc913936dd571c84c, 0x3bc3a19cd1e38e9,
    0xfb5878494ace3a5f, 0x4ab48a04065c723,
    0x9d174b2dcec0e47b, 0x62eb0d64283f9c76,
    0xc45d1df942711d9a, 0x3ba5d0bd324f8394,
    0xf5746577930d6500, 0xca8f44ec7ee36479,
    0x9968bf6abbe85f20, 0x7e998b13cf4e1ecb,
    0xbfc2ef456ae276e8, 0x9e3fedd8c321a67e,
    0xefb3ab16c59b14a2, 0xc5cfe94ef3ea101e,
    0x95d04aee3b80ece5, 0xbba1f1d158724a12,
    0xbb445da9ca61281f, 0x2a8a6e45ae8edc97,
    0xea1575143cf97226, 0xf52d09d71a3293bd,
    0x924d692ca61be758, 0x593c2626705f9c56,
    0xb6e0c377cfa2e12e, 0x6f8b2fb00c77836c,
    0xe498f455c38b997a, 0xb6dfb9c0f956447,
    0x8edf98b59a373fec, 0x4724bd4189bd5eac,
    0xb2977ee300c50fe7, 0x58edec91ec2cb657,
    0xdf3d5e9bc0f653e1, 0x2f2967b66737e3ed,
    0x8b865b215899f46c, 0xbd79e0d20082ee74,
    0xae67f1e9aec07187, 0xecd8590680a3aa11,
    0xda01ee641a708de9, 0xe80e6f4820cc9495,
    0x884134fe908658b2, 0x3109058d147fdcdd,
    0xaa51823e34a7eede, 0xbd4b46f0599fd415,
    0xd4e5e2cdc1d1ea96, 0x6c9e18ac7007c91a,
    0x850fadc09923329e, 0x3e2cf6bc604ddb0,
    0xa6539930bf6bff45, 0x84db8346b786151c,
    0xcfe87f7cef46ff16, 0xe612641865679a63,
    0x81f14fae158c5f6e, 0x4fcb7e8f3f60c07e,
    0xa26da3999aef7749, 0xe3be5e330f38f09d,
    0xcb090c8001ab551c, 0x5cadf5bfd3072cc5,
    0xfdcb4fa002162a63, 0x73d9732fc7c8f7f6,
    0x9e9f11c4014dda7e, 0x2867e7fddcdd9afa,
    0xc646d63501a1511d, 0xb281e1fd541501b8,
    0xf7d88bc24209a565, 0x1f225a7ca91a4226,
    0x9ae757596946075f, 0x3375788de9b06958,
    0xc1a12d2fc3978937, 0x52d6b1641c83ae,
    0xf209787bb47d6b84, 0xc0678c5dbd23a49a,
    0x9745eb4d50ce6332, 0xf840b7ba963646e0,
    0xbd176620a501fbff, 0xb650e5a93bc3d898,
    0xec5d3fa8ce427aff, 0xa3e51f138ab4cebe,
    0x93ba47c980e98cdf, 0xc66f336c36b10137,
    0xb8a8d9bbe123f017, 0xb80b0047445d4184,
    0xe6d3102ad96cec1d, 0xa60dc059157491e5,
    0x9043ea1ac7e41392, 0x87c89837ad68db2f,
    0xb454e4a179dd1877, 0x29babe4598c311fb,
    0xe16a1dc9d8545e94, 0xf4296dd6fef3d67a,
    0x8ce2529e2734bb1d, 0x1899e4a65f58660c,
    0xb01ae745b101e9e4, 0x5ec05dcff72e7f8f,
    0xdc21a1171d42645d, 0x76707543f4fa1f73,
    0x899504ae72497eba, 0x6a06494a791c53a8,
    0xabfa45da0edbde69, 0x487db9d17636892,
    0xd6f8d7509292d603, 0x45a9d2845d3c42b6,
    0x865b86925b9bc5c2, 0xb8a2392ba45a9b2,
    0xa7f26836f282b732, 0x8e6cac7768d7141e,
    0xd1ef0244af2364ff, 0x3207d795430cd926,
    0x8335616aed761f1f, 0x7f44e6bd49e807b8,
    0xa402b9c5a8d3a6e7, 0x5f16206c9c6209a6,
    0xcd036837130890a1, 0x36dba887c37a8c0f,
    0x802221226be55a64, 0xc2494954da2c9789,
    0xa02aa96b06deb0fd, 0xf2db9baa10b7bd6c,
    0xc83553c5c8965d3d, 0x6f92829494e5acc7,
    0xfa42a8b73abbf48c, 0xcb772339ba1f17f9,
    0x9c69a97284b578d7, 0xff2a760414536efb,
    0xc38413cf25e2d70d, 0xfef5138519684aba,
    0xf46518c2ef5b8cd1, 0x7eb258665fc25d69,
    0x98bf2f79d5993802, 0xef2f773ffbd97a61,
    0xbeeefb584aff8603, 0xaafb550ffacfd8fa,
    0xeeaaba2e5dbf6784, 0x95ba2a53f983cf38,
    0x952ab45cfa97a0b2, 0xdd945a747bf26183,
    0xba756174393d88df, 0x94f971119aeef9e4,
    0xe912b9d1478ceb17, 0x7a37cd5601aab85d,
    0x91abb422ccb812ee, 0xac62e055c10ab33a,
    0xb616a12b7fe617aa, 0x577b986b314d6009,
    0xe39c49765fdf9d94, 0xed5a7e85fda0b80b,
    0x8e41ade9fbebc27d, 0x14588f13be847307,
    0xb1d219647ae6b31c, 0x596eb2d8ae258fc8,
    0xde469fbd99a05fe3, 0x6fca5f8ed9aef3bb,
    0x8aec23d680043bee, 0x25de7bb9480d5854,
    0xada72ccc20054ae9, 0xaf561aa79a10ae6a,
    0xd910f7ff28069da4, 0x1b2ba1518094da04,
    0x87aa9aff79042286, 0x90fb44d2f05d0842,
    0xa99541bf57452b28, 0x353a1607ac744a53,
    0xd3fa922f2d1675f2, 0x42889b8997915ce8,
    0x847c9b5d7c2e09b7, 0x69956135febada11,
    0xa59bc234db398c25, 0x43fab9837e699095,
    0xcf02b2c21207ef2e, 0x94f967e45e03f4bb,
    0x8161afb94b44f57d, 0x1d1be0eebac278f5,
    0xa1ba1ba79e1632dc, 0x6462d92a69731732,
    0xca28a291859bbf93, 0x7d7b8f7503cfdcfe,
    0xfcb2cb35e702af78, 0x5cda735244c3d43e,
    0x9defbf01b061adab, 0x3a0888136afa64a7,
    0xc56baec21c7a1916, 0x88aaa1845b8fdd0,
    0xf6c69a72a3989f5b, 0x8aad549e57273d45,
    0x9a3c2087a63f6399, 0x36ac54e2f678864b,
    0xc0cb28a98fcf3c7f, 0x84576a1bb416a7dd,
    0xf0fdf2d3f3c30b9f, 0x656d44a2a11c51d5,
    0x969eb7c47859e743, 0x9f644ae5a4b1b325,
    0xbc4665b596706114, 0x873d5d9f0dde1fee,
    0xeb57ff22fc0c7959, 0xa90cb506d155a7ea,
    0x9316ff75dd87cbd8, 0x9a7f12442d588f2,
    0xb7dcbf5354e9bece, 0xc11ed6d538aeb2f,
    0xe5d3ef282a242e81, 0x8f1668c8a86da5fa,
    0x8fa475791a569d10, 0xf96e017d694487bc,
    0xb38d92d760ec4455, 0x37c981dcc395a9ac,
    0xe070f78d3927556a, 0x85bbe253f47b1417,
    0x8c469ab843b89562, 0x93956d7478ccec8e,
    0xaf58416654a6babb, 0x387ac8d1970027b2,
    0xdb2e51bfe9d0696a, 0x6997b05fcc0319e,
    0x88fcf317f22241e2, 0x441fece3bdf81f03,
    0xab3c2fddeeaad25a, 0xd527e81cad7626c3,
    0xd60b3bd56a5586f1, 0x8a71e223d8d3b074,
    0x85c7056562757456, 0xf6872d5667844e49,
    0xa738c6bebb12d16c, 0xb428f8ac016561db,
    0xd106f86e69d785c7, 0xe13336d701beba52,
    0x82a45b450226b39c, 0xecc0024661173473,
    0xa34d721642b06084, 0x27f002d7f95d0190,
    0xcc20ce9bd35c78a5, 0x31ec038df7b441f4,
    0xff290242c83396ce, 0x7e67047175a15271,
    0x9f79a169bd203e41, 0xf0062c6e984d386,
    0xc75809c42c684dd1, 0x52c07b78a3e60868,
    0xf92e0c3537826145, 0xa7709a56ccdf8a82,
    0x9bbcc7a142b17ccb, 0x88a66076400bb691,
    0xc2abf989935ddbfe, 0x6acff893d00ea435,
    0xf356f7ebf83552fe, 0x583f6b8c4124d43,
    0x98165af37b2153de, 0xc3727a337a8b704a,
    0xbe1bf1b059e9a8d6, 0x744f18c0592e4c5c,
    0xeda2ee1c7064130c, 0x1162def06f79df73,
    0x9485d4d1c63e8be7, 0x8addcb5645ac2ba8,
    0xb9a74a0637ce2ee1, 0x6d953e2bd7173692,
    0xe8111c87c5c1ba99, 0xc8fa8db6ccdd0437,
    0x910ab1d4db9914a0, 0x1d9c9892400a22a2,
    0xb54d5e4a127f59c8, 0x2503beb6d00cab4b,
    0xe2a0b5dc971f303a, 0x2e44ae64840fd61d,
    0x8da471a9de737e24, 0x5ceaecfed289e5d2,
    0xb10d8e1456105dad, 0x7425a83e872c5f47,
    0xdd50f1996b947518, 0xd12f124e28f77719,
    0x8a5296ffe33cc92f, 0x82bd6b70d99aaa6f,
    0xace73cbfdc0bfb7b, 0x636cc64d1001550b,
    0xd8210befd30efa5a, 0x3c47f7e05401aa4e,
    0x8714a775e3e95c78, 0x65acfaec34810a71,
    0xa8d9d1535ce3b396, 0x7f1839a741a14d0d,
    0xd31045a8341ca07c, 0x1ede48111209a050,
    0x83ea2b892091e44d, 0x934aed0aab460432,
    0xa4e4b66b68b65d60, 0xf81da84d5617853f,
    0xce1de40642e3f4b9, 0x36251260ab9d668e,
    0x80d2ae83e9ce78f3, 0xc1d72b7c6b426019,
    0xa1075a24e4421730, 0xb24cf65b8612f81f,
    0xc94930ae1d529cfc, 0xdee033f26797b627,
    0xfb9b7cd9a4a7443c, 0x169840ef017da3b1,
    0x9d412e0806e88aa5, 0x8e1f289560ee864e,
    0xc491798a08a2ad4e, 0xf1a6f2bab92a27e2,
    0xf5b5d7ec8acb58a2, 0xae10af696774b1db,
    0x9991a6f3d6bf1765, 0xacca6da1e0a8ef29,
    0xbff610b0cc6edd3f, 0x17fd090a58d32af3,
    0xeff394dcff8a948e, 0xddfc4b4cef07f5b0,
    0x95f83d0a1fb69cd9, 0x4abdaf101564f98e,
    0xbb764c4ca7a4440f, 0x9d6d1ad41abe37f1,
    0xea53df5fd18d5513, 0x84c86189216dc5ed,
    0x92746b9be2f8552c, 0x32fd3cf5b4e49bb4,
    0xb7118682dbb66a77, 0x3fbc8c33221dc2a1,
    0xe4d5e82392a40515, 0xfabaf3feaa5334a,
    0x8f05b1163ba6832d, 0x29cb4d87f2a7400e,
    0xb2c71d5bca9023f8, 0x743e20e9ef511012,
    0xdf78e4b2bd342cf6, 0x914da9246b255416,
    0x8bab8eefb6409c1a, 0x1ad089b6c2f7548e,
    0xae9672aba3d0c320, 0xa184ac2473b529b1,
    0xda3c0f568cc4f3e8, 0xc9e5d72d90a2741e,
    0x8865899617fb1871, 0x7e2fa67c7a658892,
    0xaa7eebfb9df9de8d, 0xddbb901b98feeab7,
    0xd51ea6fa85785631, 0x552a74227f3ea565,
    0x8533285c936b35de, 0xd53a88958f87275f,
    0xa67ff273b8460356, 0x8a892abaf368f137,
    0xd01fef10a657842c, 0x2d2b7569b0432d85,
    0x8213f56a67f6b29b, 0x9c3b29620e29fc73,
    0xa298f2c501f45f42, 0x8349f3ba91b47b8f,
    0xcb3f2f7642717713, 0x241c70a936219a73,
    0xfe0efb53d30dd4d7, 0xed238cd383aa0110,
    0x9ec95d1463e8a506, 0xf4363804324a40aa,
    0xc67bb4597ce2ce48, 0xb143c6053edcd0d5,
    0xf81aa16fdc1b81da, 0xdd94b7868e94050a,
    0x9b10a4e5e9913128, 0xca7cf2b4191c8326,
    0xc1d4ce1f63f57d72, 0xfd1c2f611f63a3f0,
    0xf24a01a73cf2dccf, 0xbc633b39673c8cec,
    0x976e41088617ca01, 0xd5be0503e085d813,
    0xbd49d14aa79dbc82, 0x4b2d8644d8a74e18,
    0xec9c459d51852ba2, 0xddf8e7d60ed1219e,
    0x93e1ab8252f33b45, 0xcabb90e5c942b503,
    0xb8da1662e7b00a17, 0x3d6a751f3b936243,
    0xe7109bfba19c0c9d, 0xcc512670a783ad4,
    0x906a617d450187e2, 0x27fb2b80668b24c5,
    0xb484f9dc9641e9da, 0xb1f9f660802dedf6,
    0xe1a63853bbd26451, 0x5e7873f8a0396973,
    0x8d07e33455637eb2, 0xdb0b487b6423e1e8,
    0xb049dc016abc5e5f, 0x91ce1a9a3d2cda62,
    0xdc5c5301c56b75f7, 0x7641a140cc7810fb,
    0x89b9b3e11b6329ba, 0xa9e904c87fcb0a9d,
    0xac2820d9623bf429, 0x546345fa9fbdcd44,
    0xd732290fbacaf133, 0xa97c177947ad4095,
    0x867f59a9d4bed6c0, 0x49ed8eabcccc485d,
    0xa81f301449ee8c70, 0x5c68f256bfff5a74,
    0xd226fc195c6a2f8c, 0x73832eec6fff3111,
    0x83585d8fd9c25db7, 0xc831fd53c5ff7eab,
    0xa42e74f3d032f525, 0xba3e7ca8b77f5e55,
    0xcd3a1230c43fb26f, 0x28ce1bd2e55f35eb,
    0x80444b5e7aa7cf85, 0x7980d163cf5b81b3,
    0xa0555e361951c366, 0xd7e105bcc332621f,
    0xc86ab5c39fa63440, 0x8dd9472bf3fefaa7,
    0xfa856334878fc150, 0xb14f98f6f0feb951,
    0x9c935e00d4b9d8d2, 0x6ed1bf9a569f33d3,
    0xc3b8358109e84f07, 0xa862f80ec4700c8,
    0xf4a642e14c6262c8, 0xcd27bb612758c0fa,
    0x98e7e9cccfbd7dbd, 0x8038d51cb897789c,
    0xbf21e44003acdd2c, 0xe0470a63e6bd56c3,
    0xeeea5d5004981478, 0x1858ccfce06cac74,
    0x95527a5202df0ccb, 0xf37801e0c43ebc8,
    0xbaa718e68396cffd, 0xd30560258f54e6ba,
    0xe950df20247c83fd, 0x47c6b82ef32a2069,
    0x91d28b7416cdd27e, 0x4cdc331d57fa5441,
    0xb6472e511c81471d, 0xe0133fe4adf8e952,
    0xe3d8f9e563a198e5, 0x58180fddd97723a6,
    0x8e679c2f5e44ff8f, 0x570f09eaa7ea7648,
};

using powers = powers_template<>;

// This will compute or rather approximate w * 5**q and return a pair of 64-bit words
// approximating the result, with the high" part corresponding to the most significant
// bits and the low part corresponding to the least significant bits.
//
template <int bit_precision>
WJR_INTRINSIC_INLINE uint128_t compute_product_approximation(int64_t q, uint64_t w) {
    const int index = 2 * int(q - powers::smallest_power_of_five);
    // For small values of q, e.g., q in [0,27], the answer is always exact because
    // The line uint128_t firstproduct = full_multiplication(w, power_of_five_128[index]);
    // gives the exact answer.
    uint128_t firstproduct = mul64x64to128(w, powers::power_of_five_128[index]);
    static_assert((bit_precision >= 0) && (bit_precision <= 64),
                  " precision should  be in (0,64]");
    constexpr uint64_t precision_mask =
        (bit_precision < 64) ? (uint64_t(0xFFFFFFFFFFFFFFFF) >> bit_precision)
                             : uint64_t(0xFFFFFFFFFFFFFFFF);
    if ((firstproduct.high & precision_mask) ==
        precision_mask) { // could further guard with (lower + w < lower)
        // regarding the second product, we only need secondproduct.high, but our
        // expectation is that the compiler will optimize this extra work away if needed.
        const uint128_t secondproduct =
            mul64x64to128(w, powers::power_of_five_128[index + 1]);
        firstproduct.low += secondproduct.high;
        if (secondproduct.high > firstproduct.low) {
            firstproduct.high++;
        }
    }
    return firstproduct;
}

namespace detail {
/**
 * For q in (0,350), we have that
 *  f = (((152170 + 65536) * q ) >> 16);
 * is equal to
 *   floor(p) + q
 * where
 *   p = log(5**q)/log(2) = q * log(5)/log(2)
 *
 * For negative values of q in (-400,0), we have that
 *  f = (((152170 + 65536) * q ) >> 16);
 * is equal to
 *   -ceil(p) + q
 * where
 *   p = log(5**-q)/log(2) = -q * log(5)/log(2)
 */
constexpr WJR_INTRINSIC_INLINE int32_t power(int32_t q) noexcept {
    return (((152170 + 65536) * q) >> 16) + 63;
}
} // namespace detail

// create an adjusted mantissa, biased by the invalid power2
// for significant digits already multiplied by 10 ** q.
template <typename binary>
WJR_INTRINSIC_INLINE adjusted_mantissa compute_error_scaled(int64_t q, uint64_t w,
                                                            int lz) noexcept {
    const int hilz = int(w >> 63) ^ 1;
    adjusted_mantissa answer;
    answer.mantissa = w << hilz;
    const int bias = binary::mantissa_explicit_bits() - binary::minimum_exponent();
    answer.power2 =
        int32_t(detail::power(int32_t(q)) + bias - hilz - lz - 62 + invalid_am_bias);
    return answer;
}

// w * 10 ** q, without rounding the representation up.
// the power2 in the exponent will be adjusted by invalid_am_bias.
template <typename binary>
WJR_INTRINSIC_INLINE adjusted_mantissa compute_error(int64_t q, uint64_t w) noexcept {
    const int lz = clz(w);
    w <<= lz;
    const uint128_t product =
        compute_product_approximation<binary::mantissa_explicit_bits() + 3>(q, w);
    return compute_error_scaled<binary>(q, product.high, lz);
}

// w * 10 ** q
// The returned value should be a valid ieee64 number that simply need to be packed.
// However, in some very rare cases, the computation will fail. In such cases, we
// return an adjusted_mantissa with a negative power of 2: the caller should recompute
// in such cases.
template <typename binary>
WJR_CONST WJR_INTRINSIC_INLINE adjusted_mantissa compute_float(int64_t q,
                                                               uint64_t w) noexcept {
    adjusted_mantissa answer;
    if ((w == 0) || (q < binary::smallest_power_of_ten())) {
        answer.power2 = 0;
        answer.mantissa = 0;
        // result should be zero
        return answer;
    }
    if (q > binary::largest_power_of_ten()) {
        // we want to get infinity:
        answer.power2 = binary::infinite_power();
        answer.mantissa = 0;
        return answer;
    }
    // At this point in time q is in [powers::smallest_power_of_five,
    // powers::largest_power_of_five].

    // We want the most significant bit of i to be 1. Shift if needed.
    const int lz = clz(w);
    w <<= lz;

    // The required precision is binary::mantissa_explicit_bits() + 3 because
    // 1. We need the implicit bit
    // 2. We need an extra bit for rounding purposes
    // 3. We might lose a bit due to the "upperbit" routine (result too small, requiring a
    // shift)

    const uint128_t product =
        compute_product_approximation<binary::mantissa_explicit_bits() + 3>(q, w);
    if (product.low == 0xFFFFFFFFFFFFFFFF) { //  could guard it further
        // In some very rare cases, this could happen, in which case we might need a more
        // accurate computation that what we can provide cheaply. This is very, very
        // unlikely.
        //
        const bool inside_safe_exponent =
            (q >= -27) && (q <= 55); // always good because 5**q <2**128 when q>=0,
        // and otherwise, for q<0, we have 5**-q<2**64 and the 128-bit reciprocal allows
        // for exact computation.
        if (!inside_safe_exponent) {
            return compute_error_scaled<binary>(q, product.high, lz);
        }
    }
    // The "compute_product_approximation" function can be slightly slower than a
    // branchless approach: uint128_t product = compute_product(q, w); but in practice, we
    // can win big with the compute_product_approximation if its additional branch is
    // easily predicted. Which is best is data specific.
    const int upperbit = int(product.high >> 63);

    answer.mantissa =
        product.high >> (upperbit + 64 - binary::mantissa_explicit_bits() - 3);

    answer.power2 =
        int32_t(detail::power(int32_t(q)) + upperbit - lz - binary::minimum_exponent());
    if (answer.power2 <= 0) { // we have a subnormal?
        // Here have that answer.power2 <= 0 so -answer.power2 >= 0
        if (-answer.power2 + 1 >= 64) { // if we have more than 64 bits below the minimum
                                        // exponent, you have a zero for sure.
            answer.power2 = 0;
            answer.mantissa = 0;
            // result should be zero
            return answer;
        }
        // next line is safe because -answer.power2 + 1 < 64
        answer.mantissa >>= -answer.power2 + 1;
        // Thankfully, we can't have both "round-to-even" and subnormals because
        // "round-to-even" only occurs for powers close to 0.
        answer.mantissa += (answer.mantissa & 1); // round up
        answer.mantissa >>= 1;
        // There is a weird scenario where we don't have a subnormal but just.
        // Suppose we start with 2.2250738585072013e-308, we end up
        // with 0x3fffffffffffff x 2^-1023-53 which is technically subnormal
        // whereas 0x40000000000000 x 2^-1023-53  is normal. Now, we need to round
        // up 0x3fffffffffffff x 2^-1023-53  and once we do, we are no longer
        // subnormal, but we can only know this after rounding.
        // So we only declare a subnormal if we are smaller than the threshold.
        answer.power2 =
            (answer.mantissa < (uint64_t(1) << binary::mantissa_explicit_bits())) ? 0 : 1;
        return answer;
    }

    // usually, we round *up*, but if we fall right in between and and we have an
    // even basis, we need to round down
    // We are only concerned with the cases where 5**q fits in single 64-bit word.
    if ((product.low <= 1) && (q >= binary::min_exponent_round_to_even()) &&
        (q <= binary::max_exponent_round_to_even()) &&
        ((answer.mantissa & 3) == 1)) { // we may fall between two floats!
        // To be in-between two floats we need that in doing
        //   answer.mantissa = product.high >> (upperbit + 64 -
        //   binary::mantissa_explicit_bits() - 3);
        // ... we dropped out only zeroes. But if this happened, then we can go back!!!
        if ((answer.mantissa << (upperbit + 64 - binary::mantissa_explicit_bits() - 3)) ==
            product.high) {
            answer.mantissa &= ~uint64_t(1); // flip it so that we do not round up
        }
    }

    answer.mantissa += (answer.mantissa & 1); // round up
    answer.mantissa >>= 1;
    if (answer.mantissa >= (uint64_t(2) << binary::mantissa_explicit_bits())) {
        answer.mantissa = (uint64_t(1) << binary::mantissa_explicit_bits());
        answer.power2++; // undo previous addition
    }

    answer.mantissa &= ~(uint64_t(1) << binary::mantissa_explicit_bits());
    if (answer.power2 >= binary::infinite_power()) { // infinity
        answer.power2 = binary::infinite_power();
        answer.mantissa = 0;
    }
    return answer;
}

/// @brief special case of compute_float when q = 0.
template <typename binary>
WJR_CONST WJR_INTRINSIC_INLINE adjusted_mantissa compute_integer(uint64_t w) noexcept {
    adjusted_mantissa answer;
    // We want the most significant bit of i to be 1. Shift if needed.
    const int lz = clz(w);
    w <<= lz;

    // The required precision is binary::mantissa_explicit_bits() + 3 because
    // 1. We need the implicit bit
    // 2. We need an extra bit for rounding purposes
    // 3. We might lose a bit due to the "upperbit" routine (result too small, requiring a
    // shift)

    const uint128_t product =
        compute_product_approximation<binary::mantissa_explicit_bits() + 3>(0, w);
    // The "compute_product_approximation" function can be slightly slower than a
    // branchless approach: uint128_t product = compute_product(q, w); but in practice, we
    // can win big with the compute_product_approximation if its additional branch is
    // easily predicted. Which is best is data specific.
    const int upperbit = int(product.high >> 63);

    answer.mantissa =
        product.high >> (upperbit + 64 - binary::mantissa_explicit_bits() - 3);

    answer.power2 = int32_t(63 + upperbit - lz - binary::minimum_exponent());
    if (answer.power2 <= 0) { // we have a subnormal?
        // Here have that answer.power2 <= 0 so -answer.power2 >= 0
        if (-answer.power2 + 1 >= 64) { // if we have more than 64 bits below the minimum
                                        // exponent, you have a zero for sure.
            answer.power2 = 0;
            answer.mantissa = 0;
            // result should be zero
            return answer;
        }
        // next line is safe because -answer.power2 + 1 < 64
        answer.mantissa >>= -answer.power2 + 1;
        // Thankfully, we can't have both "round-to-even" and subnormals because
        // "round-to-even" only occurs for powers close to 0.
        answer.mantissa += (answer.mantissa & 1); // round up
        answer.mantissa >>= 1;
        // There is a weird scenario where we don't have a subnormal but just.
        // Suppose we start with 2.2250738585072013e-308, we end up
        // with 0x3fffffffffffff x 2^-1023-53 which is technically subnormal
        // whereas 0x40000000000000 x 2^-1023-53  is normal. Now, we need to round
        // up 0x3fffffffffffff x 2^-1023-53  and once we do, we are no longer
        // subnormal, but we can only know this after rounding.
        // So we only declare a subnormal if we are smaller than the threshold.
        answer.power2 =
            (answer.mantissa < (uint64_t(1) << binary::mantissa_explicit_bits())) ? 0 : 1;
        return answer;
    }

    // usually, we round *up*, but if we fall right in between and and we have an
    // even basis, we need to round down
    // We are only concerned with the cases where 5**q fits in single 64-bit word.
    if (product.low <= 1 &&
        (answer.mantissa & 3) == 1) { // we may fall between two floats!
        // To be in-between two floats we need that in doing
        //   answer.mantissa = product.high >> (upperbit + 64 -
        //   binary::mantissa_explicit_bits() - 3);
        // ... we dropped out only zeroes. But if this happened, then we can go back!!!
        if ((answer.mantissa << (upperbit + 64 - binary::mantissa_explicit_bits() - 3)) ==
            product.high) {
            answer.mantissa &= ~uint64_t(1); // flip it so that we do not round up
        }
    }

    answer.mantissa += (answer.mantissa & 1); // round up
    answer.mantissa >>= 1;
    if (answer.mantissa >= (uint64_t(2) << binary::mantissa_explicit_bits())) {
        answer.mantissa = (uint64_t(1) << binary::mantissa_explicit_bits());
        answer.power2++; // undo previous addition
    }

    answer.mantissa &= ~(uint64_t(1) << binary::mantissa_explicit_bits());
    if (answer.power2 >= binary::infinite_power()) { // infinity
        answer.power2 = binary::infinite_power();
        answer.mantissa = 0;
    }
    return answer;
}

// 1e0 to 1e19
constexpr static uint64_t powers_of_ten_uint64[] = {1UL,
                                                    10UL,
                                                    100UL,
                                                    1000UL,
                                                    10000UL,
                                                    100000UL,
                                                    1000000UL,
                                                    10000000UL,
                                                    100000000UL,
                                                    1000000000UL,
                                                    10000000000UL,
                                                    100000000000UL,
                                                    1000000000000UL,
                                                    10000000000000UL,
                                                    100000000000000UL,
                                                    1000000000000000UL,
                                                    10000000000000000UL,
                                                    100000000000000000UL,
                                                    1000000000000000000UL,
                                                    10000000000000000000UL};

// calculate the exponent, in scientific notation, of the number.
// this algorithm is not even close to optimized, but it has no practical
// effect on performance: in order to have a faster algorithm, we'd need
// to slow down performance for faster algorithms, and this is still fast.
WJR_INTRINSIC_INLINE int32_t scientific_exponent(int64_t exponent,
                                                 uint64_t mantissa) noexcept {
    return int32_t(exponent) + count_digits<10>(mantissa) - 1;
}

// this converts a native floating-point number to an extended-precision float.
template <typename T>
WJR_INTRINSIC_INLINE adjusted_mantissa to_extended(T value) noexcept {
    using equiv_uint = typename binary_format<T>::equiv_uint;
    constexpr equiv_uint exponent_mask = binary_format<T>::exponent_mask();
    constexpr equiv_uint mantissa_mask = binary_format<T>::mantissa_mask();
    constexpr equiv_uint hidden_bit_mask = binary_format<T>::hidden_bit_mask();

    adjusted_mantissa am;
    int32_t bias =
        binary_format<T>::mantissa_explicit_bits() - binary_format<T>::minimum_exponent();
    equiv_uint bits;
    std::memcpy(&bits, &value, sizeof(T));
    if ((bits & exponent_mask) == 0) {
        // denormal
        am.power2 = 1 - bias;
        am.mantissa = bits & mantissa_mask;
    } else {
        // normal
        am.power2 =
            int32_t((bits & exponent_mask) >> binary_format<T>::mantissa_explicit_bits());
        am.power2 -= bias;
        am.mantissa = (bits & mantissa_mask) | hidden_bit_mask;
    }

    return am;
}

// get the extended precision value of the halfway point between b and b+u.
// we are given a native float that represents b, so we need to adjust it
// halfway between b and b+u.
template <typename T>
WJR_INTRINSIC_INLINE adjusted_mantissa to_extended_halfway(T value) noexcept {
    adjusted_mantissa am = to_extended(value);
    am.mantissa <<= 1;
    am.mantissa += 1;
    am.power2 -= 1;
    return am;
}

// round an extended-precision float to the nearest machine float.
template <typename T, typename callback>
WJR_INTRINSIC_INLINE void round(adjusted_mantissa &am, callback cb) noexcept {
    int32_t mantissa_shift = 64 - binary_format<T>::mantissa_explicit_bits() - 1;
    if (-am.power2 >= mantissa_shift) {
        // have a denormal float
        int32_t shift = -am.power2 + 1;
        cb(am, std::min<int32_t>(shift, 64));
        // check for round-up: if rounding-nearest carried us to the hidden bit.
        am.power2 =
            (am.mantissa < (uint64_t(1) << binary_format<T>::mantissa_explicit_bits()))
                ? 0
                : 1;
        return;
    }

    // have a normal float, use the default shift.
    cb(am, mantissa_shift);

    // check for carry
    if (am.mantissa >= (uint64_t(2) << binary_format<T>::mantissa_explicit_bits())) {
        am.mantissa = (uint64_t(1) << binary_format<T>::mantissa_explicit_bits());
        am.power2++;
    }

    // check for infinite: we could have carried to an infinite power
    am.mantissa &= ~(uint64_t(1) << binary_format<T>::mantissa_explicit_bits());
    if (am.power2 >= binary_format<T>::infinite_power()) {
        am.power2 = binary_format<T>::infinite_power();
        am.mantissa = 0;
    }
}

template <typename callback>
WJR_INTRINSIC_INLINE void round_nearest_tie_even(adjusted_mantissa &am, int32_t shift,
                                                 callback cb) noexcept {
    uint64_t mask;
    uint64_t halfway;
    if (shift == 64) {
        mask = UINT64_MAX;
    } else {
        mask = (uint64_t(1) << shift) - 1;
    }
    if (shift == 0) {
        halfway = 0;
    } else {
        halfway = uint64_t(1) << (shift - 1);
    }
    uint64_t truncated_bits = am.mantissa & mask;
    uint64_t is_above = truncated_bits > halfway;
    uint64_t is_halfway = truncated_bits == halfway;

    // shift digits into position
    if (shift == 64) {
        am.mantissa = 0;
    } else {
        am.mantissa >>= shift;
    }
    am.power2 += shift;

    const bool is_odd = (am.mantissa & 1) == 1;
    am.mantissa += uint64_t(cb(is_odd, is_halfway, is_above));
}

WJR_INTRINSIC_INLINE void round_down(adjusted_mantissa &am, int32_t shift) noexcept {
    if (shift == 64) {
        am.mantissa = 0;
    } else {
        am.mantissa >>= shift;
    }
    am.power2 += shift;
}

WJR_INTRINSIC_INLINE void skip_zeros(const char *&first, const char *last) noexcept {
    uint64_t val;
    while (std::distance(first, last) >= 8) {
        val = read_memory<uint64_t>(first, endian::native);
        if (val != 0x3030303030303030) {
            break;
        }
        first += 8;
    }
    while (first != last) {
        if (*first != '0') {
            break;
        }
        first++;
    }
}

// determine if any non-zero digits were truncated.
// all characters must be valid digits.
WJR_INTRINSIC_INLINE bool is_truncated(const char *first, const char *last) noexcept {
    // do 8-bit optimizations, can just compare to 8 literal 0s.
    uint64_t val;
    while (std::distance(first, last) >= 8) {
        val = read_memory<uint64_t>(first, endian::native);
        if (val != 0x3030303030303030) {
            return true;
        }
        first += 8;
    }
    while (first != last) {
        if (*first != '0') {
            return true;
        }
        first++;
    }
    return false;
}

WJR_INTRINSIC_INLINE bool is_truncated(span<const char> s) noexcept {
    return is_truncated(s.begin_unsafe(), s.end_unsafe());
}

WJR_INTRINSIC_INLINE void parse_eight_digits(const char *&p, uint64_t &value,
                                             size_t &counter, size_t &count) noexcept {
    value = value * 100000000 + parse_eight_digits_unrolled(p);
    p += 8;
    counter += 8;
    count += 8;
}

WJR_INTRINSIC_INLINE void parse_one_digit(const char *&p, uint64_t &value,
                                          size_t &counter, size_t &count) noexcept {
    value = value * 10 + uint64_t(*p - '0');
    p++;
    counter++;
    count++;
}

WJR_INTRINSIC_INLINE void add_native(biginteger &big, uint64_t power,
                                     uint64_t value) noexcept {
    big *= power;
    big += value;
}

WJR_INTRINSIC_INLINE void round_up_bigint(biginteger &big, size_t &count) noexcept {
    // need to round-up the digits, but need to avoid rounding
    // ....9999 to ...10000, which could cause a false halfway point.
    add_native(big, 10, 1);
    count++;
}

WJR_INTRINSIC_INLINE void pow5(biginteger &big, uint32_t exp) noexcept {
    static constexpr uint32_t large_step = 135;
    static constexpr uint64_t small_power_of_5[] = {
        1UL,
        5UL,
        25UL,
        125UL,
        625UL,
        3125UL,
        15625UL,
        78125UL,
        390625UL,
        1953125UL,
        9765625UL,
        48828125UL,
        244140625UL,
        1220703125UL,
        6103515625UL,
        30517578125UL,
        152587890625UL,
        762939453125UL,
        3814697265625UL,
        19073486328125UL,
        95367431640625UL,
        476837158203125UL,
        2384185791015625UL,
        11920928955078125UL,
        59604644775390625UL,
        298023223876953125UL,
        1490116119384765625UL,
        7450580596923828125UL,
    };

    constexpr static uint64_t large_power_of_5[] = {
        1414648277510068013UL, 9180637584431281687UL, 4539964771860779200UL,
        10482974169319127550UL, 198276706040285095UL};

    const auto large = make_biginteger_data(
        span<const uint64_t>(large_power_of_5, std::size(large_power_of_5)));

    while (exp >= large_step) {
        big *= large;
        exp -= large_step;
    }

    constexpr uint32_t small_step = 27;
    constexpr uint64_t max_native = 7450580596923828125UL;

    while (exp >= small_step) {
        big *= max_native;
        exp -= small_step;
    }

    if (exp != 0) {
        big *= small_power_of_5[exp];
    }
}

WJR_INTRINSIC_INLINE void pow2(biginteger &big, uint32_t exp) noexcept {
    mul_2exp(big, big, exp);
}

WJR_INTRINSIC_INLINE void pow10(biginteger &big, uint32_t exp) noexcept {
    pow5(big, exp);
    pow2(big, exp);
}

WJR_INTRINSIC_INLINE uint64_t empty_hi64(bool &truncated) noexcept {
    truncated = false;
    return 0;
}

WJR_INTRINSIC_INLINE uint64_t uint64_hi64(uint64_t r0, bool &truncated) noexcept {
    truncated = false;
    int shl = clz(r0);
    return r0 << shl;
}

WJR_INTRINSIC_INLINE uint64_t uint64_hi64(uint64_t r0, uint64_t r1,
                                          bool &truncated) noexcept {
    int shl = clz(r0);
    if (shl == 0) {
        truncated = r1 != 0;
        return r0;
    } else {
        int shr = 64 - shl;
        truncated = (r1 << shl) != 0;
        return (r0 << shl) | (r1 >> shr);
    }
}

// get the high 64 bits from the vector, and if bits were truncated.
// this is to get the significant digits for the float.
WJR_INTRINSIC_INLINE uint64_t hi64(biginteger &big, bool &truncated) noexcept {
    const auto n = big.size();
    if (n == 0) {
        return empty_hi64(truncated);
    }
    if (n == 1) {
        return uint64_hi64(big.back(), truncated);
    }

    uint64_t result = uint64_hi64(big.rbegin()[0], big.rbegin()[1], truncated);
    truncated |= reverse_find_not_n(big.data(), 0, n - 2) != 0;
    return result;
}

// parse the significant digits into a big integer
template <typename T>
inline void parse_mantissa(biginteger &result, span<const char> integer,
                           span<const char> fraction, size_t &digits) noexcept {
    constexpr size_t max_digits = binary_format<T>::max_digits();

    // try to minimize the number of big integer and scalar multiplication.
    // therefore, try to parse 8 digits at a time, and multiply by the largest
    // scalar value (9 or 19 digits) for each step.
    size_t counter = 0;
    digits = 0;
    uint64_t value = 0;
    size_t step = 19;

    // process all integer digits.
    const char *p = integer.data();
    const char *pend = p + integer.size();
    skip_zeros(p, pend);
    // process all digits, in increments of step per loop
    while (p != pend) {
        while ((std::distance(p, pend) >= 8) && (step - counter >= 8) &&
               (max_digits - digits >= 8)) {
            parse_eight_digits(p, value, counter, digits);
        }
        while (counter < step && p != pend && digits < max_digits) {
            parse_one_digit(p, value, counter, digits);
        }
        if (digits == max_digits) {
            // add the temporary value, then check if we've truncated any digits
            add_native(result, uint64_t(powers_of_ten_uint64[counter]), value);
            bool truncated = is_truncated(p, pend);
            if (fraction.data() != nullptr) {
                truncated |= is_truncated(fraction);
            }
            if (truncated) {
                round_up_bigint(result, digits);
            }
            return;
        } else {
            add_native(result, uint64_t(powers_of_ten_uint64[counter]), value);
            counter = 0;
            value = 0;
        }
    }

    // add our fraction digits, if they're available.
    if (fraction.data() != nullptr) {
        p = fraction.data();
        pend = p + fraction.size();
        if (digits == 0) {
            skip_zeros(p, pend);
        }
        // process all digits, in increments of step per loop
        while (p != pend) {
            while ((std::distance(p, pend) >= 8) && (step - counter >= 8) &&
                   (max_digits - digits >= 8)) {
                parse_eight_digits(p, value, counter, digits);
            }
            while (counter < step && p != pend && digits < max_digits) {
                parse_one_digit(p, value, counter, digits);
            }
            if (digits == max_digits) {
                // add the temporary value, then check if we've truncated any digits
                add_native(result, uint64_t(powers_of_ten_uint64[counter]), value);
                bool truncated = is_truncated(p, pend);
                if (truncated) {
                    round_up_bigint(result, digits);
                }
                return;
            } else {
                add_native(result, uint64_t(powers_of_ten_uint64[counter]), value);
                counter = 0;
                value = 0;
            }
        }
    }

    if (counter != 0) {
        add_native(result, uint64_t(powers_of_ten_uint64[counter]), value);
    }
}

template <typename T>
inline adjusted_mantissa positive_digit_comp(biginteger &bigmant,
                                             int32_t exponent) noexcept {
    pow10(bigmant, static_cast<uint32_t>(exponent));
    adjusted_mantissa answer;
    bool truncated;
    answer.mantissa = hi64(bigmant, truncated);
    int bias =
        binary_format<T>::mantissa_explicit_bits() - binary_format<T>::minimum_exponent();
    answer.power2 = bit_width(bigmant) - 64 + bias;

    round<T>(answer, [truncated](adjusted_mantissa &a, int32_t shift) {
        round_nearest_tie_even(
            a, shift, [truncated](bool is_odd, bool is_halfway, bool is_above) -> bool {
                return is_above || (is_halfway && truncated) || (is_odd && is_halfway);
            });
    });

    return answer;
}

// the scaling here is quite simple: we have, for the real digits `m * 10^e`,
// and for the theoretical digits `n * 2^f`. Since `e` is always negative,
// to scale them identically, we do `n * 2^f * 5^-f`, so we now have `m * 2^e`.
// we then need to scale by `2^(f- e)`, and then the two significant digits
// are of the same magnitude.
template <typename T>
inline adjusted_mantissa negative_digit_comp(biginteger &bigmant, adjusted_mantissa am,
                                             int32_t exponent) noexcept {
    biginteger &real_digits = bigmant;
    int32_t real_exp = exponent;

    // get the value of `b`, rounded down, and get a biginteger representation of b+h
    adjusted_mantissa am_b = am;
    // gcc7 buf: use a lambda to remove the noexcept qualifier bug with
    // -Wnoexcept-type.
    round<T>(am_b, [](adjusted_mantissa &a, int32_t shift) { round_down(a, shift); });
    T b;
    to_float(false, am_b, b);
    adjusted_mantissa theor = to_extended_halfway(b);
    biginteger theor_digits(theor.mantissa);
    int32_t theor_exp = theor.power2;

    // scale real digits and theor digits to be same power.
    int32_t pow2_exp = theor_exp - real_exp;
    uint32_t pow5_exp = uint32_t(-real_exp);
    if (pow5_exp != 0) {
        pow5(theor_digits, pow5_exp);
    }
    if (pow2_exp > 0) {
        pow2(theor_digits, static_cast<uint32_t>(pow2_exp));
    } else if (pow2_exp < 0) {
        pow2(real_digits, static_cast<uint32_t>(-pow2_exp));
    }

    // compare digits, and use it to director rounding
    int ord = compare(real_digits, theor_digits);
    adjusted_mantissa answer = am;
    round<T>(answer, [ord](adjusted_mantissa &a, int32_t shift) {
        round_nearest_tie_even(a, shift, [ord](bool is_odd, bool _, bool __) -> bool {
            (void)_;  // not needed, since we've done our comparison
            (void)__; // not needed, since we've done our comparison
            if (ord > 0) {
                return true;
            } else if (ord < 0) {
                return false;
            } else {
                return is_odd;
            }
        });
    });

    return answer;
}

template <typename T>
inline adjusted_mantissa digit_comp(adjusted_mantissa am, span<const char> integer,
                                    span<const char> fraction, int32_t sci_exp) {
    size_t digits = 0;
    biginteger bigmant;
    parse_mantissa<T>(bigmant, integer, fraction, digits);
    int32_t exponent = sci_exp + 1 - int32_t(digits);
    if (exponent >= 0) {
        return positive_digit_comp<T>(bigmant, exponent);
    } else {
        return negative_digit_comp<T>(bigmant, am, exponent);
    }
}

namespace detail {
/**
 * Special case +inf, -inf, nan, infinity, -infinity.
 * The case comparisons could be made much faster given that we know that the
 * strings a null-free and fixed.
 **/
template <typename T>
from_chars_result<> parse_infnan(const char *first, const char *last, T &value) noexcept {
    from_chars_result<> answer;
    answer.ptr = first;
    answer.ec = std::errc(); // be optimistic
    bool minusSign = false;
    if (*first == '-') {     // assume first < last, so dereference without checks;
                             // C++17 20.19.3.(7.1) explicitly forbids '+' here
        minusSign = true;
        ++first;
    }
    if (last - first >= 3) {
        if (fastfloat_strncasecmp(first, "nan", 3)) {
            answer.ptr = (first += 3);
            value = minusSign ? -std::numeric_limits<T>::quiet_NaN()
                              : std::numeric_limits<T>::quiet_NaN();
            // Check for possible nan(n-char-seq-opt), C++17 20.19.3.7,
            // C11 7.20.1.3.3. At least MSVC produces nan(ind) and nan(snan).
            if (first != last && *first == '(') {
                for (const char *ptr = first + 1; ptr != last; ++ptr) {
                    if (*ptr == ')') {
                        answer.ptr = ptr + 1; // valid nan(n-char-seq-opt)
                        break;
                    } else if (!(('a' <= *ptr && *ptr <= 'z') ||
                                 ('A' <= *ptr && *ptr <= 'Z') ||
                                 ('0' <= *ptr && *ptr <= '9') || *ptr == '_'))
                        break; // forbidden char, not nan(n-char-seq-opt)
                }
            }
            return answer;
        }
        if (fastfloat_strncasecmp(first, "inf", 3)) {
            if ((last - first >= 8) && fastfloat_strncasecmp(first + 3, "inity", 5)) {
                answer.ptr = first + 8;
            } else {
                answer.ptr = first + 3;
            }
            value = minusSign ? -std::numeric_limits<T>::infinity()
                              : std::numeric_limits<T>::infinity();
            return answer;
        }
    }
    answer.ec = std::errc::invalid_argument;
    return answer;
}

/**
 * Returns true if the floating-pointing rounding mode is to 'nearest'.
 * It is the default on most system. This function is meant to be inexpensive.
 * Credit : @mwalcott3
 */
WJR_INTRINSIC_INLINE bool rounds_to_nearest() noexcept {
    // https://lemire.me/blog/2020/06/26/gcc-not-nearest/
#if (FLT_EVAL_METHOD != 1) && (FLT_EVAL_METHOD != 0)
    return false;
#endif
    // See
    // A fast function to check your floating-point rounding mode
    // https://lemire.me/blog/2022/11/16/a-fast-function-to-check-your-floating-point-rounding-mode/
    //
    // This function is meant to be equivalent to :
    // prior: #include <cfenv>
    //  return fegetround() == FE_TONEAREST;
    // However, it is expected to be much faster than the fegetround()
    // function call.
    //
    // The volatile keywoard prevents the compiler from computing the function
    // at compile-time.
    // There might be other ways to prevent compile-time optimizations (e.g., asm).
    // The value does not need to be std::numeric_limits<float>::min(), any small
    // value so that 1 + x should round to 1 would do (after accounting for excess
    // precision, as in 387 instructions).
    static volatile float fmin = std::numeric_limits<float>::min();
    float fmini = fmin; // we copy it so that it gets loaded at most once.
//
// Explanation:
// Only when fegetround() == FE_TONEAREST do we have that
// fmin + 1.0f == 1.0f - fmin.
//
// FE_UPWARD:
//  fmin + 1.0f > 1
//  1.0f - fmin == 1
//
// FE_DOWNWARD or  FE_TOWARDZERO:
//  fmin + 1.0f == 1
//  1.0f - fmin < 1
//
// Note: This may fail to be accurate if fast-math has been
// enabled, as rounding conventions may not apply.
#ifdef WJR_COMPILER_MSVC
#pragma warning(push)
//  todo: is there a VS warning?
//  see
//  https://stackoverflow.com/questions/46079446/is-there-a-warning-for-floating-point-equality-checking-in-visual-studio-2013
#elif defined(__clang__)
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wfloat-equal"
#elif defined(__GNUC__)
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wfloat-equal"
#endif
    return (fmini + 1.0f == 1.0f - fmini);
#ifdef WJR_COMPILER_MSVC
#pragma warning(pop)
#elif defined(__clang__)
#pragma clang diagnostic pop
#elif defined(__GNUC__)
#pragma GCC diagnostic pop
#endif
}

} // namespace detail

struct parsed_number_string {
    int64_t exponent{0};
    bool negative{false};
    // contains the range of the significant digits
    span<const char> integer{};  // non-nullable
    span<const char> fraction{}; // nullable
};

template <typename Writer, typename Op>
from_chars_result<> __from_chars_impl(const char *first, const char *last, Writer wr,
                                      Op options) noexcept {
    static_assert(!std::is_reference_v<Writer>, "");

    using T = typename Writer::float_type;
    constexpr bool is_support_integral = Writer::support_integral::value;
    constexpr bool is_constant_options = !std::is_same_v<Op, chars_format>;

    from_chars_result<> answer;

    if (WJR_UNLIKELY(first == last)) {
        answer.ec = std::errc::invalid_argument;
        answer.ptr = first;
        return answer;
    }

    const char *p = first;
    const auto fmt = to_underlying(static_cast<chars_format>(options));

    parsed_number_string pns;
    pns.negative = (*p == '-');

    if (*p == '-') { // C++17 20.19.3.(7.1) explicitly forbids '+' sign here
        if (++p == last) {
            answer.ec = std::errc{};
            answer.ptr = first;
            return answer;
        }
    }

    const char *const start_digits = p;
    uint64_t uval = 0; // an unsigned int avoids signed overflows (which are bad)

    const char *end_of_integer_part;
    int64_t digit_count;
    int64_t exponent;
    int64_t exp_number; // explicit exponential part

    constexpr auto __try_match = [](uint8_t &ch) {
        ch -= '0';
        return ch < 10;
    };

    do {
        uint8_t ch = *p;
        if (!__try_match(ch)) { // This situation rarely occurs
            if constexpr (is_constant_options) {
                if (fmt & to_underlying(chars_format::__json_format)) {
                    answer.ec = std::errc{};
                    answer.ptr = first;
                    return answer;
                }
            }

            break;
        }

        do {
            // a multiplication by 10 is cheaper than an arbitrary integer
            // multiplication
            uval = 10 * uval + ch; // might overflow, we will handle the overflow later

            if (++p == last) {
                goto INTEGER_AT_END;
            }

            ch = *p;
        } while (WJR_LIKELY(__try_match(ch)));
    } while (0);

    do {
        end_of_integer_part = p;
        digit_count = static_cast<int64_t>(p - start_digits);
        pns.integer = span<const char>(start_digits, static_cast<size_t>(digit_count));

        if constexpr (is_constant_options) {
            if (fmt & to_underlying(chars_format::__json_format)) {
                // at least 1 digit in integer part, without leading zeros
                if (digit_count == 0 || (start_digits[0] == '0' && digit_count > 1)) {
                    return answer;
                }
            }
        }

        if (*p != '.') {
            exponent = 0;
            if (*p == 'e' || *p == 'E') {
                break;
            }

            goto INTEGER;
        }

        ++p;
        const char *before = p;
        // can occur at most twice without overflowing, but let it occur more, since
        // for integers with many digits, digit parsing is the primary bottleneck.
        while ((std::distance(p, last) >= 8) && is_made_of_eight_digits_fast(p)) {
            uval = uval * 100000000 +
                   parse_eight_digits_unrolled(
                       p); // in rare cases, this will overflow, but that's ok
            p += 8;
        }

        while ((p != last) && is_integer(*p)) {
            const auto digit = uint32_t(*p - '0');
            ++p;
            uval = uval * 10 + digit; // in rare cases, this will overflow, but that's ok
        }

        exponent = before - p;
        pns.fraction = span<const char>(before, size_t(p - before));
        digit_count -= exponent;

        auto &float_v = wr.get_float();
        if constexpr (is_constant_options) {
            if (fmt & to_underlying(chars_format::__json_format)) {
                if (WJR_UNLIKELY(exponent == 0)) {
                    return detail::parse_infnan(first, last, float_v);
                }
            } else {
                if (WJR_UNLIKELY(digit_count == 0)) {
                    return detail::parse_infnan(first, last, float_v);
                }
            }
        } else {
            if (WJR_UNLIKELY(digit_count == 0)) {
                return detail::parse_infnan(first, last, float_v);
            }
        }
    } while (0);

    exp_number = 0;

    if (bool(fmt & to_underlying(chars_format::scientific)) && (p != last) &&
        (('e' == *p) || ('E' == *p))) {
        const char *location_of_e = p;
        ++p;
        bool neg_exp = false;
        if ((p != last) && ('-' == *p)) {
            neg_exp = true;
            ++p;
        } else if ((p != last) &&
                   ('+' == *p)) { // '+' on exponent is allowed by C++17 20.19.3.(7.1)
            ++p;
        }
        if ((p == last) || !is_integer(*p)) {
            if (!bool(fmt & to_underlying(chars_format::fixed))) {
                // We are in error.
                return detail::parse_infnan(first, last, wr.get_float());
            }
            // Otherwise, we will be ignoring the 'e'.
            p = location_of_e;
        } else {
            while ((p != last) && is_integer(*p)) {
                const auto digit = uint32_t(*p - '0');
                if (exp_number < 0x10000000) {
                    exp_number = 10 * exp_number + digit;
                }
                ++p;
            }
            if (neg_exp) {
                exp_number = -exp_number;
            }
            exponent += exp_number;
        }
    } else {
        // If it scientific and not fixed, we have to bail out.
        if (bool(fmt & to_underlying(chars_format::scientific)) &&
            !bool(fmt & to_underlying(chars_format::fixed))) {
            return detail::parse_infnan(first, last, wr.get_float());
        }
    }

    do {
        answer.ec = std::errc(); // be optimistic
        answer.ptr = p;
        bool too_many_digits = false;

        // If we frequently had to deal with long strings of digits,
        // we could extend our code by using a 128-bit integer instead
        // of a 64-bit integer. However, this is uncommon.
        //
        // We can deal with up to 19 digits.
        if (digit_count > 19) { // this is uncommon
            // It is possible that the integer had an overflow.
            // We have to handle the case where we have 0.0000somenumber.
            // We need to be mindful of the case where we only have zeroes...
            // E.g., 0.000000000...000.
            const char *start = start_digits;
            while ((start != last) && (*start == '0' || *start == '.')) {
                if (*start == '0') {
                    digit_count--;
                }
                start++;
            }

            if (digit_count > 19) {
                too_many_digits = true;
                // Let us start again, this time, avoiding overflows.
                // We don't need to check if is_integer, since we use the
                // pre-tokenized spans from above.
                uval = 0;
                p = pns.integer.data();
                const char *int_end = p + pns.integer.size();
                constexpr uint64_t minimal_nineteen_digit_integer =
                    1000000000000000000ull;
                while ((uval < minimal_nineteen_digit_integer) && (p != int_end)) {
                    uval = uval * 10 + uint64_t(*p - '0');
                    ++p;
                }
                if (uval >= minimal_nineteen_digit_integer) { // We have a big integers
                    exponent = end_of_integer_part - p + exp_number;
                } else { // We have a value with a fractional component.
                    p = pns.fraction.data();
                    const char *frac_end = p + pns.fraction.size();
                    while ((uval < minimal_nineteen_digit_integer) && (p != frac_end)) {
                        uval = uval * 10 + uint64_t(*p - '0');
                        ++p;
                    }
                    exponent = pns.fraction.data() - p + exp_number;
                }
                // We have now corrected both exponent and uval, to a truncated value
            }
        }

        pns.exponent = exponent;

        T &float_v = wr.get_float();

        // The implementation of the Clinger's fast path is convoluted because
        // we want round-to-nearest in all cases, irrespective of the rounding mode
        // selected on the thread.
        // We proceed optimistically, assuming that detail::rounds_to_nearest()
        // returns true.
        if (binary_format<T>::min_exponent_fast_path() <= pns.exponent &&
            pns.exponent <= binary_format<T>::max_exponent_fast_path() &&
            !too_many_digits) {
            // Unfortunately, the conventional Clinger's fast path is only possible
            // when the system rounds to the nearest float.
            //
            // We expect the next branch to almost always be selected.
            // We could check it first (before the previous branch), but
            // there might be performance advantages at having the check
            // be last.
            if (detail::rounds_to_nearest()) {
                // We have that fegetround() == FE_TONEAREST.
                // Next is Clinger's fast path.
                if (uval <= binary_format<T>::max_mantissa_fast_path()) {
                    float_v = T(uval);
                    if (pns.exponent < 0) {
                        float_v =
                            float_v / binary_format<T>::exact_power_of_ten(-pns.exponent);
                    } else {
                        float_v =
                            float_v * binary_format<T>::exact_power_of_ten(pns.exponent);
                    }
                    if (pns.negative) {
                        float_v = -float_v;
                    }
                    return answer;
                }
            } else {
                // We do not have that fegetround() == FE_TONEAREST.
                // Next is a modified Clinger's fast path, inspired by Jakub Jelnek's
                // proposal
                if (pns.exponent >= 0 &&
                    uval <= binary_format<T>::max_mantissa_fast_path(pns.exponent)) {
#if defined(__clang__)
                    // ClangCL may map 0 to -0.0 when fegetround() == FE_DOWNWARD
                    if (uval == 0) {
                        float_v = pns.negative ? T(-0.) : T(0.);
                        return answer;
                    }
#endif
                    float_v =
                        T(uval) * binary_format<T>::exact_power_of_ten(pns.exponent);
                    if (pns.negative) {
                        float_v = -float_v;
                    }
                    return answer;
                }
            }
        }

        adjusted_mantissa am = compute_float<binary_format<T>>(pns.exponent, uval);
        if (too_many_digits && am.power2 >= 0) {
            if (am != compute_float<binary_format<T>>(pns.exponent, uval + 1)) {
                am = compute_error<binary_format<T>>(pns.exponent, uval);
            }
        }

        // If we called compute_float<binary_format<T>>(pns.exponent, uval)
        // and we have an invalid power (am.power2 < 0), then we need to go the long
        // way around again. This is very uncommon.
        if (am.power2 < 0) {
            am.power2 -= invalid_am_bias;

            const int32_t sci_exp = scientific_exponent(pns.exponent, uval);
            am = digit_comp<T>(am, pns.integer, pns.fraction, sci_exp);
        }

        to_float(pns.negative, am, float_v);
        // Test for over/underflow.
        if ((uval != 0 && am.mantissa == 0 && am.power2 == 0) ||
            am.power2 == binary_format<T>::infinite_power()) {
            answer.ec = std::errc::result_out_of_range;
        }

        return answer;
    } while (0);

INTEGER_AT_END:
    end_of_integer_part = p;
    digit_count = static_cast<int64_t>(p - start_digits);
    pns.integer = span<const char>(start_digits, static_cast<size_t>(digit_count));

    if constexpr (is_constant_options) {
        if (fmt & to_underlying(chars_format::__json_format)) {
            // at least 1 digit in integer part, without leading zeros
            if (digit_count == 0 || (start_digits[0] == '0' && digit_count > 1)) {
                return answer;
            }
        }
    }

INTEGER:
    answer.ec = std::errc(); // be optimistic
    answer.ptr = p;

    // If we frequently had to deal with long strings of digits,
    // we could extend our code by using a 128-bit integer instead
    // of a 64-bit integer. However, this is uncommon.
    //
    // We can deal with up to 19 digits.
    if (digit_count > 19) { // this is uncommon
        // It is possible that the integer had an overflow.
        // We have to handle the case where we have 0.0000somenumber.
        // We need to be mindful of the case where we only have zeroes...
        // E.g., 0.000000000...000.
        const char *start = start_digits;
        while ((start != last) && *start == '0') {
            --digit_count;
            start++;
        }

        if (digit_count > 19) {
            p = start;

            uval = __from_chars_unroll_16<10>(reinterpret_cast<const uint8_t *>(p),
                                              char_converter);
            p += 16;
            uval = uval * 10 + char_converter.template from<10>(*p++);
            uval = uval * 10 + char_converter.template from<10>(*p++);
            uval = uval * 10 + char_converter.template from<10>(*p++);

            exponent = end_of_integer_part - p;
            pns.exponent = exponent;

            WJR_ASSUME(exponent >= 0);

            if constexpr (is_support_integral) {
                constexpr uint64_t max_quot = std::numeric_limits<uint64_t>::max() / 10;
                constexpr uint32_t max_rem = std::numeric_limits<uint64_t>::max() % 10;

                if (!pns.negative && digit_count == 20 &&
                    (uval < max_quot ||
                     (uval == max_quot && static_cast<uint32_t>(*p - '0') <= max_rem))) {
                    uint64_t &u64_v = wr.get_u64();
                    u64_v = uval;
                    return answer;
                }
            }

            T &float_v = wr.get_float();

            adjusted_mantissa am = compute_float<binary_format<T>>(pns.exponent, uval);
            if (am.power2 >= 0) {
                if (am != compute_float<binary_format<T>>(pns.exponent, uval + 1)) {
                    am = compute_error<binary_format<T>>(pns.exponent, uval);
                }
            }

            // If we called compute_float<binary_format<T>>(pns.exponent,
            // uval) and we have an invalid power (am.power2 < 0), then we
            // need to go the long way around again. This is very uncommon.
            if (am.power2 < 0) {
                am.power2 -= invalid_am_bias;

                const int32_t sci_exp = scientific_exponent(pns.exponent, uval);
                am = digit_comp<T>(am, pns.integer, pns.fraction, sci_exp);
            }

            to_float(pns.negative, am, float_v);
            // Test for over/underflow.
            if ((uval != 0 && am.mantissa == 0 && am.power2 == 0) ||
                am.power2 == binary_format<T>::infinite_power()) {
                answer.ec = std::errc::result_out_of_range;
            }

            return answer;
        }
    }

    pns.exponent = 0;

    if constexpr (is_support_integral) {
        if (!pns.negative) {
            uint64_t &u64_v = wr.get_u64();
            u64_v = uval;
            return answer;
        } else if (uval <= static_cast<uint64_t>(-std::numeric_limits<int64_t>::min())) {
            int64_t &i64_v = wr.get_i64();
            i64_v = static_cast<int64_t>(-uval);
            return answer;
        }
    }

    auto &float_v = wr.get_float();

    if (WJR_LIKELY(uval <= binary_format<T>::max_mantissa_fast_path())) {
#if defined(__clang__)
        // ClangCL may map 0 to -0.0 when fegetround() == FE_DOWNWARD
        if (uval == 0) {
            float_v = pns.negative ? T(-0.) : T(0.);
            return answer;
        }
#endif

        float_v = T(uval);
        if (pns.negative) {
            float_v = -float_v;
        }

        return answer;
    }

    adjusted_mantissa am = compute_integer<binary_format<T>>(uval);
    WJR_ASSERT_ASSUME(am.power2 >= 0);

    to_float(pns.negative, am, float_v);
    // Test for over/underflow.
    if ((uval != 0 && am.mantissa == 0 && am.power2 == 0) ||
        am.power2 == binary_format<T>::infinite_power()) {
        answer.ec = std::errc::result_out_of_range;
    }

    return answer;
}

} // namespace wjr::fastfloat

namespace wjr {
using fastfloat::from_chars;
}

#endif // WJR_FORMAT_FASTFLOAT_HPP__